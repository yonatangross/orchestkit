/**
 * Configuration for TriTerminalRace demo
 * Showcasing the /ork:add-golden skill at 3 difficulty levels
 */

import type { z } from "zod";
import type { triTerminalRaceSchema } from "../TriTerminalRace";

export const addGoldenDemoConfig: z.infer<typeof triTerminalRaceSchema> = {
  skillName: "add-golden",
  skillCommand: "/ork:add-golden",
  hook: "Curate your training data gold standard",
  primaryColor: "#f59e0b",
  secondaryColor: "#22c55e",
  accentColor: "#8b5cf6",

  phases: [
    { name: "Analyze Input", shortName: "Analyze" },
    { name: "Validate Quality", shortName: "Validate" },
    { name: "Extract Features", shortName: "Extract" },
    { name: "Add to Dataset", shortName: "Store" },
  ],

  // SIMPLE LEVEL - Add single example
  simple: {
    name: "Simple",
    description: "add API response example",
    inputCount: 1,
    files: [
      {
        name: "data/golden/",
        status: "completed",
        children: [
          { name: "api-responses.jsonl", status: "completed", lines: 45 },
        ],
      },
    ],
    references: [
      { name: "golden-dataset-curation", status: "loaded", category: "data" },
      { name: "quality-validation", status: "loaded", category: "qa" },
    ],
    claudeResponse: [
      "Adding to golden dataset:",
      "",
      "â€¢ Input: 1 example",
      "â€¢ Format: API response",
      "â€¢ Quality: Validated",
      "â€¢ Dataset: api-responses",
    ],
    codeSnippet: `GOLDEN DATASET UPDATED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dataset: api-responses.jsonl

New Example Added:
â”Œâ”€ Input
â”‚  POST /api/users
â”‚  {"name": "Alice", "email": "alice@example.com"}
â”‚
â”œâ”€ Expected Output
â”‚  {"id": "usr_123", "name": "Alice", "status": "created"}
â”‚
â”œâ”€ Metadata
â”‚  âœ“ Category: user-management
â”‚  âœ“ Tags: [create, validation, success]
â”‚  âœ“ Difficulty: simple
â”‚  âœ“ Source: production-logs
â”‚
â””â”€ Quality Checks
   âœ“ Schema valid
   âœ“ No PII detected
   âœ“ Deterministic output
   âœ“ Unique (no duplicates)

Dataset Stats:
â”œâ”€ Total examples: 46
â”œâ”€ Coverage: user-management 100%
â””â”€ Quality score: 9.8/10`,
    completionTime: "3s",
    metrics: {
      Examples: "1",
      Dataset: "api-responses",
      Quality: "9.8/10",
    },
  },

  // MEDIUM LEVEL - Add batch with validation
  medium: {
    name: "Medium",
    description: "add error handling examples",
    inputCount: 12,
    files: [
      {
        name: "data/golden/",
        status: "completed",
        children: [
          { name: "error-responses.jsonl", status: "completed", lines: 156 },
          { name: "validation-errors.jsonl", status: "completed", lines: 89 },
          { name: "edge-cases.jsonl", status: "writing", lines: 67 },
        ],
      },
    ],
    references: [
      { name: "golden-dataset-curation", status: "loaded", category: "data" },
      { name: "error-taxonomy", status: "loaded", category: "validation" },
      { name: "edge-case-detection", status: "loading", category: "testing" },
    ],
    claudeResponse: [
      "Adding error handling examples:",
      "",
      "â€¢ Input: 12 examples",
      "â€¢ Validated: 11 passed",
      "â€¢ Rejected: 1 (duplicate)",
      "â€¢ Categories: 4 error types",
      "â€¢ Coverage improved: +15%",
    ],
    codeSnippet: `GOLDEN DATASET UPDATED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Batch: error-handling-examples

Processing Results:
â”Œâ”€ Accepted (11 examples)
â”‚  â”œâ”€ 400 Bad Request (3)
â”‚  â”‚   âœ“ Missing required field
â”‚  â”‚   âœ“ Invalid email format
â”‚  â”‚   âœ“ Exceeds max length
â”‚  â”‚
â”‚  â”œâ”€ 401 Unauthorized (2)
â”‚  â”‚   âœ“ Expired token
â”‚  â”‚   âœ“ Invalid signature
â”‚  â”‚
â”‚  â”œâ”€ 404 Not Found (3)
â”‚  â”‚   âœ“ User not found
â”‚  â”‚   âœ“ Resource deleted
â”‚  â”‚   âœ“ Invalid route
â”‚  â”‚
â”‚  â””â”€ 500 Internal Error (3)
â”‚      âœ“ Database timeout
â”‚      âœ“ Third-party failure
â”‚      âœ“ Unhandled exception
â”‚
â”œâ”€ Rejected (1 example)
â”‚  âœ— Duplicate of existing example
â”‚    Reason: 98% similarity to error_045
â”‚
â””â”€ Quality Validation
   âœ“ Schema compliance: 100%
   âœ“ PII scan: Clean
   âœ“ Determinism check: Passed
   âœ“ Edge case coverage: +15%

Dataset Stats:
â”œâ”€ error-responses.jsonl: 167 examples
â”œâ”€ validation-errors.jsonl: 89 examples
â”œâ”€ edge-cases.jsonl: 67 examples
â”œâ”€ Total coverage: 78% â†’ 93%
â””â”€ Quality score: 9.6/10

Recommendations:
âš  Missing: 429 Rate Limit examples
âš  Missing: 503 Service Unavailable
ğŸ’¡ Run: /add-golden --generate rate-limit`,
    completionTime: "12s",
    metrics: {
      Accepted: "11",
      Rejected: "1",
      Coverage: "93%",
      Quality: "9.6/10",
    },
  },

  // ADVANCED LEVEL - Full dataset curation
  advanced: {
    name: "Advanced",
    description: "curate ML training dataset",
    inputCount: 156,
    files: [
      {
        name: "data/golden/",
        status: "completed",
        children: [
          {
            name: "training/",
            status: "completed",
            children: [
              { name: "positive-examples.jsonl", status: "completed", lines: 2456 },
              { name: "negative-examples.jsonl", status: "completed", lines: 1234 },
              { name: "edge-cases.jsonl", status: "completed", lines: 567 },
            ],
          },
          {
            name: "validation/",
            status: "completed",
            children: [
              { name: "holdout-set.jsonl", status: "completed", lines: 456 },
              { name: "adversarial.jsonl", status: "writing", lines: 234 },
            ],
          },
          {
            name: "test/",
            status: "pending",
            children: [
              { name: "benchmark.jsonl", status: "pending", lines: 0 },
            ],
          },
        ],
      },
    ],
    references: [
      { name: "golden-dataset-curation", status: "loaded", category: "data" },
      { name: "ml-data-quality", status: "loaded", category: "ml" },
      { name: "dataset-balancing", status: "loaded", category: "stats" },
      { name: "adversarial-examples", status: "loading", category: "security" },
      { name: "benchmark-creation", status: "pending", category: "eval" },
    ],
    claudeResponse: [
      "Curating ML training dataset:",
      "",
      "â€¢ Input: 156 raw examples",
      "â€¢ Validated: 148 accepted",
      "â€¢ Rejected: 8 (quality issues)",
      "â€¢ Auto-generated: 24 adversarial",
      "â€¢ Train/Val/Test: 70/15/15",
      "â€¢ Class balance: Optimized",
      "â€¢ Dedup: 12 removed",
    ],
    codeSnippet: `GOLDEN DATASET CURATION COMPLETE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Project: intent-classification-v2

PROCESSING SUMMARY:
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ML TRAINING DATASET CURATED                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ Input Processing (156 examples)
â”‚  â”œâ”€ Accepted: 148 (94.9%)
â”‚  â”œâ”€ Rejected: 8 (5.1%)
â”‚  â”‚   â”œâ”€ Ambiguous label: 3
â”‚  â”‚   â”œâ”€ PII detected: 2
â”‚  â”‚   â”œâ”€ Duplicate: 2
â”‚  â”‚   â””â”€ Schema invalid: 1
â”‚  â”‚
â”‚  â””â”€ Auto-Augmented: 24
â”‚      â”œâ”€ Adversarial perturbations: 12
â”‚      â”œâ”€ Synonym replacements: 8
â”‚      â””â”€ Typo injection: 4
â”‚
â”œâ”€ Dataset Split (172 total)
â”‚  â”œâ”€ Training: 120 (70%)
â”‚  â”‚   â”œâ”€ positive-examples.jsonl: 67
â”‚  â”‚   â”œâ”€ negative-examples.jsonl: 38
â”‚  â”‚   â””â”€ edge-cases.jsonl: 15
â”‚  â”‚
â”‚  â”œâ”€ Validation: 26 (15%)
â”‚  â”‚   â””â”€ holdout-set.jsonl: 26
â”‚  â”‚
â”‚  â””â”€ Test: 26 (15%)
â”‚      â”œâ”€ benchmark.jsonl: 18
â”‚      â””â”€ adversarial.jsonl: 8
â”‚
â”œâ”€ Class Distribution
â”‚  â”œâ”€ Intent: greet (23%)
â”‚  â”œâ”€ Intent: query (28%)
â”‚  â”œâ”€ Intent: command (31%)
â”‚  â”œâ”€ Intent: farewell (10%)
â”‚  â””â”€ Intent: other (8%)
â”‚  âœ“ Balance score: 0.92 (excellent)
â”‚
â”œâ”€ Quality Metrics
â”‚  â”œâ”€ Label consistency: 98.2%
â”‚  â”œâ”€ Inter-annotator agreement: 0.94 kappa
â”‚  â”œâ”€ PII compliance: 100%
â”‚  â”œâ”€ Schema compliance: 100%
â”‚  â”œâ”€ Uniqueness: 100% (after dedup)
â”‚  â””â”€ Difficulty distribution:
â”‚      â”œâ”€ Easy: 40%
â”‚      â”œâ”€ Medium: 45%
â”‚      â””â”€ Hard: 15%
â”‚
â”œâ”€ Feature Analysis
â”‚  â”œâ”€ Avg token length: 12.4
â”‚  â”œâ”€ Vocabulary size: 2,456 unique tokens
â”‚  â”œâ”€ OOV estimate: 3.2%
â”‚  â””â”€ Domain coverage: 94%
â”‚
â”œâ”€ Versioning
â”‚  â”œâ”€ Version: v2.1.0
â”‚  â”œâ”€ Previous: v2.0.0 (1,234 examples)
â”‚  â”œâ”€ Delta: +172 examples (+13.9%)
â”‚  â””â”€ Changelog: AUTO-GENERATED
â”‚
â””â”€ Export Formats
   âœ“ JSONL (primary)
   âœ“ CSV (compatibility)
   âœ“ HuggingFace datasets
   âœ“ TensorFlow tfrecord

RECOMMENDATIONS:
â”Œâ”€ Coverage Gaps Detected
â”‚  âš  Missing: multi-language examples (0%)
â”‚  âš  Missing: code-mixed queries (2%)
â”‚  âš  Low: negation patterns (5%)
â”‚
â”œâ”€ Suggested Actions
â”‚  1. /add-golden --generate multi-language
â”‚  2. /add-golden --augment negation
â”‚  3. Review adversarial edge cases
â”‚
â””â”€ Next Steps
   â†’ Train model on v2.1.0
   â†’ Run benchmark comparison
   â†’ Schedule human review for rejects

Dataset Location:
  data/golden/intent-classification-v2/
  â””â”€ README.md (auto-generated documentation)`,
    completionTime: "45s",
    metrics: {
      Accepted: "148",
      Augmented: "24",
      "Train/Val/Test": "120/26/26",
      Balance: "0.92",
      Quality: "9.4/10",
    },
  },

  summaryTitle: "GOLDEN DATASET CURATED",
  summaryTagline: "Quality data in. Quality AI out. Production ready.",

  backgroundMusic: "audio/ambient-tech.mp3",
  musicVolume: 0.08,
};

export default addGoldenDemoConfig;
