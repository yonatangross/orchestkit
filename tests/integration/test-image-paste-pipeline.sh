#!/bin/bash
# Generated by OrchestKit Claude Plugin
# Created: 2026-02-15

# ============================================================================
# Image Paste Pipeline Integration Tests
# Issue #620: Image paste kills context window
# ============================================================================
# Integration tests that verify the FULL UserPromptSubmit hook pipeline
# handles image/binary data correctly end-to-end.
#
# Unlike unit tests (test-image-paste-guard.sh), these tests:
#   1. Run ALL 5 UserPromptSubmit hooks as CC would fire them
#   2. Verify guards survive esbuild compilation (dist bundles)
#   3. Test the actual hooks.json → run-hook.mjs → compiled bundle pipeline
#   4. Measure aggregate latency across all hooks
#   5. Verify no hook leaks image data into additionalContext/systemMessage
# ============================================================================

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/../.." && pwd)"

RUN_HOOK="$PROJECT_ROOT/src/hooks/bin/run-hook.mjs"
HOOKS_JSON="$PROJECT_ROOT/src/hooks/hooks.json"
DIST_DIR="$PROJECT_ROOT/src/hooks/dist"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

TESTS_PASSED=0
TESTS_FAILED=0

# Test environment
export CLAUDE_PROJECT_DIR="$PROJECT_ROOT"
export CLAUDE_SESSION_ID="image-paste-integration-test-$$"

log_pass() {
    echo -e "  ${GREEN}○${NC} $1... ${GREEN}PASS${NC}"
    TESTS_PASSED=$((TESTS_PASSED + 1))
}

log_fail() {
    echo -e "  ${RED}✗${NC} $1... ${RED}FAIL${NC}"
    echo -e "    ${RED}$2${NC}"
    TESTS_FAILED=$((TESTS_FAILED + 1))
}

# Run a hook and return stdout
run_hook() {
    local hook_name="$1"
    local json_input="$2"
    local timeout_sec="${3:-5}"

    if command -v gtimeout >/dev/null 2>&1; then
        echo "$json_input" | gtimeout "${timeout_sec}" node "$RUN_HOOK" "$hook_name" 2>/dev/null || true
    elif command -v timeout >/dev/null 2>&1; then
        echo "$json_input" | timeout "${timeout_sec}" node "$RUN_HOOK" "$hook_name" 2>/dev/null || true
    else
        echo "$json_input" | node "$RUN_HOOK" "$hook_name" 2>/dev/null || true
    fi
}

# Generate fake base64 content
generate_base64_block() {
    local length="$1"
    local pattern="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    local result=""
    while [[ ${#result} -lt "$length" ]]; do
        result="${result}${pattern}"
    done
    echo "${result:0:$length}"
}

# Check if output is safe (no image data leaked into context)
output_is_safe() {
    local output="$1"
    local image_marker="$2"
    # Check that the output doesn't contain any of the image data
    if echo "$output" | grep -q "$image_marker" 2>/dev/null; then
        return 1  # LEAKED
    fi
    return 0  # SAFE
}

# Get all UserPromptSubmit hook names from hooks.json
get_prompt_hooks() {
    jq -r '.hooks.UserPromptSubmit[].hooks[].command' "$HOOKS_JSON" 2>/dev/null | \
        sed -n 's/.*run-hook\(-silent\)\{0,1\}\.mjs \([^ "]*\).*/\2/p' || true
}

echo ""
echo -e "${CYAN}════════════════════════════════════════════════════════════════${NC}"
echo -e "${CYAN}  Image Paste Pipeline Integration Tests (Issue #620)${NC}"
echo -e "${CYAN}════════════════════════════════════════════════════════════════${NC}"

# Prerequisites
if [[ ! -f "$RUN_HOOK" ]]; then
    echo -e "${RED}SKIP: run-hook.mjs not found${NC}"
    exit 0
fi
if [[ ! -f "$HOOKS_JSON" ]]; then
    echo -e "${RED}SKIP: hooks.json not found${NC}"
    exit 0
fi

# ============================================================================
# 1. Full pipeline test: ALL UserPromptSubmit hooks with image data
# ============================================================================

echo ""
echo -e "  ${CYAN}Full Pipeline: All UserPromptSubmit hooks with image data${NC}"
echo ""

# Build a realistic image payload (base64 PNG-like data, ~5KB)
IMAGE_B64=$(generate_base64_block 5000)
IMAGE_MARKER="${IMAGE_B64:100:50}"  # Unique substring to check for leaks
IMAGE_INPUT=$(jq -n --arg p "data:image/png;base64,${IMAGE_B64}" \
    '{"prompt":$p,"tool_name":"","session_id":"test-image","tool_input":{}}')

# Run every prompt hook and verify safe output
PROMPT_HOOKS=$(get_prompt_hooks)
ALL_HOOKS_SAFE=true
HOOK_COUNT=0

while IFS= read -r hook_name; do
    [[ -z "$hook_name" ]] && continue
    HOOK_COUNT=$((HOOK_COUNT + 1))

    local_output=$(run_hook "$hook_name" "$IMAGE_INPUT")

    if [[ -z "$local_output" ]]; then
        # Empty output means hook failed silently — acceptable
        continue
    fi

    # Verify valid JSON
    if ! echo "$local_output" | jq -e '.' >/dev/null 2>&1; then
        log_fail "hook $hook_name returns valid JSON for image input" "Got: ${local_output:0:100}"
        ALL_HOOKS_SAFE=false
        continue
    fi

    # Verify no image data leaked into output
    if ! output_is_safe "$local_output" "$IMAGE_MARKER"; then
        log_fail "hook $hook_name does not leak image data" "Image data found in output"
        ALL_HOOKS_SAFE=false
    fi
done <<< "$PROMPT_HOOKS"

if [[ "$ALL_HOOKS_SAFE" == "true" && "$HOOK_COUNT" -gt 0 ]]; then
    log_pass "all $HOOK_COUNT UserPromptSubmit hooks handle image data safely"
else
    [[ "$HOOK_COUNT" -eq 0 ]] && log_fail "found UserPromptSubmit hooks" "No hooks found in hooks.json"
fi

# ============================================================================
# 2. Pipeline latency: all hooks complete within budget
# ============================================================================

echo ""
echo -e "  ${CYAN}Pipeline Latency: aggregate across all hooks${NC}"
echo ""

OVERSIZED_INPUT=$(jq -n --arg p "$(head -c 60000 /dev/urandom | base64 | tr -d '\n' | head -c 60000)" \
    '{"prompt":$p,"tool_name":"","session_id":"test-perf","tool_input":{}}' 2>/dev/null || \
    jq -n --arg p "$(generate_base64_block 60000)" \
    '{"prompt":$p,"tool_name":"","session_id":"test-perf","tool_input":{}}')

# Per-hook timing: each hook must complete in <500ms on 60KB payload
HOOK_TIMING_OK=true
while IFS= read -r hook_name; do
    [[ -z "$hook_name" ]] && continue
    local_start=$(python3 -c "import time; print(int(time.time()*1000))")
    run_hook "$hook_name" "$OVERSIZED_INPUT" 5 >/dev/null
    local_end=$(python3 -c "import time; print(int(time.time()*1000))")
    local_elapsed=$((local_end - local_start))
    if [[ "$local_elapsed" -ge 500 ]]; then
        log_fail "hook $hook_name completes in <500ms on 60KB" "Took ${local_elapsed}ms"
        HOOK_TIMING_OK=false
    fi
done <<< "$PROMPT_HOOKS"

if [[ "$HOOK_TIMING_OK" == "true" ]]; then
    log_pass "all hooks complete in <500ms individually on 60KB payload"
fi

# Aggregate timing: full pipeline across all hooks
START_MS=$(python3 -c "import time; print(int(time.time()*1000))")

while IFS= read -r hook_name; do
    [[ -z "$hook_name" ]] && continue
    run_hook "$hook_name" "$OVERSIZED_INPUT" 5 >/dev/null
done <<< "$PROMPT_HOOKS"

END_MS=$(python3 -c "import time; print(int(time.time()*1000))")
TOTAL_MS=$((END_MS - START_MS))

if [[ "$TOTAL_MS" -lt 5000 ]]; then
    log_pass "full pipeline (60KB payload, $HOOK_COUNT hooks) completes in ${TOTAL_MS}ms (< 5000ms)"
else
    log_fail "full pipeline (60KB payload) completes within 5s" "Took ${TOTAL_MS}ms"
fi

# ============================================================================
# 3. Compiled bundle verification: guards in dist/prompt.mjs
# ============================================================================

echo ""
echo -e "  ${CYAN}Compiled Bundle: guards survive esbuild${NC}"
echo ""

PROMPT_BUNDLE="$DIST_DIR/prompt.mjs"

if [[ ! -f "$PROMPT_BUNDLE" ]]; then
    log_fail "prompt.mjs bundle exists" "Not found at $PROMPT_BUNDLE"
else
    # Test: MAX_PROMPT_LENGTH compiled into bundle
    if grep -q "MAX_PROMPT_LENGTH" "$PROMPT_BUNDLE" || grep -q "50000\|50_000\|5e4" "$PROMPT_BUNDLE"; then
        log_pass "MAX_PROMPT_LENGTH guard compiled into prompt.mjs"
    else
        log_fail "MAX_PROMPT_LENGTH guard compiled into prompt.mjs" "Not found in compiled bundle"
    fi

    # Test: isImageOrBinaryPrompt logic compiled into bundle
    if grep -q "data:image" "$PROMPT_BUNDLE"; then
        log_pass "data:image URI detection compiled into prompt.mjs"
    else
        log_fail "data:image URI detection compiled into prompt.mjs" "Not found in compiled bundle"
    fi

    # Test: base64 block detection compiled
    if grep -q "A-Za-z0-9+/=" "$PROMPT_BUNDLE" || grep -q "1024" "$PROMPT_BUNDLE"; then
        log_pass "base64 block detection compiled into prompt.mjs"
    else
        log_fail "base64 block detection compiled into prompt.mjs" "Not found in compiled bundle"
    fi

    # Test: non-text ratio check compiled
    if grep -q "nonText" "$PROMPT_BUNDLE" || grep -q "non.*[Tt]ext" "$PROMPT_BUNDLE"; then
        log_pass "non-text content ratio check compiled into prompt.mjs"
    else
        log_fail "non-text content ratio check compiled into prompt.mjs" "Not found in compiled bundle"
    fi
fi

# ============================================================================
# 4. run-hook.mjs stdin cap in place
# ============================================================================

echo ""
echo -e "  ${CYAN}Stdin Cap: run-hook.mjs boundary protection${NC}"
echo ""

if grep -q "MAX_STDIN_BYTES" "$RUN_HOOK"; then
    # Extract the value
    CAP_VALUE=$(grep "MAX_STDIN_BYTES" "$RUN_HOOK" | grep -oE '[0-9]+ *\* *[0-9]+' | head -1)
    if [[ -n "$CAP_VALUE" ]]; then
        log_pass "stdin cap defined: $CAP_VALUE bytes"
    else
        log_pass "stdin cap defined in run-hook.mjs"
    fi
else
    log_fail "stdin cap defined in run-hook.mjs" "MAX_STDIN_BYTES not found"
fi

# Verify the fallback behavior (truncated JSON → run with empty input → no crash)
if grep -q "JSON incomplete" "$RUN_HOOK" || grep -q "runHook(normalizeInput({}))" "$RUN_HOOK"; then
    log_pass "stdin cap has graceful fallback (empty input on truncation)"
else
    log_fail "stdin cap has graceful fallback" "Fallback pattern not found"
fi

# ============================================================================
# 5. No-regression: normal text prompts still work through pipeline
# ============================================================================

echo ""
echo -e "  ${CYAN}No-Regression: normal prompts still processed${NC}"
echo ""

NORMAL_INPUT='{"prompt":"implement a new authentication system using JWT tokens","tool_name":"","session_id":"test-normal","tool_input":{}}'

NORMAL_OK=true
while IFS= read -r hook_name; do
    [[ -z "$hook_name" ]] && continue
    local_output=$(run_hook "$hook_name" "$NORMAL_INPUT")

    if [[ -z "$local_output" ]]; then
        continue
    fi

    if ! echo "$local_output" | jq -e '.continue' >/dev/null 2>&1; then
        log_fail "hook $hook_name processes normal prompt" "Invalid output: ${local_output:0:100}"
        NORMAL_OK=false
    fi
done <<< "$PROMPT_HOOKS"

if [[ "$NORMAL_OK" == "true" ]]; then
    log_pass "all hooks process normal text prompts correctly"
fi

# ============================================================================
# 6. Edge case: prompt just under MAX_PROMPT_LENGTH (49K) processes normally
# ============================================================================

echo ""
echo -e "  ${CYAN}Edge Cases${NC}"
echo ""

UNDER_LIMIT=$(python3 -c "print('implement ' + 'a' * 49000)")
UNDER_INPUT=$(jq -n --arg p "$UNDER_LIMIT" '{"prompt":$p,"tool_name":"","session_id":"test-edge","tool_input":{}}')

UNDER_OUTPUT=$(run_hook "prompt/unified-dispatcher" "$UNDER_INPUT" 10)
if [[ -n "$UNDER_OUTPUT" ]] && echo "$UNDER_OUTPUT" | jq -e '.continue' >/dev/null 2>&1; then
    log_pass "prompt at 49K chars (under limit) processes normally"
else
    log_fail "prompt at 49K chars (under limit) processes normally" "Got: ${UNDER_OUTPUT:0:100}"
fi

# Edge case: prompt just over MAX_PROMPT_LENGTH (51K) is blocked
OVER_LIMIT=$(python3 -c "print('a' * 51000)")
OVER_INPUT=$(jq -n --arg p "$OVER_LIMIT" '{"prompt":$p,"tool_name":"","session_id":"test-edge2","tool_input":{}}')

OVER_OUTPUT=$(run_hook "prompt/unified-dispatcher" "$OVER_INPUT" 10)
OVER_SUPPRESS=$(echo "$OVER_OUTPUT" | jq -r '.suppressOutput' 2>/dev/null)
if [[ "$OVER_SUPPRESS" == "true" ]]; then
    log_pass "prompt at 51K chars (over limit) returns silent success"
else
    log_fail "prompt at 51K chars (over limit) returns silent success" "Got: ${OVER_OUTPUT:0:100}"
fi

# Edge case: empty prompt (no crash)
EMPTY_INPUT='{"prompt":"","tool_name":"","session_id":"test-empty","tool_input":{}}'
EMPTY_OUTPUT=$(run_hook "prompt/unified-dispatcher" "$EMPTY_INPUT")
if [[ -n "$EMPTY_OUTPUT" ]] && echo "$EMPTY_OUTPUT" | jq -e '.continue' >/dev/null 2>&1; then
    log_pass "empty prompt does not crash"
else
    log_fail "empty prompt does not crash" "Got: ${EMPTY_OUTPUT:0:100}"
fi

# Edge case: null prompt field (no crash)
NULL_INPUT='{"tool_name":"","session_id":"test-null","tool_input":{}}'
NULL_OUTPUT=$(run_hook "prompt/unified-dispatcher" "$NULL_INPUT")
if [[ -n "$NULL_OUTPUT" ]] && echo "$NULL_OUTPUT" | jq -e '.continue' >/dev/null 2>&1; then
    log_pass "missing prompt field does not crash"
else
    log_fail "missing prompt field does not crash" "Got: ${NULL_OUTPUT:0:100}"
fi

# ============================================================================
# SUMMARY
# ============================================================================

echo ""
echo -e "${CYAN}════════════════════════════════════════════════════════════════${NC}"
TOTAL=$((TESTS_PASSED + TESTS_FAILED))
echo -e "  Total: $TOTAL  |  Passed: ${GREEN}${TESTS_PASSED}${NC}  |  Failed: ${RED}${TESTS_FAILED}${NC}"
echo -e "${CYAN}════════════════════════════════════════════════════════════════${NC}"

if [[ $TESTS_FAILED -gt 0 ]]; then
    echo -e "  ${RED}FAIL${NC}: Image paste pipeline integration tests failed"
    exit 1
else
    echo -e "  ${GREEN}ALL TESTS PASSED!${NC}"
    exit 0
fi
