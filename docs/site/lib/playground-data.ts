// AUTO-GENERATED by scripts/generate-playground-data.js
// DO NOT EDIT MANUALLY — your changes will be overwritten.
// Run: npm run build (or node scripts/generate-playground-data.js)

// ── Types ──────────────────────────────────────────────────

export interface SkillDetail {
  name: string;
  description: string;
  version: string;
  author: string;
  tags: string[];
  userInvocable: boolean;
  context: string;
  allowedTools: string[];
  skills: string[];
  agent: string | null;
  structure: Record<string, string[]>;
  content: string;
  contentTruncated: boolean;
  plugins: string[];
  relatedAgents: string[];
}

export interface Plugin {
  name: string;
  description: string;
  fullDescription: string;
  category: string;
  version: string;
  skillCount: number;
  agentCount: number;
  hooks: number;
  commandCount: number;
  color: string;
  required: boolean;
  recommended: boolean;
  skills: string[];
  agents: string[];
  commands: string[];
}

export interface AgentSummary {
  name: string;
  description: string;
  plugins: string[];
  model: string;
  category: string;
}

export interface Composition {
  id: string;
  skill: string;
  command: string;
  hook: string;
  style: string;
  format: string;
  width: number;
  height: number;
  fps: number;
  durationSeconds: number;
  folder: string;
  category: string;
  primaryColor: string;
  relatedPlugin: string;
  tags: string[];
  thumbnailCdn?: string;
  videoCdn?: string;
}

export interface CategoryMeta {
  color: string;
  label: string;
}

export interface Totals {
  plugins: number;
  skills: number;
  agents: number;
  hooks: number;
  commands: number;
  compositions: number;
}

// ── Data ───────────────────────────────────────────────────

export const TOTALS: Totals = {
  "plugins": 3,
  "skills": 199,
  "agents": 36,
  "hooks": 119,
  "commands": 24,
  "compositions": 14
};

export const PLUGINS: Plugin[] = [
  {
    "name": "orkl",
    "description": "Universal toolkit — 88 skills, 36 agents, 119 hooks. Language-agnostic, works for any stack.",
    "fullDescription": "The universal OrchestKit toolkit. Includes all workflow skills (implement, explore, verify, review-pr, commit), all memory skills (remember, memory, mem0, fabric), product/UX skills, accessibility, and all specialized agents. Language-agnostic — works for any tech stack.",
    "category": "development",
    "version": "6.0.3",
    "skillCount": 88,
    "agentCount": 36,
    "hooks": 119,
    "commandCount": 24,
    "color": "#8b5cf6",
    "required": false,
    "recommended": true,
    "skills": [
      "explore",
      "implement",
      "verify",
      "review-pr",
      "create-pr",
      "commit",
      "fix-issue",
      "assess",
      "assess-complexity",
      "doctor",
      "errors",
      "remember",
      "memory",
      "memory-fabric",
      "brainstorming",
      "git-recovery",
      "worktree-coordination",
      "help",
      "configure",
      "feedback"
    ],
    "agents": [
      "accessibility-specialist",
      "ai-safety-auditor",
      "backend-system-architect",
      "business-case-builder",
      "ci-cd-engineer",
      "code-quality-reviewer",
      "data-pipeline-engineer",
      "database-engineer",
      "debug-investigator",
      "demo-producer",
      "deployment-manager",
      "documentation-specialist",
      "event-driven-architect",
      "frontend-ui-developer",
      "git-operations-engineer",
      "infrastructure-architect",
      "llm-integrator",
      "market-intelligence",
      "metrics-architect",
      "monitoring-engineer",
      "multimodal-specialist",
      "performance-engineer",
      "prioritization-analyst",
      "product-strategist",
      "prompt-engineer",
      "python-performance-engineer",
      "rapid-ui-designer",
      "release-engineer",
      "requirements-translator",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer",
      "test-generator",
      "ux-researcher",
      "web-research-analyst",
      "workflow-architect"
    ],
    "commands": [
      "add-golden",
      "assess",
      "assess-complexity",
      "audit-full",
      "brainstorming",
      "commit",
      "competitive-monitoring",
      "configure",
      "create-pr",
      "demo-producer",
      "doctor",
      "explore",
      "feedback",
      "fix-issue",
      "git-recovery",
      "help",
      "implement",
      "memory",
      "remember",
      "review-pr",
      "skill-evolution",
      "upgrade-assessment",
      "verify",
      "worktree-coordination"
    ]
  },
  {
    "name": "ork-creative",
    "description": "Video production add-on — 16 skills, 1 agent. Demo recording, Remotion, storyboarding.",
    "fullDescription": "Video production toolkit for OrchestKit. Includes demo recording, Remotion composition, storyboarding, narration scripting, content recipes, and visual effects skills. Adds the demo-producer agent.",
    "category": "development",
    "version": "6.0.3",
    "skillCount": 16,
    "agentCount": 1,
    "hooks": 119,
    "commandCount": 1,
    "color": "#ec4899",
    "required": false,
    "recommended": false,
    "skills": [
      "demo-producer",
      "terminal-demo-generator",
      "remotion-composer",
      "manim-visualizer",
      "video-storyboarding",
      "video-pacing",
      "narration-scripting",
      "content-type-recipes",
      "hook-formulas",
      "scene-intro-cards",
      "callout-positioning",
      "thumbnail-first-frame",
      "ascii-visualizer",
      "audio-mixing-patterns",
      "music-sfx-selection",
      "elevenlabs-narration"
    ],
    "agents": [
      "demo-producer"
    ],
    "commands": [
      "demo-producer"
    ]
  },
  {
    "name": "ork",
    "description": "Full specialized toolkit — 199 skills, 36 agents, 119 hooks. Adds Python, React, LLM/RAG patterns.",
    "fullDescription": "The complete OrchestKit toolkit. Everything in orkl PLUS specialized patterns for Python (FastAPI, SQLAlchemy, Celery), React (RSC, TanStack, Zustand), LLM integration (function calling, streaming, fine-tuning), RAG retrieval, LangGraph workflows, and MCP server patterns.",
    "category": "development",
    "version": "6.0.3",
    "skillCount": 199,
    "agentCount": 36,
    "hooks": 119,
    "commandCount": 24,
    "color": "#06b6d4",
    "required": false,
    "recommended": false,
    "skills": [
      "a11y-testing",
      "add-golden",
      "advanced-guardrails",
      "agent-loops",
      "agentic-rag-patterns",
      "aggregate-patterns",
      "alembic-migrations",
      "alternative-agent-frameworks",
      "api-design-framework",
      "api-versioning",
      "architecture-decision-record",
      "ascii-visualizer",
      "assess",
      "assess-complexity",
      "asyncio-advanced",
      "audio-language-models",
      "audio-mixing-patterns",
      "audit-full",
      "auth-patterns",
      "backend-architecture-enforcer",
      "background-jobs",
      "best-practices",
      "biome-linting",
      "brainstorming"
    ],
    "agents": [
      "accessibility-specialist",
      "ai-safety-auditor",
      "backend-system-architect",
      "business-case-builder",
      "ci-cd-engineer",
      "code-quality-reviewer",
      "data-pipeline-engineer",
      "database-engineer",
      "debug-investigator",
      "demo-producer",
      "deployment-manager",
      "documentation-specialist",
      "event-driven-architect",
      "frontend-ui-developer",
      "git-operations-engineer",
      "infrastructure-architect",
      "llm-integrator",
      "market-intelligence",
      "metrics-architect",
      "monitoring-engineer",
      "multimodal-specialist",
      "performance-engineer",
      "prioritization-analyst",
      "product-strategist",
      "prompt-engineer",
      "python-performance-engineer",
      "rapid-ui-designer",
      "release-engineer",
      "requirements-translator",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer",
      "test-generator",
      "ux-researcher",
      "web-research-analyst",
      "workflow-architect"
    ],
    "commands": [
      "add-golden",
      "assess",
      "assess-complexity",
      "audit-full",
      "brainstorming",
      "commit",
      "competitive-monitoring",
      "configure",
      "create-pr",
      "demo-producer",
      "doctor",
      "explore",
      "feedback",
      "fix-issue",
      "git-recovery",
      "help",
      "implement",
      "memory",
      "remember",
      "review-pr",
      "skill-evolution",
      "upgrade-assessment",
      "verify",
      "worktree-coordination"
    ]
  }
];

export const AGENTS: AgentSummary[] = [
  {
    "name": "accessibility-specialist",
    "description": "Accessibility expert who audits and implements WCAG 2.2 compliance, screen reader compatibility, and keyboard navigation patterns. Focuses on inclusive design, ARIA patterns, and automated a11y testing. Auto Mode keywords - accessibility, a11y, WCAG, screen reader, keyboard navigation, ARIA, inclusive design, contrast, focus management",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "frontend"
  },
  {
    "name": "ai-safety-auditor",
    "description": "AI safety and security auditor for LLM systems. Red teaming, prompt injection, jailbreak testing, guardrail validation, OWASP LLM compliance. Use for safety audit, security audit, red team, guardrails, jailbreak, prompt injection, OWASP LLM, vulnerabilities, penetration testing, mcp security, tool poisoning.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "security"
  },
  {
    "name": "backend-system-architect",
    "description": "Backend architect who designs REST/GraphQL APIs, database schemas, microservice boundaries, and distributed systems. Focuses on scalability, security, performance optimization, and clean architecture patterns. Activates for API design, database schema, microservice, backend architecture, REST, GraphQL, distributed systems, endpoint, route, model, migration, authentication, authorization, JWT, OAuth, rate limiting, middleware, service layer, repository pattern, dependency injection",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "backend"
  },
  {
    "name": "business-case-builder",
    "description": "Business analyst who builds ROI projections, cost-benefit analyses, risk assessments, and investment justifications to support product decisions with financial rationale. Activates for ROI, cost-benefit, risk assessment, investment justification, business case, budget, revenue impact, cost analysis, financial, payback period, NPV, IRR, TCO, revenue projection",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "product"
  },
  {
    "name": "ci-cd-engineer",
    "description": "CI/CD specialist who designs and implements GitHub Actions workflows, GitLab CI pipelines, and automated deployment strategies. Focuses on build optimization, caching, matrix testing, and security scanning integration. Auto Mode keywords - CI/CD, pipeline, GitHub Actions, GitLab CI, workflow, build, deploy, artifact, cache, matrix testing, release automation",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "devops"
  },
  {
    "name": "code-quality-reviewer",
    "description": "Quality assurance expert who reviews code for bugs, security vulnerabilities, performance issues, and compliance with best practices. Runs linting, type checking, ensures test coverage, and validates architectural patterns. Auto Mode keywords: test, review, quality, lint, security, coverage, audit, validate, CI, pipeline, check, verify, type-check",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "testing"
  },
  {
    "name": "data-pipeline-engineer",
    "description": "Data pipeline specialist who generates embeddings, implements chunking strategies, manages vector indexes, and transforms raw data for AI consumption. Ensures data quality and optimizes batch processing for production scale. Activates for embeddings, chunking, vector index, data pipeline, batch processing, ETL, regenerate embeddings, cache warming, data transformation, data quality, vector rebuild, embedding cache",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "data"
  },
  {
    "name": "database-engineer",
    "description": "PostgreSQL specialist who designs schemas, creates migrations, optimizes queries, and configures pgvector/full-text search. Uses pg-aiguide MCP for best practices and produces Alembic migrations with proper constraints and indexes. Auto Mode keywords: database, schema, migration, PostgreSQL, pgvector, SQL, Alembic, index, constraint",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "backend"
  },
  {
    "name": "debug-investigator",
    "description": "Debug specialist who performs systematic root cause analysis on bugs, errors, exceptions, crashes, and failures. Uses scientific method to isolate issues, traces execution paths, analyzes logs and stack traces. Use when investigating broken functionality, debugging regressions, or analyzing flaky tests.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "testing"
  },
  {
    "name": "demo-producer",
    "description": "Universal demo video producer that creates polished marketing videos for any content - skills, agents, plugins, tutorials, CLI tools, or code walkthroughs. Uses VHS terminal recording and Remotion composition. Activates for demo, video, marketing, showcase, terminal recording, VHS, remotion, tutorial, screencast",
    "plugins": [
      "ork",
      "ork-creative",
      "orkl"
    ],
    "model": "sonnet",
    "category": "development"
  },
  {
    "name": "deployment-manager",
    "description": "Release and deployment specialist who manages production releases, rollback procedures, feature flags, and blue-green deployments. Focuses on zero-downtime deployments and incident response. Auto Mode keywords - deployment, release, rollback, blue-green, canary, feature flag, zero-downtime, production, rollout, incident",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "devops"
  },
  {
    "name": "documentation-specialist",
    "description": "Technical writing and documentation expert. API docs, READMEs, technical guides, ADRs, changelogs, OpenAPI specs. Use for documentation, readme, api-docs, technical-writing, adr, changelog, openapi, swagger, doc-generation.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "development"
  },
  {
    "name": "event-driven-architect",
    "description": "Event-driven architecture specialist who designs event sourcing systems, message queue topologies, and CQRS patterns. Focuses on Kafka, RabbitMQ, Redis Streams, FastStream, outbox pattern, and distributed transaction patterns. Auto Mode keywords - event sourcing, message queue, Kafka, RabbitMQ, pub/sub, CQRS, event-driven, async, saga, event store, outbox, CDC, Debezium",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "backend"
  },
  {
    "name": "frontend-ui-developer",
    "description": "Frontend developer who builds React 19/TypeScript components with optimistic updates, concurrent features, Zod-validated APIs, exhaustive type safety, and modern 2026 patterns. Activates for React, TypeScript, component, UI, frontend, optimistic updates, Zod, concurrent, TSX, hook, TanStack, Suspense, skeleton, form, validation, mutation, lazy loading, view transitions, scroll animations, PWA, charts, dashboard",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "frontend"
  },
  {
    "name": "git-operations-engineer",
    "description": "Git operations specialist who manages branches, commits, rebases, merges, stacked PRs, and recovery operations. Ensures clean commit history and proper branching workflows. Auto Mode keywords - git, branch, commit, rebase, merge, stacked, recovery, reflog, cherry-pick, worktree, squash, reset",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "development"
  },
  {
    "name": "infrastructure-architect",
    "description": "Infrastructure as Code specialist who designs Terraform modules, Kubernetes manifests, and cloud architecture. Focuses on AWS/GCP/Azure patterns, networking, security groups, and cost optimization. Auto Mode keywords - infrastructure, Terraform, Kubernetes, AWS, GCP, Azure, VPC, EKS, RDS, cloud architecture, IaC",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "devops"
  },
  {
    "name": "llm-integrator",
    "description": "LLM integration specialist who connects to OpenAI/Anthropic/Ollama APIs, designs prompt templates, implements function calling and streaming, and optimizes token costs with caching strategies. Activates for LLM, OpenAI, Anthropic, Ollama, prompt, function calling, streaming, token keywords.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "ai"
  },
  {
    "name": "market-intelligence",
    "description": "Market research specialist who analyzes competitive landscapes, identifies market trends, sizes opportunities (TAM/SAM/SOM), and surfaces threats/opportunities to inform product strategy. Activates for market research, competitor, TAM, SAM, SOM, market size, competitive landscape keywords.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "product"
  },
  {
    "name": "metrics-architect",
    "description": "Metrics specialist who designs OKRs, KPIs, success criteria, and instrumentation plans to measure product outcomes and validate hypotheses. Activates for OKR, KPI, metrics, success criteria, instrumentation keywords.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "product"
  },
  {
    "name": "monitoring-engineer",
    "description": "Observability and monitoring specialist. Prometheus metrics, Grafana dashboards, alerting rules, distributed tracing, log aggregation, SLOs/SLIs. Use for monitoring, prometheus, grafana, alerting, tracing, opentelemetry, metrics, observability, logs, slo, sli.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "devops"
  },
  {
    "name": "multimodal-specialist",
    "description": "Vision, audio, and video processing specialist who integrates GPT-5, Claude 4.5, Gemini 3, and Grok 4 for image analysis, transcription, and multimodal RAG. Activates for vision, image, audio, video, multimodal, whisper, tts, transcription, speech-to-text, document vision, OCR, captioning, CLIP, visual keywords.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "ai"
  },
  {
    "name": "performance-engineer",
    "description": "Performance engineer who optimizes Core Web Vitals, analyzes bundles, profiles render performance, and sets up RUM. Activates for performance, Core Web Vitals, LCP, INP, CLS, bundle size, Lighthouse, optimization, slow, latency, profiling, metrics, RUM, bundle, chunk, splitting, speed",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "frontend"
  },
  {
    "name": "prioritization-analyst",
    "description": "Prioritization specialist who scores features using RICE/ICE/WSJF frameworks, analyzes opportunity costs, manages backlog ranking, and recommends what to build next based on value and effort. Activates for RICE, ICE, WSJF, prioritization, backlog, opportunity cost keywords.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "product"
  },
  {
    "name": "product-strategist",
    "description": "Product strategy specialist who validates value propositions, aligns features with business goals, evaluates build/buy/partner decisions, and recommends go/no-go with strategic rationale. Activates for product strategy, value proposition, build/buy/partner, go/no-go",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "product"
  },
  {
    "name": "prompt-engineer",
    "description": "Expert prompt designer and optimizer. Chain-of-thought, few-shot learning, structured outputs, prompt versioning, A/B testing, cost optimization. Use for prompts, prompt-engineering, cot, few-shot, prompt design, prompt optimization, structured-output, a-b-testing, cost-optimization, prompt-testing, evaluation.",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "ai"
  },
  {
    "name": "python-performance-engineer",
    "description": "Python performance specialist who profiles, optimizes, and benchmarks Python applications. Focuses on memory optimization, async performance, database query optimization, caching strategies, and load testing. Activates for performance, profiling, memory leak, slow query, optimization, bottleneck, benchmark, latency, throughput, cProfile, memory_profiler, scalability, connection pool, cache, N+1",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "backend"
  },
  {
    "name": "rapid-ui-designer",
    "description": "UI/UX designer specializing in rapid prototyping with Tailwind CSS. Creates design systems, component specifications, responsive layouts, and accessibility-compliant mockups that bridge design and implementation. Activates for UI, UX, prototype, Tailwind, design system, component, mockup",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "frontend"
  },
  {
    "name": "release-engineer",
    "description": "Release and versioning specialist who manages GitHub releases, milestones, changelogs, and semantic versioning. Handles release automation and project tracking. Auto Mode keywords - release, milestone, changelog, tag, version, semver, sprint, roadmap",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "devops"
  },
  {
    "name": "requirements-translator",
    "description": "Requirements specialist who transforms ambiguous ideas into clear PRDs, user stories with acceptance criteria, and scoped specifications ready for engineering handoff. Activates for PRD, user story, acceptance criteria, requirements, specification",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "product"
  },
  {
    "name": "security-auditor",
    "description": "Security specialist who scans for vulnerabilities, audits dependencies, checks OWASP Top 10 compliance, and identifies secrets/credentials in code. Returns actionable findings with severity and remediation steps. Auto Mode keywords - security, vulnerability, CVE, audit, OWASP, injection, XSS, CSRF, secrets, credentials, npm audit, pip-audit, bandit",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "security"
  },
  {
    "name": "security-layer-auditor",
    "description": "Security layer auditor who verifies defense-in-depth implementation across 8 security layers, from edge to storage, ensuring comprehensive protection. Auto Mode keywords - security layer, defense-in-depth, security audit, 8 layers",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "security"
  },
  {
    "name": "system-design-reviewer",
    "description": "System design reviewer who evaluates implementation plans against scale, data, security, UX, and coherence criteria before code is written. Auto Mode keywords: system design, architecture review, scale, security review, implementation plan",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "development"
  },
  {
    "name": "test-generator",
    "description": "Test specialist who analyzes code coverage gaps, generates unit/integration tests, and creates test fixtures. Uses MSW for API mocking and VCR.py for HTTP recording. Produces runnable tests with meaningful assertions. Activates for test, coverage, unit test, integration test, MSW, VCR, fixture",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "testing"
  },
  {
    "name": "ux-researcher",
    "description": "User research specialist who creates personas, maps user journeys, validates design decisions, and ensures features solve real user problems through data-driven insights and behavioral analysis. Auto-activates for user research, persona, user journey, usability, user testing, insights",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "frontend"
  },
  {
    "name": "web-research-analyst",
    "description": "Web research specialist using browser automation and Tavily API for competitive intelligence, market research, documentation capture, and technical reconnaissance. Activates for web research, scraping, competitor analysis, documentation capture, browser automation, web scraping, content extraction, tavily",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "inherit",
    "category": "research"
  },
  {
    "name": "workflow-architect",
    "description": "Multi-agent workflow specialist who designs LangGraph pipelines, implements supervisor-worker patterns, manages state and checkpointing, and orchestrates RAG retrieval flows for complex AI systems. Auto-activates for LangGraph, workflow, supervisor, state, checkpoint, RAG, multi-agent",
    "plugins": [
      "ork",
      "orkl"
    ],
    "model": "opus",
    "category": "ai"
  }
];

export const CATEGORIES: Record<string, CategoryMeta> = {
  "development": {
    "color": "#8b5cf6",
    "label": "Development"
  },
  "ai": {
    "color": "#06b6d4",
    "label": "AI"
  },
  "backend": {
    "color": "#f59e0b",
    "label": "Backend"
  },
  "frontend": {
    "color": "#ec4899",
    "label": "Frontend"
  },
  "testing": {
    "color": "#22c55e",
    "label": "Testing"
  },
  "security": {
    "color": "#ef4444",
    "label": "Security"
  },
  "devops": {
    "color": "#f97316",
    "label": "DevOps"
  },
  "product": {
    "color": "#a855f7",
    "label": "Product"
  },
  "data": {
    "color": "#6366f1",
    "label": "Data"
  },
  "research": {
    "color": "#14b8a6",
    "label": "Research"
  }
};

export const COMPOSITIONS: Composition[] = [
  {
    "id": "Implement",
    "skill": "implement",
    "command": "/ork:implement",
    "hook": "Add auth in seconds, not hours",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Core-Skills",
    "category": "core",
    "primaryColor": "#8b5cf6",
    "relatedPlugin": "orkl",
    "tags": [
      "core",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/ac596921e6535c7f52c0d6177b50803d5cbebecd-639x360.png",
    "videoCdn": "https://cdn.sanity.io/files/8cv388wg/production/ebd9b9be8a68c1b174b30476a939282a26e76b4c.mp4"
  },
  {
    "id": "Verify",
    "skill": "verify",
    "command": "/ork:verify",
    "hook": "6 agents validate your feature",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Core-Skills",
    "category": "core",
    "primaryColor": "#22c55e",
    "relatedPlugin": "orkl",
    "tags": [
      "core",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/43bf6882afcd73f8f5ae8e35d312b32ded656eeb-639x360.png"
  },
  {
    "id": "Commit",
    "skill": "commit",
    "command": "/ork:commit",
    "hook": "Conventional commits in seconds",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Core-Skills",
    "category": "core",
    "primaryColor": "#06b6d4",
    "relatedPlugin": "orkl",
    "tags": [
      "core",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/66f43642b59e09d058ab03cfdd0d10073a2f3eba-639x360.png"
  },
  {
    "id": "Explore",
    "skill": "explore",
    "command": "/ork:explore",
    "hook": "Understand codebases in minutes",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Core-Skills",
    "category": "core",
    "primaryColor": "#06b6d4",
    "relatedPlugin": "orkl",
    "tags": [
      "core",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/d0741c09b66f877401ccfc27f956578e3ce47e2c-639x360.png"
  },
  {
    "id": "Remember",
    "skill": "remember",
    "command": "/ork:remember",
    "hook": "Build your team's knowledge base",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Memory-Skills",
    "category": "memory",
    "primaryColor": "#8b5cf6",
    "relatedPlugin": "orkl",
    "tags": [
      "memory",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/7f4b1fcaf5783671e1cd06cc078206f85442dbf8-639x360.png"
  },
  {
    "id": "Memory",
    "skill": "memory",
    "command": "/ork:memory",
    "hook": "Search, load, sync, visualize your knowledge",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Memory-Skills",
    "category": "memory",
    "primaryColor": "#06b6d4",
    "relatedPlugin": "orkl",
    "tags": [
      "memory",
      "landscape",
      "tri-terminal"
    ]
  },
  {
    "id": "ReviewPR",
    "skill": "review-pr",
    "command": "/ork:review-pr",
    "hook": "Expert PR review in minutes",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Review-Skills",
    "category": "review",
    "primaryColor": "#f97316",
    "relatedPlugin": "orkl",
    "tags": [
      "review",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/b187e003ab94d1e9b3eae5aae5e7d47a1fa7fc3d-639x360.png"
  },
  {
    "id": "CreatePR",
    "skill": "create-pr",
    "command": "/ork:create-pr",
    "hook": "PRs that pass review the first time",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Review-Skills",
    "category": "review",
    "primaryColor": "#22c55e",
    "relatedPlugin": "orkl",
    "tags": [
      "review",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/a43efa564e0cb78e7edbf4d97bf919373ac9198e-639x360.png"
  },
  {
    "id": "FixIssue",
    "skill": "fix-issue",
    "command": "/ork:fix-issue",
    "hook": "From bug report to merged fix in minutes",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Review-Skills",
    "category": "review",
    "primaryColor": "#ef4444",
    "relatedPlugin": "orkl",
    "tags": [
      "review",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/43b1dc8b4b09894e4b81bdb54e46087e9b7b1246-639x360.png"
  },
  {
    "id": "Doctor",
    "skill": "doctor",
    "command": "/ork:doctor",
    "hook": "Health diagnostics for OrchestKit systems",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/DevOps-Skills",
    "category": "devops",
    "primaryColor": "#ef4444",
    "relatedPlugin": "orkl",
    "tags": [
      "devops",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/5d0342006116a8ece0678441c5fe5a392d7b6c10-639x360.png"
  },
  {
    "id": "Configure",
    "skill": "configure",
    "command": "/ork:configure",
    "hook": "Your AI toolkit, your rules",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/DevOps-Skills",
    "category": "devops",
    "primaryColor": "#f59e0b",
    "relatedPlugin": "orkl",
    "tags": [
      "devops",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/daef6693e325ab9e6b5cd7df2c3bdb5252b7aeac-639x360.png"
  },
  {
    "id": "Brainstorming",
    "skill": "brainstorming",
    "command": "/ork:brainstorming",
    "hook": "Generate ideas in parallel. 4 specialists.",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/AI-Skills",
    "category": "ai",
    "primaryColor": "#f59e0b",
    "relatedPlugin": "orkl",
    "tags": [
      "ai",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/5f5a4e19631f87fd49c9853f63b8b472e1d5d657-639x360.png",
    "videoCdn": "https://cdn.sanity.io/files/8cv388wg/production/ec4da43076fd69090737ce846df4fea831475f22.mp4"
  },
  {
    "id": "Assess",
    "skill": "assess",
    "command": "/ork:assess",
    "hook": "Evaluate quality across 6 dimensions",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/AI-Skills",
    "category": "ai",
    "primaryColor": "#22c55e",
    "relatedPlugin": "orkl",
    "tags": [
      "ai",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/8c69c775078b8d410530eeda745c7b84cef3d7bb-639x360.png"
  },
  {
    "id": "DemoProducer",
    "skill": "demo-producer",
    "command": "/ork:demo-producer",
    "hook": "Professional demos in minutes, not days",
    "style": "TriTerminalRace",
    "format": "landscape",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "durationSeconds": 20,
    "folder": "Production/Landscape-16x9/Advanced-Skills",
    "category": "advanced",
    "primaryColor": "#ec4899",
    "relatedPlugin": "orkl",
    "tags": [
      "advanced",
      "landscape",
      "tri-terminal"
    ],
    "thumbnailCdn": "https://cdn.sanity.io/images/8cv388wg/production/5c6414c0d1a2024c1b7b2316becb78ca7f06eb7f-639x360.png"
  }
];

export const SKILLS: Record<string, SkillDetail> = {
  "a11y-testing": {
    "name": "a11y-testing",
    "description": "Automated accessibility testing with axe-core, Playwright, and jest-axe for WCAG compliance. Use when adding or validating a11y tests, running WCAG checks, or auditing UI accessibility.",
    "version": "1.1.0",
    "author": "OrchestKit",
    "tags": [
      "accessibility",
      "testing",
      "axe-core",
      "playwright",
      "wcag",
      "a11y",
      "jest-axe"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "a11y-testing-tools.md"
      ],
      "scripts": [
        "a11y-test-template.ts"
      ],
      "checklists": [
        "a11y-testing-checklist.md"
      ]
    },
    "content": "# Accessibility Testing\n\nAutomated accessibility testing with axe-core for WCAG 2.2 compliance. Catches 30-50% of issues automatically.\n\n## Overview\n\n- Implementing CI/CD accessibility gates\n- Running pre-release compliance audits\n- Testing component accessibility in unit tests\n- Validating page-level accessibility with E2E tests\n- Ensuring keyboard navigation works correctly\n\n## Quick Reference\n\n### jest-axe Unit Testing\n\n```typescript\n// jest.setup.ts\nimport { toHaveNoViolations } from 'jest-axe';\nexpect.extend(toHaveNoViolations);\n\n// Button.test.tsx\nimport { render } from '@testing-library/react';\nimport { axe } from 'jest-axe';\n\nit('has no a11y violations', async () => {\n  const { container } = render(<Button>Click me</Button>);\n  expect(await axe(container)).toHaveNoViolations();\n});\n```\n\n### Playwright + axe-core E2E\n\n```typescript\n// e2e/accessibility.spec.ts\nimport { test, expect } from '@playwright/test';\nimport AxeBuilder from '@axe-core/playwright';\n\ntest('page has no a11y violations', async ({ page }) => {\n  await page.goto('/');\n  const results = await new AxeBuilder({ page })\n    .withTags(['wcag2a', 'wcag2aa', 'wcag22aa'])\n    .analyze();\n  expect(results.violations).toEqual([]);\n});\n\ntest('modal state has no violations', async ({ page }) => {\n  await page.goto('/');\n  await page.click('[data-testid=\"open-modal\"]');\n  await page.waitForSelector('[role=\"dialog\"]');\n\n  const results = await new AxeBuilder({ page })\n    .include('[role=\"dialog\"]')\n    .withTags(['wcag2a', 'wcag2aa'])\n    .analyze();\n  expect(results.violations).toEqual([]);\n});\n```\n\n### CI/CD Integration\n\n```yaml\n# .github/workflows/accessibility.yml\nname: Accessibility\non: [pull_request]\n\njobs:\n  a11y:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with: { node-version: '20', cache: 'npm' }\n      - run: npm ci\n      - run: npm run test:a11y\n      - run: npm run build\n      - run: npx playwright install --with-deps chromium\n      - run: npm start & npx wait-on http://localhost:3000\n      - run: npx playwright test e2e/accessibility\n```\n\n## Key Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Test runner | jest-axe + Playwright | Unit + E2E coverage |\n| WCAG level | AA (wcag2aa) | Industry standard, legal compliance |\n| CI gate | Block on violations | Prevent regression |\n| Browser matrix | Chromium + Firefox | Cross-browser coverage |\n| Exclusions | Third-party widgets only | Minimize blind spots |\n| Tags | wcag2a, wcag2aa, wcag22aa | Full WCAG 2.2 AA |\n| State testing | Test all interactive states | Modal, error, loading |\n\n## Anti-Patterns (FORBIDDEN)\n\n```typescript\n// BAD: Disabling rules globally\nconst results = await axe(container, {\n  rules: { 'color-contrast': { enabled: false } }  // NEVER disable rules\n});\n\n// BAD: Excluding too much\nnew AxeBuilder({ page })\n  .exclude('body')  // Defeats the purpose\n  .analyze();\n\n// BAD: Only testing happy path\nit('form is ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer",
      "test-generator"
    ]
  },
  "add-golden": {
    "name": "add-golden",
    "description": "Adds documents to golden dataset with validation. Use when curating test data or saving examples.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "curation",
      "golden-dataset",
      "evaluation",
      "testing",
      "quality-scoring",
      "bias-detection"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "golden-dataset-validation",
      "llm-evaluation",
      "test-data-management"
    ],
    "agent": null,
    "structure": {
      "references": [
        "bias-detection-guide.md",
        "quality-scoring.md",
        "silver-gold-promotion.md"
      ],
      "assets": [
        "diversity-dashboard.md",
        "version-entry.json"
      ],
      "scripts": [
        "diversity-checker.py"
      ]
    },
    "content": "# Add to Golden Dataset\n\nMulti-agent curation workflow with quality score explanations, bias detection, and version tracking.\n\n## Quick Start\n\n```bash\n/add-golden https://example.com/article\n/add-golden https://arxiv.org/abs/2312.xxxxx\n```\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main curation task\nTaskCreate(\n  subject=\"Add to golden dataset: {url}\",\n  description=\"Multi-agent curation with quality explanation\",\n  activeForm=\"Curating document\"\n)\n\n# Create subtasks for 9-phase process\nphases = [\"Fetch content\", \"Run quality analysis\", \"Explain scores\",\n          \"Check bias\", \"Check diversity\", \"Validate\", \"Get approval\",\n          \"Write to dataset\", \"Update version\"]\nfor phase in phases:\n    TaskCreate(subject=phase, activeForm=f\"{phase}ing\")\n```\n\n---\n\n## Workflow Overview\n\n| Phase | Activities | Output |\n|-------|------------|--------|\n| **1. Input Collection** | Get URL, detect content type | Document metadata |\n| **2. Fetch and Extract** | Parse document structure | Structured content |\n| **3. Quality Analysis** | 4 parallel agents evaluate | Raw scores |\n| **4. Quality Explanation** | Explain WHY each score | Score rationale |\n| **5. Bias Detection** | Check for bias in content | Bias report |\n| **6. Diversity Check** | Assess dataset balance | Diversity metrics |\n| **7. Validation** | Schema, duplicates, gates | Validation status |\n| **8. Silver-to-Gold** | Promote or mark as silver | Classification |\n| **9. Version Tracking** | Track changes, rollback | Version entry |\n\n---\n\n## Phase 1-2: Input and Extraction\n\nDetect content type: article, tutorial, documentation, research_paper.\n\nExtract: title, sections, code blocks, key terms, metadata (author, date).\n\n---\n\n## Phase 3: Parallel Quality Analysis (4 Agents)\n\nLaunch ALL agents in ONE message with `run_in_background=True`.\n\n| Agent | Focus | Output |\n|-------|-------|--------|\n| code-quality-reviewer | Accuracy, coherence, depth, relevance | Quality scores |\n| workflow-architect | Keyword directness, paraphrase, reasoning | Difficulty level |\n| data-pipeline-engineer | Primary/secondary domains, skill level | Tags |\n| test-generator | Direct, paraphrased, multi-hop queries | Test queries |\n\nSee [Quality Scoring](references/quality-scoring.md) for detailed criteria.\n\n---\n\n## Phase 4: Quality Explanation\n\nEach dimension gets WHY explanation:\n\n```markdown\n### Accuracy: [N.NN]/1.0\n**Why this score:**\n- [Specific reason with evidence]\n**What would improve it:**\n- [Specific improvement]\n```\n\n---\n\n## Phase 5: Bias Detection\n\nSee [Bias Detection Guide](references/bias-detection-guide.md) for patterns.\n\nCheck for:\n- Technology bias (favors specific tools)\n- Recency bias (ignores LTS versions)\n- Complexity bias (assumed knowledge)\n- Vendor bias (promotes products)\n- Geographic/cultural bias\n\n| Bias Score | Action |\n|------------|--------|\n| 0-2 | Proceed normally |\n| 3-5 | Add disclaimer |\n| 6-8 | Require user review |\n| 9-10 | Recommend against |\n\n---\n\n## Phase 6: Diversity Dashboa",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "advanced-guardrails": {
    "name": "advanced-guardrails",
    "description": "LLM guardrails with NeMo, Guardrails AI, and OpenAI. Input/output rails, hallucination prevention, fact-checking, toxicity detection, red-teaming patterns. Use when building LLM guardrails, safety checks, or red-team workflows.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "guardrails",
      "nemo",
      "safety",
      "hallucination",
      "factuality",
      "red-teaming",
      "colang"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "ai-safety-auditor",
    "structure": {
      "references": [
        "factuality-checking.md",
        "guardrails-ai.md",
        "nemo-guardrails.md",
        "openai-guardrails.md",
        "red-teaming.md"
      ],
      "scripts": [
        "create-guardrails-config.md",
        "nemo-config.yaml",
        "rails-pipeline.py"
      ],
      "checklists": [
        "guardrails-deployment.md"
      ]
    },
    "content": "# Advanced Guardrails\n\nProduction LLM safety using NeMo Guardrails, Guardrails AI, and OpenAI moderation with red-teaming validation.\n\n> **NeMo Guardrails **: LangChain 1.x compatible, parallel rails execution, OpenTelemetry tracing. **DeepTeam**: 40+ vulnerabilities, OWASP Top 10 alignment.\n\n## Overview\n\n- Implementing input/output validation for LLM applications\n- Preventing hallucinations and enforcing factuality\n- Detecting and filtering toxic, harmful, or off-topic content\n- Restricting LLM responses to specific domains/topics\n- PII detection and redaction in LLM outputs\n- Red-teaming and adversarial testing of LLM systems\n- OWASP Top 10 for LLMs compliance\n\n## Framework Comparison\n\n| Framework | Best For | Key Features |\n|-----------|----------|--------------|\n| **NeMo Guardrails** | Programmable flows, Colang 2.0 | Input/output rails, fact-checking, dialog control |\n| **Guardrails AI** | Validator-based, modular | 100+ validators, PII, toxicity, structured output |\n| **OpenAI Guardrails** | Drop-in wrapper | Simple integration, moderation API |\n| **DeepTeam** | Red teaming, adversarial | GOAT attacks, multi-turn jailbreaking, vulnerability scanning |\n\n## Quick Reference\n\n### NeMo Guardrails with Guardrails AI Integration\n\n```yaml\n# config.yml\nmodels:\n  - type: main\n    engine: openai\n    model: gpt-5.2\n\nrails:\n  config:\n    guardrails_ai:\n      validators:\n        - name: toxic_language\n          parameters:\n            threshold: 0.5\n            validation_method: \"sentence\"\n        - name: guardrails_pii\n          parameters:\n            entities: [\"phone_number\", \"email\", \"ssn\", \"credit_card\"]\n        - name: restricttotopic\n          parameters:\n            valid_topics: [\"technology\", \"support\"]\n        - name: valid_length\n          parameters:\n            min: 10\n            max: 500\n\n  input:\n    flows:\n      - guardrailsai check input $validator=\"guardrails_pii\"\n      - guardrailsai check input $validator=\"competitor_check\"\n\n  output:\n    flows:\n      - guardrailsai check output $validator=\"toxic_language\"\n      - guardrailsai check output $validator=\"restricttotopic\"\n      - guardrailsai check output $validator=\"valid_length\"\n```\n\n### Colang 2.0 Fact-Checking Rails\n\n```colang\ndefine flow answer question with facts\n  \"\"\"Enable fact-checking for RAG responses.\"\"\"\n  user ...\n  $answer = execute rag()\n  $check_facts = True  # Enables fact-checking rail\n  bot $answer\n\ndefine flow check hallucination\n  \"\"\"Block responses about people without verification.\"\"\"\n  user ask about people\n  $check_hallucination = True  # Blocking mode\n  bot respond about people\n\ndefine flow restrict competitor mentions\n  \"\"\"Prevent discussing competitor products.\"\"\"\n  user ask about $competitor\n  if $competitor in [\"CompetitorA\", \"CompetitorB\"]\n    bot \"I can only discuss our products.\"\n  else\n    bot respond normally\n```\n\n### Guardrails AI Validators\n\n```python\nfrom guardrails import Guard\nfrom guardrails.hub import (\n    ToxicLanguage,\n    DetectPII,\n    Re",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ai-safety-auditor"
    ]
  },
  "agent-loops": {
    "name": "agent-loops",
    "description": "Agentic workflow patterns for autonomous LLM reasoning. Use when building ReAct agents, implementing reasoning loops, or creating LLMs that plan and execute multi-step tasks.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ai",
      "llm",
      "agents",
      "react",
      "reasoning",
      "autonomous"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "scripts": [
        "agent-workflow-template.ts"
      ]
    },
    "content": "# Agent Loops\n\nEnable LLMs to reason, plan, and take autonomous actions.\n\n## ReAct Pattern (Reasoning + Acting)\n\n```python\nREACT_PROMPT = \"\"\"You are an agent that reasons step by step.\n\nFor each step, respond with:\nThought: [your reasoning about what to do next]\nAction: [tool_name(arg1, arg2)]\nObservation: [you'll see the result here]\n\nWhen you have the final answer:\nThought: I now have enough information\nFinal Answer: [your response]\n\nAvailable tools: {tools}\n\nQuestion: {question}\n\"\"\"\n\nasync def react_loop(question: str, tools: dict, max_steps: int = 10) -> str:\n    \"\"\"Execute ReAct reasoning loop.\"\"\"\n    history = REACT_PROMPT.format(tools=list(tools.keys()), question=question)\n\n    for step in range(max_steps):\n        response = await llm.chat([{\"role\": \"user\", \"content\": history}])\n        history += response.content\n\n        # Check for final answer\n        if \"Final Answer:\" in response.content:\n            return response.content.split(\"Final Answer:\")[-1].strip()\n\n        # Extract and execute action\n        if \"Action:\" in response.content:\n            action = parse_action(response.content)\n            result = await tools[action.name](*action.args)\n            history += f\"\\nObservation: {result}\\n\"\n\n    return \"Max steps reached without answer\"\n```\n\n## Plan-and-Execute Pattern\n\n```python\nasync def plan_and_execute(goal: str) -> str:\n    \"\"\"Create plan first, then execute steps.\"\"\"\n    # 1. Generate plan\n    plan = await llm.chat([{\n        \"role\": \"user\",\n        \"content\": f\"Create a step-by-step plan to: {goal}\\n\\nFormat as numbered list.\"\n    }])\n\n    steps = parse_plan(plan.content)\n    results = []\n\n    # 2. Execute each step\n    for i, step in enumerate(steps):\n        result = await execute_step(step, context=results)\n        results.append({\"step\": step, \"result\": result})\n\n        # 3. Check if replanning needed\n        if should_replan(results):\n            return await plan_and_execute(\n                f\"{goal}\\n\\nProgress so far: {results}\"\n            )\n\n    # 4. Synthesize final answer\n    return await synthesize(goal, results)\n```\n\n## Self-Correction Loop\n\n```python\nasync def self_correcting_agent(task: str, max_retries: int = 3) -> str:\n    \"\"\"Agent that validates and corrects its own output.\"\"\"\n    for attempt in range(max_retries):\n        # Generate response\n        response = await llm.chat([{\n            \"role\": \"user\",\n            \"content\": task\n        }])\n\n        # Self-validate\n        validation = await llm.chat([{\n            \"role\": \"user\",\n            \"content\": f\"\"\"Validate this response for the task: {task}\n\nResponse: {response.content}\n\nCheck for:\n1. Correctness - Is it factually accurate?\n2. Completeness - Does it fully answer the task?\n3. Format - Is it properly formatted?\n\nIf valid, respond: VALID\nIf invalid, respond: INVALID: [what's wrong and how to fix]\"\"\"\n        }])\n\n        if \"VALID\" in validation.content:\n            return response.content\n\n        # Correct based on feedback\n        task",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "agentic-rag-patterns": {
    "name": "agentic-rag-patterns",
    "description": "Advanced RAG with Self-RAG, Corrective-RAG, and knowledge graphs. Use when building agentic RAG pipelines, adaptive retrieval, or query rewriting.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "self-rag",
      "crag",
      "knowledge-graph",
      "langgraph",
      "agentic"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "adaptive-retrieval.md",
        "corrective-rag.md",
        "knowledge-graph-rag.md",
        "self-rag.md"
      ],
      "scripts": [
        "crag-workflow.py",
        "self-rag-graph.py"
      ],
      "checklists": [
        "rag-quality.md"
      ]
    },
    "content": "# Agentic RAG Patterns\n\nBuild self-correcting retrieval systems with LLM-driven decision making.\n\n> **LangGraph 1.0.6** (Jan 2026): langgraph-checkpoint 4.0.0, compile-time checkpointer validation, namespace sanitization.\n\n## Architecture Overview\n\n```\nQuery → [Retrieve] → [Grade] → [Generate/Rewrite/Web Search] → Response\n              ↓           ↓\n         Documents    Quality Check\n                          ↓\n                   Route Decision:\n                   - Good docs → Generate\n                   - Poor docs → Rewrite query\n                   - No docs → Web fallback\n```\n\n## Self-RAG State Definition\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom typing import TypedDict, List, Annotated\nfrom langchain_core.documents import Document\nimport operator\n\nclass RAGState(TypedDict):\n    \"\"\"State for agentic RAG workflows.\"\"\"\n    question: str\n    documents: Annotated[List[Document], operator.add]\n    generation: str\n    web_search_needed: bool\n    retry_count: int\n    relevance_scores: dict[str, float]\n```\n\n## Core Retrieval Node\n\n```python\ndef retrieve(state: RAGState) -> dict:\n    \"\"\"Retrieve documents from vector store.\"\"\"\n    question = state[\"question\"]\n    documents = retriever.invoke(question)\n    return {\"documents\": documents, \"question\": question}\n```\n\n## Document Grading (Self-RAG Core)\n\n```python\nfrom pydantic import BaseModel, Field\n\nclass GradeDocuments(BaseModel):\n    \"\"\"Binary score for document relevance.\"\"\"\n    binary_score: str = Field(\n        description=\"Relevance score 'yes' or 'no'\"\n    )\n\ndef grade_documents(state: RAGState) -> dict:\n    \"\"\"Grade documents for relevance - core Self-RAG pattern.\"\"\"\n    question = state[\"question\"]\n    documents = state[\"documents\"]\n\n    filtered_docs = []\n    relevance_scores = {}\n\n    for doc in documents:\n        score = retrieval_grader.invoke({\n            \"question\": question,\n            \"document\": doc.page_content\n        })\n        doc_id = doc.metadata.get(\"id\", hash(doc.page_content))\n        relevance_scores[doc_id] = 1.0 if score.binary_score == \"yes\" else 0.0\n\n        if score.binary_score == \"yes\":\n            filtered_docs.append(doc)\n\n    # Trigger web search if too many docs filtered out\n    web_search_needed = len(filtered_docs) < len(documents) // 2\n\n    return {\n        \"documents\": filtered_docs,\n        \"web_search_needed\": web_search_needed,\n        \"relevance_scores\": relevance_scores\n    }\n```\n\n## Query Transformation\n\n```python\ndef transform_query(state: RAGState) -> dict:\n    \"\"\"Transform query for better retrieval.\"\"\"\n    question = state[\"question\"]\n\n    better_question = question_rewriter.invoke({\n        \"question\": question,\n        \"feedback\": \"Rephrase to improve retrieval. Be specific.\"\n    })\n\n    return {\n        \"question\": better_question,\n        \"retry_count\": state.get(\"retry_count\", 0) + 1\n    }\n```\n\n## Web Search Fallback (CRAG)\n\n```python\ndef web_search(state: RAGState) -> dict:\n    \"\"\"Fallback to web search when document",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "aggregate-patterns": {
    "name": "aggregate-patterns",
    "description": "DDD aggregate design patterns for consistency boundaries and invariants. Use when designing aggregate roots, enforcing business invariants, handling cross-aggregate references, or optimizing aggregate size.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ddd",
      "aggregate",
      "consistency",
      "invariants",
      "domain-modeling",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "aggregate-sizing.md",
        "eventual-consistency.md",
        "invariant-enforcement.md"
      ],
      "scripts": [
        "aggregate-root-template.py"
      ],
      "checklists": [
        "aggregate-checklist.md"
      ]
    },
    "content": "# Aggregate Design Patterns\n\nDesign aggregates with clear boundaries, invariants, and consistency guarantees.\n\n## Overview\n\n- Defining transactional consistency boundaries\n- Enforcing business invariants across related entities\n- Designing aggregate roots and their children\n- Handling references between aggregates\n- Optimizing aggregate size for performance\n\n## Core Concepts\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                 ORDER AGGREGATE                         │\n│  ┌─────────────────────────────────────────────────┐   │\n│  │         Order (Aggregate Root)                   │   │\n│  │  • id: UUID (UUIDv7)                            │   │\n│  │  • customer_id: UUID (reference by ID!)         │   │\n│  │  • status: OrderStatus                          │   │\n│  └─────────────────────────────────────────────────┘   │\n│           │                      │                      │\n│  ┌────────────────┐    ┌────────────────┐              │\n│  │  OrderItem     │    │  OrderItem     │              │\n│  │  (child)       │    │  (child)       │              │\n│  └────────────────┘    └────────────────┘              │\n│                                                         │\n│  INVARIANTS enforced by root:                          │\n│  • Total = sum of items                                │\n│  • Max 100 items per order                             │\n│  • Cannot modify after shipped                         │\n└─────────────────────────────────────────────────────────┘\n```\n\n### Four Rules\n\n1. **Root controls access** - External code only references aggregate root\n2. **Transactional boundary** - One aggregate per transaction\n3. **Reference by ID** - Never hold references to other aggregates\n4. **Invariants enforced** - Root ensures all business rules\n\n## Quick Reference\n\n```python\nfrom dataclasses import dataclass, field\nfrom uuid import UUID\nfrom uuid_utils import uuid7\n\n@dataclass\nclass OrderAggregate:\n    \"\"\"Aggregate root with invariant enforcement.\"\"\"\n\n    id: UUID = field(default_factory=uuid7)\n    customer_id: UUID  # Reference by ID, not Customer object!\n    _items: list[\"OrderItem\"] = field(default_factory=list)\n    status: str = \"draft\"\n\n    MAX_ITEMS = 100\n\n    def add_item(self, product_id: UUID, quantity: int, price: Money) -> None:\n        \"\"\"Add item with invariant checks.\"\"\"\n        self._ensure_modifiable()\n        if len(self._items) >= self.MAX_ITEMS:\n            raise DomainError(\"Max items exceeded\")\n        self._items.append(OrderItem(product_id, quantity, price))\n\n    def _ensure_modifiable(self) -> None:\n        if self.status != \"draft\":\n            raise DomainError(f\"Cannot modify {self.status} order\")\n```\n\nSee [aggregate-root-template.py](scripts/aggregate-root-template.py) for complete implementation.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Aggregate size | Small (< 20 children), split if larger |\n| Cross-aggregate refs | Always by ID, never by object |\n| Consis",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "alembic-migrations": {
    "name": "alembic-migrations",
    "description": "Alembic migration patterns for SQLAlchemy 2.0 async. Use when creating database migrations, managing schema versions, handling zero-downtime deployments, or implementing reversible database changes.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "alembic",
      "migrations",
      "sqlalchemy",
      "database",
      "schema",
      "python",
      "async"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "database-engineer",
    "structure": {
      "references": [
        "alembic-advanced.md"
      ],
      "scripts": [
        "create-migration.md",
        "detect-model-changes.py",
        "migration-template.py"
      ],
      "checklists": [
        "migration-checklist.md"
      ]
    },
    "content": "# Alembic Migration Patterns ()\n\nDatabase migration management with Alembic for SQLAlchemy 2.0 async applications.\n\n## Overview\n\n- Creating or modifying database tables and columns\n- Auto-generating migrations from SQLAlchemy models\n- Implementing zero-downtime schema changes\n- Rolling back or managing migration history\n- Adding indexes on large production tables\n- Setting up Alembic with async PostgreSQL (asyncpg)\n\n## Quick Reference\n\n### Initialize Alembic (Async Template)\n\n```bash\n# Initialize with async template for asyncpg\nalembic init -t async migrations\n\n# Creates:\n# - alembic.ini\n# - migrations/env.py (async-ready)\n# - migrations/script.py.mako\n# - migrations/versions/\n```\n\n### Async env.py Configuration\n\n```python\n# migrations/env.py\nimport asyncio\nfrom logging.config import fileConfig\n\nfrom sqlalchemy import pool\nfrom sqlalchemy.engine import Connection\nfrom sqlalchemy.ext.asyncio import async_engine_from_config\n\nfrom alembic import context\n\n# Import your models' Base for autogenerate\nfrom app.models.base import Base\n\nconfig = context.config\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\ntarget_metadata = Base.metadata\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode - generates SQL.\"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n    with context.begin_transaction():\n        context.run_migrations()\n\ndef do_run_migrations(connection: Connection) -> None:\n    context.configure(connection=connection, target_metadata=target_metadata)\n    with context.begin_transaction():\n        context.run_migrations()\n\nasync def run_async_migrations() -> None:\n    \"\"\"Run migrations in 'online' mode with async engine.\"\"\"\n    connectable = async_engine_from_config(\n        config.get_section(config.config_ini_section, {}),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\ndef run_migrations_online() -> None:\n    \"\"\"Entry point for online migrations.\"\"\"\n    asyncio.run(run_async_migrations())\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n```\n\n### Migration Template\n\n```python\n\"\"\"Add users table.\n\nRevision ID: abc123\nRevises: None\nCreate Date: -01-17 10:00:00.000000\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects.postgresql import UUID\n\nrevision = 'abc123'\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\ndef upgrade() -> None:\n    op.create_table(\n        'users',\n        sa.Column('id', UUID(as_uuid=True), primary_key=True),\n        sa.Column('email', sa.String(255), nullable=False),\n        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now()),\n    )\n    op.c",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "database-engineer"
    ]
  },
  "alternative-agent-frameworks": {
    "name": "alternative-agent-frameworks",
    "description": "Multi-agent frameworks beyond LangGraph. CrewAI crews, Microsoft Agent Framework, OpenAI Agents SDK, GPT-5.2-Codex. Use when building multi-agent systems, choosing frameworks.",
    "version": "1.1.0",
    "author": "OrchestKit",
    "tags": [
      "crewai",
      "autogen",
      "openai-agents",
      "microsoft",
      "multi-agent",
      "orchestration",
      "gpt-5.2-codex"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "crewai-patterns.md",
        "framework-comparison.md",
        "gpt-5-2-codex.md",
        "microsoft-agent-framework.md",
        "openai-agents-sdk.md"
      ],
      "scripts": [
        "crewai-crew.py",
        "openai-multi-agent.py"
      ],
      "checklists": [
        "framework-selection.md"
      ]
    },
    "content": "# Alternative Agent Frameworks\n\nMulti-agent frameworks beyond LangGraph for specialized use cases.\n\n## Framework Comparison\n\n| Framework | Best For | Key Features |  Status |\n|-----------|----------|--------------|-------------|\n| LangGraph 1.0.6 | Complex stateful workflows | Persistence, streaming, human-in-loop | Production |\n| CrewAI 1.8.x | Role-based collaboration | Flows, hierarchical crews, a2a, HITL | Production |\n| OpenAI Agents SDK 0.7.0 | OpenAI ecosystem | Handoffs, guardrails, MCPServerManager, Sessions | Production |\n| GPT-5.2-Codex | Long-horizon coding | Context compaction, project-scale, security | Production |\n| MS Agent Framework | Enterprise | AutoGen+SK merger, A2A, compliance | Public Preview |\n| AG2 | Open-source, flexible | Community fork of AutoGen | Active |\n\n## CrewAI Hierarchical Crew (1.8.x)\n\n```python\nfrom crewai import Agent, Crew, Task, Process\nfrom crewai.flow.flow import Flow, listen, start\n\n# Manager coordinates the team\nmanager = Agent(\n    role=\"Project Manager\",\n    goal=\"Coordinate team efforts and ensure project success\",\n    backstory=\"Experienced project manager skilled at delegation\",\n    allow_delegation=True,\n    memory=True,\n    verbose=True\n)\n\n# Specialist agents\nresearcher = Agent(\n    role=\"Researcher\",\n    goal=\"Provide accurate research and analysis\",\n    backstory=\"Expert researcher with deep analytical skills\",\n    allow_delegation=False,\n    verbose=True\n)\n\nwriter = Agent(\n    role=\"Writer\",\n    goal=\"Create compelling content\",\n    backstory=\"Skilled writer who creates engaging content\",\n    allow_delegation=False,\n    verbose=True\n)\n\n# Manager-led task\nproject_task = Task(\n    description=\"Create a comprehensive market analysis report\",\n    expected_output=\"Executive summary, analysis, recommendations\",\n    agent=manager\n)\n\n# Hierarchical crew\ncrew = Crew(\n    agents=[manager, researcher, writer],\n    tasks=[project_task],\n    process=Process.hierarchical,\n    manager_llm=\"gpt-5.2\",\n    memory=True,\n    verbose=True\n)\n\nresult = crew.kickoff()\n```\n\n## OpenAI Agents SDK Multi-Agent (0.7.0)\n\n```python\nfrom agents import Agent, Runner, handoff, RunConfig\nfrom agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n# Note: v0.7.0 adds MCPServerManager, opt-in nested handoffs, requires openai v2.x\n\n# Define specialized agents\nresearcher_agent = Agent(\n    name=\"researcher\",\n    instructions=f\"\"\"{RECOMMENDED_PROMPT_PREFIX}\nYou are a research specialist. Gather information and facts.\nWhen research is complete, hand off to the writer.\"\"\",\n    model=\"gpt-5.2\"\n)\n\nwriter_agent = Agent(\n    name=\"writer\",\n    instructions=f\"\"\"{RECOMMENDED_PROMPT_PREFIX}\nYou are a content writer. Create compelling content from research.\nWhen done, hand off to orchestrator for final review.\"\"\",\n    model=\"gpt-5.2\"\n)\n\n# Orchestrator with handoffs\norchestrator = Agent(\n    name=\"orchestrator\",\n    instructions=f\"\"\"{RECOMMENDED_PROMPT_PREFIX}\nYou coordinate research and writing tasks.\nHand off to researcher for inf",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "api-design-framework": {
    "name": "api-design-framework",
    "description": "Comprehensive API design patterns for REST, GraphQL, and gRPC. Use when designing APIs, creating endpoints, adding routes, implementing pagination, rate limiting, or authentication patterns.",
    "version": "1.2.0",
    "author": "AI Agent Hub",
    "tags": [
      "api",
      "rest",
      "graphql",
      "grpc",
      "backend",
      "documentation"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "frontend-integration.md",
        "graphql-api.md",
        "grpc-api.md",
        "rest-api.md",
        "rest-patterns.md"
      ],
      "assets": [
        "asyncapi-template.yaml",
        "openapi-template.yaml"
      ],
      "scripts": [
        "create-openapi-spec.md"
      ],
      "checklists": [
        "api-design-checklist.md"
      ]
    },
    "content": "# API Design Framework\n\nThis skill provides comprehensive guidance for designing robust, scalable, and developer-friendly APIs. Whether building REST, GraphQL, or gRPC services, this framework ensures consistency, usability, and maintainability.\n\n## Overview\n- Designing new API endpoints or services\n- Establishing API conventions for a team or organization\n- Reviewing API designs for consistency and best practices\n- Migrating or versioning existing APIs\n- Creating API documentation (OpenAPI, AsyncAPI)\n- Choosing between REST, GraphQL, or gRPC\n\n## API Design Principles\n\n### 1. Developer Experience First\nAPIs should be intuitive and self-documenting:\n- Clear, consistent naming conventions\n- Predictable behavior and responses\n- Comprehensive documentation\n- Helpful error messages\n\n### 2. Consistency Over Cleverness\nFollow established patterns rather than inventing new ones:\n- Standard HTTP methods and status codes (REST)\n- Conventional query structures (GraphQL)\n- Idiomatic proto definitions (gRPC)\n\n### 3. Evolution Without Breaking Changes\nDesign for change from day one:\n- API versioning strategy\n- Backward compatibility considerations\n- Deprecation policies\n- Migration paths\n\n### 4. Performance by Design\nConsider performance implications:\n- Pagination for large datasets\n- Filtering and partial responses\n- Caching strategies\n- Rate limiting\n\n---\n\n## Bundled Resources\n\n- `assets/openapi-template.yaml` - OpenAPI 3.1 specification template\n- `assets/asyncapi-template.yaml` - AsyncAPI specification template\n- `references/rest-api.md` - REST API design patterns\n- `references/graphql-api.md` - GraphQL API design patterns\n- `references/grpc-api.md` - gRPC API design patterns\n- `references/frontend-integration.md` - Frontend API integration patterns\n\n---\n\n## Protocol References\n\n### REST API Design\n**See: `references/rest-api.md`**\n\nKey topics covered:\n- Resource naming conventions (plural nouns, hierarchical relationships)\n- HTTP methods (GET, POST, PUT, PATCH, DELETE)\n- Status codes (2xx, 4xx, 5xx)\n- Request/response formats\n- Pagination (cursor-based vs offset-based)\n- Filtering, sorting, field selection\n- API versioning strategies\n- Rate limiting headers\n- Authentication patterns (Bearer, API Key)\n\n### GraphQL API Design\n**See: `references/graphql-api.md`**\n\nKey topics covered:\n- Schema design principles (nullable by default)\n- Connection pattern for lists (edges, nodes, pageInfo)\n- Input types for mutations\n- Query design patterns\n- Field-level error handling\n\n### gRPC API Design\n**See: `references/grpc-api.md`**\n\nKey topics covered:\n- Proto file structure\n- Service and message definitions\n- gRPC status codes mapping to HTTP equivalents\n\n### Frontend API Integration\n**See: `references/frontend-integration.md`**\n\nKey topics covered:\n- Runtime validation with Zod\n- Request interceptors with ky\n- Error enrichment pattern\n- TanStack Query integration\n\n---\n\n## Quick Reference: HTTP Status Codes\n\n| Code | Name | Use Case |\n|------|------|----------|\n| 200 |",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "documentation-specialist"
    ]
  },
  "api-versioning": {
    "name": "api-versioning",
    "description": "API versioning strategies including URL path, header, and content negotiation. Use when migrating v1 to v2, handling breaking changes, implementing deprecation or sunset policies, or managing backward compatibility.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "api",
      "versioning",
      "rest",
      "fastapi",
      "backward-compatibility"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "versioning-strategies.md"
      ],
      "scripts": [
        "fastapi-versioned-router.py"
      ],
      "checklists": [
        "versioning-checklist.md"
      ]
    },
    "content": "# API Versioning Strategies\n\nDesign APIs that evolve gracefully without breaking clients.\n\n## Strategy Comparison\n\n| Strategy | Example | Pros | Cons |\n|----------|---------|------|------|\n| URL Path | `/api/v1/users` | Simple, visible, cacheable | URL pollution |\n| Header | `X-API-Version: 1` | Clean URLs | Hidden, harder to test |\n| Query Param | `?version=1` | Easy testing | Messy, cache issues |\n| Content-Type | `Accept: application/vnd.api.v1+json` | RESTful | Complex |\n\n## URL Path Versioning (Recommended)\n\n### FastAPI Structure\n\n```\nbackend/app/\n├── api/\n│   ├── v1/\n│   │   ├── __init__.py\n│   │   ├── routes/\n│   │   │   ├── users.py\n│   │   │   └── analyses.py\n│   │   └── router.py\n│   ├── v2/\n│   │   ├── __init__.py\n│   │   ├── routes/\n│   │   │   ├── users.py      # Updated schemas\n│   │   │   └── analyses.py\n│   │   └── router.py\n│   └── router.py             # Combines all versions\n```\n\n### Router Setup\n\n```python\n# backend/app/api/router.py\nfrom fastapi import APIRouter\nfrom app.api.v1.router import router as v1_router\nfrom app.api.v2.router import router as v2_router\n\napi_router = APIRouter()\napi_router.include_router(v1_router, prefix=\"/v1\")\napi_router.include_router(v2_router, prefix=\"/v2\")\n\n# main.py\napp.include_router(api_router, prefix=\"/api\")\n```\n\n### Version-Specific Schemas\n\n```python\n# v1/schemas/user.py\nclass UserResponseV1(BaseModel):\n    id: str\n    name: str  # Single name field\n\n# v2/schemas/user.py\nclass UserResponseV2(BaseModel):\n    id: str\n    first_name: str  # Split into first/last\n    last_name: str\n    full_name: str   # Computed for convenience\n```\n\n### Shared Business Logic\n\n```python\n# services/user_service.py (version-agnostic)\nclass UserService:\n    async def get_user(self, user_id: str) -> User:\n        return await self.repo.get_by_id(user_id)\n\n# v1/routes/users.py\n@router.get(\"/{user_id}\", response_model=UserResponseV1)\nasync def get_user_v1(user_id: str, service: UserService = Depends()):\n    user = await service.get_user(user_id)\n    return UserResponseV1(id=user.id, name=user.full_name)\n\n# v2/routes/users.py\n@router.get(\"/{user_id}\", response_model=UserResponseV2)\nasync def get_user_v2(user_id: str, service: UserService = Depends()):\n    user = await service.get_user(user_id)\n    return UserResponseV2(\n        id=user.id,\n        first_name=user.first_name,\n        last_name=user.last_name,\n        full_name=f\"{user.first_name} {user.last_name}\",\n    )\n```\n\n## Header-Based Versioning\n\n```python\nfrom fastapi import Header, HTTPException\n\nasync def get_api_version(\n    x_api_version: str = Header(default=\"1\", alias=\"X-API-Version\")\n) -> int:\n    try:\n        version = int(x_api_version)\n        if version not in [1, 2]:\n            raise ValueError()\n        return version\n    except ValueError:\n        raise HTTPException(400, \"Invalid API version\")\n\n@router.get(\"/users/{user_id}\")\nasync def get_user(\n    user_id: str,\n    version: int = Depends(get_api_version),\n    service: UserService = Depends(),\n",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "architecture-decision-record": {
    "name": "architecture-decision-record",
    "description": "Use this skill when documenting significant architectural decisions. Provides ADR templates following the Nygard format with sections for context, decision, consequences, and alternatives. Use when writing ADRs, recording decisions, or evaluating options.",
    "version": "2.0.0",
    "author": "AI Agent Hub",
    "tags": [
      "architecture",
      "documentation",
      "decision-making",
      "backend"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "adr-best-practices.md"
      ],
      "assets": [
        "adr-template.md"
      ],
      "scripts": [
        "adr-frontmatter.yaml",
        "adr-manager.py",
        "create-adr.md",
        "list-adrs.py"
      ],
      "checklists": [
        "adr-review-checklist.md"
      ]
    },
    "content": "# Architecture Decision Records\nArchitecture Decision Records (ADRs) are lightweight documents that capture important architectural decisions along with their context and consequences. This skill provides templates, examples, and best practices for creating and maintaining ADRs in your projects.\n\n## Overview\n- Making significant technology choices (databases, frameworks, cloud providers)\n- Designing system architecture or major components\n- Establishing patterns or conventions for the team\n- Evaluating trade-offs between multiple approaches\n- Documenting decisions that will impact future development\n\n## Why ADRs Matter\n\nADRs serve as architectural memory for your team:\n- **Context Preservation**: Capture why decisions were made, not just what was decided\n- **Onboarding**: Help new team members understand architectural rationale\n- **Prevent Revisiting**: Avoid endless debates about settled decisions\n- **Track Evolution**: See how architecture evolved over time\n- **Accountability**: Clear ownership and decision timeline\n\n## ADR Format (Nygard Template)\n\nEach ADR should follow this structure:\n\n### 1. Title\nFormat: `ADR-####: [Decision Title]`\nExample: `ADR-0001: Adopt Microservices Architecture`\n\n### 2. Status\nCurrent state of the decision:\n- **Proposed**: Under consideration\n- **Accepted**: Decision approved and being implemented\n- **Superseded**: Replaced by a later decision (reference ADR number)\n- **Deprecated**: No longer recommended but not yet replaced\n- **Rejected**: Considered but not adopted (document why)\n\n### 3. Context\n**What to include:**\n- Problem statement or opportunity\n- Business/technical constraints\n- Stakeholder requirements\n- Current state of the system\n- Forces at play (conflicting concerns)\n\n### 4. Decision\n**What to include:**\n- The choice being made\n- Key principles or patterns to follow\n- What will change as a result\n- Who is responsible for implementation\n\n**Be specific and actionable:**\n- ✅ \"We will adopt microservices architecture using Node.js with Express\"\n- ❌ \"We will consider using microservices\"\n\n### 5. Consequences\n**What to include:**\n- Positive outcomes (benefits)\n- Negative outcomes (costs, risks, trade-offs)\n- Neutral outcomes (things that change but aren't clearly better/worse)\n\n### 6. Alternatives Considered\n**Document at least 2 alternatives:**\n\n**For each alternative, explain:**\n- What it was\n- Why it was considered\n- Why it was not chosen\n\n### 7. References (Optional)\nLinks to relevant resources:\n- Meeting notes or discussion threads\n- Related ADRs\n- External research or articles\n- Proof of concept implementations\n\n## ADR Lifecycle\n\n```\nProposed → Accepted → [Implemented] → (Eventually) Superseded/Deprecated\n          ↓\n      Rejected\n```\n\n## Best Practices\n\n### 1. **Keep ADRs Immutable**\nOnce accepted, don't edit ADRs. Create new ADRs that supersede old ones.\n- ✅ Create ADR-0015 that supersedes ADR-0003\n- ❌ Update ADR-0003 with new decisions\n\n### 2. **Write in Present Tense**\nADRs are historical records ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "documentation-specialist",
      "git-operations-engineer",
      "system-design-reviewer"
    ]
  },
  "ascii-visualizer": {
    "name": "ascii-visualizer",
    "description": "Use when visualizing architecture, data flows, or system diagrams in text. Creates ASCII visualizer diagrams for plans, workflows, and structures.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ascii",
      "visualization",
      "diagrams",
      "architecture",
      "2025"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "architecture-diagrams.md",
        "comparisons.md",
        "file-trees.md",
        "workflows.md"
      ],
      "scripts": [
        "diagram-templates.md"
      ],
      "checklists": [
        "diagram-creation-checklist.md"
      ]
    },
    "content": "# ASCII Visualizer Skill\n\nCreate clear ASCII visualizations for explaining complex concepts.\n\n## Box-Drawing Characters\n\n**IMPORTANT:** Use a fixed-width (monospace) font for proper rendering.\n\n```\n┌─┐│└─┘  Standard weight\n┏━┓┃┗━┛  Heavy weight\n├─┤┬┴    Connectors\n╔═╗║╚═╝  Double lines\n```\n\n## Quick Examples\n\n### Architecture\n```\n┌──────────────┐      ┌──────────────┐\n│   Frontend   │─────▶│   Backend    │\n│   React 19   │      │   FastAPI    │\n└──────────────┘      └───────┬──────┘\n                              │\n                              ▼\n                      ┌──────────────┐\n                      │  PostgreSQL  │\n                      └──────────────┘\n```\n\n### Progress\n```\n[████████░░] 80% Complete\n✅ Design    (2 days)\n✅ Backend   (5 days)\n🔄 Frontend  (3 days)\n⏳ Testing   (pending)\n```\n\nSee `references/` for complete patterns.\n\n## Related Skills\n\n- `architecture-decision-record` - Document decisions that ASCII diagrams help visualize\n- `brainstorming` - Use visualizations to explore and communicate ideas\n- `explore` - Visualize codebase structure during exploration\n\n## Capability Details\n\n### architecture-diagrams\n**Keywords:** architecture, diagram, system design, components, flow\n**Solves:**\n- How do I visualize system architecture?\n- Show component relationships with ASCII\n- Explain system design visually\n- Create architecture diagrams in documentation\n\n### workflows\n**Keywords:** workflow, process, steps, pipeline, flowchart\n**Solves:**\n- How do I visualize process flow?\n- Show step-by-step workflow with ASCII\n- Explain pipeline stages visually\n- Document multi-agent workflows\n\n### comparisons\n**Keywords:** compare, vs, before after, metrics, changes\n**Solves:**\n- How do I compare two options visually?\n- Show before/after metrics\n- Display progress comparison\n- Visualize A/B testing results\n\n### file-trees\n**Keywords:** file tree, directory, structure, folder hierarchy\n**Solves:**\n- How do I show directory structure?\n- Visualize file hierarchy with ASCII\n- Explain codebase organization\n- Document project structure\n\n### progress-tracking\n**Keywords:** progress, status, completion, percentage, metrics\n**Solves:**\n- How do I show progress visually?\n- Create progress bars with ASCII\n- Display completion status\n- Track task completion metrics",
    "contentTruncated": false,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": [
      "system-design-reviewer"
    ]
  },
  "assess": {
    "name": "assess",
    "description": "Assesses and rates quality 0-10 with pros/cons analysis. Use when evaluating code, designs, or approaches.",
    "version": "1.1.0",
    "author": "OrchestKit",
    "tags": [
      "assessment",
      "evaluation",
      "quality",
      "comparison",
      "pros-cons",
      "rating"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Read",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "TaskList",
      "mcp__memory__search_nodes",
      "Bash"
    ],
    "skills": [
      "code-review-playbook",
      "assess-complexity",
      "quality-gates",
      "architecture-decision-record",
      "memory"
    ],
    "agent": null,
    "structure": {
      "references": [
        "alternative-analysis.md",
        "improvement-prioritization.md",
        "scoring-rubric.md"
      ],
      "assets": [
        "assessment-report.md",
        "comparison-table.md"
      ],
      "checklists": [
        "assessment-checklist.md"
      ]
    },
    "content": "# Assess\n\nComprehensive assessment skill for answering \"is this good?\" with structured evaluation, scoring, and actionable recommendations.\n\n## Quick Start\n\n```bash\n/assess backend/app/services/auth.py\n/assess our caching strategy\n/assess the current database schema\n/assess frontend/src/components/Dashboard\n```\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify assessment dimensions:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What dimensions to assess?\",\n    \"header\": \"Dimensions\",\n    \"options\": [\n      {\"label\": \"Full assessment (Recommended)\", \"description\": \"All dimensions: quality, maintainability, security, performance\"},\n      {\"label\": \"Code quality only\", \"description\": \"Readability, complexity, best practices\"},\n      {\"label\": \"Security focus\", \"description\": \"Vulnerabilities, attack surface, compliance\"},\n      {\"label\": \"Quick score\", \"description\": \"Just give me a 0-10 score with brief notes\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full assessment**: All 7 phases, parallel agents\n- **Code quality only**: Skip security and performance phases\n- **Security focus**: Prioritize security-auditor agent\n- **Quick score**: Single pass, brief output\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — assessors cross-validate scores) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Full assessment with 6 dimension agents → recommend **Agent Teams**; Quick score or single-dimension → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Score calibration | Lead normalizes independently | Assessors discuss disagreements |\n| Cross-dimension findings | Lead correlates after completion | Security assessor alerts performance assessor of overlap |\n| Cost | ~200K tokens | ~500K tokens |\n| Best for | Quick scores, single dimension | Full multi-dimensional assessment |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining assessment.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main assessment task\nTaskCreate(\n  subject=\"Assess: {target}\",\n  description=\"Comprehensive evaluation with quality scores and recommendations\",\n  activeForm=\"Assessing {target}\"\n)\n\n# Create subtasks for 7-phase process\nfor phase in [\"Understand target\", \"Rate quality\", \"List pros/cons\",\n              \"Compare alternatives\", \"Generate suggestions\",\n              \"Estimate effort\", \"Compile report\"]:\n    TaskCreate(subject=phase, activeForm=f\"{phase}ing\")\n```\n\n---\n\n## What This Skill Answers\n\n| Question | How It's Answered |\n|----------|-------------------|\n| \"Is this good?\" | Quality score 0-10 with reasoning |\n| \"What are the trade-offs?\" | Structured pros/cons list |\n| \"Should we change this?\" | Improvement suggestions with effort |\n| \"What are th",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "assess-complexity": {
    "name": "assess-complexity",
    "description": "Assesses task complexity with codebase metrics. Use when determining if a task needs breakdown.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "quality-gates",
      "planning",
      "complexity",
      "assessment"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash",
      "Task",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "quality-gates",
      "brainstorming",
      "memory"
    ],
    "agent": null,
    "structure": {
      "scripts": [
        "analyze-codebase.sh"
      ]
    },
    "content": "# Assess Complexity\n\nEvaluate task complexity using automated codebase analysis before starting implementation work.\n\n## Overview\n\n- Determining if a task is ready for implementation\n- Deciding whether to break down a large task\n- Estimating effort before committing to work\n- Identifying high-risk areas in the codebase\n- Planning sprint work with complexity scores\n\n## Usage\n\nAssess complexity for: **$ARGUMENTS**\n\n## Step 1: Gather Metrics\n\nRun the analysis script to collect codebase metrics:\n\n!`./scripts/analyze-codebase.sh $ARGUMENTS`\n\n## Step 2: Assess Each Criterion\n\nScore each criterion from 1-5 based on the metrics and your understanding:\n\n### 1. Lines of Code\n\n| Range | Score |\n|-------|-------|\n| < 50 lines | 1 |\n| 50-200 lines | 2 |\n| 200-500 lines | 3 |\n| 500-1500 lines | 4 |\n| 1500+ lines | 5 |\n\n### 2. Time Estimate\n\n| Duration | Score |\n|----------|-------|\n| < 30 minutes | 1 |\n| 30 min - 2 hours | 2 |\n| 2-8 hours | 3 |\n| 8-24 hours (1-3 days) | 4 |\n| 24+ hours (3+ days) | 5 |\n\n### 3. Number of Files\n\n| Count | Score |\n|-------|-------|\n| 1 file | 1 |\n| 2-3 files | 2 |\n| 4-10 files | 3 |\n| 11-25 files | 4 |\n| 26+ files | 5 |\n\n### 4. Dependencies Count\n\n| Unique Modules | Score |\n|----------------|-------|\n| 0 dependencies | 1 |\n| 1 dependency | 2 |\n| 2-3 dependencies | 3 |\n| 4-6 dependencies | 4 |\n| 7+ dependencies | 5 |\n\n### 5. Unknowns/Uncertainty\n\n| Level | Score |\n|-------|-------|\n| No unknowns - Everything clear | 1 |\n| Minimal - 1-2 minor questions | 2 |\n| Some - Several questions, researchable | 3 |\n| Significant - Many questions, requires exploration | 4 |\n| Many - Unclear scope, needs prototyping | 5 |\n\n### 6. Cross-Cutting Concerns\n\n| Scope | Score |\n|-------|-------|\n| Isolated change - Single module | 1 |\n| Minor integration - 2-3 modules | 2 |\n| Multiple integrations - 4-5 modules | 3 |\n| Cross-cutting - Affects many modules | 4 |\n| Architectural - System-wide impact | 5 |\n\n### 7. Risk Level\n\n| Risk | Score |\n|------|-------|\n| No risk - Trivial change | 1 |\n| Low risk - Well-understood pattern | 2 |\n| Medium risk - Some complexity, testable | 3 |\n| High risk - Complex logic, many edge cases | 4 |\n| Very high risk - Mission-critical, high stakes | 5 |\n\n## Step 3: Calculate Total Score\n\n**Sum all scores:** _____ / 35\n\n**Calculate average:** Total / 7 = _____\n\n### Complexity Level Assignment\n\n| Average Score | Level | Classification |\n|---------------|-------|----------------|\n| 1.0 - 1.4 | 1 | Trivial |\n| 1.5 - 2.4 | 2 | Simple |\n| 2.5 - 3.4 | 3 | Moderate |\n| 3.5 - 4.4 | 4 | Complex |\n| 4.5 - 5.0 | 5 | Very Complex |\n\n## Step 4: Decision\n\n### Level 1-3: Proceed\n\nTask is manageable. Continue with implementation.\n\n### Level 4-5: Break Down\n\nTask is too complex. Decompose into subtasks and reassess each part.\n\n## Output Format\n\nProvide assessment in this format:\n\n```\n## Complexity Assessment: [Target]\n\n**Date:** YYYY-MM-DD\n**Assessor:** [Agent Name]\n\n### Scores\n| Criterion | Score |\n|-----------|-------|\n| Lines of Code | X/",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "asyncio-advanced": {
    "name": "asyncio-advanced",
    "description": "Python asyncio patterns with TaskGroup, structured concurrency, and modern 3.11+ features. Use when implementing concurrent operations, async context managers, or high-performance async services.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "asyncio",
      "python",
      "concurrency",
      "taskgroup",
      "structured-concurrency"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "semaphore-patterns.md",
        "taskgroup-patterns.md"
      ],
      "scripts": [
        "async-service-template.py"
      ],
      "checklists": [
        "async-implementation-checklist.md"
      ]
    },
    "content": "# Asyncio Advanced Patterns ()\n\nModern Python asyncio patterns using structured concurrency, TaskGroup, and Python 3.11+ features.\n\n## Overview\n\n- Implementing concurrent HTTP requests or database queries\n- Building async services with proper cancellation handling\n- Managing multiple concurrent tasks with error propagation\n- Rate limiting async operations with semaphores\n- Bridging sync code to async contexts\n\n## Quick Reference\n\n### TaskGroup (Replaces gather)\n\n```python\nimport asyncio\n\nasync def fetch_user_data(user_id: str) -> dict:\n    \"\"\"Fetch user data concurrently - all tasks complete or all cancelled.\"\"\"\n    async with asyncio.TaskGroup() as tg:\n        user_task = tg.create_task(fetch_user(user_id))\n        orders_task = tg.create_task(fetch_orders(user_id))\n        preferences_task = tg.create_task(fetch_preferences(user_id))\n\n    # All tasks guaranteed complete here\n    return {\n        \"user\": user_task.result(),\n        \"orders\": orders_task.result(),\n        \"preferences\": preferences_task.result(),\n    }\n```\n\n### TaskGroup with Timeout\n\n```python\nasync def fetch_with_timeout(urls: list[str], timeout_sec: float = 30) -> list[dict]:\n    \"\"\"Fetch all URLs with overall timeout - structured concurrency.\"\"\"\n    results = []\n\n    async with asyncio.timeout(timeout_sec):\n        async with asyncio.TaskGroup() as tg:\n            tasks = [tg.create_task(fetch_url(url)) for url in urls]\n\n    return [t.result() for t in tasks]\n```\n\n### Semaphore for Concurrency Limiting\n\n```python\nclass RateLimitedClient:\n    \"\"\"HTTP client with concurrency limiting.\"\"\"\n\n    def __init__(self, max_concurrent: int = 10):\n        self._semaphore = asyncio.Semaphore(max_concurrent)\n        self._session: aiohttp.ClientSession | None = None\n\n    async def fetch(self, url: str) -> dict:\n        async with self._semaphore:  # Limit concurrent requests\n            async with self._session.get(url) as response:\n                return await response.json()\n\n    async def fetch_many(self, urls: list[str]) -> list[dict]:\n        async with asyncio.TaskGroup() as tg:\n            tasks = [tg.create_task(self.fetch(url)) for url in urls]\n        return [t.result() for t in tasks]\n```\n\n### Exception Group Handling\n\n```python\nasync def process_batch(items: list[dict]) -> tuple[list[dict], list[Exception]]:\n    \"\"\"Process batch, collecting both successes and failures.\"\"\"\n    results = []\n    errors = []\n\n    try:\n        async with asyncio.TaskGroup() as tg:\n            tasks = [tg.create_task(process_item(item)) for item in items]\n    except* ValueError as eg:\n        # Handle specific exception types from ExceptionGroup\n        errors.extend(eg.exceptions)\n    except* Exception as eg:\n        errors.extend(eg.exceptions)\n    else:\n        results = [t.result() for t in tasks]\n\n    return results, errors\n```\n\n### Sync-to-Async Bridge\n\n```python\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\n# For CPU-bound or blocking sync code\nasync def run_blocking_operat",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "event-driven-architect",
      "python-performance-engineer"
    ]
  },
  "audio-language-models": {
    "name": "audio-language-models",
    "description": "Gemini Live API, Grok Voice Agent, GPT-4o-Transcribe, AssemblyAI patterns for real-time voice, speech-to-text, and TTS. Use when implementing voice agents, audio transcription, or conversational AI.",
    "version": "1.1.0",
    "author": "OrchestKit",
    "tags": [
      "audio",
      "multimodal",
      "gemini-live",
      "grok-voice",
      "whisper",
      "tts",
      "speech",
      "voice-agent"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "multimodal-specialist",
    "structure": {
      "references": [
        "streaming-audio.md",
        "tts-patterns.md",
        "whisper-integration.md"
      ],
      "checklists": [
        "implementation.md"
      ]
    },
    "content": "# Audio Language Models ()\n\nBuild real-time voice agents and audio processing using the latest native speech-to-speech models.\n\n## Overview\n\n- Real-time voice assistants and agents\n- Live conversational AI (phone agents, support bots)\n- Audio transcription with speaker diarization\n- Multilingual voice interactions\n- Text-to-speech generation\n- Voice-to-voice translation\n\n## Model Comparison (January )\n\n### Real-Time Voice (Speech-to-Speech)\n\n| Model | Latency | Languages | Price | Best For |\n|-------|---------|-----------|-------|----------|\n| **Grok Voice Agent** | <1s TTFA | 100+ | $0.05/min | Fastest, #1 Big Bench |\n| **Gemini Live API** | Low | 24 (30 voices) | Usage-based | Emotional awareness |\n| **OpenAI Realtime** | ~1s | 50+ | $0.10/min | Ecosystem integration |\n\n### Speech-to-Text Only\n\n| Model | WER | Latency | Best For |\n|-------|-----|---------|----------|\n| **Gemini 2.5 Pro** | ~5% | Medium | 9.5hr audio, diarization |\n| **GPT-4o-Transcribe** | ~7% | Medium | Accuracy + accents |\n| **AssemblyAI Universal-2** | 8.4% | 200ms | Best features |\n| **Deepgram Nova-3** | ~18% | <300ms | Lowest latency |\n| **Whisper Large V3** | 7.4% | Slow | Self-host, 99+ langs |\n\n## Grok Voice Agent API (xAI) - Fastest\n\n```python\nimport asyncio\nimport websockets\nimport json\n\nasync def grok_voice_agent():\n    \"\"\"Real-time voice agent with Grok - #1 on Big Bench Audio.\n\n    Features:\n    - <1 second time-to-first-audio (5x faster than competitors)\n    - Native speech-to-speech (no transcription intermediary)\n    - 100+ languages, $0.05/min\n    - OpenAI Realtime API compatible\n    \"\"\"\n    uri = \"wss://api.x.ai/v1/realtime\"\n    headers = {\"Authorization\": f\"Bearer {XAI_API_KEY}\"}\n\n    async with websockets.connect(uri, extra_headers=headers) as ws:\n        # Configure session\n        await ws.send(json.dumps({\n            \"type\": \"session.update\",\n            \"session\": {\n                \"model\": \"grok-4-voice\",\n                \"voice\": \"Aria\",  # or \"Eve\", \"Leo\"\n                \"instructions\": \"You are a helpful voice assistant.\",\n                \"input_audio_format\": \"pcm16\",\n                \"output_audio_format\": \"pcm16\",\n                \"turn_detection\": {\"type\": \"server_vad\"}\n            }\n        }))\n\n        # Stream audio in/out\n        async def send_audio(audio_stream):\n            async for chunk in audio_stream:\n                await ws.send(json.dumps({\n                    \"type\": \"input_audio_buffer.append\",\n                    \"audio\": base64.b64encode(chunk).decode()\n                }))\n\n        async def receive_audio():\n            async for message in ws:\n                data = json.loads(message)\n                if data[\"type\"] == \"response.audio.delta\":\n                    yield base64.b64decode(data[\"delta\"])\n\n        return send_audio, receive_audio\n\n# Expressive voice with auditory cues\nasync def expressive_response(ws, text: str):\n    \"\"\"Use auditory cues for natural speech.\"\"\"\n    # Supports: [whisper], [sigh], [laugh], [pause]\n    ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "multimodal-specialist"
    ]
  },
  "audio-mixing-patterns": {
    "name": "audio-mixing-patterns",
    "description": "ffmpeg audio mixing patterns for video production. Use when mixing narration with music, implementing ducking, or balancing volume levels for demos",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "audio",
      "ffmpeg",
      "mixing",
      "ducking",
      "narration",
      "music"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "ducking-patterns.md",
        "ffmpeg-filters.md",
        "volume-balancing.md"
      ]
    },
    "content": "# Audio Mixing Patterns\n\nComprehensive guide to audio mixing for video production using ffmpeg. Covers narration/music balancing, automatic ducking, timing control, and loudness normalization.\n\n## Core Principle\n\n**Quality Audio = Clear Narration + Supportive Music + Appropriate Levels**\n\nThe human voice occupies 85-255 Hz (fundamental) with harmonics up to 8kHz. Music must support, not compete.\n\n## Volume Balancing Formula\n\n```\nStandard Video Mix Ratios:\n--------------------------\nNarration:  100% (reference level)\nMusic:      15-20% of narration level\nSFX:        70-100% of narration level (contextual)\n\ndB Relationships:\n-----------------\nNarration:  -14 dB LUFS (dialogue standard)\nMusic bed:  -30 to -35 dB LUFS (under narration)\nMusic only: -16 dB LUFS (no narration sections)\nSFX:        -18 to -20 dB LUFS\n```\n\n### Volume Multiplier Quick Reference\n\n| Ratio | Multiplier | Use Case |\n|-------|------------|----------|\n| 100% | 1.0 | Full volume (narration) |\n| 70% | 0.7 | Prominent SFX |\n| 50% | 0.5 | Equal blend |\n| 30% | 0.3 | Noticeable background |\n| 20% | 0.2 | Subtle bed (recommended music) |\n| 15% | 0.15 | Minimal presence |\n| 10% | 0.1 | Barely audible |\n\n## Basic ffmpeg Mixing Commands\n\n### Two-Track Mix (Narration + Music)\n\n```bash\n# Basic mix: narration at full, music at 15%\nffmpeg -i narration.mp3 -i music.mp3 \\\n  -filter_complex \"[0:a]volume=1.0[narr];[1:a]volume=0.15[music];[narr][music]amix=inputs=2:duration=first\" \\\n  -c:a aac -b:a 192k output.m4a\n```\n\n### Three-Track Mix (Narration + Music + SFX)\n\n```bash\nffmpeg -i narration.mp3 -i music.mp3 -i sfx.mp3 \\\n  -filter_complex \"\\\n    [0:a]volume=1.0[narr];\\\n    [1:a]volume=0.15[music];\\\n    [2:a]volume=0.7[sfx];\\\n    [narr][music][sfx]amix=inputs=3:duration=first:weights='3 1 2'\" \\\n  -c:a aac -b:a 192k output.m4a\n```\n\n## Timing with adelay Filter\n\nThe `adelay` filter positions audio at precise timestamps.\n\n### Syntax\n\n```bash\nadelay=delays[|delays...][,all=1]\n# delays: milliseconds or samples (with 'S' suffix)\n# all=1: apply same delay to all channels\n```\n\n### Position Music at Specific Time\n\n```bash\n# Start music at 5 seconds\nffmpeg -i narration.mp3 -i music.mp3 \\\n  -filter_complex \"\\\n    [0:a]volume=1.0[narr];\\\n    [1:a]adelay=5000|5000,volume=0.15[music];\\\n    [narr][music]amix=inputs=2:duration=first\" \\\n  output.m4a\n```\n\n### Multiple Timed Audio Cues\n\n```bash\n# Narration starts at 0, music at 2s, SFX at 5.5s\nffmpeg -i narration.mp3 -i music.mp3 -i sfx.wav \\\n  -filter_complex \"\\\n    [0:a]volume=1.0[narr];\\\n    [1:a]adelay=2000|2000,volume=0.15[music];\\\n    [2:a]adelay=5500|5500,volume=0.7[sfx];\\\n    [narr][music][sfx]amix=inputs=3:duration=longest\" \\\n  output.m4a\n```\n\n## Audio Ducking\n\nAutomatically lower music when speech is present.\n\n### Simple Sidechain Compression (Ducking)\n\n```bash\nffmpeg -i narration.mp3 -i music.mp3 \\\n  -filter_complex \"\\\n    [0:a]asplit=2[narr][sc];\\\n    [1:a][sc]sidechaincompress=threshold=0.02:ratio=10:attack=50:release=500[ducked];\\\n    [narr][ducked]am",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "audit-full": {
    "name": "audit-full",
    "description": "Full-codebase audit using 1M context window. Security, architecture, and dependency analysis in a single pass. Use when you need whole-project analysis.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "architecture",
      "audit",
      "dependencies",
      "1m-context",
      "cross-file"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Read",
      "Grep",
      "Glob",
      "Bash",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "TaskList",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "security-scanning",
      "defense-in-depth",
      "owasp-top-10",
      "clean-architecture",
      "quality-gates"
    ],
    "agent": null,
    "structure": {
      "references": [
        "architecture-review-guide.md",
        "dependency-audit-guide.md",
        "security-audit-guide.md",
        "token-estimation.md"
      ],
      "assets": [
        "audit-report-template.md",
        "severity-matrix.md"
      ],
      "scripts": [
        "estimate-tokens.sh"
      ],
      "checklists": [
        "audit-completion.md"
      ]
    },
    "content": "# Full-Codebase Audit\n\nSingle-pass whole-project analysis leveraging Opus 4.6's extended context window. Loads entire codebases (~50K LOC) into context for cross-file vulnerability detection, architecture review, and dependency analysis.\n\n## Quick Start\n\n```bash\n/audit-full                          # Full audit (all modes)\n/audit-full security                 # Security-focused audit\n/audit-full architecture             # Architecture review\n/audit-full dependencies             # Dependency audit\n```\n\n> **Opus 4.6**: Uses `complexity: max` for extended thinking across entire codebases. 1M context (beta, Tier 4+) enables cross-file reasoning that chunked approaches miss.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify audit scope:\n\n```python\nAskUserQuestion(\n  questions=[\n    {\n      \"question\": \"What type of audit do you want to run?\",\n      \"header\": \"Audit mode\",\n      \"options\": [\n        {\"label\": \"Full audit (Recommended)\", \"description\": \"Security + architecture + dependencies in one pass\"},\n        {\"label\": \"Security audit\", \"description\": \"Cross-file vulnerability analysis, data flow tracing, OWASP mapping\"},\n        {\"label\": \"Architecture review\", \"description\": \"Pattern consistency, coupling analysis, dependency violations\"},\n        {\"label\": \"Dependency audit\", \"description\": \"License compliance, CVE checking, version currency\"}\n      ],\n      \"multiSelect\": false\n    },\n    {\n      \"question\": \"What should be audited?\",\n      \"header\": \"Scope\",\n      \"options\": [\n        {\"label\": \"Entire codebase\", \"description\": \"Load all source files into context\"},\n        {\"label\": \"Specific directory\", \"description\": \"Focus on a subdirectory (e.g., src/api/)\"},\n        {\"label\": \"Changed files only\", \"description\": \"Audit only files changed vs main branch\"}\n      ],\n      \"multiSelect\": false\n    }\n  ]\n)\n```\n\n**Based on answers, adjust workflow:**\n- **Full audit**: All 3 domains, maximum context usage\n- **Security only**: Focus token budget on source + config files\n- **Architecture only**: Focus on module boundaries, imports, interfaces\n- **Dependency only**: Focus on lock files, manifests, import maps\n- **Changed files only**: Use `git diff --name-only main...HEAD` to scope\n\n---\n\n## CRITICAL: Task Management is MANDATORY\n\n```python\nTaskCreate(\n  subject=\"Full-codebase audit\",\n  description=\"Single-pass audit using extended context\",\n  activeForm=\"Running full-codebase audit\"\n)\n\n# Phase subtasks\nTaskCreate(subject=\"Estimate token budget and plan loading\", activeForm=\"Estimating token budget\")\nTaskCreate(subject=\"Load codebase into context\", activeForm=\"Loading codebase\")\nTaskCreate(subject=\"Run audit analysis\", activeForm=\"Analyzing codebase\")\nTaskCreate(subject=\"Generate audit report\", activeForm=\"Generating report\")\n```\n\n---\n\n## STEP 1: Estimate Token Budget\n\nBefore loading files, estimate whether the codebase fits in context.\n\n### Run Token Estimation\n\n```bash\n# Use the estimation script\nbash ${",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "auth-patterns": {
    "name": "auth-patterns",
    "description": "Authentication and authorization patterns. Use when implementing login flows, JWT tokens, session management, password security, OAuth 2.1, Passkeys/WebAuthn, or role-based access control.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "authentication",
      "oauth",
      "passkeys"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Write",
      "Edit",
      "Bash"
    ],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "oauth-2.1-passkeys.md"
      ],
      "scripts": [
        "auth-middleware-template.py"
      ],
      "checklists": [
        "auth-checklist.md"
      ]
    },
    "content": "# Authentication Patterns\n\nImplement secure authentication with OAuth 2.1, Passkeys, and modern security standards.\n\n## Overview\n\n- Login/signup flows\n- JWT token management\n- Session security\n- OAuth 2.1 with PKCE\n- Passkeys/WebAuthn\n- Multi-factor authentication\n- Role-based access control\n\n## Quick Reference\n\n### Password Hashing (Argon2id)\n\n```python\nfrom argon2 import PasswordHasher\nph = PasswordHasher()\npassword_hash = ph.hash(password)\nph.verify(password_hash, password)\n```\n\n### JWT Access Token\n\n```python\nimport jwt\nfrom datetime import datetime, timedelta, timezone\npayload = {\n    'user_id': user_id,\n    'type': 'access',\n    'exp': datetime.now(timezone.utc) + timedelta(minutes=15),\n}\ntoken = jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n```\n\n### OAuth 2.1 with PKCE (Required)\n\n```python\nimport hashlib, base64, secrets\ncode_verifier = secrets.token_urlsafe(64)\ndigest = hashlib.sha256(code_verifier.encode()).digest()\ncode_challenge = base64.urlsafe_b64encode(digest).rstrip(b'=').decode()\n```\n\n### Session Security\n\n```python\napp.config['SESSION_COOKIE_SECURE'] = True      # HTTPS only\napp.config['SESSION_COOKIE_HTTPONLY'] = True    # No JS access\napp.config['SESSION_COOKIE_SAMESITE'] = 'Strict'\n```\n\n## Token Expiry ( Guidelines)\n\n| Token Type | Expiry | Storage |\n|------------|--------|---------|\n| Access | 15 min - 1 hour | Memory only |\n| Refresh | 7-30 days | HTTPOnly cookie |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# ❌ NEVER store passwords in plaintext\nuser.password = request.form['password']\n\n# ❌ NEVER use implicit OAuth grant\nresponse_type=token  # Deprecated in OAuth 2.1\n\n# ❌ NEVER skip rate limiting on login\n@app.route('/login')  # No rate limit!\n\n# ❌ NEVER reveal if email exists\nreturn \"Email not found\"  # Information disclosure\n\n# ✅ ALWAYS use Argon2id or bcrypt\npassword_hash = ph.hash(password)\n\n# ✅ ALWAYS use PKCE\ncode_challenge=challenge&code_challenge_method=S256\n\n# ✅ ALWAYS rate limit auth endpoints\n@limiter.limit(\"5 per minute\")\n\n# ✅ ALWAYS use generic error messages\nreturn \"Invalid credentials\"\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Password hash | **Argon2id** > bcrypt |\n| Access token expiry | 15 min - 1 hour |\n| Refresh token expiry | 7-30 days with rotation |\n| Session cookie | HTTPOnly, Secure, SameSite=Strict |\n| Rate limit | 5 attempts per minute |\n| MFA | Passkeys > TOTP > SMS |\n| OAuth | 2.1 with PKCE (no implicit) |\n\n## Detailed Documentation\n\n| Resource | Description |\n|----------|-------------|\n| [references/oauth-2.1-passkeys.md](references/oauth-2.1-passkeys.md) | OAuth 2.1, PKCE, Passkeys/WebAuthn |\n| [examples/auth-implementations.md](examples/auth-implementations.md) | Complete implementation examples |\n| [checklists/auth-checklist.md](checklists/auth-checklist.md) | Security checklist |\n| [scripts/auth-middleware-template.py](scripts/auth-middleware-template.py) | Flask/FastAPI middleware |\n\n## Related Skills\n\n- `owasp-top-10` - Security fundamentals\n-",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "security-auditor",
      "security-layer-auditor"
    ]
  },
  "backend-architecture-enforcer": {
    "name": "backend-architecture-enforcer",
    "description": "Enforces FastAPI Clean Architecture with blocking validation. Use when implementing router-service-repository patterns, enforcing layer separation, or validating dependency injection in backend code.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "backend",
      "fastapi",
      "architecture",
      "enforcement",
      "blocking",
      "clean-architecture",
      "di"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "dependency-injection.md",
        "layer-rules.md",
        "violation-examples.md"
      ]
    },
    "content": "Enforce FastAPI Clean Architecture with **BLOCKING** validation.\n\n## Architecture Overview\n\n```\n+-------------------------------------------------------------------+\n|                        ROUTERS LAYER                               |\n|  HTTP concerns only: request parsing, response formatting          |\n|  Files: router_*.py, routes_*.py, api_*.py                        |\n+-------------------------------------------------------------------+\n|                        SERVICES LAYER                              |\n|  Business logic: orchestration, validation, transformations        |\n|  Files: *_service.py                                              |\n+-------------------------------------------------------------------+\n|                      REPOSITORIES LAYER                            |\n|  Data access: database queries, external API calls                 |\n|  Files: *_repository.py, *_repo.py                                |\n+-------------------------------------------------------------------+\n|                        MODELS LAYER                                |\n|  Data structures: SQLAlchemy models, Pydantic schemas             |\n|  Files: *_model.py (ORM), *_schema.py (Pydantic)                 |\n+-------------------------------------------------------------------+\n```\n\n## Validation Rules (BLOCKING)\n\n| Rule | Check | Layer |\n|------|-------|-------|\n| **No DB in Routers** | Database operations blocked | routers/ |\n| **No HTTP in Services** | HTTPException blocked | services/ |\n| **No Business Logic in Routers** | Complex logic blocked | routers/ |\n| **Use Depends()** | Direct instantiation blocked | routers/ |\n| **Async Consistency** | Sync calls in async blocked | all |\n| **File Naming** | Must follow naming convention | all |\n\n## File Naming Conventions\n\n### Quick Reference\n\n| Layer | Allowed Patterns | Blocked Patterns |\n|-------|-----------------|------------------|\n| **Routers** | `router_*.py`, `routes_*.py`, `api_*.py`, `deps.py` | `users.py`, `UserRouter.py` |\n| **Services** | `*_service.py` | `users.py`, `UserService.py`, `service_*.py` |\n| **Repositories** | `*_repository.py`, `*_repo.py` | `users.py`, `repository_*.py` |\n| **Schemas** | `*_schema.py`, `*_dto.py`, `*_request.py`, `*_response.py` | `users.py`, `UserSchema.py` |\n| **Models** | `*_model.py`, `*_entity.py`, `*_orm.py`, `base.py` | `users.py`, `UserModel.py` |\n\n## Layer Separation Summary\n\n### Routers (HTTP Only)\n- Request parsing and response formatting\n- HTTP status codes and auth checks\n- Delegate to services via `Depends()`\n\n### Services (Business Logic)\n- Validation and orchestration\n- Data transformations\n- Raise domain exceptions (NOT HTTPException)\n\n### Repositories (Data Access)\n- Database queries and persistence\n- External API calls\n- Return domain objects or None\n\n## Dependency Injection Quick Reference\n\n```python\n# deps.py - Dependency providers\ndef get_user_repository(\n    db: AsyncSession = Depends(get_db),\n) -> UserRepository:\n    return UserRepository(",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "background-jobs": {
    "name": "background-jobs",
    "description": "Async task processing with Celery, ARQ, and Redis for Python backends. Use when implementing background tasks, job queues, workers, scheduled jobs, or periodic task processing.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "background-jobs",
      "celery",
      "arq",
      "redis",
      "async",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "task-queue-patterns.md"
      ],
      "scripts": [
        "arq-worker-template.py"
      ],
      "checklists": [
        "background-jobs-checklist.md"
      ]
    },
    "content": "# Background Job Patterns\n\nOffload long-running tasks with async job queues.\n\n## Overview\n\n- Long-running tasks (report generation, data processing)\n- Email/notification sending\n- Scheduled/periodic tasks\n- Webhook processing\n- Data export/import pipelines\n- Non-LLM async operations (use LangGraph for LLM workflows)\n\n## Tool Selection\n\n| Tool | Language | Best For | Complexity |\n|------|----------|----------|------------|\n| ARQ | Python (async) | FastAPI, simple jobs | Low |\n| Celery | Python | Complex workflows, enterprise | High |\n| RQ | Python | Simple Redis queues | Low |\n| Dramatiq | Python | Reliable messaging | Medium |\n\n## ARQ (Async Redis Queue)\n\n### Setup\n\n```python\n# backend/app/workers/arq_worker.py\nfrom arq import create_pool\nfrom arq.connections import RedisSettings\n\nasync def startup(ctx: dict):\n    \"\"\"Initialize worker resources.\"\"\"\n    ctx[\"db\"] = await create_db_pool()\n    ctx[\"http\"] = httpx.AsyncClient()\n\nasync def shutdown(ctx: dict):\n    \"\"\"Cleanup worker resources.\"\"\"\n    await ctx[\"db\"].close()\n    await ctx[\"http\"].aclose()\n\nclass WorkerSettings:\n    redis_settings = RedisSettings(host=\"redis\", port=6379)\n    functions = [\n        send_email,\n        generate_report,\n        process_webhook,\n    ]\n    on_startup = startup\n    on_shutdown = shutdown\n    max_jobs = 10\n    job_timeout = 300  # 5 minutes\n```\n\n### Task Definition\n\n```python\nfrom arq import func\n\nasync def send_email(\n    ctx: dict,\n    to: str,\n    subject: str,\n    body: str,\n) -> dict:\n    \"\"\"Send email task.\"\"\"\n    http = ctx[\"http\"]\n    response = await http.post(\n        \"https://api.sendgrid.com/v3/mail/send\",\n        json={\"to\": to, \"subject\": subject, \"html\": body},\n        headers={\"Authorization\": f\"Bearer {SENDGRID_KEY}\"},\n    )\n    return {\"status\": response.status_code, \"to\": to}\n\nasync def generate_report(\n    ctx: dict,\n    report_id: str,\n    format: str = \"pdf\",\n) -> dict:\n    \"\"\"Generate report asynchronously.\"\"\"\n    db = ctx[\"db\"]\n    data = await db.fetch_report_data(report_id)\n    pdf_bytes = await render_pdf(data)\n    await db.save_report_file(report_id, pdf_bytes)\n    return {\"report_id\": report_id, \"size\": len(pdf_bytes)}\n```\n\n### Enqueue from FastAPI\n\n```python\nfrom arq import create_pool\nfrom arq.connections import RedisSettings\n\n# Dependency\nasync def get_arq_pool():\n    return await create_pool(RedisSettings(host=\"redis\"))\n\n@router.post(\"/api/v1/reports\")\nasync def create_report(\n    data: ReportRequest,\n    arq: ArqRedis = Depends(get_arq_pool),\n):\n    report = await service.create_report(data)\n\n    # Enqueue background job\n    job = await arq.enqueue_job(\n        \"generate_report\",\n        report.id,\n        format=data.format,\n    )\n\n    return {\"report_id\": report.id, \"job_id\": job.job_id}\n\n@router.get(\"/api/v1/jobs/{job_id}\")\nasync def get_job_status(\n    job_id: str,\n    arq: ArqRedis = Depends(get_arq_pool),\n):\n    job = Job(job_id, arq)\n    status = await job.status()\n    result = await job.result() if status == JobStatus.co",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "event-driven-architect"
    ]
  },
  "best-practices": {
    "name": "best-practices",
    "description": "View and manage your personal best practices library with success/failure patterns. Use when viewing best practices, checking patterns, reviewing success/failure history.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "best-practices",
      "patterns",
      "anti-patterns",
      "mem0",
      "learning"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [
      "Read",
      "Bash"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "proactive-warnings.md"
      ]
    },
    "content": "# Best Practices - View Your Pattern Library\n\nDisplay your aggregated best practices library, showing successful patterns and anti-patterns across all projects.\n\n## Usage\n\n```\n/best-practices                     # Show full library\n/best-practices <category>          # Filter by category\n/best-practices --warnings          # Show only anti-patterns\n/best-practices --successes         # Show only successes\n/best-practices --stats             # Show statistics only\n```\n\n## Options\n\n- `<category>` - Filter by specific category (pagination, database, authentication, etc.)\n- `--warnings` - Show only anti-patterns (failed patterns)\n- `--successes` - Show only successful patterns\n- `--stats` - Show statistics summary without individual patterns\n\n## Workflow\n\n### 1. Query mem0 for Best Practices\n\nUse the mem0 CLI script:\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/src/skills/mem0-memory/scripts/crud/search-memories.py \\\n  --query \"patterns outcomes\" \\\n  --user-id \"project-decisions\" \\\n  --limit 100\n```\n\n### 2. Aggregate Results\n\nGroup patterns by category, then by outcome:\n\n```json\n{\n  \"pagination\": {\n    \"successes\": [...],\n    \"failures\": [...]\n  },\n  \"authentication\": {\n    \"successes\": [...],\n    \"failures\": [...]\n  }\n}\n```\n\n### 3. Calculate Statistics\n\nFor each pattern:\n- Count occurrences across projects\n- Calculate success rate: successes / (successes + failures)\n- Note which projects contributed\n\n### 4. Display Output\n\n**Full Library View:**\n```\n📚 Your Best Practices Library\n═══════════════════════════════════════════════════════════════\n\nPAGINATION\n─────────────────────────────────────────────────────────────\n  ✅ Cursor-based pagination (3 projects, always worked)\n     \"Scales well for large datasets\"\n\n  ❌ Offset pagination (failed in 2 projects)\n     \"Caused timeouts on tables with 1M+ rows\"\n     💡 Lesson: Use cursor-based for large datasets\n\nAUTHENTICATION\n─────────────────────────────────────────────────────────────\n  ✅ JWT + httpOnly refresh tokens (4 projects)\n     \"Secure and scalable for web apps\"\n\n  ⚠️ Session-based auth (mixed: 1 success, 1 failure)\n     \"Works but scaling issues in high-traffic scenarios\"\n\n───────────────────────────────────────────────────────────────\n📊 Summary: 8 patterns | 5 ✅ successes | 3 ❌ anti-patterns\n💡 Use `/remember --success` or `/remember --failed` to add more\n```\n\n**Stats Only View (`--stats`):**\n```\n📊 Best Practices Statistics\n═══════════════════════════════════════════════════════════════\n\nTotal Patterns: 15\n├── ✅ Successful: 10 (67%)\n├── ❌ Anti-patterns: 5 (33%)\n└── ⚠️ Mixed: 2\n\nCategories:\n├── pagination: 3 patterns (2 ✅, 1 ❌)\n├── authentication: 4 patterns (3 ✅, 1 ⚠️)\n├── database: 5 patterns (4 ✅, 1 ❌)\n└── api: 3 patterns (1 ✅, 2 ❌)\n\nProjects Contributing: 7\nLast Updated: 2 days ago\n```\n\n**Filtered View (by category):**\n```\n📚 Best Practices: PAGINATION\n═══════════════════════════════════════════════════════════════\n\n  ✅ Cursor-based pagination (3 projects, always worked)\n     \"Scales well for large ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "biome-linting": {
    "name": "biome-linting",
    "description": "Biome 2.0+ linting and formatting for fast, unified code quality. Includes type inference, ESLint migration, CI integration, and 421 lint rules. Use when migrating from ESLint/Prettier or setting up new projects.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "biome",
      "linting",
      "formatting",
      "eslint-migration",
      "ci",
      "code-quality",
      "typescript"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "biome-json-config.md",
        "ci-integration.md",
        "eslint-migration.md",
        "type-aware-rules.md"
      ],
      "scripts": [
        "biome-strict.json",
        "biome.json",
        "github-action.yml"
      ],
      "checklists": [
        "migration-checklist.md"
      ]
    },
    "content": "# Biome Linting\n\nFast, unified linting and formatting (10-25x faster than ESLint + Prettier).\n\n## Why Biome in 2026\n\n| Aspect | Biome | ESLint + Prettier |\n|--------|-------|-------------------|\n| Speed | ~200ms for 10k lines | 3-5s |\n| Config files | 1 (biome.json) | 4+ |\n| npm packages | 1 binary | 127+ |\n| Rules | 421 | Varies by plugins |\n| Type inference | Yes (v2.0+) | Requires tsconfig |\n\n## Quick Start\n\n```bash\n# Install\nnpm install --save-dev --save-exact @biomejs/biome\n\n# Initialize\nnpx @biomejs/biome init\n\n# Check (lint + format)\nnpx @biomejs/biome check .\n\n# Fix\nnpx @biomejs/biome check --write .\n\n# CI mode (fails on errors)\nnpx @biomejs/biome ci .\n```\n\n## Biome 2.0 Features\n\n**Type Inference**: Reads `.d.ts` from node_modules for type-aware rules:\n\n```json\n{\n  \"linter\": {\n    \"rules\": {\n      \"nursery\": {\n        \"noFloatingPromises\": \"error\"  // Catches unhandled promises\n      }\n    }\n  }\n}\n```\n\n**Multi-file Analysis**: Cross-module analysis for better diagnostics.\n\n## Basic Configuration\n\n```json\n{\n  \"$schema\": \"https://biomejs.dev/schemas/2.0.0/schema.json\",\n  \"formatter\": {\n    \"enabled\": true,\n    \"indentStyle\": \"space\",\n    \"indentWidth\": 2,\n    \"lineWidth\": 100\n  },\n  \"linter\": {\n    \"enabled\": true,\n    \"rules\": {\n      \"recommended\": true,\n      \"correctness\": {\n        \"noUnusedVariables\": \"error\",\n        \"noUnusedImports\": \"error\"\n      },\n      \"suspicious\": {\n        \"noExplicitAny\": \"warn\"\n      }\n    }\n  },\n  \"javascript\": {\n    \"formatter\": {\n      \"quoteStyle\": \"single\",\n      \"trailingCommas\": \"all\"\n    }\n  }\n}\n```\n\n## ESLint Migration\n\n```bash\n# Auto-migrate configuration\nnpx @biomejs/biome migrate eslint --write\n```\n\n**Common Rule Mappings:**\n| ESLint | Biome |\n|--------|-------|\n| no-unused-vars | correctness/noUnusedVariables |\n| no-console | suspicious/noConsole |\n| @typescript-eslint/* | Most supported |\n| eslint-plugin-react | Most supported |\n| eslint-plugin-jsx-a11y | Most supported |\n\n## CI Integration\n\n```yaml\n# .github/workflows/lint.yml\n- uses: biomejs/setup-biome@v2\n- run: biome ci .\n```\n\n## Overrides for Gradual Adoption\n\n```json\n{\n  \"overrides\": [\n    {\n      \"include\": [\"*.test.ts\", \"*.spec.ts\"],\n      \"linter\": {\n        \"rules\": {\n          \"suspicious\": { \"noExplicitAny\": \"off\" }\n        }\n      }\n    },\n    {\n      \"include\": [\"legacy/**\"],\n      \"linter\": { \"enabled\": false }\n    }\n  ]\n}\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| New vs migration | Biome first for new projects; migrate existing gradually |\n| Config strictness | Start with recommended, tighten over time |\n| CI strategy | Use `biome ci` for strict mode, `biome check` for local |\n| Type inference | Enable for TypeScript projects (v2.0+) |\n\n## Related Skills\n\n- `vite-advanced` - Build tooling integration\n- `react-server-components-framework` - React linting rules\n- `ci-cd-engineer` - CI pipeline setup\n\n## References\n\n- [ESLint Migration](references/eslint-migration.md) - Step-by-step migr",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ci-cd-engineer",
      "code-quality-reviewer",
      "frontend-ui-developer"
    ]
  },
  "brainstorming": {
    "name": "brainstorming",
    "description": "Design exploration with parallel agents. Use when brainstorming ideas, exploring solutions, or comparing alternatives.",
    "version": "4.2.0",
    "author": "OrchestKit",
    "tags": [
      "planning",
      "ideation",
      "creativity",
      "design"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Task",
      "Read",
      "Grep",
      "Glob",
      "TaskCreate",
      "TaskUpdate",
      "TaskList",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "architecture-decision-record",
      "api-design-framework",
      "design-system-starter",
      "memory",
      "remember",
      "assess-complexity"
    ],
    "agent": null,
    "structure": {
      "references": [
        "common-pitfalls.md",
        "devils-advocate-prompts.md",
        "divergent-techniques.md",
        "evaluation-rubric.md",
        "example-session-auth.md",
        "example-session-dashboard.md",
        "phase-workflow.md",
        "socratic-questions.md"
      ],
      "assets": [
        "idea-evaluation-template.md"
      ],
      "scripts": [
        "create-design-doc.md",
        "decision-matrix-template.md",
        "design-doc-template.md"
      ],
      "checklists": [
        "brainstorm-completion.md",
        "brainstorm-session-checklist.md"
      ]
    },
    "content": "# Brainstorming Ideas Into Designs\n\nTransform rough ideas into fully-formed designs through intelligent agent selection and structured exploration.\n\n**Core principle:** Analyze the topic, select relevant agents dynamically, explore alternatives in parallel, present design incrementally.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify brainstorming constraints:\n\n```python\nAskUserQuestion(\n  questions=[\n    {\n      \"question\": \"What type of design exploration?\",\n      \"header\": \"Type\",\n      \"options\": [\n        {\"label\": \"Open exploration (Recommended)\", \"description\": \"Generate 10+ ideas, evaluate all, synthesize top 3\"},\n        {\"label\": \"Constrained design\", \"description\": \"I have specific requirements to work within\"},\n        {\"label\": \"Comparison\", \"description\": \"Compare 2-3 specific approaches I have in mind\"},\n        {\"label\": \"Quick ideation\", \"description\": \"Generate ideas fast, skip deep evaluation\"}\n      ],\n      \"multiSelect\": false\n    },\n    {\n      \"question\": \"Any preferences or constraints?\",\n      \"header\": \"Constraints\",\n      \"options\": [\n        {\"label\": \"None\", \"description\": \"Explore all possibilities\"},\n        {\"label\": \"Use existing patterns\", \"description\": \"Prefer patterns already in codebase\"},\n        {\"label\": \"Minimize complexity\", \"description\": \"Favor simpler solutions\"},\n        {\"label\": \"I'll specify\", \"description\": \"Let me provide specific constraints\"}\n      ],\n      \"multiSelect\": false\n    }\n  ]\n)\n```\n\n**Based on answers, adjust workflow:**\n- **Open exploration**: Full 7-phase process with all agents\n- **Constrained design**: Skip divergent phase, focus on feasibility\n- **Comparison**: Skip ideation, jump to evaluation phase\n- **Quick ideation**: Generate ideas, skip deep evaluation\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — agents debate and challenge ideas) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Open exploration with 3+ agents → recommend **Agent Teams** (real-time debate produces better ideas); Quick ideation → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Idea generation | Each agent generates independently | Agents riff on each other's ideas |\n| Devil's advocate | Lead challenges after all complete | Agents challenge each other in real-time |\n| Cost | ~150K tokens | ~400K tokens |\n| Best for | Quick ideation, constrained design | Open exploration, deep evaluation |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining phases.\n\n---\n\n## CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n```python\n# Create main task IMMEDIATELY\nTaskCreate(\n  subject=\"Brainstorm: {topic}\",\n  description=\"Design exploration with parallel agent research\",\n  activeForm=\"Brainstorming {topic}\"\n)\n\n# Create subtasks for each phase\nTask",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "business-case-builder",
      "product-strategist"
    ]
  },
  "browser-automation": {
    "name": "browser-automation",
    "description": "Headless browser automation using Vercel's agent-browser CLI. 93% less context than Playwright MCP. Snapshot + refs workflow with element references. Use when automating browser tasks, web scraping, form filling, or content capture.",
    "version": "3.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "browser",
      "automation",
      "headless",
      "scraping",
      "vercel",
      "agent-browser"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Bash",
      "Read",
      "Write"
    ],
    "skills": [],
    "agent": "test-generator",
    "structure": {},
    "content": "# Browser Automation with agent-browser\n\nHeadless browser CLI by Vercel. Full upstream docs: [github.com/vercel-labs/agent-browser](https://github.com/vercel-labs/agent-browser)\n\n## Installation\n\n```bash\nnpm install -g agent-browser\nagent-browser install                # Download Chromium\nagent-browser install --with-deps    # With system dependencies (Linux)\n# Optional: npx skills add vercel-labs/agent-browser\n```\n\n## Quick Start\n\n```bash\nagent-browser open <url>          # Navigate to page\nagent-browser snapshot -i         # Get interactive elements with refs\nagent-browser click @e1           # Click element by ref\nagent-browser fill @e2 \"text\"     # Fill input by ref\nagent-browser close               # Close browser\n```\n\n## Core Concept: Snapshot + Refs\n\nRun `agent-browser snapshot -i` to get interactive elements tagged `@e1`, `@e2`, etc. Use these refs for all subsequent interactions. Re-snapshot after navigation or significant DOM changes. This yields **93% less context** than full-DOM approaches.\n\n## When to Use\n\n- Web scraping from JS-rendered / SPA pages\n- Form automation and multi-step workflows\n- Screenshot capture and visual verification\n- E2E test generation and debugging\n- Content capture from authenticated pages\n\n## Key Commands\n\n| Command | Purpose |\n|---------|---------|\n| `open <url>` | Navigate to URL |\n| `snapshot -i` | Interactive elements with refs |\n| `click @e1` | Click element |\n| `fill @e2 \"text\"` | Clear + type into input |\n| `get text @e1` | Extract element text |\n| `wait --load networkidle` | Wait for SPA render |\n| `screenshot <path>` | Save screenshot |\n| `state save <file>` | Persist cookies/storage |\n| `state load <file>` | Restore session |\n| `eval \"js\"` | Run JavaScript |\n| `record start <path>` | Start video recording |\n| `record stop` | Stop recording |\n| `--session <name>` | Isolate parallel sessions |\n| `--headed` | Show browser window |\n\nRun `agent-browser --help` for the full 60+ command reference.\n\n## OrchestKit Integration\n\n**Safety hook** — `agent-browser-safety.ts` blocks destructive patterns (credential exfil, recursive spawning) automatically via pretool hook.\n\n**Sessions** — Use `--session <name>` to run isolated parallel browsers within a single Claude Code session.\n\n**Environment variables:**\n\n```bash\nAGENT_BROWSER_SESSION=\"my-session\"   # Default session name\nAGENT_BROWSER_PROFILE=\"/path\"        # Persistent browser profile\nAGENT_BROWSER_PROVIDER=\"browserbase\" # Cloud provider (browserbase | kernel | browseruse)\nAGENT_BROWSER_HEADED=1               # Run headed\n```\n\n## Upstream Documentation\n\n- **GitHub:** [vercel-labs/agent-browser](https://github.com/vercel-labs/agent-browser)\n- **CLI help:** `agent-browser --help`\n- **Skills add:** `npx skills add vercel-labs/agent-browser`\n\n## Related Skills\n\n- `browser-content-capture` — Content extraction patterns using agent-browser\n- `webapp-testing` — E2E testing with Playwright test framework\n- `e2e-testing` — End-to-end testing patterns",
    "contentTruncated": false,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "web-research-analyst"
    ]
  },
  "browser-content-capture": {
    "name": "browser-content-capture",
    "description": "Capture content from JavaScript-rendered pages, login-protected sites, and multi-page documentation using agent-browser CLI. Use when capturing browser content, extracting web data, saving page content.",
    "version": "2.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "browser",
      "agent-browser",
      "scraping",
      "spa",
      "authentication"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Bash",
      "Read",
      "Write"
    ],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "agent-browser-commands.md",
        "auth-handling.md",
        "multi-page-crawl.md",
        "spa-extraction.md"
      ],
      "scripts": [
        "auth-capture.sh",
        "capture-workflow.sh",
        "multi-page-crawl.md",
        "multi-page-crawl.sh"
      ],
      "checklists": [
        "browser-capture-checklist.md"
      ]
    },
    "content": "# Browser Content Capture\n\n**Capture web content that traditional scrapers cannot access using agent-browser CLI.**\n\n## Overview\n\nThis skill enables content extraction from sources that require browser-level access:\n- **JavaScript-rendered SPAs** (React, Vue, Angular apps)\n- **Login-protected documentation** (private wikis, gated content)\n- **Dynamic content** (infinite scroll, lazy loading, client-side routing)\n- **Multi-page site crawls** (documentation trees, tutorial series)\n\n## When to Use\n\n**Use when:**\n- `WebFetch` returns empty or partial content\n- Page requires JavaScript execution to render\n- Content is behind authentication\n- Need to navigate multi-page structures\n- Extracting from client-side routed apps\n\n**Do NOT use when:**\n- Static HTML pages (use `WebFetch` - faster)\n- Public API endpoints (use direct HTTP calls)\n- Simple RSS/Atom feeds\n\n---\n\n## Quick Start\n\n### Basic Capture Pattern\n\n```bash\n# 1. Navigate to URL\nagent-browser open https://docs.example.com\n\n# 2. Wait for content to render\nagent-browser wait --load networkidle\n\n# 3. Get interactive snapshot\nagent-browser snapshot -i\n\n# 4. Extract text content\nagent-browser get text body\n\n# 5. Take screenshot\nagent-browser screenshot /tmp/capture.png\n\n# 6. Close when done\nagent-browser close\n```\n\n---\n\n## agent-browser Commands Reference\n\n| Command | Purpose | When to Use |\n|---------|---------|-------------|\n| `open <url>` | Go to URL | First step of any capture |\n| `snapshot -i` | Get interactive element tree | Understanding page structure |\n| `eval \"<script>\"` | Run custom JS | Extract specific content |\n| `click @e#` | Click elements | Navigate menus, pagination |\n| `fill @e# \"value\"` | Fill inputs | Authentication flows |\n| `wait @e#` | Wait for element | Dynamic content loading |\n| `screenshot <path>` | Capture image | Visual verification |\n| `console` | Read JS console | Debug extraction issues |\n| `network requests` | Monitor XHR/fetch | Find API endpoints |\n\n**Quick reference:** See [references/agent-browser-commands.md](references/agent-browser-commands.md) or run `agent-browser --help`\n\n---\n\n## Capture Patterns\n\n### Pattern 1: SPA Content Extraction\n\nFor React/Vue/Angular apps where content renders client-side:\n\n```bash\n# Navigate and wait for hydration\nagent-browser open https://react-docs.example.com\nagent-browser wait --load networkidle\n\n# Get snapshot to identify content element\nagent-browser snapshot -i\n\n# Extract after framework mounts (use ref from snapshot)\nagent-browser get text @e5  # Main content area\n\n# Or use eval for custom extraction\nagent-browser eval \"document.querySelector('article').innerText\"\n```\n\n**Details:** See [references/spa-extraction.md](references/spa-extraction.md)\n\n### Pattern 2: Authentication Flow\n\nFor login-protected content:\n\n```bash\n# Navigate to login\nagent-browser open https://docs.example.com/login\nagent-browser snapshot -i\n\n# Fill credentials (refs from snapshot)\nagent-browser fill @e1 \"user@example.com\"  # Email field\nagent-browser f",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "web-research-analyst"
    ]
  },
  "business-case-analysis": {
    "name": "business-case-analysis",
    "description": "ROI, NPV, IRR, payback period, and total cost of ownership analysis for investment decisions. Use when building financial justification for projects, evaluating SaaS investments, or comparing alternatives.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "finance",
      "roi",
      "npv",
      "irr",
      "tco",
      "business-case"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "business-case-builder",
    "structure": {
      "references": [
        "roi-calculation-guide.md"
      ],
      "assets": [
        "business-case-template.md"
      ],
      "checklists": [
        "business-case-checklist.md"
      ]
    },
    "content": "# Business Case Analysis\n\nFinancial frameworks for justifying investments, evaluating projects, and comparing alternatives.\n\n## Key Financial Metrics\n\n### Return on Investment (ROI)\n\nSimple measure of profitability relative to cost.\n\n```\nROI = (Net Benefits - Total Costs) / Total Costs × 100%\n```\n\n**Example:**\n```\nProject cost: $500,000\nAnnual benefits: $200,000 over 5 years\n\nTotal benefits: $1,000,000\nROI = ($1,000,000 - $500,000) / $500,000 × 100% = 100%\n```\n\n**Limitation:** Does not account for time value of money.\n\n### Net Present Value (NPV)\n\nGold standard for project evaluation—discounts future cash flows to present value.\n\n```\nNPV = Σ (Cash Flow_t / (1 + r)^t) - Initial Investment\n```\n\nWhere:\n- `t` = time period\n- `r` = discount rate (cost of capital)\n\n**Example:**\n```python\ndef calculate_npv(\n    initial_investment: float,\n    cash_flows: list[float],\n    discount_rate: float = 0.10  # 10% typical\n) -> float:\n    npv = -initial_investment\n    for t, cf in enumerate(cash_flows, start=1):\n        npv += cf / ((1 + discount_rate) ** t)\n    return npv\n\n# Example: $500K investment, $200K/year for 5 years\nnpv = calculate_npv(500_000, [200_000] * 5, 0.10)\n# NPV = $258,157 (positive = good investment)\n```\n\n**Decision Rule:**\n- NPV > 0: Accept (creates value)\n- NPV < 0: Reject (destroys value)\n- NPV = 0: Indifferent\n\n### Internal Rate of Return (IRR)\n\nThe discount rate at which NPV equals zero.\n\n```python\ndef calculate_irr(cash_flows: list[float]) -> float:\n    \"\"\"\n    cash_flows[0] is initial investment (negative)\n    Returns the IRR as a decimal\n    \"\"\"\n    from scipy.optimize import brentq\n\n    def npv_at_rate(r):\n        return sum(cf / (1 + r) ** t for t, cf in enumerate(cash_flows))\n\n    return brentq(npv_at_rate, -0.99, 10.0)\n\n# Example: -$500K initial, then $200K/year for 5 years\nirr = calculate_irr([-500_000, 200_000, 200_000, 200_000, 200_000, 200_000])\n# IRR ≈ 28.6%\n```\n\n**Decision Rule:**\n- IRR > hurdle rate (cost of capital): Accept\n- IRR < hurdle rate: Reject\n\n**Typical Hurdle Rates ():**\n- Conservative enterprise: 10-12%\n- Growth company: 15-20%\n- Startup: 25-40%\n\n### Payback Period\n\nTime to recover initial investment.\n\n```\nPayback Period = Initial Investment / Annual Cash Flow\n```\n\n**Example:**\n```\nInvestment: $500,000\nAnnual savings: $200,000\nPayback = $500,000 / $200,000 = 2.5 years\n```\n\n**Typical Expectations ():**\n- SaaS investments: 6-12 months\n- Enterprise platforms: 12-24 months\n- Infrastructure: 24-36 months\n\n## Total Cost of Ownership (TCO)\n\n### Build vs. Buy TCO Comparison\n\n```markdown\n## Build Option (3-Year TCO)\n\n### Year 1\n| Category | Cost |\n|----------|------|\n| Development team (4 FTEs × $150K) | $600,000 |\n| Infrastructure setup | $50,000 |\n| Tools & licenses | $20,000 |\n| **Year 1 Total** | **$670,000** |\n\n### Year 2-3 (Maintenance)\n| Category | Annual Cost |\n|----------|-------------|\n| Maintenance team (2 FTEs) | $300,000 |\n| Infrastructure | $60,000 |\n| Technical debt | $50,000 |\n| **Annual Total** | **$410,000",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "business-case-builder"
    ]
  },
  "cache-cost-tracking": {
    "name": "cache-cost-tracking",
    "description": "LLM cost tracking with Langfuse for cached responses. Use when monitoring cache effectiveness, tracking cost savings, or attributing costs to agents in multi-agent systems.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "llm",
      "cost",
      "caching",
      "langfuse",
      "observability"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "checklists": [
        "cache-cost-checklist.md"
      ]
    },
    "content": "# Cache Cost Tracking\n\nMonitor LLM costs and cache effectiveness.\n\n## Langfuse Automatic Tracking\n\n```python\nfrom langfuse.decorators import observe, langfuse_context\n\n@observe(as_type=\"generation\")\nasync def call_llm_with_cache(\n    prompt: str,\n    agent_type: str,\n    analysis_id: UUID\n) -> str:\n    \"\"\"LLM call with automatic cost tracking.\"\"\"\n\n    # Link to parent trace\n    langfuse_context.update_current_trace(\n        name=f\"{agent_type}_generation\",\n        session_id=str(analysis_id)\n    )\n\n    # Check caches\n    if cache_key in lru_cache:\n        langfuse_context.update_current_observation(\n            metadata={\"cache_layer\": \"L1\", \"cache_hit\": True}\n        )\n        return lru_cache[cache_key]\n\n    similar = await semantic_cache.get(prompt, agent_type)\n    if similar:\n        langfuse_context.update_current_observation(\n            metadata={\"cache_layer\": \"L2\", \"cache_hit\": True}\n        )\n        return similar\n\n    # LLM call - Langfuse tracks tokens/cost automatically\n    response = await llm.generate(prompt)\n\n    langfuse_context.update_current_observation(\n        metadata={\n            \"cache_layer\": \"L4\",\n            \"cache_hit\": False,\n            \"prompt_cache_hit\": response.usage.cache_read_input_tokens > 0\n        }\n    )\n\n    return response.content\n```\n\n## Hierarchical Cost Rollup\n\n```python\nclass AnalysisWorkflow:\n    @observe(as_type=\"trace\")\n    async def run_analysis(self, url: str, analysis_id: UUID):\n        \"\"\"Parent trace aggregates child costs.\n\n        Trace Hierarchy:\n        run_analysis (trace)\n        ├── security_agent (generation)\n        ├── tech_agent (generation)\n        └── synthesis (generation)\n        \"\"\"\n        langfuse_context.update_current_trace(\n            name=\"content_analysis\",\n            session_id=str(analysis_id),\n            tags=[\"multi-agent\"]\n        )\n\n        for agent in self.agents:\n            await self.run_agent(agent, content, analysis_id)\n\n    @observe(as_type=\"generation\")\n    async def run_agent(self, agent, content, analysis_id):\n        \"\"\"Child generation - costs roll up to parent.\"\"\"\n        langfuse_context.update_current_observation(\n            name=f\"{agent.name}_generation\",\n            metadata={\"agent_type\": agent.name}\n        )\n        return await agent.analyze(content)\n```\n\n## Cost Queries\n\n```python\nfrom langfuse import Langfuse\n\nasync def get_analysis_costs(analysis_id: UUID) -> dict:\n    langfuse = Langfuse()\n\n    traces = langfuse.get_traces(session_id=str(analysis_id), limit=1)\n\n    if traces.data:\n        trace = traces.data[0]\n        return {\n            \"total_cost\": trace.total_cost,\n            \"input_tokens\": trace.usage.input_tokens,\n            \"output_tokens\": trace.usage.output_tokens,\n            \"cache_read_tokens\": trace.usage.cache_read_input_tokens,\n        }\n\nasync def get_costs_by_agent() -> list[dict]:\n    generations = langfuse.get_generations(\n        from_timestamp=datetime.now() - timedelta(days=7),\n        limit=1000\n    )\n\n  ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "metrics-architect"
    ]
  },
  "caching-strategies": {
    "name": "caching-strategies",
    "description": "Backend caching patterns with Redis including write-through, write-behind, cache-aside, and invalidation strategies. Use when implementing Redis cache, managing TTL/expiration, preventing cache stampede, or optimizing cache hit rates.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "caching",
      "redis",
      "performance",
      "fastapi",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "cache-patterns.md"
      ],
      "scripts": [
        "redis-cache-service.py"
      ],
      "checklists": [
        "caching-checklist.md"
      ]
    },
    "content": "# Backend Caching Strategies\n\nOptimize performance with Redis caching patterns and smart invalidation.\n\n## Pattern Selection\n\n| Pattern | Write | Read | Consistency | Use Case |\n|---------|-------|------|-------------|----------|\n| Cache-Aside | DB first | Cache → DB | Eventual | General purpose |\n| Write-Through | Cache + DB | Cache | Strong | Critical data |\n| Write-Behind | Cache, async DB | Cache | Eventual | High write load |\n| Read-Through | Cache handles | Cache → DB | Eventual | Simplified reads |\n\n## Cache-Aside (Lazy Loading)\n\n```python\nimport redis.asyncio as redis\nfrom typing import TypeVar, Callable\nimport json\n\nT = TypeVar(\"T\")\n\nclass CacheAside:\n    def __init__(self, redis_client: redis.Redis, default_ttl: int = 3600):\n        self.redis = redis_client\n        self.ttl = default_ttl\n\n    async def get_or_set(\n        self,\n        key: str,\n        fetch_fn: Callable[[], T],\n        ttl: int | None = None,\n        serialize: Callable[[T], str] = json.dumps,\n        deserialize: Callable[[str], T] = json.loads,\n    ) -> T:\n        \"\"\"Get from cache, or fetch and cache.\"\"\"\n        # Try cache first\n        cached = await self.redis.get(key)\n        if cached:\n            return deserialize(cached)\n\n        # Cache miss - fetch from source\n        value = await fetch_fn()\n\n        # Store in cache\n        await self.redis.setex(\n            key,\n            ttl or self.ttl,\n            serialize(value),\n        )\n        return value\n\n# Usage\ncache = CacheAside(redis_client)\n\nasync def get_analysis(analysis_id: str) -> Analysis:\n    return await cache.get_or_set(\n        key=f\"analysis:{analysis_id}\",\n        fetch_fn=lambda: repo.get_by_id(analysis_id),\n        ttl=1800,  # 30 minutes\n    )\n```\n\n## Write-Through Cache\n\n```python\nclass WriteThroughCache:\n    def __init__(self, redis_client: redis.Redis, ttl: int = 3600):\n        self.redis = redis_client\n        self.ttl = ttl\n\n    async def write(\n        self,\n        key: str,\n        value: T,\n        db_write_fn: Callable[[T], Awaitable[T]],\n    ) -> T:\n        \"\"\"Write to both cache and database synchronously.\"\"\"\n        # Write to database first (consistency)\n        result = await db_write_fn(value)\n\n        # Then update cache\n        await self.redis.setex(key, self.ttl, json.dumps(result))\n\n        return result\n\n    async def read(self, key: str) -> T | None:\n        \"\"\"Read from cache only.\"\"\"\n        cached = await self.redis.get(key)\n        return json.loads(cached) if cached else None\n\n# Usage\ncache = WriteThroughCache(redis_client)\n\nasync def update_analysis(analysis_id: str, data: AnalysisUpdate) -> Analysis:\n    return await cache.write(\n        key=f\"analysis:{analysis_id}\",\n        value=data,\n        db_write_fn=lambda d: repo.update(analysis_id, d),\n    )\n```\n\n## Write-Behind (Write-Back)\n\n```python\nimport asyncio\nfrom collections import deque\n\nclass WriteBehindCache:\n    def __init__(\n        self,\n        redis_client: redis.Redis,\n        flush_interval: fl",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "data-pipeline-engineer",
      "database-engineer",
      "performance-engineer",
      "python-performance-engineer"
    ]
  },
  "callout-positioning": {
    "name": "callout-positioning",
    "description": "Debug grids and coordinate systems for video annotations. Use when positioning callouts, arrows, or debugging coordinate misalignment in Remotion",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "remotion",
      "callout",
      "annotation",
      "debug",
      "coordinates",
      "arrows"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "calibration-workflow.md",
        "coordinate-systems.md",
        "debug-grid-component.md"
      ]
    },
    "content": "# Callout Positioning\n\nDebug grids and coordinate systems for accurate arrow/annotation placement in Remotion video compositions. Essential for precise callout placement across different resolutions and aspect ratios.\n\n## Overview\n\n- Positioning callouts, arrows, and annotations in video compositions\n- Debugging coordinate misalignment in Remotion renders\n- Calibrating element positions using screenshot-based workflow\n- Creating responsive annotations for multi-resolution exports\n- Building reusable callout components with precise positioning\n\n## Quick Start\n\n```tsx\n// 1. Enable debug grid during development\nimport { DebugGrid } from './components/DebugGrid';\n\n<AbsoluteFill>\n  <YourScene />\n  <DebugGrid enabled={process.env.NODE_ENV === 'development'} />\n</AbsoluteFill>\n\n// 2. Position callouts using grid coordinates\n<Callout\n  x={960}   // Center horizontal (1920/2)\n  y={540}   // Center vertical (1080/2)\n  type=\"pointer\"\n  label=\"Click here\"\n/>\n```\n\n## Coordinate Systems\n\n### 1920x1080 (Horizontal/Landscape)\n\nStandard YouTube/Twitter format. Origin at top-left.\n\n| Region | X Range | Y Range | Description |\n|--------|---------|---------|-------------|\n| Top-Left | 0-640 | 0-360 | Logo/watermark |\n| Top-Center | 640-1280 | 0-360 | Titles |\n| Top-Right | 1280-1920 | 0-360 | Controls/badges |\n| Center | 640-1280 | 360-720 | Main content |\n| Bottom | 0-1920 | 720-1080 | CTAs/captions |\n\n### 1080x1920 (Vertical/Portrait)\n\nTikTok/Reels/Shorts format. Origin at top-left.\n\n| Region | X Range | Y Range | Description |\n|--------|---------|---------|-------------|\n| Safe-Top | 0-1080 | 200-400 | Below platform UI |\n| Center | 0-1080 | 640-1280 | Main content |\n| Safe-Bottom | 0-1080 | 1520-1720 | Above controls |\n\n### 1080x1080 (Square)\n\nInstagram/LinkedIn format.\n\n| Region | X Range | Y Range | Description |\n|--------|---------|---------|-------------|\n| Center | 270-810 | 270-810 | Safe content zone |\n| Margins | 0-270 | 0-1080 | Decorative only |\n\n## Debug Grid Component\n\nEnable during development to visualize coordinates.\n\n```tsx\nimport { DebugGrid } from './components/DebugGrid';\n\n// In your composition\n<AbsoluteFill>\n  <YourSceneContent />\n\n  {/* Toggle with prop or env var */}\n  <DebugGrid\n    enabled={showDebug}\n    gridSize={100}        // Grid cell size in pixels\n    showCoordinates       // Show X,Y at cursor position\n    showRulers            // Show pixel rulers on edges\n    highlightCenter       // Crosshair at center\n    opacity={0.5}\n  />\n</AbsoluteFill>\n```\n\n**See: `references/debug-grid-component.md`** for full component implementation.\n\n## Callout Types\n\n### 1. Pointer Callout\n\nArrow pointing to a specific location with label.\n\n```tsx\n<PointerCallout\n  targetX={400}\n  targetY={300}\n  labelX={600}\n  labelY={200}\n  label=\"Important feature\"\n  arrowColor=\"#8b5cf6\"\n  animate              // Fade in with arrow draw\n/>\n```\n\n### 2. Bracket Callout\n\nBrackets around a region to highlight an area.\n\n```tsx\n<BracketCallout\n  x={300}\n  y={200}\n  widt",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "celery-advanced": {
    "name": "celery-advanced",
    "description": "Advanced Celery patterns including canvas workflows, priority queues, rate limiting, multi-queue routing, and production monitoring. Use when implementing complex task orchestration, task prioritization, or enterprise-grade background processing.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "celery",
      "canvas",
      "workflow",
      "priority-queue",
      "rate-limiting",
      "task-routing",
      "flower"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "python-performance-engineer",
    "structure": {
      "references": [
        "canvas-workflows.md",
        "celery-beat-scheduling.md",
        "priority-queue-setup.md",
        "rate-limiting-patterns.md"
      ],
      "scripts": [
        "canvas-workflow-template.py",
        "celery-config-template.py",
        "priority-task-template.py"
      ],
      "checklists": [
        "monitoring-checklist.md",
        "production-checklist.md"
      ]
    },
    "content": "# Advanced Celery Patterns\n\nEnterprise-grade task orchestration beyond basic background jobs.\n\n## Overview\n\n- Complex multi-step task workflows (ETL pipelines, order processing)\n- Priority-based task processing (premium vs standard users)\n- Rate-limited external API calls (API quotas, throttling)\n- Multi-queue routing (dedicated workers per task type)\n- Production monitoring and observability\n- Task result aggregation and fan-out patterns\n\n## Canvas Workflows\n\n### Signatures (Task Invocation)\n\n```python\nfrom celery import signature, chain, group, chord\n\n# Create a reusable task signature\nsig = signature(\"tasks.process_order\", args=[order_id], kwargs={\"priority\": \"high\"})\n\n# Immutable signature (won't receive results from previous task)\nsig = process_order.si(order_id)\n\n# Partial signature (curry arguments)\npartial_sig = send_email.s(subject=\"Order Update\")\n# Later: partial_sig.delay(to=\"user@example.com\", body=\"...\")\n```\n\n### Chains (Sequential Execution)\n\n```python\nfrom celery import chain\n\n# Tasks execute sequentially, passing results\nworkflow = chain(\n    extract_data.s(source_id),      # Returns raw_data\n    transform_data.s(),              # Receives raw_data, returns clean_data\n    load_data.s(destination_id),     # Receives clean_data\n)\nresult = workflow.apply_async()\n\n# Access intermediate results\nchain_result = result.get()  # Final result\nparent_result = result.parent.get()  # Previous task result\n\n# Error handling in chains\n@celery_app.task(bind=True)\ndef transform_data(self, raw_data):\n    try:\n        return do_transform(raw_data)\n    except TransformError as exc:\n        # Chain stops here, no subsequent tasks run\n        raise self.retry(exc=exc, countdown=60)\n```\n\n### Groups (Parallel Execution)\n\n```python\nfrom celery import group\n\n# Execute tasks in parallel\nparallel = group(\n    process_chunk.s(chunk) for chunk in chunks\n)\ngroup_result = parallel.apply_async()\n\n# Wait for all to complete\nresults = group_result.get()  # List of results\n\n# Check completion status\ngroup_result.ready()      # All completed?\ngroup_result.successful() # All succeeded?\ngroup_result.failed()     # Any failed?\n\n# Iterate as they complete\nfor result in group_result:\n    if result.ready():\n        print(f\"Completed: {result.get()}\")\n```\n\n### Chords (Parallel + Callback)\n\n```python\nfrom celery import chord\n\n# Parallel execution with callback when all complete\nworkflow = chord(\n    [process_chunk.s(chunk) for chunk in chunks],\n    aggregate_results.s()  # Receives list of all results\n)\nresult = workflow.apply_async()\n\n# Chord with header and body\nheader = group(fetch_data.s(url) for url in urls)\nbody = combine_data.s()\nworkflow = chord(header, body)\n\n# Error handling: if any header task fails, body won't run\n@celery_app.task(bind=True)\ndef aggregate_results(self, results):\n    # results = [result1, result2, ...]\n    return sum(results)\n```\n\n### Map and Starmap\n\n```python\n# Map: apply same task to each item\nworkflow = process_item.map([item1, item2, item3])\n\n",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "python-performance-engineer"
    ]
  },
  "clean-architecture": {
    "name": "clean-architecture",
    "description": "SOLID principles, hexagonal architecture, ports and adapters, and DDD tactical patterns for maintainable backends. Use when implementing clean architecture, decoupling services, separating domain logic, or creating testable architecture.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "architecture",
      "solid",
      "hexagonal",
      "ddd",
      "python",
      "fastapi"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "code-quality-reviewer",
    "structure": {
      "references": [
        "hexagonal-architecture.md"
      ],
      "scripts": [
        "domain-entity-template.py"
      ],
      "checklists": [
        "solid-checklist.md"
      ]
    },
    "content": "# Clean Architecture Patterns\n\nBuild maintainable, testable backends with SOLID principles and hexagonal architecture.\n\n## SOLID Principles ( Python)\n\n### S - Single Responsibility\n\n```python\n# BAD: One class doing everything\nclass UserManager:\n    def create_user(self, data): ...\n    def send_welcome_email(self, user): ...\n    def generate_report(self, users): ...\n\n# GOOD: Separate responsibilities\nclass UserService:\n    def create_user(self, data: UserCreate) -> User: ...\n\nclass EmailService:\n    def send_welcome(self, user: User) -> None: ...\n\nclass ReportService:\n    def generate_user_report(self, users: list[User]) -> Report: ...\n```\n\n### O - Open/Closed (Protocol-based)\n\n```python\nfrom typing import Protocol\n\nclass PaymentProcessor(Protocol):\n    async def process(self, amount: Decimal) -> PaymentResult: ...\n\nclass StripeProcessor:\n    async def process(self, amount: Decimal) -> PaymentResult:\n        # Stripe implementation\n        ...\n\nclass PayPalProcessor:\n    async def process(self, amount: Decimal) -> PaymentResult:\n        # PayPal implementation - extends without modifying\n        ...\n```\n\n### L - Liskov Substitution\n\n```python\n# Any implementation of Repository can substitute another\nclass IUserRepository(Protocol):\n    async def get_by_id(self, id: str) -> User | None: ...\n    async def save(self, user: User) -> User: ...\n\nclass PostgresUserRepository:\n    async def get_by_id(self, id: str) -> User | None: ...\n    async def save(self, user: User) -> User: ...\n\nclass InMemoryUserRepository:  # For testing - fully substitutable\n    async def get_by_id(self, id: str) -> User | None: ...\n    async def save(self, user: User) -> User: ...\n```\n\n### I - Interface Segregation\n\n```python\n# BAD: Fat interface\nclass IRepository(Protocol):\n    async def get(self, id: str): ...\n    async def save(self, entity): ...\n    async def delete(self, id: str): ...\n    async def search(self, query: str): ...\n    async def bulk_insert(self, entities): ...\n\n# GOOD: Segregated interfaces\nclass IReader(Protocol):\n    async def get(self, id: str) -> T | None: ...\n\nclass IWriter(Protocol):\n    async def save(self, entity: T) -> T: ...\n\nclass ISearchable(Protocol):\n    async def search(self, query: str) -> list[T]: ...\n```\n\n### D - Dependency Inversion\n\n```python\nfrom typing import Protocol\nfrom fastapi import Depends\n\nclass IAnalysisRepository(Protocol):\n    async def get_by_id(self, id: str) -> Analysis | None: ...\n\nclass AnalysisService:\n    def __init__(self, repo: IAnalysisRepository):\n        self._repo = repo  # Depends on abstraction, not concrete\n\n# FastAPI DI\ndef get_analysis_service(\n    db: AsyncSession = Depends(get_db)\n) -> AnalysisService:\n    repo = PostgresAnalysisRepository(db)\n    return AnalysisService(repo)\n```\n\n## Hexagonal Architecture (Ports & Adapters)\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      DRIVING ADAPTERS                        │\n│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌───────",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "code-review-playbook": {
    "name": "code-review-playbook",
    "description": "Use this skill when conducting or improving code reviews. Provides structured review processes, conventional comments patterns, language-specific checklists, and feedback templates. Use when reviewing PRs or standardizing review practices.",
    "version": "2.0.0",
    "author": "AI Agent Hub",
    "tags": [
      "code-review",
      "quality",
      "collaboration",
      "best-practices"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "code-quality-reviewer",
    "structure": {
      "references": [
        "review-patterns.md"
      ],
      "assets": [
        "pr-template.md",
        "review-feedback-template.md"
      ],
      "scripts": [
        "fetch-pr-data.sh",
        "review-pr.md",
        "run-pr-checks.py"
      ],
      "checklists": [
        "code-review-checklist.md"
      ]
    },
    "content": "# Code Review Playbook\nThis skill provides a comprehensive framework for effective code reviews that improve code quality, share knowledge, and foster collaboration. Whether you're a reviewer giving feedback or an author preparing code for review, this playbook ensures reviews are thorough, consistent, and constructive.\n\n## Overview\n- Reviewing pull requests or merge requests\n- Preparing code for review (self-review)\n- Establishing code review standards for teams\n- Training new developers on review best practices\n- Resolving disagreements about code quality\n- Improving review processes and efficiency\n\n## Code Review Philosophy\n\n### Purpose of Code Reviews\n\nCode reviews serve multiple purposes:\n\n1. **Quality Assurance**: Catch bugs, logic errors, and edge cases\n2. **Knowledge Sharing**: Spread domain knowledge across the team\n3. **Consistency**: Ensure codebase follows conventions and patterns\n4. **Mentorship**: Help developers improve their skills\n5. **Collective Ownership**: Build shared responsibility for code\n6. **Documentation**: Create discussion history for future reference\n\n### Principles\n\n**Be Kind and Respectful:**\n- Review the code, not the person\n- Assume positive intent\n- Praise good solutions\n- Frame feedback constructively\n\n**Be Specific and Actionable:**\n- Point to specific lines of code\n- Explain *why* something should change\n- Suggest concrete improvements\n- Provide examples when helpful\n\n**Balance Speed with Thoroughness:**\n- Aim for timely feedback (< 24 hours)\n- Don't rush critical reviews\n- Use automation for routine checks\n- Focus human review on logic and design\n\n**Distinguish Must-Fix from Nice-to-Have:**\n- Use conventional comments to indicate severity\n- Block merges only for critical issues\n- Allow authors to defer minor improvements\n- Capture deferred work in follow-up tickets\n\n---\n\n## Conventional Comments\n\nA standardized format for review comments that makes intent clear.\n\n### Format\n\n```\n<label> [decorations]: <subject>\n\n[discussion]\n```\n\n### Labels\n\n| Label | Meaning | Blocks Merge? |\n|-------|---------|---------------|\n| **praise** | Highlight something positive | No |\n| **nitpick** | Minor, optional suggestion | No |\n| **suggestion** | Propose an improvement | No |\n| **issue** | Problem that should be addressed | Usually |\n| **question** | Request clarification | No |\n| **thought** | Idea to consider | No |\n| **chore** | Routine task (formatting, deps) | No |\n| **note** | Informational comment | No |\n| **todo** | Follow-up work needed | Maybe |\n| **security** | Security concern | **Yes** |\n| **bug** | Potential bug | **Yes** |\n| **breaking** | Breaking change | **Yes** |\n\n### Decorations\n\nOptional modifiers in square brackets:\n\n| Decoration | Meaning |\n|------------|---------|\n| **[blocking]** | Must be addressed before merge |\n| **[non-blocking]** | Optional, can be deferred |\n| **[if-minor]** | Only if it's a quick fix |\n\n### Examples\n\n```typescript\n// ✅ Good: Clear, specific, actionable\n\npraise: Excellent use o",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "commit": {
    "name": "commit",
    "description": "Creates commits with conventional format and validation. Use when committing changes or generating commit messages.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "commit",
      "version-control",
      "conventional-commits"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Bash"
    ],
    "skills": [
      "git-recovery"
    ],
    "agent": null,
    "structure": {
      "references": [
        "conventional-commits.md",
        "recovery.md"
      ]
    },
    "content": "# Smart Commit\n\nSimple, validated commit creation. Run checks locally, no agents needed for standard commits.\n\n## Quick Start\n\n```bash\n/commit\n```\n\n## Workflow\n\n### Phase 1: Pre-Commit Safety Check\n\n```bash\n# CRITICAL: Verify we're not on dev/main\nBRANCH=$(git branch --show-current)\nif [[ \"$BRANCH\" == \"dev\" || \"$BRANCH\" == \"main\" || \"$BRANCH\" == \"master\" ]]; then\n  echo \"STOP! Cannot commit directly to $BRANCH\"\n  echo \"Create a feature branch: git checkout -b issue/<number>-<description>\"\n  exit 1\nfi\n```\n\n### Phase 2: Run Validation Locally\n\nRun every check that CI runs:\n\n```bash\n# Backend (Python)\npoetry run ruff format --check app/\npoetry run ruff check app/\npoetry run mypy app/\n\n# Frontend (Node.js)\nnpm run format:check\nnpm run lint\nnpm run typecheck\n```\n\nFix any failures before proceeding.\n\n### Phase 3: Review Changes\n\n```bash\ngit status\ngit diff --staged   # What will be committed\ngit diff            # Unstaged changes\n```\n\n### Phase 4: Stage and Commit\n\n```bash\n# Stage files\ngit add <files>\n# Or all: git add .\n\n# Commit with conventional format\ngit commit -m \"<type>(#<issue>): <brief description>\n\n- [Change 1]\n- [Change 2]\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n\n# Verify\ngit log -1 --stat\n```\n\n## Commit Types\n\n| Type | Use For |\n|------|---------|\n| `feat` | New feature |\n| `fix` | Bug fix |\n| `refactor` | Code improvement |\n| `docs` | Documentation |\n| `test` | Tests only |\n| `chore` | Build/deps/CI |\n\n## Rules\n\n1. **Run validation locally** - Don't spawn agents to run lint/test\n2. **NO file creation** - Don't create MD files or documentation\n3. **One logical change per commit** - Keep commits focused\n4. **Reference issues** - Use `#123` format in commit message\n5. **Subject line < 72 chars** - Keep it concise\n\n## Quick Commit\n\nFor trivial changes (typos, single-line fixes):\n\n```bash\ngit add . && git commit -m \"fix(#123): Fix typo in error message\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n```\n\n## Related Skills\n- create-pr: Create pull requests from commits\n- review-pr: Review changes before committing\n- fix-issue: Fix issues and commit the fixes\n- issue-progress-tracking: Auto-updates GitHub issues with commit progress\n## References\n\n- [Conventional Commits](references/conventional-commits.md)\n- [Recovery](references/recovery.md)",
    "contentTruncated": false,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "git-operations-engineer"
    ]
  },
  "competitive-monitoring": {
    "name": "competitive-monitoring",
    "description": "Tracks competitor page changes over time. Captures snapshots, detects diffs, alerts on significant changes. Supports Tavily site discovery for URL enumeration. Use when monitoring competitive intelligence, pricing changes, or feature tracking.",
    "version": "1.1.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "competitive-intelligence",
      "monitoring",
      "diff",
      "tracking",
      "pricing",
      "tavily"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "Bash",
      "Read",
      "Write",
      "WebFetch"
    ],
    "skills": [],
    "agent": "market-intelligence",
    "structure": {},
    "content": "# Competitive Monitoring\n\nTrack competitor websites for changes in pricing, features, positioning, and content.\n\n## Quick Start\n\n```bash\n# Capture initial snapshot\n/ork:competitive-monitoring capture https://competitor.com/pricing\n\n# Check for changes (compares to last snapshot)\n/ork:competitive-monitoring diff https://competitor.com/pricing\n\n# View change history\n/ork:competitive-monitoring history competitor.com\n```\n\n## Core Concepts\n\n### Snapshot\nA point-in-time capture of a webpage including:\n- **Text content** - Main body text\n- **Structured data** - Pricing tiers, feature lists, etc.\n- **Screenshot** - Visual state\n- **Metadata** - Timestamp, URL, capture method\n\n### Diff\nComparison between two snapshots showing:\n- **Added content** - New text, features, prices\n- **Removed content** - Deleted sections\n- **Changed content** - Modified values\n- **Visual changes** - Layout/design shifts\n\n### Change Classification\n\n| Severity | Examples | Action |\n|----------|----------|--------|\n| **Critical** | Price increase/decrease, major feature change | Immediate alert |\n| **High** | New feature added, feature removed | Review required |\n| **Medium** | Copy changes, positioning shift | Note for analysis |\n| **Low** | Typos, minor styling | Log only |\n\n## Site Discovery with Tavily (Optional Pre-Step)\n\nWhen `TAVILY_API_KEY` is available, use Tavily's crawl API to discover and extract all key pages on a competitor's site in one call. This replaces the manual map→extract two-step workflow.\n\n### Option A: Crawl (Recommended — Single Call)\n\n```bash\n# Crawl competitor site — discovers URLs and extracts content in one step\ncurl -s -X POST 'https://api.tavily.com/crawl' \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: Bearer $TAVILY_API_KEY\" \\\n  -d '{\n    \"url\": \"https://competitor.com\",\n    \"max_depth\": 2,\n    \"limit\": 50,\n    \"include_raw_content\": \"markdown\",\n    \"include_paths\": [\"/pricing*\", \"/features*\", \"/changelog*\", \"/blog*\"]\n  }' | python3 -c \"\nimport json, sys\ndata = json.load(sys.stdin)\nfor page in data.get('results', []):\n    fname = page['url'].replace('https://', '').replace('/', '_')\n    with open(f'.competitive-intel/snapshots/{fname}.md', 'w') as f:\n        f.write(page.get('raw_content', page.get('content', '')))\n    print(f'Captured: {page[\\\"url\\\"]}')\n\"\n```\n\n### Option B: Map + Extract (Granular Control)\n\nUse when you need to filter URLs before extracting:\n\n```bash\n# Step 1: Discover URLs\ncurl -s -X POST 'https://api.tavily.com/map' \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: Bearer $TAVILY_API_KEY\" \\\n  -d '{\"url\": \"https://competitor.com\", \"max_depth\": 2, \"limit\": 50}' \\\n  | python3 -c \"\nimport json, sys\nfor url in json.load(sys.stdin).get('urls', []): print(url)\n\" > .competitive-intel/discovered-urls.txt\n\n# Step 2: Filter and batch extract\nURLS=$(grep -E '(pricing|features|changelog)' .competitive-intel/discovered-urls.txt \\\n  | head -20 | python3 -c \"import json,sys; print(json.dumps([l.strip() for l in sys",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "web-research-analyst"
    ]
  },
  "configure": {
    "name": "configure",
    "description": "Configures OrchestKit settings. Use when customizing MCP servers, plugin options, or preferences.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "configuration",
      "setup",
      "wizard",
      "customization"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Bash",
      "Read",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "mcp-config.md",
        "presets.md"
      ]
    },
    "content": "# OrchestKit Configuration\n\nInteractive setup for customizing your OrchestKit installation.\n\n## Quick Start\n\n```bash\n/configure\n```\n\n## Step 1: Choose Preset\n\nUse AskUserQuestion:\n\n| Preset | Skills | Agents | Hooks | Description |\n|--------|--------|--------|-------|-------------|\n| **Complete** | 78 | 20 | 92 | Everything |\n| **Standard** | 78 | 0 | 92 | Skills, no agents |\n| **Lite** | 10 | 0 | 92 | Essential only |\n| **Hooks-only** | 0 | 0 | 92 | Just safety |\n| **Monorepo** | 78 | 20 | 92 | Complete + monorepo detection |\n\n## Step 2: Customize Skill Categories\n\nCategories available:\n- AI/ML (26 skills)\n- Backend (15 skills)\n- Frontend (8 skills)\n- Testing (13 skills)\n- Security (7 skills)\n- DevOps (4 skills)\n- Planning (6 skills)\n\n## Step 3: Customize Agents\n\n**Product Agents (6):**\n- market-intelligence\n- product-strategist\n- requirements-translator\n- ux-researcher\n- prioritization-analyst\n- business-case-builder\n\n**Technical Agents (14):**\n- backend-system-architect\n- frontend-ui-developer\n- database-engineer\n- llm-integrator\n- workflow-architect\n- data-pipeline-engineer\n- test-generator\n- code-quality-reviewer\n- security-auditor\n- security-layer-auditor\n- debug-investigator\n- metrics-architect\n- rapid-ui-designer\n- system-design-reviewer\n\n## Step 4: Configure Hooks\n\n**Safety Hooks (Always On):**\n- git-branch-protection\n- file-guard\n- redact-secrets\n\n**Toggleable Hooks:**\n- Productivity (auto-approve, logging)\n- Quality Gates (coverage, patterns)\n- Team Coordination (locks, conflicts)\n- Notifications (desktop, sound)\n\n## Step 5: Configure MCPs (Optional)\n\nAll MCPs disabled by default. Enable selectively:\n\n| MCP | Purpose |\n|-----|---------|\n| context7 | Library documentation |\n| sequential-thinking | Complex reasoning |\n| memory | Cross-session persistence |\n| playwright | Browser automation |\n\n## Step 6: CC 2.1.7 Settings (New)\n\nConfigure CC 2.1.7-specific features:\n\n### Turn Duration Display\n\n```\nEnable turn duration in statusline? [y/N]: y\n```\n\nAdds to settings.json:\n```json\n{\n  \"statusline\": {\n    \"showTurnDuration\": true\n  }\n}\n```\n\n### MCP Auto-Deferral Threshold\n\n```\nMCP deferral threshold (default 10%): 10\n```\n\nAdds to config.json:\n```json\n{\n  \"cc217\": {\n    \"mcp_defer_threshold\": 0.10,\n    \"use_effective_window\": true\n  }\n}\n```\n\n### Effective Context Window Mode\n\n```\nUse effective context window for calculations? [Y/n]: y\n```\n\nWhen enabled:\n- Statusline shows `context_window.effective_percentage`\n- Compression triggers use effective window\n- MCP deferral more accurate\n\n## Step 7: CC 2.1.20 Settings\n\nConfigure CC 2.1.20-specific features:\n\n### Task Deletion Support\n\n```\nEnable task deletion (status: \"deleted\")? [Y/n]: y\n```\n\nEnables orphan detection and automatic cleanup of blocked tasks.\n\n### PR Status Enrichment\n\n```\nEnable PR status enrichment at session start? [Y/n]: y\n```\n\nDetects open PRs on current branch and sets `ORCHESTKIT_PR_URL` / `ORCHESTKIT_PR_STATE` env vars.\n\n### Background Agent Permission Pre-Mapping\n\n```\nEnable pe",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "connection-pooling": {
    "name": "connection-pooling",
    "description": "Database and HTTP connection pooling patterns for Python async applications. Use when configuring asyncpg pools, aiohttp sessions, or optimizing connection lifecycle in high-concurrency services.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "connection-pool",
      "asyncpg",
      "aiohttp",
      "database",
      "http",
      "performance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "pool-sizing.md"
      ],
      "scripts": [
        "pool-setup-template.py"
      ],
      "checklists": [
        "connection-pool-checklist.md"
      ]
    },
    "content": "# Connection Pooling Patterns ()\n\nDatabase and HTTP connection pooling for high-performance async Python applications.\n\n## Overview\n\n- Configuring asyncpg/SQLAlchemy connection pools\n- Setting up aiohttp ClientSession for HTTP requests\n- Diagnosing connection exhaustion or leaks\n- Optimizing pool sizes for workload\n- Implementing health checks and connection validation\n\n## Quick Reference\n\n### SQLAlchemy Async Pool Configuration\n\n```python\nfrom sqlalchemy.ext.asyncio import create_async_engine\n\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@localhost/db\",\n\n    # Pool sizing\n    pool_size=20,           # Steady-state connections\n    max_overflow=10,        # Burst capacity (total max = 30)\n\n    # Connection health\n    pool_pre_ping=True,     # Validate before use (adds ~1ms latency)\n    pool_recycle=3600,      # Recreate connections after 1 hour\n\n    # Timeouts\n    pool_timeout=30,        # Wait for connection from pool\n    connect_args={\n        \"command_timeout\": 60,      # Query timeout\n        \"server_settings\": {\n            \"statement_timeout\": \"60000\",  # 60s query timeout\n        },\n    },\n)\n```\n\n### Direct asyncpg Pool\n\n```python\nimport asyncpg\n\npool = await asyncpg.create_pool(\n    \"postgresql://user:pass@localhost/db\",\n\n    # Pool sizing\n    min_size=10,            # Minimum connections kept open\n    max_size=20,            # Maximum connections\n\n    # Connection lifecycle\n    max_inactive_connection_lifetime=300,  # Close idle after 5 min\n\n    # Timeouts\n    command_timeout=60,     # Query timeout\n    timeout=30,             # Connection timeout\n\n    # Setup for each connection\n    setup=setup_connection,\n)\n\nasync def setup_connection(conn):\n    \"\"\"Run on each new connection.\"\"\"\n    await conn.execute(\"SET timezone TO 'UTC'\")\n    await conn.execute(\"SET statement_timeout TO '60s'\")\n```\n\n### aiohttp Session Pool\n\n```python\nimport aiohttp\nfrom aiohttp import TCPConnector\n\nconnector = TCPConnector(\n    # Connection limits\n    limit=100,              # Total connections\n    limit_per_host=20,      # Per-host limit\n\n    # Timeouts\n    keepalive_timeout=30,   # Keep-alive duration\n\n    # SSL\n    ssl=False,              # Or ssl.SSLContext for HTTPS\n\n    # DNS\n    ttl_dns_cache=300,      # DNS cache TTL\n)\n\nsession = aiohttp.ClientSession(\n    connector=connector,\n    timeout=aiohttp.ClientTimeout(\n        total=30,           # Total request timeout\n        connect=10,         # Connection timeout\n        sock_read=20,       # Read timeout\n    ),\n)\n\n# IMPORTANT: Reuse session across requests\n# Create once at startup, close at shutdown\n```\n\n### FastAPI Lifespan with Pools\n\n```python\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup: create pools\n    app.state.db_pool = await asyncpg.create_pool(DATABASE_URL)\n    app.state.http_session = aiohttp.ClientSession(\n        connector=TCPConnector(limit=100)\n    )\n\n    yield\n\n    # Shutdown: cl",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "python-performance-engineer"
    ]
  },
  "content-type-recipes": {
    "name": "content-type-recipes",
    "description": "Step-by-step recipes for demo videos. Use when creating skill demos, agent showcases, plugin installs, or tutorial walkthroughs with precise timing",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "recipes",
      "demos",
      "templates",
      "timing",
      "production"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "agent-demo-recipe.md",
        "plugin-demo-recipe.md",
        "skill-demo-recipe.md",
        "tutorial-recipe.md"
      ]
    },
    "content": "# Content Type Recipes\n\nComplete production recipes for creating demo videos across different OrchestKit content types. Each recipe provides exact timing, shot breakdowns, audio cues, text overlays, and transitions.\n\n## Recipe Overview\n\n| Content Type | Duration | Use Case |\n|--------------|----------|----------|\n| Skill Demo | 15-25s | Single skill showcase |\n| Agent Demo | 20-30s | Parallel execution, multi-agent |\n| Plugin Install | 10-15s | Quick impact, marketplace |\n| Tutorial | 60-120s | Educational, step-by-step |\n| Comparison | 20-40s | Before/after transformations |\n| Feature Highlight | 10-20s | Single feature focus |\n\n## Quick Reference\n\n### Frame Rate & Resolution\n- **Frame Rate**: 30fps (standard), 60fps (smooth typing)\n- **Resolution**: 1920x1080 (YouTube), 1080x1920 (shorts)\n- **Aspect Ratios**: 16:9 (horizontal), 9:16 (vertical), 1:1 (social)\n\n### Timing Constants\n\n```typescript\nconst TIMING = {\n  TYPING_SPEED: 50,      // ms per character\n  COMMAND_PAUSE: 500,    // ms after command typed\n  RESULT_DELAY: 200,     // ms before showing result\n  READ_TIME: 3000,       // ms for text comprehension\n  TRANSITION: 300,       // ms for smooth transitions\n};\n```\n\n### Audio Cues Library\n- **Key Press**: Subtle mechanical keyboard sound\n- **Command Execute**: Soft whoosh or confirmation tone\n- **Success**: Bright chime (C major)\n- **Error**: Low tone (for contrast demos)\n- **Transition**: Subtle swoosh\n\n## Recipe 1: Skill Demo (15-25 seconds)\n\n**Purpose**: Showcase a single skill's capability in minimal time.\n\n### Structure\n\n```\n[0:00-0:03] Hook - Problem statement\n[0:03-0:08] Command - Type and execute\n[0:08-0:18] Result - Show output with highlights\n[0:18-0:22] Impact - Key benefit callout\n[0:22-0:25] CTA - Next step or skill name\n```\n\n### Shot List\n\n| Shot | Duration | Camera | Subject | Notes |\n|------|----------|--------|---------|-------|\n| 1 | 3s | Static | Terminal | Problem text overlay |\n| 2 | 5s | Static | Terminal | Typing animation |\n| 3 | 10s | Slow zoom | Output | Highlight key areas |\n| 4 | 4s | Pull back | Full screen | Impact + CTA |\n| 5 | 3s | Static | Skill badge | End card |\n\nSee `references/skill-demo-recipe.md` for detailed breakdown.\n\n## Recipe 2: Agent Demo (20-30 seconds)\n\n**Purpose**: Demonstrate multi-agent coordination and parallel execution.\n\n### Structure\n\n```\n[0:00-0:04] Setup - Show the task\n[0:04-0:10] Dispatch - Agent spawning visualization\n[0:10-0:22] Parallel Work - Split screen showing agents\n[0:22-0:27] Synthesis - Results combining\n[0:27-0:30] Summary - Agent count and time saved\n```\n\nSee `references/agent-demo-recipe.md` for detailed breakdown.\n\n## Recipe 3: Plugin Install Demo (10-15 seconds)\n\n**Purpose**: Quick impact showcase for marketplace listings.\n\n### Structure\n\n```\n[0:00-0:02] Before State - Empty/manual\n[0:02-0:06] Install Command - One line\n[0:06-0:10] Transformation - Capabilities appear\n[0:10-0:13] Available Now - Feature list flash\n[0:13-0:15] Install CTA\n```\n\nSee `references/plugin-de",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "context-compression": {
    "name": "context-compression",
    "description": "Use when conversation context is too long, hitting token limits, or responses are degrading. Compresses history while preserving critical information using anchored summarization and probe-based validation.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "context",
      "compression",
      "summarization",
      "memory",
      "optimization"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "compression-strategies.md",
        "priority-management.md"
      ],
      "assets": [
        "anchored-summary-template.md",
        "compression-probes-template.md"
      ],
      "checklists": [
        "compression-checklist.md"
      ]
    },
    "content": "# Context Compression\n\n**Reduce context size while preserving information critical to task completion.**\n\n## Overview\n\nContext compression is essential for long-running agent sessions. The goal is NOT maximum compression—it's preserving enough information to complete tasks without re-fetching.\n\n**Key Metric:** Tokens-per-task (total tokens to complete a task), NOT tokens-per-request.\n\n## When to Use\n\n- Long-running conversations approaching context limits\n- Multi-step agent workflows with accumulating history\n- Sessions with large tool outputs\n- Memory management in persistent agents\n\n---\n\n## Strategy Quick Reference\n\n| Strategy | Compression | Interpretable | Verifiable | Best For |\n|----------|-------------|---------------|------------|----------|\n| Anchored Iterative | 60-80% | Yes | Yes | Long sessions |\n| Opaque | 95-99% | No | No | Storage-critical |\n| Regenerative Full | 70-85% | Yes | Partial | Simple tasks |\n| Sliding Window | 50-70% | Yes | Yes | Real-time chat |\n\n**Recommended:** Anchored Iterative Summarization with probe-based evaluation.\n\n---\n\n## Anchored Summarization (RECOMMENDED)\n\nMaintains structured, persistent summaries with forced sections:\n\n```\n## Session Intent\n[What we're trying to accomplish - NEVER lose this]\n\n## Files Modified\n- path/to/file.ts: Added function X, modified class Y\n\n## Decisions Made\n- Decision 1: Chose X over Y because [rationale]\n\n## Current State\n[Where we are in the task - progress indicator]\n\n## Blockers / Open Questions\n- Question 1: Awaiting user input on...\n\n## Next Steps\n1. Complete X\n2. Test Y\n```\n\n**Why it works:**\n- Structure FORCES preservation of critical categories\n- Each section must be explicitly populated (can't silently drop info)\n- Incremental merge (new compressions extend, don't replace)\n\n---\n\n## Implementation\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\n@dataclass\nclass AnchoredSummary:\n    \"\"\"Structured summary with forced sections.\"\"\"\n\n    session_intent: str\n    files_modified: dict[str, list[str]] = field(default_factory=dict)\n    decisions_made: list[dict] = field(default_factory=list)\n    current_state: str = \"\"\n    blockers: list[str] = field(default_factory=list)\n    next_steps: list[str] = field(default_factory=list)\n    compression_count: int = 0\n\n    def merge(self, new_content: \"AnchoredSummary\") -> \"AnchoredSummary\":\n        \"\"\"Incrementally merge new summary into existing.\"\"\"\n        return AnchoredSummary(\n            session_intent=new_content.session_intent or self.session_intent,\n            files_modified={**self.files_modified, **new_content.files_modified},\n            decisions_made=self.decisions_made + new_content.decisions_made,\n            current_state=new_content.current_state,\n            blockers=new_content.blockers,\n            next_steps=new_content.next_steps,\n            compression_count=self.compression_count + 1,\n        )\n\n    def to_markdown(self) -> str:\n        \"\"\"Render as markdown for context injection.",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "context-engineering": {
    "name": "context-engineering",
    "description": "Use when designing agent system prompts, optimizing RAG retrieval, or when context is too expensive or slow. Reduces tokens while maintaining quality through strategic positioning and attention-aware design.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "context",
      "attention",
      "optimization",
      "llm",
      "performance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "attention-mechanics.md",
        "context-layers.md"
      ],
      "checklists": [
        "context-optimization-checklist.md"
      ]
    },
    "content": "# Context Engineering\n\n**The discipline of curating the smallest high-signal token set that achieves desired outcomes.**\n\n## Overview\n\nContext engineering goes beyond prompt engineering. While prompts focus on *what* you ask, context engineering focuses on *everything* the model sees—system instructions, tool definitions, documents, message history, and tool outputs.\n\n**Key Insight:** Context windows are constrained not by raw token capacity but by attention mechanics. As context grows, models experience degradation.\n\n## When to Use\n\n- Designing agent system prompts\n- Optimizing RAG retrieval pipelines\n- Managing long-running conversations\n- Building multi-agent architectures\n- Reducing token costs while maintaining quality\n\n---\n\n## The \"Lost in the Middle\" Phenomenon\n\nModels pay unequal attention across the context window:\n\n```\nAttention\nStrength   ████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░████████\n           ↑                                                      ↑\n        START              MIDDLE (weakest attention)           END\n```\n\n**Practical Implications:**\n\n| Position | Attention | Best For |\n|----------|-----------|----------|\n| START | High | System identity, critical instructions, constraints |\n| MIDDLE | Low | Background context, optional details |\n| END | High | Current task, recent messages, immediate query |\n\n---\n\n## The Five Context Layers\n\n### 1. System Prompts (Identity Layer)\n\nEstablishes agent identity at the right \"altitude\":\n\n```\nTOO HIGH (vague):        \"You are a helpful assistant\"\nTOO LOW (brittle):       \"Always respond with exactly 3 bullet points...\"\nOPTIMAL (principled):    \"You are a senior engineer who values clarity,\n                          tests assumptions, and explains trade-offs\"\n```\n\n**Best Practices:**\n- Define role and expertise level\n- State core principles (not rigid rules)\n- Include what NOT to do (boundaries)\n- Position at START of context\n\n### 2. Tool Definitions (Capability Layer)\n\nTools steer behavior through descriptions:\n\n```python\n# ❌ BAD: Ambiguous - when would you use this?\n@tool\ndef search(query: str) -> str:\n    \"\"\"Search for information.\"\"\"\n    pass\n\n# ✅ GOOD: Clear trigger conditions\n@tool\ndef search_documentation(query: str) -> str:\n    \"\"\"\n    Search internal documentation for technical answers.\n\n    USE WHEN:\n    - User asks about internal APIs or services\n    - Question requires company-specific knowledge\n    - Public information is insufficient\n\n    DO NOT USE WHEN:\n    - Question is general programming knowledge\n    - User explicitly wants external sources\n    \"\"\"\n    pass\n```\n\n**Rule:** If a human cannot definitively say which tool to use, an agent cannot either.\n\n### 3. Retrieved Documents (Knowledge Layer)\n\nJust-in-time loading beats pre-loading:\n\n```python\n# ❌ BAD: Pre-load everything\ncontext = load_all_documentation()  # 50k tokens!\n\n# ✅ GOOD: Progressive disclosure\ndef build_context(query: str) -> str:\n    # Stage 1: Lightweight retrieval (500 tokens)\n    summaries = sear",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "prompt-engineer"
    ]
  },
  "contextual-retrieval": {
    "name": "contextual-retrieval",
    "description": "Anthropic's Contextual Retrieval technique for improved RAG. Use when chunks lose context during retrieval, implementing hybrid BM25+vector search, or reducing retrieval failures.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "retrieval",
      "anthropic",
      "bm25",
      "vector-search"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {},
    "content": "# Contextual Retrieval\nPrepend situational context to chunks before embedding to preserve document-level meaning.\n\n## The Problem\n\nTraditional chunking loses context:\n```\nOriginal document: \"ACME Q3 2024 Earnings Report...\"\nChunk: \"Revenue increased 15% compared to the previous quarter.\"\n\nQuery: \"What was ACME's Q3 2024 revenue growth?\"\nResult: Chunk doesn't mention \"ACME\" or \"Q3 2024\" - retrieval fails\n```\n\n## The Solution\n\n**Contextual Retrieval** prepends a brief context to each chunk:\n```\nContextualized chunk:\n\"This chunk is from ACME Corp's Q3 2024 earnings report, specifically\nthe revenue section. Revenue increased 15% compared to the previous quarter.\"\n```\n\n## Implementation\n\n### Context Generation\n```python\nimport anthropic\n\nclient = anthropic.Anthropic()\n\nCONTEXT_PROMPT = \"\"\"\n<document>\n{document}\n</document>\n\nHere is the chunk we want to situate within the document:\n<chunk>\n{chunk}\n</chunk>\n\nPlease give a short, succinct context (1-2 sentences) to situate this chunk\nwithin the overall document. Focus on information that would help retrieval.\nAnswer only with the context, nothing else.\n\"\"\"\n\ndef generate_context(document: str, chunk: str) -> str:\n    \"\"\"Generate context for a single chunk.\"\"\"\n    response = client.messages.create(\n        model=\"claude-sonnet-4-5-20251101\",\n        max_tokens=150,\n        messages=[{\n            \"role\": \"user\",\n            \"content\": CONTEXT_PROMPT.format(document=document, chunk=chunk)\n        }]\n    )\n    return response.content[0].text\n\ndef contextualize_chunk(document: str, chunk: str) -> str:\n    \"\"\"Prepend context to chunk.\"\"\"\n    context = generate_context(document, chunk)\n    return f\"{context}\\n\\n{chunk}\"\n```\n\n### Batch Processing with Caching\n```python\nfrom anthropic import Anthropic\n\nclient = Anthropic()\n\ndef contextualize_chunks_cached(document: str, chunks: list[str]) -> list[str]:\n    \"\"\"\n    Use prompt caching to efficiently process many chunks from same document.\n    Document is cached, only chunk changes per request.\n    \"\"\"\n    results = []\n\n    for i, chunk in enumerate(chunks):\n        response = client.messages.create(\n            model=\"claude-sonnet-4-5-20251101\",\n            max_tokens=150,\n            messages=[{\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": f\"<document>\\n{document}\\n</document>\",\n                        \"cache_control\": {\"type\": \"ephemeral\"}  # Cache document\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": f\"\"\"\nHere is chunk {i+1} to situate:\n<chunk>\n{chunk}\n</chunk>\n\nGive a short context (1-2 sentences) to situate this chunk.\n\"\"\"\n                    }\n                ]\n            }]\n        )\n        context = response.content[0].text\n        results.append(f\"{context}\\n\\n{chunk}\")\n\n    return results\n```\n\n### Hybrid Search (BM25 + Vector)\n\nContextual Retrieval works best with hybrid se",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "contract-testing": {
    "name": "contract-testing",
    "description": "Consumer-driven contract testing with Pact for API compatibility. Use when testing microservice integrations, verifying API contracts, preventing breaking changes, or implementing provider verification.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "pact",
      "contract",
      "consumer-driven",
      "api",
      "microservices",
      "testing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "consumer-tests.md",
        "pact-broker.md",
        "provider-verification.md"
      ],
      "scripts": [
        "consumer-test-template.py",
        "provider-verification-template.py"
      ],
      "checklists": [
        "contract-testing-checklist.md"
      ]
    },
    "content": "# Contract Testing with Pact\n\nEnsure API compatibility between services with consumer-driven contracts.\n\n## Contract Testing vs Integration Testing\n\n| Integration Testing | Contract Testing |\n|---------------------|------------------|\n| Requires all services | Each service tests independently |\n| Slow feedback loop | Fast feedback |\n| Environment-dependent | Environment-independent |\n\n## Quick Reference\n\n### Consumer Test\n\n```python\nfrom pact import Consumer, Provider, Like, EachLike\n\npact = Consumer(\"UserDashboard\").has_pact_with(\n    Provider(\"UserService\"), pact_dir=\"./pacts\"\n)\n\ndef test_get_user(user_service):\n    (\n        user_service\n        .given(\"a user with ID user-123 exists\")\n        .upon_receiving(\"a request to get user\")\n        .with_request(\"GET\", \"/api/users/user-123\")\n        .will_respond_with(200, body={\n            \"id\": Like(\"user-123\"),      # Any string\n            \"email\": Like(\"test@example.com\"),\n        })\n    )\n\n    with user_service:\n        client = UserServiceClient(base_url=user_service.uri)\n        user = client.get_user(\"user-123\")\n        assert user.id == \"user-123\"\n```\n\nSee [consumer-tests.md](references/consumer-tests.md) for matchers and patterns.\n\n### Provider Verification\n\n```python\nfrom pact import Verifier\n\ndef test_provider_honors_pact():\n    verifier = Verifier(\n        provider=\"UserService\",\n        provider_base_url=\"http://localhost:8000\",\n    )\n\n    verifier.verify_with_broker(\n        broker_url=\"https://pact-broker.example.com\",\n        consumer_version_selectors=[{\"mainBranch\": True}],\n        publish_verification_results=True,\n    )\n```\n\nSee [provider-verification.md](references/provider-verification.md) for state setup.\n\n### Pact Broker CI/CD\n\n```bash\n# Publish consumer pacts\npact-broker publish ./pacts \\\n  --broker-base-url=$PACT_BROKER_URL \\\n  --consumer-app-version=$(git rev-parse HEAD)\n\n# Check if safe to deploy\npact-broker can-i-deploy \\\n  --pacticipant=UserDashboard \\\n  --version=$(git rev-parse HEAD) \\\n  --to-environment=production\n```\n\nSee [pact-broker.md](references/pact-broker.md) for CI/CD integration.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Contract storage | Pact Broker (not git) |\n| Consumer selectors | mainBranch + deployedOrReleased |\n| Provider states | Dedicated test endpoint |\n| Verification timing | After consumer publish |\n| Matchers | Use Like(), EachLike() for flexibility |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER specify exact values when structure matters\n.will_respond_with(200, body={\n    \"id\": \"user-123\",  # WRONG - too specific\n})\n# Use: \"id\": Like(\"user-123\")\n\n# NEVER test provider implementation details\n.given(\"database has 5 rows\")  # WRONG\n# Use: \"multiple users exist\"\n\n# NEVER skip provider state setup\n.given(\"some state\")  # Must be handled!\n\n# NEVER commit pact files to git\n# Use Pact Broker for versioning\n```\n\n## Related Skills\n\n- `integration-testing` - API endpoint testing\n- `api-design-framework` - REST",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "core-web-vitals": {
    "name": "core-web-vitals",
    "description": "Core Web Vitals optimization for LCP, INP, CLS with 2026 thresholds, performance budgets, and RUM. Use when improving page performance, diagnosing CWV regressions, or setting performance budgets.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "performance",
      "core-web-vitals",
      "lcp",
      "inp",
      "cls",
      "lighthouse",
      "rum",
      "web-vitals"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob",
      "Bash"
    ],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "rum-setup.md"
      ],
      "scripts": [
        "performance-monitoring.ts"
      ],
      "checklists": [
        "cwv-checklist.md"
      ]
    },
    "content": "# Core Web Vitals\n\nPerformance optimization for Google's Core Web Vitals - LCP, INP, CLS with 2026 thresholds.\n\n## Core Web Vitals Thresholds (2026)\n\n| Metric | Good | Needs Improvement | Poor |\n|--------|------|-------------------|------|\n| LCP (Largest Contentful Paint) | ≤ 2.5s | ≤ 4.0s | > 4.0s |\n| INP (Interaction to Next Paint) | ≤ 200ms | ≤ 500ms | > 500ms |\n| CLS (Cumulative Layout Shift) | ≤ 0.1 | ≤ 0.25 | > 0.25 |\n\n> **Note**: INP replaced FID (First Input Delay) in March 2024 as the official responsiveness metric.\n\n### Upcoming 2026 Stricter Thresholds (Q4 2025 rollout)\n\n| Metric | Current Good | 2026 Good |\n|--------|--------------|-----------|\n| LCP | ≤ 2.5s | ≤ 2.0s |\n| INP | ≤ 200ms | ≤ 150ms |\n| CLS | ≤ 0.1 | ≤ 0.08 |\n\nPlan for stricter thresholds now to maintain search rankings.\n\n## LCP Optimization\n\n### 1. Identify LCP Element\n\n```javascript\n// Find LCP element in DevTools\nnew PerformanceObserver((entryList) => {\n  const entries = entryList.getEntries();\n  const lastEntry = entries[entries.length - 1];\n  console.log('LCP element:', lastEntry.element);\n  console.log('LCP time:', lastEntry.startTime);\n}).observe({ type: 'largest-contentful-paint', buffered: true });\n```\n\n### 2. Optimize LCP Images\n\n```tsx\n// Priority loading for hero image\n<img\n  src=\"/hero.webp\"\n  alt=\"Hero\"\n  fetchpriority=\"high\"\n  loading=\"eager\"\n  decoding=\"async\"\n/>\n\n// Next.js Image with priority\nimport Image from 'next/image';\n\n<Image\n  src=\"/hero.webp\"\n  alt=\"Hero\"\n  priority\n  sizes=\"100vw\"\n  quality={85}\n/>\n```\n\n### 3. Preload Critical Resources\n\n```html\n<!-- Preload LCP image -->\n<link rel=\"preload\" as=\"image\" href=\"/hero.webp\" fetchpriority=\"high\" />\n\n<!-- Preload critical font -->\n<link rel=\"preload\" as=\"font\" href=\"/fonts/inter.woff2\" type=\"font/woff2\" crossorigin />\n\n<!-- Preconnect to critical origins -->\n<link rel=\"preconnect\" href=\"https://api.example.com\" />\n<link rel=\"dns-prefetch\" href=\"https://analytics.example.com\" />\n```\n\n### 4. Server-Side Rendering\n\n```typescript\n// Next.js - ensure SSR for LCP content\nexport default async function Page() {\n  const data = await fetchCriticalData();\n  return <HeroSection data={data} />; // Rendered on server\n}\n\n// Avoid client-only LCP content\n// BAD: LCP content loaded client-side\nconst [data, setData] = useState(null);\nuseEffect(() => { fetchData().then(setData); }, []);\n```\n\n## INP Optimization\n\n### 1. Break Up Long Tasks\n\n```typescript\n// BAD: Long synchronous task (blocks main thread)\nfunction processLargeArray(items: Item[]) {\n  items.forEach(processItem); // Blocks for entire duration\n}\n\n// GOOD: Yield to main thread\nasync function processLargeArray(items: Item[]) {\n  for (const item of items) {\n    processItem(item);\n    // Yield every 50ms to allow paint\n    if (performance.now() % 50 < 1) {\n      await scheduler.yield?.() ?? new Promise(r => setTimeout(r, 0));\n    }\n  }\n}\n```\n\n### 2. Use Transitions for Non-Urgent Updates\n\n```typescript\nimport { useTransition, useDeferredValue } from 'react';\n\nfu",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "monitoring-engineer",
      "performance-engineer"
    ]
  },
  "cqrs-patterns": {
    "name": "cqrs-patterns",
    "description": "CQRS (Command Query Responsibility Segregation) patterns for separating read and write models. Use when optimizing read-heavy systems, implementing event sourcing, or building systems with different read/write scaling requirements.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "cqrs",
      "command-query",
      "read-model",
      "write-model",
      "projection",
      "event-sourcing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "event-driven-architect",
    "structure": {
      "references": [
        "command-handlers.md",
        "event-store-setup.md",
        "projection-patterns.md",
        "query-handlers.md"
      ],
      "scripts": [
        "command-bus-template.py",
        "projection-template.py",
        "query-handler-template.py"
      ],
      "checklists": [
        "cqrs-adoption-checklist.md",
        "cqrs-implementation-checklist.md",
        "event-sourcing-checklist.md"
      ]
    },
    "content": "# CQRS Patterns\n\nSeparate read and write concerns for optimized data access.\n\n## Overview\n\n- Read-heavy workloads with complex queries\n- Different scaling requirements for reads vs writes\n- Event sourcing implementations\n- Multiple read model representations of same data\n- Complex domain models with simple read requirements\n\n## When NOT to Use\n\n- Simple CRUD applications\n- Strong consistency requirements everywhere\n- Small datasets with simple queries\n\n## Architecture Overview\n\n```\n┌─────────────────┐         ┌─────────────────┐\n│   Write Side    │         │   Read Side     │\n├─────────────────┤         ├─────────────────┤\n│  ┌───────────┐  │         │  ┌───────────┐  │\n│  │ Commands  │  │         │  │  Queries  │  │\n│  └─────┬─────┘  │         │  └─────┬─────┘  │\n│  ┌─────▼─────┐  │         │  ┌─────▼─────┐  │\n│  │ Aggregate │  │         │  │Read Model │  │\n│  └─────┬─────┘  │         │  └───────────┘  │\n│  ┌─────▼─────┐  │         │        ▲        │\n│  │  Events   │──┼─────────┼────────┘        │\n│  └───────────┘  │ Publish │   Project       │\n└─────────────────┘         └─────────────────┘\n```\n\n## Command Side (Write Model)\n\n### Command and Handler\n\n```python\nfrom pydantic import BaseModel, Field\nfrom uuid import UUID, uuid4\nfrom datetime import datetime, timezone\nfrom abc import ABC, abstractmethod\n\nclass Command(BaseModel):\n    \"\"\"Base command with metadata.\"\"\"\n    command_id: UUID = Field(default_factory=uuid4)\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    user_id: UUID | None = None\n\nclass CreateOrder(Command):\n    customer_id: UUID\n    items: list[OrderItem]\n    shipping_address: Address\n\nclass CommandHandler(ABC):\n    @abstractmethod\n    async def handle(self, command: Command) -> list[\"DomainEvent\"]:\n        pass\n\nclass CreateOrderHandler(CommandHandler):\n    def __init__(self, order_repo, inventory_service):\n        self.order_repo = order_repo\n        self.inventory = inventory_service\n\n    async def handle(self, command: CreateOrder) -> list[DomainEvent]:\n        for item in command.items:\n            if not await self.inventory.check_availability(item.product_id, item.quantity):\n                raise InsufficientInventoryError(item.product_id)\n\n        order = Order.create(\n            customer_id=command.customer_id,\n            items=command.items,\n            shipping_address=command.shipping_address,\n        )\n        await self.order_repo.save(order)\n        return order.pending_events\n\nclass CommandBus:\n    def __init__(self):\n        self._handlers: dict[type, CommandHandler] = {}\n\n    def register(self, command_type: type, handler: CommandHandler):\n        self._handlers[command_type] = handler\n\n    async def dispatch(self, command: Command) -> list[DomainEvent]:\n        handler = self._handlers.get(type(command))\n        if not handler:\n            raise NoHandlerFoundError(type(command))\n        events = await handler.handle(command)\n        for event in events:\n            await ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "event-driven-architect"
    ]
  },
  "create-pr": {
    "name": "create-pr",
    "description": "Creates GitHub pull requests with validation. Use when opening PRs or submitting code for review.",
    "version": "2.3.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "github",
      "pull-request",
      "pr",
      "code-review"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "commit",
      "review-pr",
      "security-scanning",
      "memory"
    ],
    "agent": null,
    "structure": {
      "assets": [
        "pr-template.md"
      ]
    },
    "content": "# Create Pull Request\n\nComprehensive PR creation with validation. All output goes directly to GitHub PR.\n\n## Quick Start\n\n```bash\n/create-pr\n```\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify PR type:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of PR is this?\",\n    \"header\": \"Type\",\n    \"options\": [\n      {\"label\": \"Feature (Recommended)\", \"description\": \"New functionality with full validation\"},\n      {\"label\": \"Bug fix\", \"description\": \"Fix for existing issue\"},\n      {\"label\": \"Refactor\", \"description\": \"Code improvement, no behavior change\"},\n      {\"label\": \"Quick\", \"description\": \"Skip validation, just create PR\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Feature**: Full validation with all agents\n- **Bug fix**: Focus on test verification\n- **Refactor**: Skip new feature validation\n- **Quick**: Skip all validation, just create PR\n\n---\n\n## ⚠️ CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n**BEFORE doing ANYTHING else, create tasks to show progress:**\n\n```python\n# 1. Create main PR task IMMEDIATELY\nTaskCreate(\n  subject=\"Create PR for {branch}\",\n  description=\"PR creation with parallel validation agents\",\n  activeForm=\"Creating pull request\"\n)\n\n# 2. Create subtasks for phases\nTaskCreate(subject=\"Pre-flight checks\", activeForm=\"Running pre-flight checks\")\nTaskCreate(subject=\"Run parallel validation agents\", activeForm=\"Validating with agents\")\nTaskCreate(subject=\"Run local tests\", activeForm=\"Running local tests\")\nTaskCreate(subject=\"Create PR on GitHub\", activeForm=\"Creating GitHub PR\")\n\n# 3. Update status as you progress\nTaskUpdate(taskId=\"2\", status=\"in_progress\")  # When starting phase\nTaskUpdate(taskId=\"2\", status=\"completed\")    # When phase done\n```\n\n---\n\n## Workflow\n\n### Phase 1: Pre-Flight Checks\n\n```bash\n# Verify branch\nBRANCH=$(git branch --show-current)\nif [[ \"$BRANCH\" == \"dev\" || \"$BRANCH\" == \"main\" ]]; then\n  echo \"Cannot create PR from dev/main. Create a feature branch first.\"\n  exit 1\nfi\n\n# Check for uncommitted changes\nif [[ -n $(git status --porcelain) ]]; then\n  echo \"Uncommitted changes detected. Commit or stash first.\"\n  exit 1\nfi\n\n# Push branch if needed\ngit fetch origin\nif ! git rev-parse --verify origin/$BRANCH &>/dev/null; then\n  git push -u origin $BRANCH\nfi\n```\n\n### Phase 2: Parallel Pre-PR Validation (3 Agents)\n\nLaunch validation agents in ONE message BEFORE creating PR:\n\n```python\n# PARALLEL - All 3 in ONE message\nTask(\n  subagent_type=\"security-auditor\",\n  prompt=\"\"\"Security audit for PR changes:\n  1. Check for secrets/credentials in diff\n  2. Dependency vulnerabilities (npm audit/pip-audit)\n  3. OWASP Top 10 quick scan\n  Return: {status: PASS/BLOCK, issues: [...]}\n\n  SUMMARY: End with: \"RESULT: [PASS|WARN|BLOCK] - [N] issues: [brief list or 'clean']\"\n  \"\"\",\n  run_in_background=True\n)\nTask(\n  subagent_type=\"test-generator\",\n  prompt=\"\"\"Test coverage verification:\n  1. Run test suite with coverag",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "dashboard-patterns": {
    "name": "dashboard-patterns",
    "description": "Dashboard UI patterns with widget composition, real-time data updates, responsive grid layouts, and data tables for React applications. Use when building dashboards, widgets, or data tables.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "dashboard",
      "widgets",
      "data-grid",
      "real-time",
      "layout",
      "admin",
      "tanstack-table",
      "sse"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "widget-composition.md"
      ],
      "scripts": [
        "widget-card.tsx"
      ]
    },
    "content": "# Dashboard Patterns\n\nDashboard UI patterns for building admin panels, analytics dashboards, and data-driven interfaces with React.\n\n## Layout Patterns\n\n### Responsive Dashboard Grid\n\n```tsx\nfunction DashboardLayout({ children }: { children: React.ReactNode }) {\n  return (\n    <div className=\"min-h-screen bg-muted/40\">\n      <aside className=\"fixed inset-y-0 left-0 z-10 w-64 border-r bg-background\">\n        <Sidebar />\n      </aside>\n      <main className=\"pl-64\">\n        <header className=\"sticky top-0 z-10 border-b bg-background px-6 py-4\">\n          <DashboardHeader />\n        </header>\n        <div className=\"p-6\">\n          <div className=\"grid gap-6 md:grid-cols-2 lg:grid-cols-4\">{children}</div>\n        </div>\n      </main>\n    </div>\n  );\n}\n\nfunction DashboardGrid() {\n  return (\n    <div className=\"grid gap-4 grid-cols-1 sm:grid-cols-2 lg:grid-cols-4\">\n      <StatCard title=\"Revenue\" value=\"$45,231\" change=\"+12%\" />\n      <StatCard title=\"Users\" value=\"2,350\" change=\"+5.2%\" />\n      <StatCard title=\"Orders\" value=\"1,245\" change=\"+18%\" />\n      <StatCard title=\"Conversion\" value=\"3.2%\" change=\"-0.4%\" />\n      <div className=\"col-span-1 sm:col-span-2\"><RevenueChart /></div>\n      <div className=\"col-span-1 sm:col-span-2\"><TrafficChart /></div>\n      <div className=\"col-span-full\"><RecentOrdersTable /></div>\n    </div>\n  );\n}\n```\n\n## Widget Components\n\n### Stat Card Widget\n\n```tsx\nimport { TrendingUp, TrendingDown } from 'lucide-react';\n\ninterface StatCardProps {\n  title: string;\n  value: string | number;\n  change?: string;\n  changeType?: 'positive' | 'negative' | 'neutral';\n  icon?: React.ReactNode;\n}\n\nfunction StatCard({ title, value, change, changeType = 'neutral', icon }: StatCardProps) {\n  return (\n    <div className=\"rounded-xl border bg-card p-6\">\n      <div className=\"flex items-center justify-between\">\n        <p className=\"text-sm font-medium text-muted-foreground\">{title}</p>\n        {icon && <div className=\"text-muted-foreground\">{icon}</div>}\n      </div>\n      <div className=\"mt-2 flex items-baseline gap-2\">\n        <p className=\"text-3xl font-bold\">{value}</p>\n        {change && (\n          <span className={cn(\n            'flex items-center text-sm font-medium',\n            changeType === 'positive' && 'text-green-600',\n            changeType === 'negative' && 'text-red-600',\n          )}>\n            {changeType === 'positive' && <TrendingUp className=\"h-4 w-4\" />}\n            {changeType === 'negative' && <TrendingDown className=\"h-4 w-4\" />}\n            {change}\n          </span>\n        )}\n      </div>\n    </div>\n  );\n}\n```\n\n### Widget Registry Pattern\n\n```tsx\ntype WidgetType = 'stat' | 'chart' | 'table' | 'list';\n\ninterface WidgetConfig {\n  id: string;\n  type: WidgetType;\n  title: string;\n  span?: number;\n  props: Record<string, unknown>;\n}\n\nconst widgetRegistry: Record<WidgetType, React.ComponentType<any>> = {\n  stat: StatCard,\n  chart: ChartCard,\n  table: DataTable,\n  list: ListWidget,\n};\n\nfunction DashboardWidget({ co",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "database-schema-designer": {
    "name": "database-schema-designer",
    "description": "SQL and NoSQL schema design with normalization, indexing, and migration patterns. Use when designing database schemas, creating tables, optimizing slow queries, or planning database migrations.",
    "version": "2.0.0",
    "author": "AI Agent Hub",
    "tags": [
      "database",
      "schema-design",
      "sql",
      "nosql",
      "performance",
      "migrations"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "database-engineer",
    "structure": {
      "references": [
        "migration-patterns.md",
        "normalization-patterns.md"
      ],
      "checklists": [
        "schema-design-checklist.md"
      ]
    },
    "content": "# Database Schema Designer\nThis skill provides comprehensive guidance for designing robust, scalable database schemas for both SQL and NoSQL databases. Whether building from scratch or evolving existing schemas, this framework ensures data integrity, performance, and maintainability.\n\n## Overview\n- Designing new database schemas\n- Refactoring or migrating existing schemas\n- Optimizing database performance\n- Choosing between SQL and NoSQL approaches\n- Creating database migrations\n- Establishing indexing strategies\n- Modeling complex relationships\n- Planning data archival and partitioning\n\n## Database Design Philosophy\n\n### Core Principles\n\n**1. Model the Domain, Not the UI**\n- Schema reflects business entities and relationships\n- Don't let UI requirements drive data structure\n- Separate presentation concerns from data model\n\n**2. Optimize for Reads or Writes (Not Both)**\n- OLTP (transactional): Normalized, optimized for writes\n- OLAP (analytical): Denormalized, optimized for reads\n- Choose based on access patterns\n\n**3. Plan for Scale From Day One**\n- Indexing strategy\n- Partitioning approach\n- Caching layer\n- Read replicas\n\n**4. Data Integrity Over Performance**\n- Use constraints, foreign keys, validation\n- Performance issues can be optimized later\n- Data corruption is costly to fix\n\n---\n\n## SQL Database Design\n\n### Normalization\n\nDatabase normalization reduces redundancy and ensures data integrity.\n\n#### 1st Normal Form (1NF)\n**Rule**: Each column contains atomic (indivisible) values, no repeating groups.\n\n```sql\n-- ❌ Violates 1NF (multiple values in one column)\nCREATE TABLE orders (\n  id INT PRIMARY KEY,\n  customer_id INT,\n  product_ids VARCHAR(255)  -- '101,102,103' (bad!)\n);\n\n-- ✅ Follows 1NF\nCREATE TABLE orders (\n  id INT PRIMARY KEY,\n  customer_id INT\n);\n\nCREATE TABLE order_items (\n  id INT PRIMARY KEY,\n  order_id INT,\n  product_id INT,\n  FOREIGN KEY (order_id) REFERENCES orders(id)\n);\n```\n\n#### 2nd Normal Form (2NF)\n**Rule**: Must be in 1NF + all non-key columns depend on the entire primary key.\n\n#### 3rd Normal Form (3NF)\n**Rule**: Must be in 2NF + no transitive dependencies (non-key columns depend only on primary key).\n\n---\n\n### Indexing Strategies\n\nIndexes speed up reads but slow down writes. Use strategically.\n\n#### When to Create Indexes\n\n```sql\n-- ✅ Index foreign keys\nCREATE INDEX idx_orders_customer_id ON orders(customer_id);\n\n-- ✅ Index frequently queried columns\nCREATE INDEX idx_users_email ON users(email);\n\n-- ✅ Index columns used in WHERE, ORDER BY, GROUP BY\nCREATE INDEX idx_orders_created_at ON orders(created_at);\n\n-- ✅ Composite index for multi-column queries\nCREATE INDEX idx_orders_customer_status ON orders(customer_id, status);\n```\n\n#### Composite Indexes (Column Order Matters)\n\n```sql\n-- ✅ Good: Index supports both queries\nCREATE INDEX idx_orders_customer_status ON orders(customer_id, status);\n\n-- Query 1: Uses index efficiently\nSELECT * FROM orders WHERE customer_id = 123 AND status = 'pending';\n\n-- Query 2: Uses index (cu",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "database-engineer",
      "python-performance-engineer"
    ]
  },
  "database-versioning": {
    "name": "database-versioning",
    "description": "Database version control and change management patterns. Use when managing schema history, coordinating database changes across environments, implementing audit trails, or versioning database objects.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "database",
      "versioning",
      "schema",
      "change-management",
      "audit"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "database-engineer",
    "structure": {
      "references": [
        "audit-trails.md",
        "environment-coordination.md",
        "migration-testing.md",
        "object-versioning.md"
      ]
    },
    "content": "# Database Versioning Patterns\n\nVersion control strategies for database schemas and data across environments.\n\n## Overview\n\n- Tracking schema changes over time\n- Coordinating database changes across dev/staging/prod\n- Implementing database audit trails\n- Managing stored procedures and functions\n- Versioning reference data\n\n## Schema Versioning Table\n\n```sql\nCREATE TABLE schema_version (\n    version_id SERIAL PRIMARY KEY,\n    version_number VARCHAR(20) NOT NULL,\n    description TEXT NOT NULL,\n    applied_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    applied_by VARCHAR(100),\n    execution_time_ms INTEGER,\n    checksum VARCHAR(64),\n    CONSTRAINT uq_version_number UNIQUE (version_number)\n);\n```\n\n## Semantic Versioning for Databases\n\n```\nMAJOR.MINOR.PATCH\n\nMAJOR: Breaking changes (drop tables, rename columns)\nMINOR: Backward-compatible additions (new tables, nullable columns)\nPATCH: Bug fixes, index changes, data migrations\n```\n\n## Detailed Guides\n\n- **Audit trails**: See [references/audit-trails.md](references/audit-trails.md) for row versioning, temporal tables, CDC\n- **Environment coordination**: See [references/environment-coordination.md](references/environment-coordination.md) for multi-env flows, locks\n- **Object versioning**: See [references/object-versioning.md](references/object-versioning.md) for procedures, views, reference data\n- **Migration testing**: See [references/migration-testing.md](references/migration-testing.md) for pytest patterns\n\n## Best Practices\n\n| Practice | Reason |\n|----------|--------|\n| Version everything | Full traceability |\n| Immutable history | Audit compliance |\n| Test rollbacks | Ensure recoverability |\n| Environment parity | Consistent deployments |\n| Checksum verification | Detect unauthorized changes |\n\n## Anti-Patterns\n\n```python\n# NEVER modify deployed migrations - create new migration instead\n\n# NEVER delete migration history\ncommand.stamp(alembic_config, \"head\")  # Loses history\n\n# NEVER skip environments\n# Always: local -> CI -> staging -> production\n\n# NEVER version sensitive data in migrations\nop.bulk_insert(users, [{\"password\": \"secret\"}])  # Security risk!\n```\n\n## Capability Details\n\n### schema-versioning\n**Keywords:** schema version, database version, migration history\n**Solves:** Track schema changes, version history\n\n### temporal-queries\n**Keywords:** temporal, point-in-time, history query\n**Solves:** Query historical data, time-travel queries\n\n### change-tracking\n**Keywords:** cdc, change data capture, audit log\n**Solves:** Track all changes, audit compliance\n\n### environment-sync\n**Keywords:** environment sync, migration coordination\n**Solves:** Sync across environments, coordinate deployments\n\n## Related Skills\n\n- `alembic-migrations` - Migration implementation\n- `database-schema-designer` - Schema design\n- `zero-downtime-migration` - Safe production changes",
    "contentTruncated": false,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "database-engineer"
    ]
  },
  "defense-in-depth": {
    "name": "defense-in-depth",
    "description": "Use when building secure AI pipelines or hardening LLM integrations. Defense-in-depth implements 8 validation layers from edge to storage with no single point of failure.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "validation",
      "layers",
      "hardening"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "security-layer-auditor",
    "structure": {
      "references": [
        "audit-logging.md",
        "request-context-pattern.md",
        "tenant-isolation.md"
      ],
      "checklists": [
        "pre-deployment-security.md"
      ]
    },
    "content": "# Defense in Depth for AI Systems\n\n## Overview\n\nDefense in depth applies multiple security layers so that if one fails, others still protect the system. For AI applications, this means validating at every boundary: edge, gateway, input, authorization, data, LLM, output, and observability.\n\n**Core Principle:** No single security control should be the only thing protecting sensitive operations.\n\n## The 8-Layer Security Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│  Layer 0: EDGE           │  WAF, Rate Limiting, DDoS, Bot Detection    │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 1: GATEWAY        │  JWT Verify, Extract Claims, Build Context  │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 2: INPUT          │  Schema Validation, PII Detection, Injection│\n│                          │  + Tavily Prompt Injection Firewall (opt.)  │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 3: AUTHORIZATION  │  RBAC/ABAC, Tenant Check, Resource Access   │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 4: DATA ACCESS    │  Parameterized Queries, Tenant Filter       │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 5: LLM            │  Prompt Building (no IDs), Context Separation│\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 6: OUTPUT         │  Schema Validation, Guardrails, Hallucination│\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 7: STORAGE        │  Attribution, Audit Trail, Encryption       │\n├─────────────────────────────────────────────────────────────────────────┤\n│  Layer 8: OBSERVABILITY  │  Logging (sanitized), Tracing, Metrics      │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n## Layer Details\n\n### Layer 0: Edge Protection\n\n**Purpose:** Stop attacks before they reach your application.\n\n- WAF rules for OWASP Top 10\n- Rate limiting per user/IP\n- DDoS protection\n- Bot detection\n- Geo-blocking if required\n\n### Layer 1: Gateway / Authentication\n\n**Purpose:** Verify identity and build request context.\n\n```python\n@dataclass(frozen=True)\nclass RequestContext:\n    \"\"\"Immutable context that flows through the system\"\"\"\n    # Identity\n    user_id: UUID\n    tenant_id: UUID\n    session_id: str\n    permissions: frozenset[str]\n\n    # Tracing\n    request_id: str\n    trace_id: str\n\n    # Metadata\n    timestamp: datetime\n    client_ip: str\n```\n\n### Layer 2: Input Validation\n\n**Purpose:** Reject bad input early.\n\n- **Schema validation:** Pydantic/Zod for structure\n- **Content validation:** PII detection, malware scan\n- **Injection defense:** SQL, XSS, prompt injection patterns\n- **External scanning (optional):** Tavily prompt injection firewall for web-sourced content — pre-filters RAG inputs before they reach the LLM la",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "security-auditor",
      "security-layer-auditor"
    ]
  },
  "demo-producer": {
    "name": "demo-producer",
    "description": "Creates polished demo videos for skills, tutorials, and CLI demonstrations. Use when producing video showcases, marketing content, or terminal recordings.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "demo",
      "video",
      "marketing",
      "vhs",
      "remotion",
      "terminal",
      "showcase",
      "tutorial"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "content-types.md",
        "format-selection.md",
        "script-generation.md",
        "template-system.md"
      ],
      "scripts": [
        "full-pipeline.sh",
        "generate.sh"
      ]
    },
    "content": "# Demo Producer\n\nUniversal demo video creation for any content type.\n\n## Quick Start\n\n```bash\n/demo-producer                    # Interactive mode - asks what to create\n/demo-producer skill explore      # Create demo for a skill\n/demo-producer plugin ork     # Create demo for a plugin\n/demo-producer tutorial \"Building a REST API\"  # Custom tutorial\n```\n\n## Supported Content Types\n\n| Type | Source | Example |\n|------|--------|---------|\n| `skill` | skills/{name}/SKILL.md | `/demo-producer skill commit` |\n| `agent` | agents/{name}.md | `/demo-producer agent debug-investigator` |\n| `plugin` | plugins/{name}/plugin.json | `/demo-producer plugin ork` |\n| `marketplace` | Marketplace install flow | `/demo-producer marketplace ork` |\n| `tutorial` | Custom description | `/demo-producer tutorial \"Git workflow\"` |\n| `cli` | Any CLI tool | `/demo-producer cli \"npm create vite\"` |\n| `code` | Code walkthrough | `/demo-producer code src/api/auth.ts` |\n\n## Interactive Flow\n\nWhen invoked without arguments, asks:\n\n### Question 1: Content Type\n```\nWhat type of demo do you want to create?\n\n○ Skill - OrchestKit skill showcase\n○ Agent - AI agent demonstration\n○ Plugin - Plugin installation/features\n○ Tutorial - Custom coding tutorial\n○ CLI Tool - Command-line tool demo\n○ Code Walkthrough - Explain existing code\n```\n\n### Question 2: Format\n```\nWhat format(s) do you need?\n\n☑ Horizontal (16:9) - YouTube, Twitter\n☑ Vertical (9:16) - TikTok, Reels, Shorts\n☐ Square (1:1) - Instagram, LinkedIn\n```\n\n### Question 3: Style\n```\nWhat style fits your content?\n\n○ Quick Demo (6-10s) - Fast showcase, single feature\n○ Standard Demo (15-25s) - Full workflow, multiple steps\n○ Tutorial (30-60s) - Detailed explanation, code examples\n○ Cinematic (60s+) - Story-driven, high polish\n○ Scrapbook (15-35s) - Warm paper, fast cuts, social proof collage (Anthropic style)\n```\n\n### Question 4: Audio\n```\nAudio preferences?\n\n○ Music Only - Subtle ambient background\n○ Music + SFX - Background + success sounds\n○ Silent - No audio\n```\n\n## Pipeline Architecture\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│                     Demo Producer Pipeline                        │\n├──────────────────────────────────────────────────────────────────┤\n│                                                                   │\n│  ┌─────────────┐    ┌──────────────┐    ┌─────────────────────┐  │\n│  │   Content   │───▶│   Content    │───▶│   Script Generator  │  │\n│  │   Detector  │    │   Analyzer   │    │   (per type)        │  │\n│  └─────────────┘    └──────────────┘    └──────────┬──────────┘  │\n│                                                     │             │\n│                                                     ▼             │\n│  ┌─────────────┐    ┌──────────────┐    ┌─────────────────────┐  │\n│  │  Remotion   │◀───│    VHS       │◀───│   Terminal Script   │  │\n│  │  Composer   │    │   Recorder   │    │   (.sh + .tape)     │  │\n│  └──────┬──────┘    └──────────────┘    └─────────────",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": [
      "demo-producer"
    ]
  },
  "design-system-starter": {
    "name": "design-system-starter",
    "description": "Use this skill when creating or evolving design systems for applications. Provides design token structures, component architecture patterns, documentation templates, and accessibility guidelines. Ensures consistent, scalable, and accessible UI design across products.",
    "version": "1.0.0",
    "author": "AI Agent Hub",
    "tags": [
      "design-system",
      "ui",
      "components",
      "design-tokens",
      "accessibility",
      "frontend"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "rapid-ui-designer",
    "structure": {
      "references": [
        "component-examples.md",
        "component-patterns.md",
        "design-tokens.md",
        "theming.md"
      ],
      "assets": [
        "component-template.tsx",
        "design-tokens-template.json"
      ],
      "checklists": [
        "design-system-checklist.md"
      ]
    },
    "content": "# Design System Starter\n\n## Overview\n\nThis skill provides comprehensive guidance for building robust, scalable design systems that ensure visual consistency, improve development velocity, and create exceptional user experiences.\n\n**When to use this skill:**\n- Creating a new design system from scratch\n- Evolving or refactoring existing design systems\n- Establishing design token standards\n- Defining component architecture\n- Creating design documentation\n- Ensuring accessibility compliance (WCAG 2.1)\n- Implementing theming and dark mode\n\n**Bundled Resources:**\n- `references/design-tokens.md` - Complete token definitions\n- `references/component-patterns.md` - Architecture patterns\n- `references/component-examples.md` - Full component implementations\n- `references/theming.md` - Theme and dark mode patterns\n- `assets/design-tokens-template.json` - W3C design token format\n- `assets/component-template.tsx` - React component template\n\n```typescript\n// Example: Design token structure\nconst tokens = {\n  colors: {\n    primary: { base: \"#0066cc\", hover: \"#0052a3\" },\n    semantic: { success: \"#28a745\", error: \"#dc3545\" }\n  },\n  spacing: { xs: \"4px\", sm: \"8px\", md: \"16px\", lg: \"24px\" }\n};\n```\n- `checklists/design-system-checklist.md` - Design system audit checklist\n\n---\n\n## Design System Philosophy\n\nA design system is more than a component library. It includes:\n\n| Layer | Description | Examples |\n|-------|-------------|----------|\n| **Design Tokens** | Foundational design decisions | Colors, spacing, typography |\n| **Components** | Reusable UI building blocks | Button, Input, Card, Modal |\n| **Patterns** | Common UX solutions | Forms, Navigation, Layouts |\n| **Guidelines** | Rules and best practices | Accessibility, naming, APIs |\n| **Documentation** | How to use everything | Storybook, usage examples |\n\n### Core Principles\n\n1. **Consistency Over Creativity** - Predictable patterns reduce cognitive load\n2. **Accessible by Default** - WCAG 2.1 Level AA compliance minimum\n3. **Scalable and Maintainable** - Design tokens enable global changes\n4. **Developer-Friendly** - Clear API contracts and documentation\n\n---\n\n## References\n\n### Design Tokens\n**See: `references/design-tokens.md`**\n\nKey topics covered:\n- Color scales (primitive 50-950, semantic tokens)\n- Typography system (font families, sizes, weights, line heights)\n- Spacing scale (4px base system)\n- Border radius and shadow tokens\n- W3C design token format\n- Tailwind `@theme` integration\n\n**Quick Reference - Token Categories:**\n\n| Category | Examples | Scale |\n|----------|----------|-------|\n| Colors | `blue.500`, `text.primary`, `feedback.error` | 50-950 |\n| Typography | `fontSize.base`, `fontWeight.semibold` | xs-5xl |\n| Spacing | `spacing.4`, `spacing.8` | 0-24 (4px base) |\n| Border Radius | `borderRadius.md`, `borderRadius.full` | none-full |\n| Shadows | `shadow.sm`, `shadow.lg` | xs-xl |\n\n---\n\n### Component Patterns\n**See: `references/component-patterns.md`**\n\nKey topics covered:\n- Atomic Design methodol",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer",
      "rapid-ui-designer",
      "ux-researcher"
    ]
  },
  "devops-deployment": {
    "name": "devops-deployment",
    "description": "Use when setting up CI/CD pipelines, containerizing applications, deploying to Kubernetes, or writing infrastructure as code. DevOps & Deployment covers GitHub Actions, Docker, Helm, and Terraform patterns.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "devops",
      "ci-cd",
      "docker",
      "kubernetes",
      "terraform"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "ci-cd-pipelines.md",
        "deployment-strategies.md",
        "docker-patterns.md",
        "environment-management.md",
        "kubernetes-basics.md",
        "observability.md"
      ],
      "scripts": [
        "Dockerfile",
        "argocd-application.yaml",
        "create-ci-pipeline.md",
        "create-docker-compose.md",
        "docker-compose.yml",
        "external-secrets.yaml",
        "github-actions-pipeline.yml",
        "helm-values.yaml",
        "k8s-manifests.yaml",
        "terraform-aws.tf"
      ],
      "checklists": [
        "production-readiness.md"
      ]
    },
    "content": "# DevOps & Deployment Skill\n\nComprehensive frameworks for CI/CD pipelines, containerization, deployment strategies, and infrastructure automation.\n\n## Overview\n\n- Setting up CI/CD pipelines\n- Containerizing applications\n- Deploying to Kubernetes or cloud platforms\n- Implementing GitOps workflows\n- Managing infrastructure as code\n- Planning release strategies\n\n## Pipeline Architecture\n\n```\n┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐\n│    Code     │──>│    Build    │──>│    Test     │──>│   Deploy    │\n│   Commit    │   │   & Lint    │   │   & Scan    │   │  & Release  │\n└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘\n       │                 │                 │                 │\n       v                 v                 v                 v\n   Triggers         Artifacts          Reports          Monitoring\n```\n\n## Key Concepts\n\n### CI/CD Pipeline Stages\n\n1. **Lint & Type Check** - Code quality gates\n2. **Unit Tests** - Test coverage with reporting\n3. **Security Scan** - npm audit + Trivy vulnerability scanner\n4. **Build & Push** - Docker image to container registry\n5. **Deploy Staging** - Environment-gated deployment\n6. **Deploy Production** - Manual approval or automated\n\n### Container Best Practices\n\n**Multi-stage builds** minimize image size:\n- Stage 1: Install production dependencies only\n- Stage 2: Build application with dev dependencies\n- Stage 3: Production runtime with minimal footprint\n\n**Security hardening**:\n- Non-root user (uid 1001)\n- Read-only filesystem where possible\n- Health checks for orchestrator integration\n\n### Kubernetes Deployment\n\n**Essential manifests**:\n- Deployment with rolling update strategy\n- Service for internal routing\n- Ingress for external access with TLS\n- HorizontalPodAutoscaler for scaling\n\n**Security context**:\n- `runAsNonRoot: true`\n- `allowPrivilegeEscalation: false`\n- `readOnlyRootFilesystem: true`\n- Drop all capabilities\n\n### Deployment Strategies\n\n| Strategy | Use Case | Risk |\n|----------|----------|------|\n| **Rolling** | Default, gradual replacement | Low - automatic rollback |\n| **Blue-Green** | Instant switch, easy rollback | Medium - double resources |\n| **Canary** | Progressive traffic shift | Low - gradual exposure |\n\n**Rolling Update** (Kubernetes default):\n```yaml\nstrategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 25%\n    maxUnavailable: 0  # Zero downtime\n```\n\n### Secrets Management\n\nUse External Secrets Operator to sync from cloud providers:\n- AWS Secrets Manager\n- HashiCorp Vault\n- Azure Key Vault\n- GCP Secret Manager\n\n---\n\n## References\n\n### Docker Patterns\n**See: `references/docker-patterns.md`**\n\nKey topics covered:\n- Multi-stage build examples with 78% size reduction\n- Layer caching optimization\n- Security hardening (non-root, health checks)\n- Trivy vulnerability scanning\n- Docker Compose development setup\n\n### CI/CD Pipelines\n**See: `references/ci-cd-pipelines.md`**\n\nKey topics covered:\n- Branch strategy (Git Flow)\n- GitHub Acti",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "ci-cd-engineer",
      "data-pipeline-engineer",
      "deployment-manager",
      "infrastructure-architect"
    ]
  },
  "distributed-locks": {
    "name": "distributed-locks",
    "description": "Distributed locking patterns with Redis and PostgreSQL for coordination across instances. Use when implementing exclusive access, preventing race conditions, or coordinating distributed resources.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "distributed",
      "locks",
      "redis",
      "postgresql",
      "concurrency",
      "coordination"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "postgres-advisory-locks.md",
        "redis-locks.md",
        "redlock-algorithm.md"
      ],
      "scripts": [
        "distributed-lock-template.py"
      ],
      "checklists": [
        "distributed-locks-checklist.md"
      ]
    },
    "content": "# Distributed Locks\n\nCoordinate exclusive access to resources across multiple service instances.\n\n## Overview\n\n- Preventing duplicate processing of jobs/events\n- Coordinating singleton processes (cron, leaders)\n- Protecting critical sections across instances\n- Implementing leader election\n- Rate limiting at distributed level\n\n## Lock Types Comparison\n\n| Lock Type | Durability | Latency | Use Case |\n|-----------|-----------|---------|----------|\n| Redis (single) | Low | ~1ms | Fast, non-critical |\n| Redlock (multi) | High | ~5ms | Critical, HA required |\n| PostgreSQL advisory | High | ~2ms | Already using PG, ACID |\n\n## Quick Reference\n\n### Redis Lock (Single Node)\n\n```python\nfrom uuid_utils import uuid7\nimport redis.asyncio as redis\n\nclass RedisLock:\n    \"\"\"Redis lock with Lua scripts for atomicity.\"\"\"\n\n    ACQUIRE = \"if redis.call('set',KEYS[1],ARGV[1],'NX','PX',ARGV[2]) then return 1 end return 0\"\n    RELEASE = \"if redis.call('get',KEYS[1])==ARGV[1] then return redis.call('del',KEYS[1]) end return 0\"\n\n    def __init__(self, client: redis.Redis, name: str, ttl_ms: int = 30000):\n        self._client = client\n        self._name = f\"lock:{name}\"\n        self._owner = str(uuid7())\n        self._ttl = ttl_ms\n\n    async def acquire(self) -> bool:\n        return await self._client.eval(self.ACQUIRE, 1, self._name, self._owner, self._ttl) == 1\n\n    async def release(self) -> bool:\n        return await self._client.eval(self.RELEASE, 1, self._name, self._owner) == 1\n\n    async def __aenter__(self):\n        if not await self.acquire():\n            raise LockError(f\"Failed to acquire {self._name}\")\n        return self\n\n    async def __aexit__(self, *_):\n        await self.release()\n```\n\nSee [redis-locks.md](references/redis-locks.md) for complete implementation with retry/extend.\n\n### PostgreSQL Advisory Lock\n\n```python\nfrom sqlalchemy import text\n\nasync def with_advisory_lock(session, lock_id: int):\n    \"\"\"PostgreSQL advisory lock (session-level).\"\"\"\n    await session.execute(text(\"SELECT pg_advisory_lock(:id)\"), {\"id\": lock_id})\n    try:\n        yield\n    finally:\n        await session.execute(text(\"SELECT pg_advisory_unlock(:id)\"), {\"id\": lock_id})\n```\n\nSee [postgres-advisory-locks.md](references/postgres-advisory-locks.md) for transaction-level and monitoring.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Backend | Redis for speed, PG if already using it |\n| TTL | 2-3x expected operation time |\n| Retry | Exponential backoff with jitter |\n| Fencing | Include owner ID for safety |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER forget TTL (causes deadlocks)\nawait redis.set(f\"lock:{name}\", \"1\")  # WRONG - no expiry!\n\n# NEVER release without owner check\nawait redis.delete(f\"lock:{name}\")  # WRONG - might release others' lock\n\n# NEVER use single Redis for critical operations\nlock = RedisLock(single_redis, \"payment\")  # Use Redlock for HA\n\n# NEVER hold locks across await points without heartbeat\nasync with lock:\n    await ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "doctor": {
    "name": "doctor",
    "description": "OrchestKit health diagnostics for health diagnostics. Use when checking plugin health or troubleshooting issues.",
    "version": "3.0.0",
    "author": "OrchestKit",
    "tags": [
      "health-check",
      "diagnostics",
      "validation",
      "permissions",
      "hooks",
      "skills",
      "agents",
      "memory"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Bash",
      "Read",
      "Grep",
      "Glob"
    ],
    "skills": [
      "configure"
    ],
    "agent": null,
    "structure": {
      "references": [
        "agents-validation.md",
        "hook-validation.md",
        "memory-health.md",
        "permission-rules.md",
        "schema-validation.md",
        "skills-validation.md"
      ]
    },
    "content": "# OrchestKit Health Diagnostics\n\n## Overview\n\nThe `/ork:doctor` command performs comprehensive health checks on your OrchestKit installation. It auto-detects installed plugins and validates 10 categories:\n\n1. **Installed Plugins** - Detects orkl or ork\n2. **Skills Validation** - Frontmatter, references, token budget (dynamic count)\n3. **Agents Validation** - Frontmatter, tool refs, skill refs (dynamic count)\n4. **Hook Health** - Registration, bundles, async patterns\n5. **Permission Rules** - Detects unreachable rules (CC 2.1.3 feature)\n6. **Schema Compliance** - Validates JSON files against schemas\n7. **Coordination System** - Checks lock health and registry integrity\n8. **Context Budget** - Monitors token usage against budget\n9. **Memory System** - Graph, Mem0, Fabric health\n10. **Claude Code Version** - Validates CC >= 2.1.16\n\n## When to Use\n\n- After installing or updating OrchestKit\n- When hooks aren't firing as expected\n- Before deploying to a team environment\n- When debugging coordination issues\n- After running `npm run build`\n\n## Quick Start\n\n```bash\n/ork:doctor           # Standard health check\n/ork:doctor -v        # Verbose output\n/ork:doctor --json    # Machine-readable for CI\n```\n\n## CLI Options\n\n| Flag | Description |\n|------|-------------|\n| `-v`, `--verbose` | Detailed output per check |\n| `--json` | JSON output for CI integration |\n| `--category=X` | Run only specific category |\n\n## Health Check Categories\n\n### 0. Installed Plugins Detection\n\nAuto-detects which OrchestKit plugins are installed:\n\n```bash\n# Detection logic:\n# - Scans for .claude-plugin/plugin.json in plugin paths\n# - Identifies orkl or ork\n# - Counts skills/agents per installed plugin\n```\n\n**Output (orkl):**\n```\nInstalled Plugins: 1\n- orkl: 88 skills, 36 agents, 119 hook entries\n```\n\n**Output (ork full):**\n```\nInstalled Plugins: 1\n- ork: 199 skills, 36 agents, 119 hook entries\n```\n\n### 1. Skills Validation\n\nValidates skills in installed plugins (count varies by installation):\n\n```bash\n# Checks performed:\n# - SKILL.md frontmatter (name, description, user-invocable)\n# - context: fork field (required for CC 2.1.0+)\n# - Token budget compliance (300-5000 tokens)\n# - Internal link validation (references/ paths)\n# - Related Skills references exist\n```\n\n**Output (full ork):**\n```\nSkills: 186/186 valid\n- User-invocable: 24 commands\n- Reference skills: 163\n```\n\n**Output (orkl only):**\n```\nSkills: 18/18 valid\n- User-invocable: 0 commands\n- Reference skills: 18\n```\n\n### 2. Agents Validation\n\nValidates agents in installed plugins:\n\n```bash\n# Checks performed:\n# - Frontmatter fields (name, description, model, tools, skills)\n# - Model validation (opus, sonnet, haiku only)\n# - Skills references exist in src/skills/\n# - Tools are valid CC tools\n```\n\n**Output:**\n```\nAgents: 35/35 valid\n- Models: 12 sonnet, 15 haiku, 8 opus\n- All skill references valid\n```\n\n### 3. Hook Health\n\nVerifies hooks are properly configured:\n\n```bash\n# Checks performed:\n# - hooks.json schema valid\n# - Bundle fi",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "domain-driven-design": {
    "name": "domain-driven-design",
    "description": "Domain-Driven Design tactical patterns for complex business domains. Use when modeling entities, value objects, domain services, repositories, or establishing bounded contexts.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ddd",
      "domain-modeling",
      "entities",
      "value-objects",
      "bounded-contexts",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "bounded-contexts.md",
        "domain-events.md",
        "entities-value-objects.md",
        "repositories.md"
      ],
      "scripts": [
        "entity-template.py",
        "repository-template.py",
        "value-object-template.py"
      ],
      "checklists": [
        "ddd-checklist.md"
      ]
    },
    "content": "# Domain-Driven Design Tactical Patterns\n\nModel complex business domains with entities, value objects, and bounded contexts.\n\n## Overview\n\n- Modeling complex business logic\n- Separating domain from infrastructure\n- Establishing clear boundaries between subdomains\n- Building rich domain models with behavior\n- Implementing ubiquitous language in code\n\n## Building Blocks Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    DDD Building Blocks                       │\n├─────────────────────────────────────────────────────────────┤\n│  ENTITIES           VALUE OBJECTS        AGGREGATES         │\n│  Order (has ID)     Money (no ID)        [Order]→Items      │\n│                                                              │\n│  DOMAIN SERVICES    REPOSITORIES         DOMAIN EVENTS      │\n│  PricingService     IOrderRepository     OrderSubmitted     │\n│                                                              │\n│  FACTORIES          SPECIFICATIONS       MODULES            │\n│  OrderFactory       OverdueOrderSpec     orders/, payments/ │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Quick Reference\n\n### Entity (Has Identity)\n\n```python\nfrom dataclasses import dataclass, field\nfrom uuid import UUID\nfrom uuid_utils import uuid7\n\n@dataclass\nclass Order:\n    \"\"\"Entity: Has identity, mutable state, lifecycle.\"\"\"\n    id: UUID = field(default_factory=uuid7)\n    customer_id: UUID = field(default=None)\n    status: str = \"draft\"\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Order):\n            return NotImplemented\n        return self.id == other.id  # Identity equality\n\n    def __hash__(self) -> int:\n        return hash(self.id)\n```\n\nSee [entities-value-objects.md](references/entities-value-objects.md) for complete patterns.\n\n### Value Object (Immutable)\n\n```python\nfrom dataclasses import dataclass\nfrom decimal import Decimal\n\n@dataclass(frozen=True)  # MUST be frozen!\nclass Money:\n    \"\"\"Value Object: Defined by attributes, not identity.\"\"\"\n    amount: Decimal\n    currency: str\n\n    def __add__(self, other: \"Money\") -> \"Money\":\n        if self.currency != other.currency:\n            raise ValueError(\"Cannot add different currencies\")\n        return Money(self.amount + other.amount, self.currency)\n```\n\nSee [entities-value-objects.md](references/entities-value-objects.md) for Address, DateRange examples.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Entity vs VO | Has unique ID + lifecycle? Entity. Otherwise VO |\n| Entity equality | By ID, not attributes |\n| Value object mutability | Always immutable (`frozen=True`) |\n| Repository scope | One per aggregate root |\n| Domain events | Collect in entity, publish after persist |\n| Context boundaries | By business capability, not technical |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER have anemic domain models (data-only classes)\n@dataclass\nclass Order:\n    id: UUID\n    items: l",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "drift-detection": {
    "name": "drift-detection",
    "description": "Statistical and quality drift detection for LLM applications. Use when monitoring model quality degradation, input distribution shifts, or output pattern changes over time.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "drift",
      "monitoring",
      "quality",
      "statistical",
      "psi",
      "langfuse",
      "evidently"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "references": [
        "embedding-drift.md",
        "ewma-baselines.md",
        "langfuse-evidently-integration.md",
        "statistical-methods.md"
      ]
    },
    "content": "# Drift Detection\n\nMonitor LLM quality degradation and input/output distribution shifts in production.\n\n## Overview\n\n- Detecting input distribution drift (data drift)\n- Monitoring output quality degradation (concept drift)\n- Implementing statistical methods (PSI, KS, KL divergence)\n- Setting up dynamic thresholds with moving averages\n- Integrating Langfuse scores with drift analysis\n\n## Quick Reference\n\n### Population Stability Index (PSI)\n\n```python\nimport numpy as np\n\ndef calculate_psi(expected: np.ndarray, actual: np.ndarray, bins: int = 10) -> float:\n    \"\"\"\n    Calculate Population Stability Index.\n\n    Thresholds:\n    - PSI < 0.1: No significant drift\n    - 0.1 <= PSI < 0.25: Moderate drift, investigate\n    - PSI >= 0.25: Significant drift, action needed\n    \"\"\"\n    expected_pct = np.histogram(expected, bins=bins)[0] / len(expected)\n    actual_pct = np.histogram(actual, bins=bins)[0] / len(actual)\n\n    # Avoid division by zero\n    expected_pct = np.clip(expected_pct, 0.0001, None)\n    actual_pct = np.clip(actual_pct, 0.0001, None)\n\n    psi = np.sum((actual_pct - expected_pct) * np.log(actual_pct / expected_pct))\n    return psi\n\n# Usage\npsi_score = calculate_psi(baseline_scores, current_scores)\nif psi_score >= 0.25:\n    alert(\"Significant quality drift detected!\")\n```\n\n### EWMA Dynamic Threshold\n\n```python\nclass EWMADriftDetector:\n    \"\"\"Exponential Weighted Moving Average for drift detection.\"\"\"\n\n    def __init__(self, lambda_param: float = 0.2, L: float = 3.0):\n        self.lambda_param = lambda_param  # Smoothing factor\n        self.L = L  # Control limit multiplier\n        self.ewma = None\n\n    def update(self, value: float, baseline_mean: float, baseline_std: float) -> dict:\n        if self.ewma is None:\n            self.ewma = value\n        else:\n            self.ewma = self.lambda_param * value + (1 - self.lambda_param) * self.ewma\n\n        # Calculate control limits\n        factor = np.sqrt(self.lambda_param / (2 - self.lambda_param))\n        ucl = baseline_mean + self.L * baseline_std * factor\n        lcl = baseline_mean - self.L * baseline_std * factor\n\n        return {\n            \"ewma\": self.ewma,\n            \"ucl\": ucl,\n            \"lcl\": lcl,\n            \"drift_detected\": self.ewma > ucl or self.ewma < lcl\n        }\n```\n\n### Langfuse Score Trend Monitoring\n\n```python\nfrom langfuse import Langfuse\n\nlangfuse = Langfuse()\n\ndef check_quality_drift(days: int = 7, threshold_drop: float = 0.1):\n    \"\"\"Compare recent quality scores against baseline.\"\"\"\n\n    # Fetch recent scores\n    current_scores = langfuse.fetch_scores(\n        name=\"quality_overall\",\n        from_timestamp=datetime.now() - timedelta(days=1)\n    )\n\n    # Fetch baseline scores\n    baseline_scores = langfuse.fetch_scores(\n        name=\"quality_overall\",\n        from_timestamp=datetime.now() - timedelta(days=days),\n        to_timestamp=datetime.now() - timedelta(days=1)\n    )\n\n    current_mean = np.mean([s.value for s in current_scores])\n    baseline_mean = np.mean([s.",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "e2e-testing": {
    "name": "e2e-testing",
    "description": "End-to-end testing with Playwright 1.58+. Use when testing critical user journeys, browser automation, cross-browser testing, AI-assisted test generation, or validating complete application flows.",
    "version": "2.1.0",
    "author": "OrchestKit",
    "tags": [
      "playwright",
      "e2e",
      "testing",
      "ai-agents"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "playwright-1.57-api.md"
      ],
      "scripts": [
        "create-page-object.md",
        "page-object-template.ts"
      ],
      "checklists": [
        "e2e-checklist.md"
      ]
    },
    "content": "# E2E Testing with Playwright 1.58+\n\nValidate critical user journeys end-to-end with AI-assisted test generation.\n\n## Quick Reference - Semantic Locators\n\n```typescript\n// PREFERRED: Role-based locators (most resilient)\nawait page.getByRole('button', { name: 'Add to cart' }).click();\nawait page.getByRole('link', { name: 'Checkout' }).click();\n\n// GOOD: Label-based for form controls\nawait page.getByLabel('Email').fill('test@example.com');\n\n// ACCEPTABLE: Test IDs for stable anchors\nawait page.getByTestId('checkout-button').click();\n\n// AVOID: CSS selectors and XPath (fragile)\n// await page.click('[data-testid=\"add-to-cart\"]');\n```\n\n**Locator Priority:** `getByRole()` > `getByLabel()` > `getByPlaceholder()` > `getByTestId()`\n\n## Basic Test\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('user can complete checkout', async ({ page }) => {\n  await page.goto('/products');\n  await page.getByRole('button', { name: 'Add to cart' }).click();\n  await page.getByRole('link', { name: 'Checkout' }).click();\n  await page.getByLabel('Email').fill('test@example.com');\n  await page.getByRole('button', { name: 'Submit' }).click();\n  await expect(page.getByRole('heading', { name: 'Order confirmed' })).toBeVisible();\n});\n```\n\n## AI Agents (1.58+)\n\n### Initialize AI Agents\n\n```bash\n# Initialize agents for your preferred AI tool\nnpx playwright init-agents --loop=claude    # For Claude Code\nnpx playwright init-agents --loop=vscode    # For VS Code (requires v1.105+)\nnpx playwright init-agents --loop=opencode  # For OpenCode\n```\n\n### Generated Structure\n\nRunning `init-agents` creates the following:\n\n| Directory/File | Purpose |\n|----------------|---------|\n| `.github/` | Agent definitions and configuration |\n| `specs/` | Test plans in Markdown format |\n| `tests/seed.spec.ts` | Seed file for AI agents to reference |\n\n### Working with AI Agents\n\nAfter initialization, agents can:\n- Read test plans from `specs/` and generate tests\n- Use `seed.spec.ts` as a template for consistent patterns\n- Auto-repair failing tests by analyzing failures\n\n## Breaking Changes (1.58)\n\nThe following features have been removed in Playwright 1.58:\n\n| Removed | Migration |\n|---------|-----------|\n| `_react` selector | Use `getByRole()` or `getByTestId()` |\n| `_vue` selector | Use `getByRole()` or `getByTestId()` |\n| `:light` selector suffix | Use standard CSS selectors without `:light` |\n| `devtools` launch option | Use `args: ['--auto-open-devtools-for-tabs']` instead |\n| macOS 13 WebKit support | Upgrade to macOS 14+ for WebKit testing |\n\n### Migration Examples\n\n```typescript\n// Before (1.57 and earlier)\nawait page.locator('_react=MyComponent').click();\nawait page.locator('.card:light').click();\n\n// After (1.58+)\nawait page.getByTestId('my-component').click();\nawait page.locator('.card').click();\n\n// DevTools launch option\n// Before\nconst browser = await chromium.launch({ devtools: true });\n\n// After\nconst browser = await chromium.launch({\n  args: ['--auto-open-devtools-for",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer",
      "test-generator"
    ]
  },
  "edge-computing-patterns": {
    "name": "edge-computing-patterns",
    "description": "Use when deploying to Cloudflare Workers, Vercel Edge, or Deno Deploy. Covers edge middleware, streaming, runtime constraints, and globally distributed low-latency patterns.",
    "version": "1.1.0",
    "author": "AI Agent Hub",
    "tags": [
      "edge",
      "cloudflare",
      "vercel",
      "deno",
      "serverless",
      "2025"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "cloudflare-workers.md",
        "runtime-differences.md",
        "vercel-edge.md"
      ],
      "scripts": [
        "edge-function.ts",
        "edge-middleware.ts"
      ],
      "checklists": [
        "edge-deployment-checklist.md"
      ]
    },
    "content": "# Edge Computing Patterns\n\n## Overview\n\nEdge computing runs code closer to users worldwide, reducing latency from seconds to milliseconds. This skill covers Cloudflare Workers, Vercel Edge Functions, and Deno Deploy patterns for building globally distributed applications.\n\n**When to use this skill:**\n- Global applications requiring <50ms latency\n- Authentication/authorization at the edge\n- A/B testing and feature flags\n- Geo-routing and localization\n- API rate limiting and DDoS protection\n- Transforming responses (image optimization, HTML rewriting)\n\n## Platform Comparison\n\n| Feature | Cloudflare Workers | Vercel Edge | Deno Deploy |\n|---------|-------------------|-------------|-------------|\n| Cold Start | <1ms | <10ms | <10ms |\n| Locations | 300+ | 100+ | 35+ |\n| Runtime | V8 Isolates | V8 Isolates | Deno |\n| Max Duration | 30s (paid: unlimited) | 25s | 50ms-5min |\n| Free Tier | 100k req/day | 100k req/month | 100k req/month |\n\n## Platform-Specific Implementation\n\nFor detailed code examples and patterns, load the appropriate reference file:\n\n### Cloudflare Workers\n**Reference:** `references/cloudflare-workers.md`\n- Worker fetch handlers and routing\n- KV storage patterns (eventually consistent)\n- Durable Objects for stateful edge\n- Wrangler CLI and wrangler.toml configuration\n- Caching strategies with Cache API\n\n### Vercel Edge Functions\n**Reference:** `references/vercel-edge.md`\n- Edge Middleware for Next.js (auth, A/B testing, geo-routing)\n- Edge API routes with streaming\n- Edge Config for feature flags\n- Geolocation-based routing patterns\n\n### Runtime Differences\n**Reference:** `references/runtime-differences.md`\n- Node.js APIs NOT available at edge\n- Web API compatibility matrix\n- Polyfill strategies for crypto, Buffer, streams\n\n## Edge Runtime Constraints\n\n**Available APIs:**\n- fetch, Request, Response, Headers\n- URL, URLSearchParams\n- TextEncoder, TextDecoder\n- ReadableStream, WritableStream\n- crypto, SubtleCrypto (Web Crypto API)\n- Web APIs (atob, btoa, setTimeout, etc.)\n\n**NOT Available:**\n- Node.js APIs (fs, path, child_process)\n- Native modules and binary dependencies\n- File system access\n- Some npm packages with Node.js dependencies\n\n## Common Patterns Summary\n\n### Authentication at Edge\nVerify JWT tokens at edge for sub-millisecond auth checks. See `references/cloudflare-workers.md` for implementation.\n\n### Rate Limiting\nUse KV (Cloudflare) or Edge Config (Vercel) for distributed rate limiting. Pattern: IP-based key with TTL expiration.\n\n### Edge Caching\nCache API with cache-aside pattern. Check cache first, fetch origin on miss, store with TTL.\n\n### A/B Testing\nAssign users to buckets via cookie, rewrite URLs to variant pages. See `references/vercel-edge.md` for middleware pattern.\n\n### Geo-Routing\nAccess request.cf.country (Cloudflare) or request.geo (Vercel) for location-based routing.\n\n## Best Practices\n\n- Keep bundles small (<1MB compressed)\n- Use streaming for large responses to avoid timeouts\n- Leverage platform caching (KV, D",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "frontend-ui-developer"
    ]
  },
  "elevenlabs-narration": {
    "name": "elevenlabs-narration",
    "description": "ElevenLabs TTS integration for video narration. Use when generating voiceover audio, selecting voices, or building script-to-audio pipelines",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "audio",
      "narration",
      "tts",
      "elevenlabs",
      "voice",
      "speech"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "api-integration.md",
        "timing-calculation.md",
        "voice-selection.md"
      ]
    },
    "content": "# ElevenLabs Narration for Video Production\n\nComplete integration guide for using ElevenLabs text-to-speech in video production pipelines. Covers voice selection, timing calculations, API patterns, and cost optimization for professional narration.\n\n## Overview\n\n- Generating narration audio for video segments\n- Selecting appropriate voices for content type\n- Calculating segment timing from frames to milliseconds\n- Building script-to-audio pipelines\n- Optimizing API usage and costs\n- Handling rate limits and errors\n\n## ElevenLabs API Overview\n\n### Model Comparison (2026)\n\n| Model | Latency | Quality | Cost | Best For |\n|-------|---------|---------|------|----------|\n| **eleven_multilingual_v2** | Medium | Best | $0.30/1K chars | Production, multilingual |\n| **eleven_turbo_v2_5** | Low | Excellent | $0.18/1K chars | Real-time, drafts |\n| **eleven_flash_v2_5** | Lowest | Good | $0.08/1K chars | Previews, testing |\n| **eleven_english_sts_v2** | Medium | Best | $0.30/1K chars | Speech-to-speech |\n\n### API Endpoints\n\n```\nBase URL: https://api.elevenlabs.io/v1\n\nPOST /text-to-speech/{voice_id}           # Generate audio\nPOST /text-to-speech/{voice_id}/stream    # Stream audio\nGET  /voices                              # List voices\nGET  /voices/{voice_id}                   # Voice details\nGET  /user                                # Usage/quota\nPOST /speech-to-speech/{voice_id}         # Voice conversion\n```\n\n## Core Integration Pattern\n\n### Basic Text-to-Speech\n\n```typescript\nimport { ElevenLabsClient } from 'elevenlabs';\n\nconst client = new ElevenLabsClient({\n  apiKey: process.env.ELEVENLABS_API_KEY\n});\n\nasync function generateNarration(\n  text: string,\n  voiceId: string = 'Rachel'\n): Promise<Buffer> {\n  const audio = await client.generate({\n    voice: voiceId,\n    text: text,\n    model_id: 'eleven_multilingual_v2',\n    voice_settings: {\n      stability: 0.5,\n      similarity_boost: 0.8,\n      style: 0.0,\n      use_speaker_boost: true\n    }\n  });\n\n  // Convert stream to buffer\n  const chunks: Buffer[] = [];\n  for await (const chunk of audio) {\n    chunks.push(chunk);\n  }\n  return Buffer.concat(chunks);\n}\n```\n\n## Voice Selection Quick Reference\n\n### Pre-Built Voices for Video Narration\n\n| Voice | ID | Characteristics | Use Case |\n|-------|-----|-----------------|----------|\n| **Rachel** | 21m00Tcm4TlvDq8ikWAM | Warm, conversational | General narration |\n| **Adam** | pNInz6obpgDQGcFmaJgB | Deep, authoritative | Tech explainers |\n| **Antoni** | ErXwobaYiN019PkySvjV | Energetic, youthful | Product demos |\n| **Bella** | EXAVITQu4vr4xnSDxMaL | Friendly, engaging | Tutorials |\n| **Josh** | TxGEqnHWrfWFTfGW9XjX | Deep, narrative | Documentaries |\n\n### Voice Settings Explained\n\n```typescript\ninterface VoiceSettings {\n  stability: number;        // 0.0-1.0 (lower = more expressive)\n  similarity_boost: number; // 0.0-1.0 (higher = closer to original)\n  style: number;           // 0.0-1.0 (v2 models only)\n  use_speaker_boost: boolean; // Clarity enhancement\n}\n\n// Rec",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "embeddings": {
    "name": "embeddings",
    "description": "Text embeddings for semantic search and similarity. Use when converting text to vectors, choosing embedding models, implementing chunking strategies, or building document similarity features.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ai",
      "embeddings",
      "vectors",
      "semantic-search",
      "similarity"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "advanced-patterns.md",
        "chunking-strategies.md"
      ],
      "scripts": [
        "embedding-pipeline.py"
      ],
      "checklists": [
        "embedding-checklist.md"
      ]
    },
    "content": "# Embeddings\n\nConvert text to dense vector representations for semantic search and similarity.\n\n## Quick Reference\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\n# Single text embedding\nresponse = client.embeddings.create(\n    model=\"text-embedding-3-small\",\n    input=\"Your text here\"\n)\nvector = response.data[0].embedding  # 1536 dimensions\n```\n\n```python\n# Batch embedding (efficient)\ntexts = [\"text1\", \"text2\", \"text3\"]\nresponse = client.embeddings.create(\n    model=\"text-embedding-3-small\",\n    input=texts\n)\nvectors = [item.embedding for item in response.data]\n```\n\n## Model Selection\n\n| Model | Dims | Cost | Use Case |\n|-------|------|------|----------|\n| `text-embedding-3-small` | 1536 | $0.02/1M | General purpose |\n| `text-embedding-3-large` | 3072 | $0.13/1M | High accuracy |\n| `nomic-embed-text` (Ollama) | 768 | Free | Local/CI |\n\n## Chunking Strategy\n\n```python\ndef chunk_text(text: str, chunk_size: int = 512, overlap: int = 50) -> list[str]:\n    \"\"\"Split text into overlapping chunks for embedding.\"\"\"\n    words = text.split()\n    chunks = []\n\n    for i in range(0, len(words), chunk_size - overlap):\n        chunk = \" \".join(words[i:i + chunk_size])\n        if chunk:\n            chunks.append(chunk)\n\n    return chunks\n```\n\n**Guidelines:**\n- Chunk size: 256-1024 tokens (512 typical)\n- Overlap: 10-20% for context continuity\n- Include metadata (title, source) with chunks\n\n## Similarity Calculation\n\n```python\nimport numpy as np\n\ndef cosine_similarity(a: list[float], b: list[float]) -> float:\n    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n    a, b = np.array(a), np.array(b)\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# Usage\nsimilarity = cosine_similarity(vector1, vector2)\n# 1.0 = identical, 0.0 = orthogonal, -1.0 = opposite\n```\n\n## Key Decisions\n\n- **Dimension reduction**: Can truncate `text-embedding-3-large` to 1536 dims\n- **Normalization**: Most models return normalized vectors\n- **Batch size**: 100-500 texts per API call for efficiency\n\n## Common Mistakes\n\n- Embedding queries differently than documents\n- Not chunking long documents (context gets lost)\n- Using wrong similarity metric (cosine vs euclidean)\n- Re-embedding unchanged content (cache embeddings)\n\n## Advanced Patterns\n\nSee `references/advanced-patterns.md` for:\n- **Late Chunking**: Embed full document, extract chunk vectors from contextualized tokens\n- **Batch API**: Production batching with rate limiting and retry\n- **Embedding Cache**: Redis-based caching to avoid re-embedding\n- **Matryoshka Embeddings**: Dimension reduction with text-embedding-3\n\n## Related Skills\n\n- `rag-retrieval` - Using embeddings for RAG pipelines\n- `hyde-retrieval` - Hypothetical document embeddings for vocabulary mismatch\n- `contextual-retrieval` - Anthropic's context-prepending technique\n- `reranking-patterns` - Cross-encoder reranking for precision\n- `ollama-local` - Local embeddings with nomic-embed-text\n\n## Capability Details\n\n### text-to-vector\n**Keywords:** ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "multimodal-specialist"
    ]
  },
  "error-handling-rfc9457": {
    "name": "error-handling-rfc9457",
    "description": "RFC 9457 Problem Details for standardized HTTP API error responses. Use when implementing problem details format, structured API errors, error registries, or migrating from RFC 7807.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "error-handling",
      "rfc9457",
      "problem-details",
      "fastapi",
      "api"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "rfc9457-spec.md"
      ],
      "scripts": [
        "problem-detail-exceptions.py"
      ],
      "checklists": [
        "error-handling-checklist.md"
      ]
    },
    "content": "# RFC 9457 Problem Details\n\nStandardize API error responses with machine-readable problem details.\n\n## RFC 9457 vs RFC 7807\n\n| Feature | RFC 7807 (Old) | RFC 9457 (Current) |\n|---------|----------------|---------------------|\n| Status | Obsolete | Active Standard |\n| Multiple problems | Not specified | Explicitly supported |\n| Error registry | No | Yes (IANA registry) |\n| Extension fields | Implicit | Explicitly allowed |\n\n## Problem Details Schema\n\n```python\nfrom pydantic import BaseModel, Field, HttpUrl\nfrom typing import Any\n\nclass ProblemDetail(BaseModel):\n    \"\"\"RFC 9457 Problem Details for HTTP APIs.\"\"\"\n\n    type: HttpUrl = Field(\n        default=\"about:blank\",\n        description=\"URI identifying the problem type\"\n    )\n    title: str = Field(\n        description=\"Short, human-readable summary\"\n    )\n    status: int = Field(\n        ge=400, le=599,\n        description=\"HTTP status code\"\n    )\n    detail: str | None = Field(\n        default=None,\n        description=\"Human-readable explanation specific to this occurrence\"\n    )\n    instance: str | None = Field(\n        default=None,\n        description=\"URI reference identifying the specific occurrence\"\n    )\n\n    model_config = {\"extra\": \"allow\"}  # Allow extension fields\n```\n\n## FastAPI Integration\n\n### Exception Classes\n\n```python\nfrom fastapi import HTTPException\nfrom typing import Any\n\nclass ProblemException(HTTPException):\n    \"\"\"Base exception for RFC 9457 problem details.\"\"\"\n\n    def __init__(\n        self,\n        status_code: int,\n        problem_type: str,\n        title: str,\n        detail: str | None = None,\n        instance: str | None = None,\n        **extensions: Any,\n    ):\n        self.problem_type = problem_type\n        self.title = title\n        self.detail = detail\n        self.instance = instance\n        self.extensions = extensions\n        super().__init__(status_code=status_code, detail=detail)\n\n    def to_problem_detail(self) -> dict[str, Any]:\n        result = {\n            \"type\": self.problem_type,\n            \"title\": self.title,\n            \"status\": self.status_code,\n        }\n        if self.detail:\n            result[\"detail\"] = self.detail\n        if self.instance:\n            result[\"instance\"] = self.instance\n        result.update(self.extensions)\n        return result\n```\n\n### Specific Problem Types\n\n```python\nclass ValidationProblem(ProblemException):\n    def __init__(self, errors: list[dict], instance: str | None = None):\n        super().__init__(\n            status_code=422,\n            problem_type=\"https://api.example.com/problems/validation-error\",\n            title=\"Validation Error\",\n            detail=\"One or more fields failed validation\",\n            instance=instance,\n            errors=errors,  # Extension field\n        )\n\nclass NotFoundProblem(ProblemException):\n    def __init__(self, resource: str, resource_id: str, instance: str | None = None):\n        super().__init__(\n            status_code=404,\n            problem_type=\"https://api.ex",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "errors": {
    "name": "errors",
    "description": "Error pattern analysis and troubleshooting for Claude Code sessions. Use when handling errors, fixing failures, troubleshooting issues.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "errors",
      "debugging",
      "troubleshooting",
      "patterns"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [
      "Read",
      "Bash",
      "Grep"
    ],
    "skills": [],
    "agent": null,
    "structure": {},
    "content": "# Error Pattern Analysis\n\nAnalyze errors captured from Claude Code sessions to identify patterns and get actionable insights.\n\n## Quick Start\n\n```bash\n/errors              # Batch analysis of historical error patterns\n/debug               # CC 2.1.30 real-time debug for current session\n```\n\n### When to Use Which\n\n| Command | Purpose | Scope |\n|---------|---------|-------|\n| `/errors` | Batch analysis of error patterns (last 24h/7d) | Historical patterns |\n| `/debug` | Real-time debug of current session state | Current session |\n| `/ork:fix-issue` | Full RCA workflow for specific bug | Single issue |\n\n## Quick Analysis\n\n```bash\n# Run batch analysis on last 24h of errors\npython .claude/scripts/analyze_errors.py\n\n# Analyze last 7 days\npython .claude/scripts/analyze_errors.py --days 7\n\n# Generate markdown report\npython .claude/scripts/analyze_errors.py --report\n```\n\n## What Gets Captured\n\nThe error collector hook captures:\n- Tool name (Bash, mcp__memory__search_nodes, etc.)\n- Error message (first 500 chars)\n- Tool input (command/query that failed)\n- Timestamp and session ID\n\n**Location:** `.claude/logs/errors.jsonl`\n\n## Current Error Rules\n\nCheck learned patterns that trigger warnings:\n\n```bash\ncat .claude/rules/error_rules.json | jq '.rules[] | {id, signature, count: .occurrence_count}'\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `.claude/hooks/posttool/error-collector.sh` | Captures errors to JSONL |\n| `.claude/hooks/pretool/bash/error-pattern-warner.sh` | Warns before risky commands |\n| `.claude/scripts/analyze_errors.py` | Batch pattern analysis |\n| `.claude/rules/error_rules.json` | Learned error patterns |\n| `.claude/logs/errors.jsonl` | Raw error log |\n\n## Common Patterns\n\n### PostgreSQL Connection Errors\n\n```\npattern: role \"X\" does not exist\nfix: Use Docker connection: docker exec -it orchestkit-postgres-dev psql -U orchestkit_user -d orchestkit_dev\n\npattern: relation \"X\" does not exist\nfix: Check MCP postgres server connection string - may be connected to wrong database\n```\n\n## Related Skills\n- fix-issue: Fix identified errors\n- debug-investigator: Debug error root causes\n## Adding New Rules\n\nRules are auto-generated by `analyze_errors.py` when patterns repeat 2+ times.\nFor manual rules, edit `.claude/rules/error_rules.json`:\n\n```json\n{\n  \"id\": \"custom-001\",\n  \"pattern\": \"your regex pattern\",\n  \"signature\": \"human readable signature\",\n  \"tool\": \"Bash\",\n  \"occurrence_count\": 1,\n  \"fix_suggestion\": \"How to fix this\"\n}\n```",
    "contentTruncated": false,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "debug-investigator"
    ]
  },
  "event-sourcing": {
    "name": "event-sourcing",
    "description": "Event sourcing patterns for storing state as a sequence of events. Use when implementing event-driven architectures, CQRS, audit trails, or building systems requiring full history reconstruction.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "event-sourcing",
      "cqrs",
      "events",
      "audit-trail",
      "domain-events"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Write",
      "Edit",
      "Bash"
    ],
    "skills": [],
    "agent": "event-driven-architect",
    "structure": {
      "references": [
        "event-store-patterns.md"
      ],
      "scripts": [
        "event-store-template.py"
      ],
      "checklists": [
        "event-sourcing-checklist.md"
      ]
    },
    "content": "# Event Sourcing Patterns\n\nStore application state as immutable events rather than current state snapshots.\n\n## Overview\n\n- Full audit trail requirements (compliance, finance)\n- Temporal queries (\"what was state at time X?\")\n- CQRS implementations with separate read/write models\n- Systems requiring event replay and debugging\n- Microservices with eventual consistency\n\n## Quick Reference\n\n### Domain Event Base\n\n```python\nfrom pydantic import BaseModel, Field\nfrom datetime import datetime, timezone\nfrom uuid import UUID, uuid4\n\nclass DomainEvent(BaseModel):\n    event_id: UUID = Field(default_factory=uuid4)\n    aggregate_id: UUID\n    event_type: str\n    version: int\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    class Config:\n        frozen = True  # Events are immutable\n```\n\n### Event-Sourced Aggregate\n\n```python\nclass Account:\n    def __init__(self):\n        self._changes, self._version, self.balance = [], 0, 0.0\n\n    def deposit(self, amount: float):\n        self._raise_event(MoneyDeposited(aggregate_id=self.id, amount=amount, version=self._version + 1))\n\n    def _apply(self, event):\n        match event:\n            case MoneyDeposited(): self.balance += event.amount\n            case MoneyWithdrawn(): self.balance -= event.amount\n\n    def load_from_history(self, events):\n        for e in events: self._apply(e); self._version = e.version\n```\n\n### Event Store Append\n\n```python\nasync def append_events(self, aggregate_id: UUID, events: list, expected_version: int):\n    current = await self.get_version(aggregate_id)\n    if current != expected_version:\n        raise ConcurrencyError(f\"Expected {expected_version}, got {current}\")\n    for event in events:\n        await self.session.execute(insert(event_store).values(\n            event_id=event.event_id, aggregate_id=aggregate_id,\n            event_type=event.event_type, version=event.version, data=event.model_dump()\n        ))\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Event naming | Past tense (`OrderPlaced`, not `PlaceOrder`) |\n| Concurrency | Optimistic locking with version check |\n| Snapshots | Every 100-500 events for large aggregates |\n| Event schema | Version events, support upcasting |\n| Projections | Async handlers, idempotent updates |\n| Storage | PostgreSQL + JSONB or dedicated event store |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER modify stored events\nawait event_store.update(event_id, new_data)  # Destroys audit trail\n\n# NEVER include computed data in events\nclass OrderPlaced(DomainEvent):\n    total: float  # WRONG - compute from line items\n\n# NEVER ignore event ordering\nasync for event in events:  # May arrive out of order\n    await handle(event)  # Must check version/sequence\n\n# ALWAYS use immutable events\nclass Event(BaseModel):\n    class Config:\n        frozen = True  # Correct\n\n# ALWAYS version your events\nevent_schema_version: int = 1  # Support schema evolution\n```\n\n## Related Skills\n\n- `message-",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "event-driven-architect"
    ]
  },
  "evidence-verification": {
    "name": "evidence-verification",
    "description": "Collects and verifies evidence before marking tasks complete. Use when completing tasks, code reviews, or deployments to prove work with test results, build outputs, coverage metrics, and exit codes.",
    "version": "2.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "quality",
      "verification",
      "testing",
      "evidence",
      "completion"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash"
    ],
    "skills": [],
    "agent": "code-quality-reviewer",
    "structure": {
      "references": [
        "evidence-patterns.md"
      ],
      "scripts": [
        "build-evidence.md",
        "evidence-checklist.md",
        "generate-test-evidence.md",
        "test-evidence.md"
      ],
      "checklists": [
        "verification-checklist.md"
      ]
    },
    "content": "# Evidence Verification\n\nEnsures all claims are backed by executable proof: test results, coverage metrics, build success, and deployment verification.\n\n**Key Principle:** Show, don't tell. No task is complete without verifiable evidence.\n\n## Overview\n\n### Auto-Activate Triggers\n- Completing code implementation\n- Finishing code review\n- Marking tasks complete in Squad mode\n- Before agent handoff\n- Production deployment verification\n\n### Manual Activation\n- When user requests \"verify this works\"\n- Before creating pull requests\n- During quality assurance reviews\n- When troubleshooting failures\n\n---\n\n# Evidence Verification\n\n## Core Concepts\n\n### 1. Evidence Types\n\n**Test Evidence**\n- Exit code (must be 0 for success)\n- Test suite results (passed/failed/skipped)\n- Coverage percentage (if available)\n- Test duration\n\n**Build Evidence**\n- Build exit code (0 = success)\n- Compilation errors/warnings\n- Build artifacts created\n- Build duration\n\n**Deployment Evidence**\n- Deployment status (success/failed)\n- Environment deployed to\n- Health check results\n- Rollback capability verified\n\n**Code Quality Evidence**\n- Linter results (errors/warnings)\n- Type checker results\n- Security scan results\n- Accessibility audit results\n\n### 2. Evidence Collection Protocol\n\n```markdown\n## Evidence Collection Steps\n\n1. **Identify Verification Points**\n   - What needs to be proven?\n   - What could go wrong?\n   - What does \"complete\" mean?\n\n2. **Execute Verification**\n   - Run tests\n   - Run build\n   - Run linters\n   - Check deployments\n\n3. **Capture Results**\n   - Record exit codes\n   - Save output snippets\n   - Note timestamps\n   - Document environment\n\n4. **Store Evidence**\n   - Add to shared context\n   - Reference in task completion\n   - Link to artifacts\n```\n\n### 3. Verification Standards\n\n**Minimum Evidence Requirements:**\n- ✅ At least ONE verification type executed\n- ✅ Exit code captured (0 = pass, non-zero = fail)\n- ✅ Timestamp recorded\n- ✅ Evidence stored in context\n\n**Production-Grade Requirements:**\n- ✅ Tests run with exit code 0\n- ✅ Coverage >70% (or project standard)\n- ✅ Build succeeds with exit code 0\n- ✅ No critical linter errors\n- ✅ Security scan passes\n\n---\n\n# Evidence Verification\n\n## Evidence Collection Templates\n\n### Template 1: Test Evidence\n\nUse this template when running tests:\n\n```markdown\n## Test Evidence\n\n**Command:** `npm test` (or equivalent)\n**Exit Code:** 0 ✅ / non-zero ❌\n**Duration:** X seconds\n**Results:**\n- Tests passed: X\n- Tests failed: X\n- Tests skipped: X\n- Coverage: X%\n\n**Output Snippet:**\n```\n[First 10 lines of test output]\n```\n\n**Timestamp:** YYYY-MM-DD HH:MM:SS\n**Environment:** Node vX.X.X, OS, etc.\n```\n\n### Template 2: Build Evidence\n\nUse this template when building:\n\n```markdown\n## Build Evidence\n\n**Command:** `npm run build` (or equivalent)\n**Exit Code:** 0 ✅ / non-zero ❌\n**Duration:** X seconds\n**Artifacts Created:**\n- dist/bundle.js (245 KB)\n- dist/styles.css (18 KB)\n\n**Errors:** X\n**Warnings:** X\n\n**Output Snippet:**\n```\n[First 10",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "explore": {
    "name": "explore",
    "description": "Deep codebase exploration with parallel agents. Use when exploring a repo or discovering architecture.",
    "version": "2.1.0",
    "author": "OrchestKit",
    "tags": [
      "exploration",
      "code-search",
      "architecture",
      "codebase",
      "health-assessment"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Read",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "mcp__memory__search_nodes",
      "Bash"
    ],
    "skills": [
      "ascii-visualizer",
      "architecture-decision-record",
      "memory",
      "clean-architecture",
      "assess-complexity"
    ],
    "agent": null,
    "structure": {
      "references": [
        "code-health-rubric.md",
        "dependency-analysis.md",
        "findability-patterns.md"
      ],
      "assets": [
        "exploration-report.md",
        "hotspot-diagram.md"
      ],
      "scripts": [
        "dependency-mapper.sh"
      ]
    },
    "content": "# Codebase Exploration\n\nMulti-angle codebase exploration using 3-5 parallel agents.\n\n## Quick Start\n\n```bash\n/explore authentication\n```\n\n> **Opus 4.6**: Exploration agents use native adaptive thinking for deeper pattern recognition across large codebases.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify what the user wants to explore:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What aspect do you want to explore?\",\n    \"header\": \"Focus\",\n    \"options\": [\n      {\"label\": \"Full exploration (Recommended)\", \"description\": \"Code structure + data flow + architecture + health assessment\"},\n      {\"label\": \"Code structure only\", \"description\": \"Find files, classes, functions related to topic\"},\n      {\"label\": \"Data flow\", \"description\": \"Trace how data moves through the system\"},\n      {\"label\": \"Architecture patterns\", \"description\": \"Identify design patterns and integrations\"},\n      {\"label\": \"Quick search\", \"description\": \"Just find relevant files, skip deep analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full exploration**: All 8 phases, all parallel agents\n- **Code structure only**: Skip phases 4-6 (health, dependencies, product)\n- **Data flow**: Focus phase 3 agents on data tracing\n- **Architecture patterns**: Focus on backend-system-architect agent\n- **Quick search**: Skip to phase 1-2 only, return file list\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — explorers share discoveries) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Full exploration with 4+ agents → recommend **Agent Teams**; Quick search or single-focus → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Discovery sharing | Lead synthesizes after all complete | Explorers share discoveries as they go |\n| Cross-referencing | Lead connects dots | Data flow explorer alerts architecture explorer |\n| Cost | ~150K tokens | ~400K tokens |\n| Best for | Quick/focused searches | Deep full-codebase exploration |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining exploration.\n\n---\n\n## ⚠️ CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n**BEFORE doing ANYTHING else, create tasks to show progress:**\n\n```python\n# 1. Create main exploration task IMMEDIATELY\nTaskCreate(\n  subject=\"Explore: {topic}\",\n  description=\"Deep codebase exploration for {topic}\",\n  activeForm=\"Exploring {topic}\"\n)\n\n# 2. Create subtasks for phases (8-phase process)\nTaskCreate(subject=\"Initial file search\", activeForm=\"Searching files\")\nTaskCreate(subject=\"Check knowledge graph\", activeForm=\"Checking memory\")\nTaskCreate(subject=\"Launch exploration agents\", activeForm=\"Dispatching explorers\")\nTaskCreate(subject=\"Assess code health (0-10)\", activeForm=\"Assessing code health\")\nTaskCreate(sub",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "fastapi-advanced": {
    "name": "fastapi-advanced",
    "description": "FastAPI  advanced patterns including lifespan, dependencies, middleware, and Pydantic settings. Use when configuring FastAPI lifespan events, creating dependency injection, building Starlette middleware, or managing async Python services with uvicorn.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "fastapi",
      "python",
      "async",
      "middleware",
      "dependencies"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "middleware-stack.md"
      ],
      "assets": [
        "fastapi-app-template.py"
      ],
      "scripts": [
        "create-fastapi-app.md"
      ],
      "checklists": [
        "fastapi-production-checklist.md"
      ]
    },
    "content": "# FastAPI Advanced Patterns ()\n\nProduction-ready FastAPI patterns for modern Python backends.\n\n## Lifespan Management ()\n\n### Modern Lifespan Context Manager\n\n```python\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nimport redis.asyncio as redis\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan with resource management.\"\"\"\n    # Startup\n    app.state.db_engine = create_async_engine(\n        settings.database_url,\n        pool_size=5,\n        max_overflow=10,\n    )\n    app.state.redis = redis.from_url(settings.redis_url)\n\n    # Health check connections\n    async with app.state.db_engine.connect() as conn:\n        await conn.execute(text(\"SELECT 1\"))\n    await app.state.redis.ping()\n\n    yield  # Application runs\n\n    # Shutdown\n    await app.state.db_engine.dispose()\n    await app.state.redis.close()\n\napp = FastAPI(lifespan=lifespan)\n```\n\n### Lifespan with Services\n\n```python\nfrom app.services import EmbeddingsService, LLMService\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Initialize services\n    app.state.embeddings = EmbeddingsService(\n        model=settings.embedding_model,\n        batch_size=100,\n    )\n    app.state.llm = LLMService(\n        providers=[\"openai\", \"anthropic\"],\n        default=\"anthropic\",\n    )\n\n    # Warm up models (optional)\n    await app.state.embeddings.warmup()\n\n    yield\n\n    # Cleanup\n    await app.state.embeddings.close()\n    await app.state.llm.close()\n```\n\n## Dependency Injection Patterns\n\n### Database Session\n\n```python\nfrom typing import AsyncGenerator\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom fastapi import Depends, Request\n\nasync def get_db(request: Request) -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"Yield database session from app state.\"\"\"\n    async with AsyncSession(\n        request.app.state.db_engine,\n        expire_on_commit=False,\n    ) as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n```\n\n### Service Dependencies\n\n```python\nfrom functools import lru_cache\n\nclass AnalysisService:\n    def __init__(\n        self,\n        db: AsyncSession,\n        embeddings: EmbeddingsService,\n        llm: LLMService,\n    ):\n        self.db = db\n        self.embeddings = embeddings\n        self.llm = llm\n\ndef get_analysis_service(\n    db: AsyncSession = Depends(get_db),\n    request: Request = None,\n) -> AnalysisService:\n    return AnalysisService(\n        db=db,\n        embeddings=request.app.state.embeddings,\n        llm=request.app.state.llm,\n    )\n\n@router.post(\"/analyses\")\nasync def create_analysis(\n    data: AnalysisCreate,\n    service: AnalysisService = Depends(get_analysis_service),\n):\n    return await service.create(data)\n```\n\n### Cached Dependencies\n\n```python\nfrom functools import lru_cache\nfrom pydantic_settings import BaseSettings\n\nclass Sett",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "python-performance-engineer"
    ]
  },
  "feedback": {
    "name": "feedback",
    "description": "Manages OrchestKit feedback system. Use when providing feedback or viewing usage analytics.",
    "version": "1.2.0",
    "author": "OrchestKit",
    "tags": [
      "feedback",
      "learning",
      "patterns",
      "metrics",
      "privacy",
      "analytics",
      "consent"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "file-locations.md",
        "privacy-policy.md"
      ]
    },
    "content": "# Feedback - Manage Learning System\n\nView and manage the OrchestKit feedback system that learns from your usage.\n\n## Overview\n\n- Checking feedback system status\n- Pausing/resuming learning\n- Resetting learned patterns\n- Exporting feedback data\n- Managing privacy settings\n- Enabling/disabling anonymous analytics sharing\n- Viewing privacy policy\n\n## Usage\n\n```\n/feedback                    # Same as status\n/feedback status             # Show current state\n/feedback pause              # Pause learning\n/feedback resume             # Resume learning\n/feedback reset              # Clear learned patterns\n/feedback export             # Export feedback data\n/feedback settings           # Show/edit settings\n/feedback opt-in             # Enable anonymous sharing\n/feedback opt-out            # Disable anonymous sharing\n/feedback privacy            # View privacy policy\n/feedback export-analytics   # Export anonymous analytics for review\n```\n\n## Subcommands\n\n### status (default)\n\nShow the current feedback system state.\n\n**Output:**\n```\nFeedback System Status\n-----------------------------\nLearning: Enabled\nAnonymous sharing: Disabled\nData retention: 90 days\n\nLearned Patterns:\n- Auto-approves: npm install, npm test, git push (3 commands)\n- Code style: async/await preferred, TypeScript strict mode\n\nAgent Performance:\n- backend-architect: 94% success (28 spawns) [improving]\n- test-generator: 72% success (18 spawns) [declining]\n\nContext Savings: ~8k tokens/session (estimated)\n\nStorage: .claude/feedback/ (45 KB)\n```\n\n### pause\n\nTemporarily pause all learning without clearing data.\n\n**Action:**\n1. Set `pausedUntil` in preferences to a far future date\n2. Confirm to user\n\n**Output:**\n```\nFeedback learning paused\n\nYour existing patterns are preserved.\nResume with: /feedback resume\n```\n\n### resume\n\nResume paused learning.\n\n**Action:**\n1. Clear `pausedUntil` in preferences\n2. Confirm to user\n\n**Output:**\n```\nFeedback learning resumed\n\nThe system will continue learning from your usage.\n```\n\n### reset\n\nClear all learned patterns (requires confirmation).\n\n**Action:**\n1. Show what will be deleted\n2. Ask for confirmation (user must type \"RESET\")\n3. If confirmed, clear patterns file but keep preferences\n\n**Output (before confirmation):**\n```\nWARNING: This will clear all learned patterns:\n\n- 5 auto-approve permission rules\n- 3 code style preferences\n- Agent performance history\n\nYour preferences (enabled, sharing, retention) will be kept.\n\nTo confirm, respond with exactly: RESET\nTo cancel, respond with anything else.\n```\n\n**Output (after confirmation):**\n```\nFeedback data reset\n\n- Cleared 5 permission patterns\n- Cleared 3 style preferences\n- Cleared agent metrics\n\nLearning will start fresh from now.\n```\n\n### export\n\nExport all feedback data to a JSON file.\n\n**Action:**\n1. Read all feedback files\n2. Combine into single export\n3. Write to `.claude/feedback/export-{date}.json`\n\n**Output:**\n```\nExported feedback data to:\n   .claude/feedback/export-2026-01-14.json\n\nContains:\n- 5 lear",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "fine-tuning-customization": {
    "name": "fine-tuning-customization",
    "description": "LLM fine-tuning with LoRA, QLoRA, DPO alignment, and synthetic data generation. Efficient training, preference learning, data creation. Use when customizing models for specific domains.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "fine-tuning",
      "lora",
      "qlora",
      "dpo",
      "synthetic-data",
      "rlhf"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "dpo-alignment.md",
        "lora-qlora.md",
        "synthetic-data.md",
        "when-to-finetune.md"
      ],
      "scripts": [
        "create-lora-config.md",
        "dpo-training.py",
        "lora-config.yaml"
      ],
      "checklists": [
        "fine-tuning-decision.md"
      ]
    },
    "content": "# Fine-Tuning & Customization\n\nCustomize LLMs for specific domains using parameter-efficient fine-tuning and alignment techniques.\n\n> **Unsloth **: 7x longer context RL, FP8 RL on consumer GPUs, rsLoRA support. **TRL**: OpenEnv integration, vLLM server mode, transformers 5.0.0+ compatible.\n\n## Decision Framework: Fine-Tune or Not?\n\n| Approach | Try First | When It Works |\n|----------|-----------|---------------|\n| Prompt Engineering | Always | Simple tasks, clear instructions |\n| RAG | External knowledge needed | Knowledge-intensive tasks |\n| Fine-Tuning | Last resort | Deep specialization, format control |\n\n**Fine-tune ONLY when:**\n1. Prompt engineering tried and insufficient\n2. RAG doesn't capture domain nuances\n3. Specific output format consistently required\n4. Persona/style must be deeply embedded\n5. You have ~1000+ high-quality examples\n\n## LoRA vs QLoRA (Unsloth )\n\n| Criteria | LoRA | QLoRA |\n|----------|------|-------|\n| Model fits in VRAM | Use LoRA | |\n| Memory constrained | | Use QLoRA |\n| Training speed | 39% faster | |\n| Memory savings | | 75%+ (dynamic 4-bit quants) |\n| Quality | Baseline | ~Same (Unsloth recovered accuracy loss) |\n| 70B LLaMA | | <48GB VRAM with QLoRA |\n\n## Quick Reference: LoRA Training\n\n```python\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\n\n# Load with 4-bit quantization (QLoRA)\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/Meta-Llama-3.1-8B\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n\n# Add LoRA adapters\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=16,              # Rank (16-64 typical)\n    lora_alpha=32,     # Scaling (2x r)\n    lora_dropout=0.05,\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention\n        \"gate_proj\", \"up_proj\", \"down_proj\",      # MLP (QLoRA paper)\n    ],\n)\n\n# Train\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    max_seq_length=2048,\n)\ntrainer.train()\n```\n\n## DPO Alignment\n\n```python\nfrom trl import DPOTrainer, DPOConfig\n\nconfig = DPOConfig(\n    learning_rate=5e-6,  # Lower for alignment\n    beta=0.1,            # KL penalty coefficient\n    per_device_train_batch_size=4,\n    num_train_epochs=1,\n)\n\n# Preference dataset: {prompt, chosen, rejected}\ntrainer = DPOTrainer(\n    model=model,\n    ref_model=ref_model,  # Frozen reference\n    args=config,\n    train_dataset=preference_dataset,\n    tokenizer=tokenizer,\n)\ntrainer.train()\n```\n\n## Synthetic Data Generation\n\n```python\nasync def generate_synthetic(topic: str, n: int = 100) -> list[dict]:\n    \"\"\"Generate training examples using teacher model.\"\"\"\n    examples = []\n    for _ in range(n):\n        response = await client.chat.completions.create(\n            model=\"gpt-5.2\",  # Teacher\n            messages=[{\n                \"role\": \"system\",\n                \"content\": f\"Generate a training example about {topic}. \"\n                          \"Include instruction and response.\"\n            }],\n        ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator"
    ]
  },
  "fix-issue": {
    "name": "fix-issue",
    "description": "Fixes GitHub issues with parallel analysis. Use when fixing bugs or resolving issues.",
    "version": "2.1.0",
    "author": "OrchestKit",
    "tags": [
      "issue",
      "bug-fix",
      "github",
      "debugging",
      "rca",
      "prevention"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Read",
      "Write",
      "Edit",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "Grep",
      "Glob",
      "mcp__memory__search_nodes",
      "mcp__context7__get_library_docs"
    ],
    "skills": [
      "commit",
      "explore",
      "verify",
      "debug-investigator",
      "memory",
      "remember"
    ],
    "agent": null,
    "structure": {
      "references": [
        "hypothesis-rca.md",
        "prevention-patterns.md",
        "similar-issue-search.md"
      ],
      "assets": [
        "commit-template.md",
        "rca-report-template.md",
        "runbook-entry-template.md"
      ],
      "scripts": [
        "similar-issue-finder.sh"
      ],
      "checklists": [
        "fix-complete-checklist.md"
      ]
    },
    "content": "# Fix Issue\n\nSystematic issue resolution with hypothesis-based root cause analysis, similar issue detection, and prevention recommendations.\n\n## Quick Start\n\n```bash\n/fix-issue 123\n/fix-issue 456\n```\n\n> **Opus 4.6**: Root cause analysis uses native adaptive thinking. Dynamic token budgets scale with context window for thorough investigation.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify fix approach:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What approach for this fix?\",\n    \"header\": \"Approach\",\n    \"options\": [\n      {\"label\": \"Proper fix (Recommended)\", \"description\": \"Full RCA, tests, prevention recommendations\"},\n      {\"label\": \"Quick fix\", \"description\": \"Minimal fix to resolve the immediate issue\"},\n      {\"label\": \"Investigate first\", \"description\": \"Understand the issue before deciding on approach\"},\n      {\"label\": \"Hotfix\", \"description\": \"Emergency patch, minimal testing\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Proper fix**: All 11 phases, parallel agents for RCA\n- **Quick fix**: Skip phases 8-10 (prevention, runbook, lessons)\n- **Investigate first**: Only phases 1-4 (understand, search, hypotheses, analyze)\n- **Hotfix**: Minimal phases, skip similar issue search\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — RCA agents share hypotheses) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Complex cross-cutting bugs (backend + frontend + tests involved) → recommend **Agent Teams**; Focused bugs (single domain) → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Hypothesis sharing | Lead relays between agents | Investigators share hypotheses in real-time |\n| Conflicting evidence | Lead resolves | Investigators debate directly |\n| Cost | ~250K tokens | ~600K tokens |\n| Best for | Single-domain bugs | Cross-cutting bugs with multiple hypotheses |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining investigation.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main fix task\nTaskCreate(\n  subject=\"Fix issue #{number}\",\n  description=\"Systematic issue resolution with hypothesis-based RCA\",\n  activeForm=\"Fixing issue #{number}\"\n)\n\n# Create subtasks for 11-phase process\nphases = [\"Understand issue\", \"Search similar issues\", \"Form hypotheses\",\n          \"Analyze root cause\", \"Design fix\", \"Implement fix\", \"Validate fix\",\n          \"Generate prevention\", \"Create runbook\", \"Capture lessons\", \"Commit and PR\"]\nfor phase in phases:\n    TaskCreate(subject=phase, activeForm=f\"{phase}ing\")\n```\n\n---\n\n## Workflow Overview\n\n| Phase | Activities | Output |\n|-------|------------|--------|\n| **1. Understand Issue** | Read GitHub issue details | Problem statement |\n| **2. Similar Issue Detection** | Search for relate",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "focus-management": {
    "name": "focus-management",
    "description": "Keyboard focus management patterns for accessibility. Covers focus traps, roving tabindex, focus restore, skip links, and FocusScope components for WCAG-compliant interactive widgets. Use when implementing focus traps or keyboard navigation.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "accessibility",
      "focus",
      "keyboard",
      "a11y",
      "trap"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "accessibility-specialist",
    "structure": {
      "references": [
        "focus-patterns.md"
      ],
      "scripts": [
        "focus-trap-template.tsx"
      ],
      "checklists": [
        "focus-checklist.md"
      ]
    },
    "content": "# Focus Management\n\nEssential patterns for managing keyboard focus in accessible web applications, ensuring keyboard-only users can navigate complex interactive components.\n\n## Overview\n\n- Building modals, dialogs, or drawers that require focus trapping\n- Implementing tab panels, menus, or toolbars with roving tabindex\n- Restoring focus after closing overlays or completing actions\n- Creating skip links for keyboard navigation\n- Ensuring focus visibility meets WCAG 2.4.7 requirements\n\n## Quick Reference\n\n### FocusScope Trap (React Aria)\n\n```tsx\nimport { FocusTrap } from '@react-aria/focus';\n\nfunction Modal({ isOpen, onClose, children }) {\n  if (!isOpen) return null;\n  return (\n    <div role=\"dialog\" aria-modal=\"true\">\n      <FocusTrap>\n        <div className=\"modal-content\">\n          {children}\n          <button onClick={onClose}>Close</button>\n        </div>\n      </FocusTrap>\n    </div>\n  );\n}\n```\n\n### Roving Tabindex\n\n```tsx\nfunction TabList({ tabs, onSelect }) {\n  const [activeIndex, setActiveIndex] = useState(0);\n  const tabRefs = useRef<HTMLButtonElement[]>([]);\n\n  const handleKeyDown = (e: KeyboardEvent, index: number) => {\n    const keyMap: Record<string, number> = {\n      ArrowRight: (index + 1) % tabs.length,\n      ArrowLeft: (index - 1 + tabs.length) % tabs.length,\n      Home: 0, End: tabs.length - 1,\n    };\n    if (e.key in keyMap) {\n      e.preventDefault();\n      setActiveIndex(keyMap[e.key]);\n      tabRefs.current[keyMap[e.key]]?.focus();\n    }\n  };\n\n  return (\n    <div role=\"tablist\">\n      {tabs.map((tab, i) => (\n        <button key={tab.id} ref={(el) => (tabRefs.current[i] = el!)}\n          role=\"tab\" tabIndex={i === activeIndex ? 0 : -1}\n          aria-selected={i === activeIndex}\n          onKeyDown={(e) => handleKeyDown(e, i)}\n          onClick={() => { setActiveIndex(i); onSelect(tab); }}>\n          {tab.label}\n        </button>\n      ))}\n    </div>\n  );\n}\n```\n\n### Focus Restore\n\n```tsx\nfunction useRestoreFocus(isOpen: boolean) {\n  const triggerRef = useRef<HTMLElement | null>(null);\n\n  useEffect(() => {\n    if (isOpen) {\n      triggerRef.current = document.activeElement as HTMLElement;\n    } else if (triggerRef.current) {\n      triggerRef.current.focus();\n      triggerRef.current = null;\n    }\n  }, [isOpen]);\n}\n```\n\n## Key Decisions\n\n| Decision | Option A | Option B | Recommendation |\n|----------|----------|----------|----------------|\n| Trap vs Contain | `FocusTrap` (strict) | `FocusScope` (soft) | Trap for modals, Scope for popovers |\n| Restore strategy | Trigger element | Last focused | Always restore to trigger |\n| Skip links | Single main skip | Multiple landmarks | Multiple for complex layouts |\n| Initial focus | First focusable | Auto-focus input | Context-dependent, prefer inputs |\n| Focus visible | Browser default | Custom outline | Custom `:focus-visible` for consistency |\n\n## Anti-Patterns (FORBIDDEN)\n\n```tsx\n// NEVER use positive tabindex - breaks natural tab order\n<button tabIndex={5}>Bad</button>\n\n// NEVER rem",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer"
    ]
  },
  "form-state-patterns": {
    "name": "form-state-patterns",
    "description": "React Hook Form v7 with Zod validation, React 19 useActionState, Server Actions, field arrays, and async validation. Use when building complex forms, validation flows, or server action forms.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "react-hook-form",
      "zod",
      "forms",
      "validation",
      "server-actions",
      "field-arrays",
      "useActionState"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "validation-patterns.md"
      ],
      "scripts": [
        "create-form.md",
        "form-template.tsx"
      ],
      "checklists": [
        "form-checklist.md"
      ]
    },
    "content": "# Form State Patterns\n\nProduction form patterns with React Hook Form v7 + Zod - type-safe, performant, accessible.\n\n## Overview\n\n- Complex forms with validation\n- Multi-step wizards\n- Dynamic field arrays\n- Server-side validation\n- Async field validation\n- Forms with file uploads\n\n## Core Patterns\n\n### 1. Basic Form with Zod Schema\n\n```typescript\nimport { useForm } from 'react-hook-form';\nimport { zodResolver } from '@hookform/resolvers/zod';\nimport { z } from 'zod';\n\nconst userSchema = z.object({\n  email: z.string().email('Invalid email'),\n  password: z.string().min(8, 'Min 8 characters'),\n  confirmPassword: z.string(),\n}).refine((data) => data.password === data.confirmPassword, {\n  message: \"Passwords don't match\",\n  path: ['confirmPassword'],\n});\n\ntype UserForm = z.infer<typeof userSchema>;\n\nfunction SignupForm() {\n  const {\n    register,\n    handleSubmit,\n    formState: { errors, isSubmitting },\n  } = useForm<UserForm>({\n    resolver: zodResolver(userSchema),\n    defaultValues: { email: '', password: '', confirmPassword: '' },\n  });\n\n  const onSubmit = async (data: UserForm) => {\n    await api.signup(data);\n  };\n\n  return (\n    <form onSubmit={handleSubmit(onSubmit)}>\n      <input {...register('email')} aria-invalid={!!errors.email} />\n      {errors.email && <span role=\"alert\">{errors.email.message}</span>}\n\n      <input type=\"password\" {...register('password')} />\n      {errors.password && <span role=\"alert\">{errors.password.message}</span>}\n\n      <input type=\"password\" {...register('confirmPassword')} />\n      {errors.confirmPassword && <span role=\"alert\">{errors.confirmPassword.message}</span>}\n\n      <button type=\"submit\" disabled={isSubmitting}>\n        {isSubmitting ? 'Submitting...' : 'Sign Up'}\n      </button>\n    </form>\n  );\n}\n```\n\n### 2. Field Arrays (Dynamic Fields)\n\n```typescript\nimport { useFieldArray, useForm } from 'react-hook-form';\n\nconst orderSchema = z.object({\n  items: z.array(z.object({\n    productId: z.string().min(1),\n    quantity: z.number().min(1).max(100),\n  })).min(1, 'At least one item required'),\n});\n\nfunction OrderForm() {\n  const { control, register, handleSubmit } = useForm({\n    resolver: zodResolver(orderSchema),\n    defaultValues: { items: [{ productId: '', quantity: 1 }] },\n  });\n\n  const { fields, append, remove } = useFieldArray({\n    control,\n    name: 'items',\n  });\n\n  return (\n    <form onSubmit={handleSubmit(onSubmit)}>\n      {fields.map((field, index) => (\n        <div key={field.id}>\n          <input {...register(`items.${index}.productId`)} />\n          <input\n            type=\"number\"\n            {...register(`items.${index}.quantity`, { valueAsNumber: true })}\n          />\n          <button type=\"button\" onClick={() => remove(index)}>Remove</button>\n        </div>\n      ))}\n      <button type=\"button\" onClick={() => append({ productId: '', quantity: 1 })}>\n        Add Item\n      </button>\n      <button type=\"submit\">Submit Order</button>\n    </form>\n  );\n}\n```\n\n### 3. Async Field Validation\n\n``",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "function-calling": {
    "name": "function-calling",
    "description": "LLM function calling and tool use patterns. Use when enabling LLMs to call external tools, defining tool schemas, implementing tool execution loops, or getting structured output from LLMs.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "llm",
      "tools",
      "function-calling",
      "structured-output"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "tool-schema.md"
      ],
      "scripts": [
        "function-def.py"
      ],
      "checklists": [
        "tool-checklist.md"
      ]
    },
    "content": "# Function Calling\n\nEnable LLMs to use external tools and return structured data.\n\n## Basic Tool Definition (2026 Best Practice)\n\n```python\n# OpenAI format with strict mode (2026 recommended)\ntools = [{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"search_documents\",\n        \"description\": \"Search the document database for relevant content\",\n        \"strict\": True,  # ← 2026: Enables structured output validation\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The search query\"\n                },\n                \"limit\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Max results to return\"\n                }\n            },\n            \"required\": [\"query\", \"limit\"],  # All props required when strict\n            \"additionalProperties\": False     # ← 2026: Required for strict mode\n        }\n    }\n}]\n\n# Note: With strict=True:\n# - All properties must be listed in \"required\"\n# - additionalProperties must be False\n# - No \"default\" values (provide via code instead)\n```\n\n## Tool Execution Loop\n\n```python\nasync def run_with_tools(messages: list, tools: list) -> str:\n    \"\"\"Execute tool calls until LLM returns final answer.\"\"\"\n    while True:\n        response = await llm.chat(messages=messages, tools=tools)\n\n        # Check if LLM wants to call tools\n        if not response.tool_calls:\n            return response.content\n\n        # Execute each tool call\n        for tool_call in response.tool_calls:\n            result = await execute_tool(\n                tool_call.function.name,\n                json.loads(tool_call.function.arguments)\n            )\n\n            # Add tool result to conversation\n            messages.append({\n                \"role\": \"tool\",\n                \"tool_call_id\": tool_call.id,\n                \"content\": json.dumps(result)\n            })\n\n        # Continue loop (LLM will process tool results)\n\nasync def execute_tool(name: str, args: dict) -> any:\n    \"\"\"Route to appropriate tool implementation.\"\"\"\n    tools = {\n        \"search_documents\": search_documents,\n        \"get_weather\": get_weather,\n        \"calculate\": calculate,\n    }\n    return await tools[name](**args)\n```\n\n## Structured Output (Guaranteed JSON)\n\n```python\nfrom pydantic import BaseModel\n\nclass Analysis(BaseModel):\n    sentiment: str\n    confidence: float\n    key_points: list[str]\n\n# OpenAI structured output\nresponse = await client.beta.chat.completions.parse(\n    model=\"gpt-5.2\",\n    messages=[{\"role\": \"user\", \"content\": \"Analyze this text...\"}],\n    response_format=Analysis\n)\n\nanalysis = response.choices[0].message.parsed  # Typed Analysis object\n```\n\n## LangChain Tool Binding\n\n```python\nfrom langchain_core.tools import tool\nfrom pydantic import BaseModel, Field\n\n@tool\ndef search_documents(query: str, limit: int = 5) -> list[dict]:\n    \"\"\"Search the document database.\n\n    Args:\n        query: ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator",
      "prompt-engineer"
    ]
  },
  "git-recovery": {
    "name": "git-recovery",
    "description": "Recovery from git mistakes. Use when you need to undo commits, recover branches, or fix history.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "recovery",
      "undo",
      "reflog",
      "reset"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Bash"
    ],
    "skills": [],
    "agent": null,
    "structure": {},
    "content": "# Git Recovery\n\nInteractive recovery from common git mistakes. Safe operations with verification steps.\n\n## Quick Start\n\n```bash\n/git-recovery\n```\n\n## Recovery Scenarios\n\nWhen invoked, present these options to the user:\n\n### Option 1: Undo Last Commit (Keep Changes)\n\n**Scenario**: You committed but want to modify the changes before recommitting.\n\n```bash\n# Check current state first\ngit log --oneline -3\ngit status\n\n# Undo commit, keep changes staged\ngit reset --soft HEAD~1\n\n# Verify\ngit status  # Changes should be staged\ngit log --oneline -1  # Previous commit is now HEAD\n```\n\n**Safety**: Non-destructive. All changes remain staged.\n\n---\n\n### Option 2: Undo Last Commit (Discard Changes)\n\n**Scenario**: You committed something completely wrong and want to throw it away.\n\n**WARNING: DESTRUCTIVE - Changes will be lost!**\n\n```bash\n# CRITICAL: First, save a backup reference\nBACKUP_REF=$(git rev-parse HEAD)\necho \"Backup ref: $BACKUP_REF (save this to recover if needed)\"\n\n# Show what will be lost\ngit show HEAD --stat\n\n# Confirm with user before proceeding\n# Then execute:\ngit reset --hard HEAD~1\n\n# Verify\ngit log --oneline -3\ngit status  # Should be clean\n```\n\n**Recovery**: If you made a mistake, run `git reset --hard $BACKUP_REF`\n\n---\n\n### Option 3: Recover Deleted Branch\n\n**Scenario**: You deleted a branch and need it back.\n\n```bash\n# Find the branch's last commit in reflog\ngit reflog | grep -i \"branch-name\"\n# Or search all recent activity:\ngit reflog --all | head -30\n\n# Once you find the commit hash (e.g., abc1234):\ngit checkout -b recovered-branch abc1234\n\n# Verify\ngit log --oneline -5\ngit branch -v | grep recovered\n```\n\n**Note**: Reflog keeps entries for ~90 days by default.\n\n---\n\n### Option 4: Reset File to Last Commit\n\n**Scenario**: You modified a file and want to discard local changes.\n\n**WARNING: DESTRUCTIVE - Uncommitted changes to file will be lost!**\n\n```bash\n# Show current changes to file\ngit diff path/to/file\n\n# Confirm with user before proceeding\n# Then restore:\ngit checkout HEAD -- path/to/file\n\n# Or using newer git restore (Git 2.23+):\ngit restore path/to/file\n\n# Verify\ngit status path/to/file  # Should show no changes\ngit diff path/to/file    # Should be empty\n```\n\n---\n\n### Option 5: Undo a Rebase\n\n**Scenario**: A rebase went wrong and you want to return to pre-rebase state.\n\n```bash\n# Find the pre-rebase state\ngit reflog | head -20\n# Look for entry like: \"rebase (start): checkout main\"\n# The entry BEFORE that is your pre-rebase state\n\n# Alternative: ORIG_HEAD is set automatically before rebase\ngit log --oneline ORIG_HEAD -3\n\n# Reset to pre-rebase state\ngit reset --hard ORIG_HEAD\n\n# Verify\ngit log --oneline -5\ngit status\n```\n\n**Safety**: ORIG_HEAD is overwritten by other operations, use reflog if ORIG_HEAD is stale.\n\n---\n\n### Option 6: Undo a Merge\n\n**Scenario**: You merged a branch and want to undo it.\n\n```bash\n# If merge commit exists and NOT pushed:\ngit log --oneline -5  # Find the merge commit\n\n# Reset to before merge\ngit reset --hard ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "git-operations-engineer"
    ]
  },
  "git-workflow": {
    "name": "git-workflow",
    "description": "Complete git workflow patterns including GitHub Flow branching, atomic commits with interactive staging, and recovery operations using reflog. Essential patterns for clean history. Use when defining branching strategy or recovering git history.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "branch",
      "commit",
      "recovery",
      "workflow",
      "reflog",
      "staging"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "github-flow.md",
        "interactive-staging.md",
        "recovery-decision-tree.md",
        "reflog-recovery.md"
      ],
      "checklists": [
        "branch-checklist.md",
        "pre-commit-checklist.md"
      ]
    },
    "content": "# Git Workflow\n\nComplete git workflow patterns: GitHub Flow branching, atomic commits, and recovery operations. Essential for maintaining clean, reviewable history.\n\n## Branch Naming Convention\n\n```bash\n# Feature branches (link to issue)\nissue/<number>-<brief-description>\nissue/123-add-user-auth\n\n# When no issue exists\nfeature/<description>\nfix/<description>\nhotfix/<description>\n```\n\n**Branch Rules:**\n1. `main` is always deployable\n2. Branch from `main`, PR back to `main`\n3. Branches live < 1-3 days\n4. Delete branch after merge\n\n---\n\n## Atomic Commit Checklist\n\n```\n[ ] Does ONE logical thing\n[ ] Leaves codebase working (tests pass)\n[ ] Message doesn't need \"and\" in title\n[ ] Can be reverted independently\n[ ] Title < 50 chars, body wraps at 72\n```\n\n### Interactive Staging\n\n```bash\n# Stage changes hunk-by-hunk\ngit add -p\n\n# Options:\n# y - stage this hunk\n# n - skip this hunk\n# s - split into smaller hunks\n# e - manually edit the hunk\n# q - quit\n\n# Review what's staged\ngit diff --staged    # What will be committed\ngit diff             # What won't be committed\n```\n\n### Commit Patterns\n\n```bash\n# Separate concerns\ngit add -p && git commit -m \"refactor: Extract database pool\"\ngit add -p && git commit -m \"feat(#456): Add query caching\"\n\n# Never combine unrelated changes\n# BAD:  \"feat: Add auth and fix formatting\"\n# GOOD: Two separate commits\n```\n\n---\n\n## Recovery Quick Reference\n\n### The Safety Net\n\n```bash\n# ALWAYS check reflog first - it has everything\ngit reflog\n\n# Shows ALL recent HEAD movements\n# Even \"deleted\" commits live here for 90 days\n```\n\n### Common Recovery Scenarios\n\n| Scenario | Not Pushed | Already Pushed |\n|----------|------------|----------------|\n| Undo commit | `git reset --soft HEAD~1` | `git revert HEAD` |\n| Wrong branch | cherry-pick + reset | cherry-pick + revert |\n| Lost commits | `git reset --hard HEAD@{N}` | N/A |\n| Bad rebase | `git rebase --abort` or reflog | reflog + force-with-lease |\n\n### Quick Recovery Commands\n\n```bash\n# Undo last commit, keep changes staged\ngit reset --soft HEAD~1\n\n# Find lost commits\ngit reflog | grep \"your message\"\n\n# Recover to previous state\ngit reset --hard HEAD@{1}\n\n# Safe force push (feature branches only)\ngit push --force-with-lease\n```\n\n---\n\n## Standard Workflow\n\n```bash\n# 1. Start fresh\ngit checkout main && git pull origin main\ngit checkout -b issue/123-my-feature\n\n# 2. Work with atomic commits\ngit add -p\ngit commit -m \"feat(#123): Add User model\"\n\n# 3. Stay updated\ngit fetch origin && git rebase origin/main\n\n# 4. Push and PR\ngit push -u origin issue/123-my-feature\ngh pr create --fill\n\n# 5. Cleanup after merge\ngit checkout main && git pull\ngit branch -d issue/123-my-feature\n```\n\n---\n\n## Anti-Patterns\n\n```\nAvoid:\n- Long-lived branches (> 1 week)\n- Merging main into feature (use rebase)\n- Direct commits to main\n- Force push to shared branches\n- Commits that need \"and\" in message\n- Committing broken code\n```\n\n---\n\n## Best Practices Summary\n\n1. **Branch from main** - Always start fresh\n2. **Stag",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "documentation-specialist",
      "git-operations-engineer"
    ]
  },
  "github-operations": {
    "name": "github-operations",
    "description": "GitHub CLI operations for issues, PRs, milestones, and Projects v2. Covers gh commands, REST API patterns, and automation scripts. Use when managing GitHub issues, PRs, milestones, or Projects with gh.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "github",
      "gh",
      "cli",
      "issues",
      "pr",
      "milestones",
      "projects",
      "api"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "graphql-api.md",
        "issue-management.md",
        "milestone-api.md",
        "pr-workflows.md",
        "projects-v2.md"
      ]
    },
    "content": "# GitHub Operations\n\nComprehensive GitHub CLI (`gh`) operations for project management, from basic issue creation to advanced Projects v2 integration and milestone tracking via REST API.\n\n## Overview\n\n- Creating and managing GitHub issues and PRs\n- Working with GitHub Projects v2 custom fields\n- Managing milestones (sprints, releases) via REST API\n- Automating bulk operations with `gh`\n- Running GraphQL queries for complex operations\n\n---\n\n## Quick Reference\n\n### Issue Operations\n\n```bash\n# Create issue with labels and milestone\ngh issue create --title \"Bug: API returns 500\" --body \"...\" --label \"bug\" --milestone \"Sprint 5\"\n\n# List and filter issues\ngh issue list --state open --label \"backend\" --assignee @me\n\n# Edit issue metadata\ngh issue edit 123 --add-label \"high\" --milestone \"v2.0\"\n```\n\n### PR Operations\n\n```bash\n# Create PR with reviewers\ngh pr create --title \"feat: Add search\" --body \"...\" --base dev --reviewer @teammate\n\n# Watch CI status and auto-merge\ngh pr checks 456 --watch\ngh pr merge 456 --auto --squash --delete-branch\n\n# Resume a session linked to a PR (CC 2.1.27)\nclaude --from-pr 456           # Resume session with PR context (diff, comments, review status)\nclaude --from-pr https://github.com/org/repo/pull/456\n```\n\n> **Tip (CC 2.1.27):** Sessions created via `gh pr create` are automatically linked to the PR. Use `--from-pr` to resume with full PR context.\n\n### Milestone Operations (REST API)\n\n```bash\n# List milestones with progress\ngh api repos/:owner/:repo/milestones --jq '.[] | \"\\(.title): \\(.closed_issues)/\\(.open_issues + .closed_issues)\"'\n\n# Create milestone with due date\ngh api -X POST repos/:owner/:repo/milestones \\\n  -f title=\"Sprint 8\" -f due_on=\"2026-02-15T00:00:00Z\"\n\n# Close milestone\ngh api -X PATCH repos/:owner/:repo/milestones/5 -f state=closed\n```\n\n### Projects v2 Operations\n\n```bash\n# Add issue to project\ngh project item-add 1 --owner @me --url https://github.com/org/repo/issues/123\n\n# Set custom field (requires GraphQL)\ngh api graphql -f query='mutation {...}' -f projectId=\"...\" -f itemId=\"...\"\n```\n\n---\n\n## JSON Output Patterns\n\n```bash\n# Get issue numbers matching criteria\ngh issue list --json number,labels --jq '[.[] | select(.labels[].name == \"bug\")] | .[].number'\n\n# PR summary with author\ngh pr list --json number,title,author --jq '.[] | \"\\(.number): \\(.title) by \\(.author.login)\"'\n\n# Find ready-to-merge PRs\ngh pr list --json number,reviewDecision,statusCheckRollupState \\\n  --jq '[.[] | select(.reviewDecision == \"APPROVED\" and .statusCheckRollupState == \"SUCCESS\")]'\n```\n\n---\n\n## Key Concepts\n\n### Milestone vs Epic\n\n| Milestones | Epics |\n|------------|-------|\n| Time-based (sprints, releases) | Topic-based (features) |\n| Has due date | No due date |\n| Progress bar | Task list checkbox |\n| Native REST API | Needs workarounds |\n\n**Rule**: Use milestones for \"when\", use parent issues for \"what\".\n\n### Projects v2 Custom Fields\n\nProjects v2 uses GraphQL for setting custom fields (Status, Priority, Domain). Basic `gh",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "business-case-builder",
      "ci-cd-engineer",
      "deployment-manager",
      "git-operations-engineer",
      "market-intelligence",
      "prioritization-analyst",
      "product-strategist",
      "release-engineer",
      "requirements-translator"
    ]
  },
  "golden-dataset-curation": {
    "name": "golden-dataset-curation",
    "description": "Use when creating or improving golden datasets for AI evaluation. Defines quality criteria, curation workflows, and multi-agent analysis patterns for test data.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "golden-dataset",
      "curation",
      "quality",
      "multi-agent",
      "langfuse",
      "2025"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "annotation-patterns.md",
        "selection-criteria.md"
      ]
    },
    "content": "# Golden Dataset Curation\n\n**Curate high-quality documents for the golden dataset with multi-agent validation**\n\n## Overview\n\nThis skill provides patterns and workflows for **adding new documents** to the golden dataset with thorough quality analysis. It complements `golden-dataset-management` which handles backup/restore.\n\n**When to use this skill:**\n- Adding new documents to the golden dataset\n- Classifying content types and difficulty levels\n- Generating test queries for new documents\n- Running multi-agent quality analysis\n\n---\n\n## Content Types\n\n| Type | Description | Quality Focus |\n|------|-------------|---------------|\n| `article` | Technical articles, blog posts | Depth, accuracy, actionability |\n| `tutorial` | Step-by-step guides | Completeness, clarity, code quality |\n| `research_paper` | Academic papers, whitepapers | Rigor, citations, methodology |\n| `documentation` | API docs, reference materials | Accuracy, completeness, examples |\n| `video_transcript` | Transcribed video content | Structure, coherence, key points |\n| `code_repository` | README, code analysis | Code quality, documentation |\n\n---\n\n## Difficulty Levels\n\n| Level | Semantic Complexity | Expected Score | Characteristics |\n|-------|---------------------|----------------|-----------------|\n| **trivial** | Direct keyword match | >0.85 | Technical terms, exact phrases |\n| **easy** | Common synonyms | >0.70 | Well-known concepts, slight variations |\n| **medium** | Paraphrased intent | >0.55 | Conceptual queries, multi-topic |\n| **hard** | Multi-hop reasoning | >0.40 | Cross-domain, comparative analysis |\n| **adversarial** | Edge cases | Graceful degradation | Robustness tests, off-domain |\n\n---\n\n## Quality Dimensions\n\n| Dimension | Weight | Perfect | Acceptable | Failing |\n|-----------|--------|---------|------------|---------|\n| **Accuracy** | 0.25 | 0.95-1.0 | 0.70-0.94 | <0.70 |\n| **Coherence** | 0.20 | 0.90-1.0 | 0.60-0.89 | <0.60 |\n| **Depth** | 0.25 | 0.90-1.0 | 0.55-0.89 | <0.55 |\n| **Relevance** | 0.30 | 0.95-1.0 | 0.70-0.94 | <0.70 |\n\n**Evaluation focuses:**\n- **Accuracy:** Technical correctness, code validity, up-to-date info\n- **Coherence:** Logical structure, clear flow, consistent terminology\n- **Depth:** Comprehensive coverage, edge cases, appropriate detail\n- **Relevance:** Alignment with AI/ML, backend, frontend, DevOps domains\n\n---\n\n## Multi-Agent Pipeline\n\n```\nINPUT: URL/Content\n        |\n        v\n+------------------+\n|   FETCH AGENT    |  Extract structure, detect type\n+--------+---------+\n         |\n         v\n+-----------------------------------------------+\n|  PARALLEL ANALYSIS AGENTS                      |\n|  Quality | Difficulty | Domain  | Query Gen   |\n+-----------------------------------------------+\n         |\n         v\n+------------------+\n| CONSENSUS        |  Weighted score + confidence\n| AGGREGATOR       |  -> include/review/exclude\n+--------+---------+\n         |\n         v\n+------------------+\n|  USER APPROVAL   |  Show scores, confirm\n+---",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "golden-dataset-management": {
    "name": "golden-dataset-management",
    "description": "Use when backing up, restoring, or validating golden datasets. Prevents data loss and ensures test data integrity for AI/ML evaluation systems.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "golden-dataset",
      "backup",
      "data-protection",
      "testing",
      "regression"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash  # For backup/restore scripts"
    ],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "backup-restore.md",
        "storage-patterns.md",
        "validation-contracts.md",
        "versioning.md"
      ],
      "scripts": [
        "backup-golden-dataset.md",
        "backup-script.py"
      ],
      "checklists": [
        "backup-restore-checklist.md"
      ]
    },
    "content": "# Golden Dataset Management\n\n**Protect and maintain high-quality test datasets for AI/ML systems**\n\n## Overview\n\nA **golden dataset** is a curated collection of high-quality examples used for:\n- **Regression testing:** Ensure new code doesn't break existing functionality\n- **Retrieval evaluation:** Measure search quality (precision, recall, MRR)\n- **Model benchmarking:** Compare different models/approaches\n- **Reproducibility:** Consistent results across environments\n\n**When to use this skill:**\n- Building test datasets for RAG systems\n- Implementing backup/restore for critical data\n- Validating data integrity (URL contracts, embeddings)\n- Migrating data between environments\n\n---\n\n## OrchestKit's Golden Dataset\n\n**Stats (Production):**\n- **98 analyses** (completed content analyses)\n- **415 chunks** (embedded text segments)\n- **203 test queries** (with expected results)\n- **91.6% pass rate** (retrieval quality metric)\n\n**Purpose:**\n- Test hybrid search (vector + BM25 + RRF)\n- Validate metadata boosting strategies\n- Detect regressions in retrieval quality\n- Benchmark new embedding models\n\n---\n\n## Core Concepts\n\n### Data Integrity Contracts\n\n**The URL Contract:**\nGolden dataset analyses MUST store **real canonical URLs**, not placeholders.\n\n```python\n# WRONG - Placeholder URL (breaks restore)\nanalysis.url = \"https://orchestkit.dev/placeholder/123\"\n\n# CORRECT - Real canonical URL (enables re-fetch if needed)\nanalysis.url = \"https://docs.python.org/3/library/asyncio.html\"\n```\n\n**Why this matters:**\n- Enables re-fetching content if embeddings need regeneration\n- Allows validation that source content hasn't changed\n- Provides audit trail for data provenance\n\n---\n\n## Backup Strategy Comparison\n\n| Strategy | Version Control | Restore Speed | Portability | Inspection |\n|----------|-----------------|---------------|-------------|------------|\n| **JSON** (recommended) | Yes | Slower (regen embeddings) | High | Easy |\n| **SQL Dump** | No (binary) | Fast | DB-version dependent | Hard |\n\n**OrchestKit uses JSON backup** for version control and portability.\n\n---\n\n## Quick Reference\n\n### Backup Format\n\n```json\n{\n  \"version\": \"1.0\",\n  \"created_at\": \"2025-12-19T10:30:00Z\",\n  \"metadata\": {\n    \"total_analyses\": 98,\n    \"total_chunks\": 415,\n    \"total_artifacts\": 98\n  },\n  \"analyses\": [\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"url\": \"https://docs.python.org/3/library/asyncio.html\",\n      \"content_type\": \"documentation\",\n      \"status\": \"completed\",\n      \"created_at\": \"2025-11-15T08:20:00Z\",\n      \"chunks\": [\n        {\n          \"id\": \"7c9e6679-7425-40de-944b-e07fc1f90ae7\",\n          \"content\": \"asyncio is a library...\",\n          \"section_title\": \"Introduction to asyncio\"\n          // embedding NOT included (regenerated on restore)\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Key Design Decisions:**\n- Embeddings excluded (regenerate on restore with current model)\n- Nested structure (analyses -> chunks -> artifacts)\n- Metadata for validation\n- ISO time",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "data-pipeline-engineer"
    ]
  },
  "golden-dataset-validation": {
    "name": "golden-dataset-validation",
    "description": "Use when validating golden dataset quality. Runs schema checks, duplicate detection, and coverage analysis to ensure dataset integrity for AI evaluation.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "golden-dataset",
      "validation",
      "integrity",
      "schema",
      "duplicate-detection",
      "2025"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "quality-metrics.md",
        "validation-rules.md"
      ]
    },
    "content": "# Golden Dataset Validation\n\n**Ensure data integrity, prevent duplicates, and maintain quality standards**\n\n## Overview\n\nThis skill provides comprehensive validation patterns for the golden dataset, ensuring every entry meets quality standards before inclusion.\n\n**When to use this skill:**\n- Validating new documents before adding\n- Running integrity checks on existing dataset\n- Detecting duplicate or similar content\n- Analyzing coverage gaps\n- Pre-commit validation hooks\n\n---\n\n## Schema Validation\n\n### Document Schema (v2.0)\n\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"title\", \"source_url\", \"content_type\", \"sections\"],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z0-9-]+$\",\n      \"description\": \"Unique kebab-case identifier\"\n    },\n    \"title\": {\n      \"type\": \"string\",\n      \"minLength\": 10,\n      \"maxLength\": 200\n    },\n    \"source_url\": {\n      \"type\": \"string\",\n      \"format\": \"uri\",\n      \"description\": \"Canonical source URL (NOT placeholder)\"\n    },\n    \"content_type\": {\n      \"type\": \"string\",\n      \"enum\": [\"article\", \"tutorial\", \"research_paper\", \"documentation\", \"video_transcript\", \"code_repository\"]\n    },\n    \"bucket\": {\n      \"type\": \"string\",\n      \"enum\": [\"short\", \"long\"]\n    },\n    \"tags\": {\n      \"type\": \"array\",\n      \"items\": {\"type\": \"string\"},\n      \"minItems\": 2,\n      \"maxItems\": 10\n    },\n    \"sections\": {\n      \"type\": \"array\",\n      \"minItems\": 1,\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"id\", \"title\", \"content\"],\n        \"properties\": {\n          \"id\": {\"type\": \"string\", \"pattern\": \"^[a-z0-9-/]+$\"},\n          \"title\": {\"type\": \"string\"},\n          \"content\": {\"type\": \"string\", \"minLength\": 50},\n          \"granularity\": {\"enum\": [\"coarse\", \"fine\", \"summary\"]}\n        }\n      }\n    }\n  }\n}\n```\n\n### Query Schema\n\n```json\n{\n  \"type\": \"object\",\n  \"required\": [\"id\", \"query\", \"difficulty\", \"expected_chunks\", \"min_score\"],\n  \"properties\": {\n    \"id\": {\"type\": \"string\", \"pattern\": \"^q-[a-z0-9-]+$\"},\n    \"query\": {\"type\": \"string\", \"minLength\": 5, \"maxLength\": 500},\n    \"modes\": {\"type\": \"array\", \"items\": {\"enum\": [\"semantic\", \"keyword\", \"hybrid\"]}},\n    \"category\": {\"enum\": [\"specific\", \"broad\", \"negative\", \"edge\", \"coarse-to-fine\"]},\n    \"difficulty\": {\"enum\": [\"trivial\", \"easy\", \"medium\", \"hard\", \"adversarial\"]},\n    \"expected_chunks\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": 1},\n    \"min_score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1}\n  }\n}\n```\n\n---\n\n## Validation Rules Summary\n\n| Rule | Purpose | Severity |\n|------|---------|----------|\n| No Placeholder URLs | Ensure real canonical URLs | Error |\n| Unique Identifiers | No duplicate doc/query/section IDs | Error |\n| Referential Integrity | Query chunks reference valid sections | Error |\n| Content Quality | Title/content length, tag count | Warning |\n| Difficulty Distribution | Balanced query difficulty levels | Warning |\n\n---\n\n## Quic",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "grpc-python": {
    "name": "grpc-python",
    "description": "gRPC with Python using grpcio and protobuf for high-performance microservice communication. Use when implementing service-to-service APIs, streaming data, or building polyglot microservices requiring strong typing.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "grpc",
      "protobuf",
      "microservices",
      "rpc",
      "streaming",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "error-handling.md",
        "health-check-setup.md",
        "interceptor-patterns.md",
        "streaming-patterns.md"
      ],
      "scripts": [
        "grpc-client-template.py",
        "grpc-server-template.py",
        "proto-service-template.proto"
      ],
      "checklists": [
        "grpc-design-checklist.md",
        "production-checklist.md"
      ]
    },
    "content": "# gRPC Python Patterns\n\nHigh-performance RPC framework for microservice communication.\n\n## Overview\n\n- Internal microservice communication (lower latency than REST)\n- Streaming data (real-time updates, file transfers)\n- Polyglot environments (shared proto definitions)\n- Strong typing between services (compile-time validation)\n- Bidirectional streaming (chat, gaming, real-time sync)\n\n## When NOT to Use\n\n- Public APIs (prefer REST/GraphQL for browser compatibility)\n- Simple CRUD with few services (REST is simpler)\n- When HTTP/2 is not available\n\n## Proto Definition\n\n```protobuf\n// protos/user_service.proto\nsyntax = \"proto3\";\npackage user.v1;\n\nimport \"google/protobuf/timestamp.proto\";\nimport \"google/protobuf/empty.proto\";\n\nservice UserService {\n  rpc GetUser(GetUserRequest) returns (User);\n  rpc CreateUser(CreateUserRequest) returns (User);\n  rpc ListUsers(ListUsersRequest) returns (stream User);  // Server streaming\n  rpc BulkCreateUsers(stream CreateUserRequest) returns (BulkCreateResponse);  // Client streaming\n  rpc UserUpdates(stream UserUpdateRequest) returns (stream User);  // Bidirectional\n}\n\nmessage User {\n  string id = 1;\n  string email = 2;\n  string name = 3;\n  UserStatus status = 4;\n  google.protobuf.Timestamp created_at = 5;\n}\n\nenum UserStatus {\n  USER_STATUS_UNSPECIFIED = 0;\n  USER_STATUS_ACTIVE = 1;\n  USER_STATUS_INACTIVE = 2;\n}\n\nmessage GetUserRequest { string user_id = 1; }\nmessage CreateUserRequest { string email = 1; string name = 2; string password = 3; }\nmessage ListUsersRequest { int32 page_size = 1; string page_token = 2; }\nmessage BulkCreateResponse { int32 created_count = 1; repeated string user_ids = 2; }\n```\n\n### Code Generation\n\n```bash\npip install grpcio grpcio-tools\npython -m grpc_tools.protoc -I./protos --python_out=./app/protos --pyi_out=./app/protos --grpc_python_out=./app/protos ./protos/user_service.proto\n```\n\n## Server Implementation\n\n```python\nimport grpc\nfrom concurrent import futures\nfrom google.protobuf.timestamp_pb2 import Timestamp\nfrom app.protos import user_service_pb2 as pb2\nfrom app.protos import user_service_pb2_grpc as pb2_grpc\n\nclass UserServiceServicer(pb2_grpc.UserServiceServicer):\n    def __init__(self, user_repo):\n        self.user_repo = user_repo\n\n    def GetUser(self, request, context):\n        user = self.user_repo.get(request.user_id)\n        if not user:\n            context.abort(grpc.StatusCode.NOT_FOUND, f\"User {request.user_id} not found\")\n        return self._to_proto(user)\n\n    def CreateUser(self, request, context):\n        if not request.email or \"@\" not in request.email:\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Invalid email\")\n        if self.user_repo.get_by_email(request.email):\n            context.abort(grpc.StatusCode.ALREADY_EXISTS, \"Email already registered\")\n        user = self.user_repo.create(email=request.email, name=request.name)\n        return self._to_proto(user)\n\n    def ListUsers(self, request, context):\n        \"\"\"Server streaming: yield users one ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "help": {
    "name": "help",
    "description": "OrchestKit skill directory. Use when you want to see available skills or need help.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "help",
      "documentation",
      "skills",
      "discovery",
      "meta"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion"
    ],
    "skills": [],
    "agent": null,
    "structure": {},
    "content": "# OrchestKit Skill Directory\n\nInteractive guide to all user-invocable skills organized by category.\n\n## Quick Start\n\n```bash\n/ork:help           # Show all categories\n/ork:help build     # Show BUILD skills only\n/ork:help git       # Show GIT skills only\n```\n\n---\n\n## CRITICAL: Use AskUserQuestion for Category Selection\n\nWhen invoked without arguments, present categories interactively:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of task are you working on?\",\n    \"header\": \"Category\",\n    \"options\": [\n      {\"label\": \"BUILD\", \"description\": \"Implement features, brainstorm, verify\"},\n      {\"label\": \"GIT\", \"description\": \"Commits, PRs, issues, recovery\"},\n      {\"label\": \"MEMORY\", \"description\": \"Store decisions, search, sync context\"},\n      {\"label\": \"QUALITY\", \"description\": \"Assess code, health checks, golden datasets\"},\n      {\"label\": \"CONFIG\", \"description\": \"Configure OrchestKit, feedback, skill evolution\"},\n      {\"label\": \"EXPLORE\", \"description\": \"Explore codebase, coordinate worktrees\"},\n      {\"label\": \"MEDIA\", \"description\": \"Create demo videos\"},\n      {\"label\": \"Show all\", \"description\": \"List all 21 skills\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n---\n\n## Skill Categories\n\n### BUILD (3 skills)\n*Implement features and verify changes*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:implement` | Full-power feature implementation with parallel subagents | `/ork:implement user authentication` |\n| `/ork:brainstorming` | Design exploration with parallel agents | `/ork:brainstorming API design for payments` |\n| `/ork:verify` | Comprehensive verification with parallel test agents | `/ork:verify authentication flow` |\n\n---\n\n### GIT (5 skills)\n*Version control and GitHub operations*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:commit` | Creates commits with conventional format | `/ork:commit` |\n| `/ork:create-pr` | Create GitHub pull requests with validation | `/ork:create-pr` |\n| `/ork:review-pr` | PR review with parallel specialized agents | `/ork:review-pr 123` |\n| `/ork:fix-issue` | Fix GitHub issues with parallel analysis | `/ork:fix-issue 456` |\n| `/ork:git-recovery` | Recovery from git mistakes | `/ork:git-recovery` |\n\n---\n\n### MEMORY (2 skills)\n*Knowledge persistence and retrieval*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:remember` | Store decisions and patterns | `/ork:remember We use cursor pagination` |\n| `/ork:memory` | Search, load, sync, history, viz | `/ork:memory search pagination` |\n\n**Subcommands for `/ork:memory`:**\n- `search` - Search decisions and patterns\n- `load` - Load session context\n- `sync` - Sync to mem0 cloud\n- `history` - View decision timeline\n- `viz` - Visualize knowledge graph\n\n---\n\n### QUALITY (4 skills)\n*Assessment and diagnostics*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:assess` | Rate quality 0-10 with pros/cons | `/ork:assess src/api/` |\n| `/ork:",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "high-performance-inference": {
    "name": "high-performance-inference",
    "description": "High-performance LLM inference with vLLM, quantization (AWQ, GPTQ, FP8), speculative decoding, and edge deployment. Use when optimizing inference latency, throughput, or memory.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "vllm",
      "quantization",
      "inference",
      "performance",
      "edge",
      "speculative"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "edge-deployment.md",
        "quantization-guide.md",
        "speculative-decoding.md",
        "vllm-deployment.md"
      ],
      "scripts": [
        "quantization-config.py",
        "vllm-server.py"
      ],
      "checklists": [
        "inference-optimization.md"
      ]
    },
    "content": "# High-Performance Inference\n\nOptimize LLM inference for production with vLLM 0.14.x, quantization, and speculative decoding.\n\n> **vLLM 0.14.0** (Jan ): PyTorch 2.9.0, CUDA 12.9, AttentionConfig API, Python 3.12+ recommended.\n\n## Overview\n\n- Deploying LLMs with low latency requirements\n- Reducing GPU memory for larger models\n- Maximizing throughput for batch inference\n- Edge/mobile deployment with constrained resources\n- Cost optimization through efficient hardware utilization\n\n## Quick Reference\n\n```bash\n# Basic vLLM server\nvllm serve meta-llama/Meta-Llama-3.1-70B-Instruct \\\n    --tensor-parallel-size 4 \\\n    --max-model-len 8192\n\n# With quantization + speculative decoding\nvllm serve meta-llama/Meta-Llama-3.1-70B-Instruct \\\n    --quantization awq \\\n    --speculative-config '{\"method\": \"ngram\", \"num_speculative_tokens\": 5}' \\\n    --tensor-parallel-size 4 \\\n    --gpu-memory-utilization 0.9\n```\n\n## vLLM 0.14.x Key Features\n\n| Feature | Benefit |\n|---------|---------|\n| **PagedAttention** | Up to 24x throughput via efficient KV cache |\n| **Continuous Batching** | Dynamic request batching for max utilization |\n| **CUDA Graphs** | Fast model execution with graph capture |\n| **Tensor Parallelism** | Scale across multiple GPUs |\n| **Prefix Caching** | Reuse KV cache for shared prefixes |\n| **AttentionConfig** | New API replacing VLLM_ATTENTION_BACKEND env |\n| **Semantic Router** | vLLM SR v0.1 \"Iris\" for intelligent LLM routing |\n\n## Python vLLM Integration\n\n```python\nfrom vllm import LLM, SamplingParams\n\n# Initialize with optimization flags\nllm = LLM(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n    quantization=\"awq\",\n    tensor_parallel_size=2,\n    gpu_memory_utilization=0.9,\n    enable_prefix_caching=True,\n)\n\n# Sampling parameters\nsampling_params = SamplingParams(\n    temperature=0.7,\n    top_p=0.9,\n    max_tokens=1024,\n)\n\n# Generate\noutputs = llm.generate(prompts, sampling_params)\nfor output in outputs:\n    print(output.outputs[0].text)\n```\n\n## Quantization Methods\n\n| Method | Bits | Memory Savings | Speed | Quality |\n|--------|------|----------------|-------|---------|\n| FP16 | 16 | Baseline | Baseline | Best |\n| INT8 | 8 | 50% | +10-20% | Very Good |\n| AWQ | 4 | 75% | +20-40% | Good |\n| GPTQ | 4 | 75% | +15-30% | Good |\n| FP8 | 8 | 50% | +30-50% | Very Good |\n\n**When to Use Each:**\n- **FP16**: Maximum quality, sufficient memory\n- **INT8/FP8**: Balance of quality and efficiency\n- **AWQ**: Best 4-bit quality, activation-aware\n- **GPTQ**: Faster quantization, good quality\n\n## Speculative Decoding\n\nAccelerate generation by predicting multiple tokens:\n\n```python\n# N-gram based (no extra model)\nspeculative_config = {\n    \"method\": \"ngram\",\n    \"num_speculative_tokens\": 5,\n    \"prompt_lookup_max\": 5,\n    \"prompt_lookup_min\": 2,\n}\n\n# Draft model (higher quality)\nspeculative_config = {\n    \"method\": \"draft_model\",\n    \"draft_model\": \"meta-llama/Llama-3.2-1B-Instruct\",\n    \"num_speculative_tokens\": 3,\n}\n```\n\n**Expected Gains**: 1.5-2.5x throughput fo",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator"
    ]
  },
  "hook-formulas": {
    "name": "hook-formulas",
    "description": "Proven formulas for video hooks that stop the scroll. Use when writing opening lines, creating attention-grabbing intros, or optimizing first 3 seconds",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "hooks",
      "marketing",
      "attention",
      "copywriting",
      "social-media"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "hook-patterns.md",
        "platform-specific-hooks.md",
        "testing-hooks.md"
      ]
    },
    "content": "# Video Hook Formulas\n\nMaster the art of the first 3 seconds - proven patterns that stop the scroll and capture attention.\n\n## Why Hooks Matter\n\n- **47%** of video value is delivered in the first 3 seconds\n- **65%** of viewers who watch the first 3 seconds will watch at least 10 more\n- Hooks determine algorithmic reach on every platform\n\n## The Hook Framework\n\n### Anatomy of a Perfect Hook\n\n```\n[PATTERN] + [SPECIFICITY] + [TENSION] = Scroll-stopping hook\n```\n\n1. **Pattern**: Use a proven formula (see patterns below)\n2. **Specificity**: Add concrete numbers, names, or details\n3. **Tension**: Create curiosity gap or emotional response\n\n---\n\n## 12 Proven Hook Patterns\n\n### 1. The Shocking Statistic\n\n**Formula**: \"[Surprising number] + [unexpected context]\"\n\n**Examples**:\n- \"90% of Claude Code users are writing code wrong\"\n- \"This one setting saves 4 hours per week\"\n- \"Only 3% of developers know this exists\"\n\n**When to use**: Product features, productivity tips, industry insights\n\n---\n\n### 2. The Transformation Hook\n\n**Formula**: \"I went from [bad state] to [good state] in [timeframe]\"\n\n**Examples**:\n- \"I went from manual deploys to zero-downtime in 20 minutes\"\n- \"My code reviews went from 2 hours to 15 minutes\"\n- \"From 50 errors to zero - here's what changed\"\n\n**When to use**: Before/after demos, tool adoption stories\n\n---\n\n### 3. The Contrarian Statement\n\n**Formula**: \"[Common belief] is wrong. Here's why...\"\n\n**Examples**:\n- \"Writing tests first is actually slower. Let me explain.\"\n- \"Stop using ChatGPT for code. Here's what works better.\"\n- \"AI won't replace developers. It'll replace THIS instead.\"\n\n**When to use**: Thought leadership, challenging status quo\n\n---\n\n### 4. The Direct Question\n\n**Formula**: \"[Pain point question]?\" or \"What if [desired outcome]?\"\n\n**Examples**:\n- \"Tired of debugging the same errors every week?\"\n- \"What if your AI assistant actually understood your codebase?\"\n- \"Why does every PR review feel like a fight?\"\n\n**When to use**: Problem-aware audiences, relatable pain points\n\n---\n\n### 5. The \"Stop Doing This\" Hook\n\n**Formula**: \"Stop [common practice] immediately\"\n\n**Examples**:\n- \"Stop writing console.log for debugging\"\n- \"Stop copying code from ChatGPT directly\"\n- \"Stop reviewing PRs without this checklist\"\n\n**When to use**: Common mistakes, bad habits, quick wins\n\n---\n\n### 6. The Secret/Hidden Hook\n\n**Formula**: \"The [hidden/secret] [thing] that [benefit]\"\n\n**Examples**:\n- \"The hidden Claude feature that 10x'd my productivity\"\n- \"A secret prompt pattern that actually works\"\n- \"The debugging trick seniors don't share\"\n\n**When to use**: Insider knowledge, exclusive tips\n\n---\n\n### 7. The \"Most People\" Hook\n\n**Formula**: \"Most [audience] [mistake]. Here's what to do instead.\"\n\n**Examples**:\n- \"Most devs use AI wrong. Here's the right way.\"\n- \"Most teams waste 40% of their standup time\"\n- \"Most prompts fail because of this one word\"\n\n**When to use**: Positioning expertise, common mistakes\n\n---\n\n### 8. The Countdown/List Hoo",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "hyde-retrieval": {
    "name": "hyde-retrieval",
    "description": "HyDE (Hypothetical Document Embeddings) for improved semantic retrieval. Use when queries don't match document vocabulary, retrieval quality is poor, or implementing advanced RAG patterns.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "retrieval",
      "hyde",
      "semantic-search"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {},
    "content": "# HyDE (Hypothetical Document Embeddings)\n\nGenerate hypothetical answer documents to bridge vocabulary gaps in semantic search.\n\n## The Problem\n\nDirect query embedding often fails due to vocabulary mismatch:\n```\nQuery: \"scaling async data pipelines\"\nDocs use: \"event-driven messaging\", \"Apache Kafka\", \"message brokers\"\n→ Low similarity scores despite high relevance\n```\n\n## The Solution\n\nInstead of embedding the query, generate a hypothetical answer document:\n```\nQuery: \"scaling async data pipelines\"\n→ LLM generates: \"To scale asynchronous data pipelines, use event-driven\n   messaging with Apache Kafka. Message brokers provide backpressure...\"\n→ Embed the hypothetical document\n→ Now matches docs using similar terminology\n```\n\n## Implementation\n\n```python\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\n\nclass HyDEResult(BaseModel):\n    \"\"\"Result of HyDE generation.\"\"\"\n    original_query: str\n    hypothetical_doc: str\n    embedding: list[float]\n\nasync def generate_hyde(\n    query: str,\n    llm: AsyncOpenAI,\n    embed_fn: callable,\n    max_tokens: int = 150,\n) -> HyDEResult:\n    \"\"\"Generate hypothetical document and embed it.\"\"\"\n\n    # Generate hypothetical answer\n    response = await llm.chat.completions.create(\n        model=\"gpt-5.2-mini\",  # Fast, cheap model\n        messages=[\n            {\"role\": \"system\", \"content\":\n                \"Write a short paragraph that would answer this query. \"\n                \"Use technical terminology that documentation would use.\"},\n            {\"role\": \"user\", \"content\": query}\n        ],\n        max_tokens=max_tokens,\n        temperature=0.3,  # Low temp for consistency\n    )\n\n    hypothetical_doc = response.choices[0].message.content\n\n    # Embed the hypothetical document (not the query!)\n    embedding = await embed_fn(hypothetical_doc)\n\n    return HyDEResult(\n        original_query=query,\n        hypothetical_doc=hypothetical_doc,\n        embedding=embedding,\n    )\n```\n\n## With Caching\n\n```python\nfrom functools import lru_cache\nimport hashlib\n\nclass HyDEService:\n    def __init__(self, llm, embed_fn):\n        self.llm = llm\n        self.embed_fn = embed_fn\n        self._cache: dict[str, HyDEResult] = {}\n\n    def _cache_key(self, query: str) -> str:\n        return hashlib.md5(query.lower().strip().encode()).hexdigest()\n\n    async def generate(self, query: str) -> HyDEResult:\n        key = self._cache_key(query)\n\n        if key in self._cache:\n            return self._cache[key]\n\n        result = await generate_hyde(query, self.llm, self.embed_fn)\n        self._cache[key] = result\n        return result\n```\n\n## Per-Concept HyDE (Advanced)\n\nFor multi-concept queries, generate HyDE for each concept:\n\n```python\nasync def batch_hyde(\n    concepts: list[str],\n    hyde_service: HyDEService,\n) -> list[HyDEResult]:\n    \"\"\"Generate HyDE embeddings for multiple concepts in parallel.\"\"\"\n    import asyncio\n\n    tasks = [hyde_service.generate(concept) for concept in concepts]\n    return await asyncio.gather",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "i18n-date-patterns": {
    "name": "i18n-date-patterns",
    "description": "Implements internationalization (i18n) in React applications. Covers user-facing strings, date/time handling, locale-aware formatting, ICU MessageFormat, and RTL support. Use when building multilingual UIs or formatting dates/currency.",
    "version": "1.2.0",
    "author": "Yonatan Gross",
    "tags": [
      "i18n",
      "internationalization",
      "dayjs",
      "dates",
      "react-i18next",
      "localization",
      "rtl",
      "useTranslation",
      "useFormatting",
      "ICU",
      "Trans"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "formatting-utilities.md",
        "icu-messageformat.md",
        "trans-component.md"
      ],
      "checklists": [
        "i18n-checklist.md"
      ]
    },
    "content": "# i18n and Localization Patterns\n\n## Overview\n\nThis skill provides comprehensive guidance for implementing internationalization in React applications. It ensures ALL user-facing strings, date displays, currency, lists, and time calculations are locale-aware.\n\n**When to use this skill:**\n- Adding ANY user-facing text to components\n- Formatting dates, times, currency, lists, or ordinals\n- Implementing complex pluralization\n- Embedding React components in translated text\n- Supporting RTL languages (Hebrew, Arabic)\n\n**Bundled Resources:**\n- `references/formatting-utilities.md` - useFormatting hook API reference\n- `references/icu-messageformat.md` - ICU plural/select syntax\n- `references/trans-component.md` - Trans component for rich text\n- `checklists/i18n-checklist.md` - Implementation and review checklist\n- `examples/component-i18n-example.md` - Complete component example\n\n**Canonical Reference:** See `docs/i18n-standards.md` for the full i18n standards document.\n\n---\n\n## Core Patterns\n\n### 1. useTranslation Hook (All UI Strings)\n\nEvery visible string MUST use the translation function:\n\n```tsx\nimport { useTranslation } from 'react-i18next';\n\nfunction MyComponent() {\n  const { t } = useTranslation(['patients', 'common']);\n  \n  return (\n    <div>\n      <h1>{t('patients:title')}</h1>\n      <button>{t('common:actions.save')}</button>\n    </div>\n  );\n}\n```\n\n### 2. useFormatting Hook (Locale-Aware Data)\n\nAll locale-sensitive formatting MUST use the centralized hook:\n\n```tsx\nimport { useFormatting } from '@/hooks';\n\nfunction PriceDisplay({ amount, items }) {\n  const { formatILS, formatList, formatOrdinal } = useFormatting();\n  \n  return (\n    <div>\n      <p>Price: {formatILS(amount)}</p>        {/* ₪1,500.00 */}\n      <p>Items: {formatList(items)}</p>        {/* \"a, b, and c\" */}\n      <p>Position: {formatOrdinal(3)}</p>      {/* \"3rd\" */}\n    </div>\n  );\n}\n```\n\nSee `references/formatting-utilities.md` for the complete API.\n\n### 3. Date Formatting\n\nAll dates MUST use the centralized `@/lib/dates` library:\n\n```tsx\nimport { formatDate, formatDateShort, calculateWaitTime } from '@/lib/dates';\n\nconst date = formatDate(appointment.date);    // \"Jan 6, 2026\"\nconst waitTime = calculateWaitTime('09:30');  // \"15 min\"\n```\n\n### 4. ICU MessageFormat (Complex Plurals)\n\nUse ICU syntax in translation files for pluralization:\n\n```json\n{\n  \"patients\": \"{count, plural, =0 {No patients} one {# patient} other {# patients}}\"\n}\n```\n\n```tsx\nt('patients', { count: 5 })  // → \"5 patients\"\n```\n\nSee `references/icu-messageformat.md` for full syntax.\n\n### 5. Trans Component (Rich Text)\n\nFor embedded React components in translated text:\n\n```tsx\nimport { Trans } from 'react-i18next';\n\n<Trans\n  i18nKey=\"richText.welcome\"\n  values={{ name: userName }}\n  components={{ strong: <strong /> }}\n/>\n```\n\nSee `references/trans-component.md` for patterns.\n\n---\n\n## Translation File Structure\n\n```\nfrontend/src/i18n/locales/\n├── en/\n│   ├── common.json      # Shared: actions, status, time\n│   ├── p",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer"
    ]
  },
  "idempotency-patterns": {
    "name": "idempotency-patterns",
    "description": "Idempotency patterns for APIs and event handlers. Use when implementing exactly-once semantics, deduplicating requests, or building reliable distributed systems.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "idempotency",
      "deduplication",
      "exactly-once",
      "distributed-systems",
      "api"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "stripe-pattern.md"
      ],
      "scripts": [
        "idempotency-middleware-template.py"
      ],
      "checklists": [
        "idempotency-checklist.md"
      ]
    },
    "content": "# Idempotency Patterns ()\n\nPatterns for ensuring operations can be safely retried without unintended side effects.\n\n## Overview\n\n- Building payment or financial APIs\n- Implementing webhook handlers\n- Processing messages from queues\n- Creating mutation endpoints (POST, PUT, DELETE)\n- Building distributed systems with at-least-once delivery\n\n## Quick Reference\n\n### Idempotency Key Generation\n\n```python\nimport hashlib\nimport json\nfrom typing import Any\n\ndef generate_idempotency_key(\n    *,\n    entity_id: str,\n    action: str,\n    params: dict[str, Any] | None = None,\n) -> str:\n    \"\"\"\n    Generate deterministic idempotency key.\n\n    Args:\n        entity_id: Unique identifier of the entity\n        action: The action being performed\n        params: Optional parameters that affect the result\n\n    Returns:\n        32-character hex string\n    \"\"\"\n    content = f\"{entity_id}:{action}\"\n    if params:\n        # Sort keys for deterministic output\n        content += f\":{json.dumps(params, sort_keys=True)}\"\n\n    return hashlib.sha256(content.encode()).hexdigest()[:32]\n\n\n# Examples\nkey1 = generate_idempotency_key(\n    entity_id=\"order-123\",\n    action=\"create\",\n    params={\"amount\": 100, \"currency\": \"USD\"},\n)\n\nkey2 = generate_idempotency_key(\n    entity_id=\"payment-456\",\n    action=\"refund\",\n)\n```\n\n### FastAPI Idempotency Middleware\n\n```python\nfrom fastapi import Request, Response, HTTPException\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport redis.asyncio as redis\nimport json\n\nclass IdempotencyMiddleware(BaseHTTPMiddleware):\n    \"\"\"Handle Idempotency-Key header for POST/PUT/PATCH.\"\"\"\n\n    def __init__(self, app, redis_client: redis.Redis, ttl: int = 86400):\n        super().__init__(app)\n        self.redis = redis_client\n        self.ttl = ttl\n\n    async def dispatch(self, request: Request, call_next):\n        # Only apply to mutation methods\n        if request.method not in (\"POST\", \"PUT\", \"PATCH\"):\n            return await call_next(request)\n\n        # Check for idempotency key\n        idempotency_key = request.headers.get(\"Idempotency-Key\")\n        if not idempotency_key:\n            return await call_next(request)\n\n        cache_key = f\"idem:{request.url.path}:{idempotency_key}\"\n\n        # Check for cached response\n        cached = await self.redis.get(cache_key)\n        if cached:\n            data = json.loads(cached)\n            return Response(\n                content=data[\"body\"],\n                status_code=data[\"status\"],\n                media_type=\"application/json\",\n                headers={\"X-Idempotent-Replayed\": \"true\"},\n            )\n\n        # Process request\n        response = await call_next(request)\n\n        # Cache successful responses\n        if 200 <= response.status_code < 300:\n            body = b\"\".join([chunk async for chunk in response.body_iterator])\n            await self.redis.setex(\n                cache_key,\n                self.ttl,\n                json.dumps({\n                    \"body\": body.decode(),\n        ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "event-driven-architect"
    ]
  },
  "image-optimization": {
    "name": "image-optimization",
    "description": "Image optimization with Next.js 16 Image, AVIF/WebP formats, blur placeholders, responsive sizes, and CDN loaders. Use when improving image performance, responsive sizing, or Next.js image pipelines.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "images",
      "next-image",
      "avif",
      "webp",
      "responsive",
      "lazy-loading",
      "blur-placeholder",
      "lcp"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "cdn-setup.md"
      ],
      "scripts": [
        "image-component.tsx"
      ],
      "checklists": [
        "image-checklist.md"
      ]
    },
    "content": "# Image Optimization\n\nProduction image optimization patterns for modern web applications.\n\n## Overview\n\n- Optimizing Largest Contentful Paint (LCP)\n- Reducing page weight and bandwidth\n- Implementing responsive images\n- Adding blur placeholders for perceived performance\n- Converting to modern formats (AVIF, WebP)\n\n## Core Patterns\n\n### 1. Next.js Image Component\n\n```tsx\nimport Image from 'next/image';\n\n// Static import (recommended for static assets)\nimport heroImage from '@/public/hero.jpg';\n\nfunction Hero() {\n  return (\n    <Image\n      src={heroImage}\n      alt=\"Hero banner\"\n      priority // Preload for LCP\n      placeholder=\"blur\" // Automatic blur placeholder\n      quality={85}\n      sizes=\"100vw\"\n    />\n  );\n}\n\n// Remote images\n<Image\n  src=\"https://cdn.example.com/photo.jpg\"\n  alt=\"Remote photo\"\n  width={800}\n  height={600}\n  sizes=\"(max-width: 768px) 100vw, 800px\"\n/>\n```\n\n### 2. Responsive Images with Sizes\n\n```tsx\n// Full-width hero\n<Image\n  src=\"/hero.jpg\"\n  alt=\"Hero\"\n  fill\n  sizes=\"100vw\"\n  style={{ objectFit: 'cover' }}\n/>\n\n// Sidebar image (smaller on large screens)\n<Image\n  src=\"/sidebar.jpg\"\n  alt=\"Sidebar\"\n  width={400}\n  height={300}\n  sizes=\"(max-width: 768px) 100vw, 33vw\"\n/>\n\n// Grid of cards\n<Image\n  src={`/products/${id}.jpg`}\n  alt={product.name}\n  width={300}\n  height={300}\n  sizes=\"(max-width: 640px) 50vw, (max-width: 1024px) 33vw, 25vw\"\n/>\n```\n\n### 3. Blur Placeholders\n\n```tsx\n// Static imports get automatic blur\nimport photo from '@/public/photo.jpg';\n<Image src={photo} alt=\"Photo\" placeholder=\"blur\" />\n\n// Remote images need blurDataURL\n<Image\n  src=\"https://cdn.example.com/photo.jpg\"\n  alt=\"Photo\"\n  width={800}\n  height={600}\n  placeholder=\"blur\"\n  blurDataURL=\"data:image/jpeg;base64,/9j/4AAQSkZJRg...\"\n/>\n\n// Generate blurDataURL at build time\nimport { getPlaiceholder } from 'plaiceholder';\n\nexport async function getStaticProps() {\n  const { base64 } = await getPlaiceholder('/public/photo.jpg');\n  return { props: { blurDataURL: base64 } };\n}\n```\n\n### 4. Format Selection (AVIF/WebP)\n\n```tsx\n// next.config.js - Enable AVIF\nmodule.exports = {\n  images: {\n    formats: ['image/avif', 'image/webp'],\n    deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],\n    imageSizes: [16, 32, 48, 64, 96, 128, 256, 384],\n  },\n};\n\n// HTML picture element for non-Next.js\n<picture>\n  <source srcSet=\"/hero.avif\" type=\"image/avif\" />\n  <source srcSet=\"/hero.webp\" type=\"image/webp\" />\n  <img src=\"/hero.jpg\" alt=\"Hero\" width=\"1200\" height=\"600\" />\n</picture>\n```\n\n### 5. Lazy Loading Patterns\n\n```tsx\n// Default: lazy loading (below the fold)\n<Image src=\"/photo.jpg\" alt=\"Photo\" width={400} height={300} />\n\n// Above the fold: eager loading\n<Image\n  src=\"/hero.jpg\"\n  alt=\"Hero\"\n  width={1200}\n  height={600}\n  priority // Preloads, no lazy loading\n/>\n\n// Native lazy loading (non-Next.js)\n<img\n  src=\"/photo.jpg\"\n  alt=\"Photo\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  width=\"400\"\n  height=\"300\"\n/>\n```\n\n### 6. Image CDN Configuration\n\n```tsx\n// ne",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "performance-engineer"
    ]
  },
  "implement": {
    "name": "implement",
    "description": "Full-power feature implementation with parallel subagents. Use when implementing, building, or creating features.",
    "version": "2.1.0",
    "author": "OrchestKit",
    "tags": [
      "implementation",
      "feature",
      "full-stack",
      "parallel-agents",
      "reflection",
      "worktree"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "mcp__context7__query_docs",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "api-design-framework",
      "react-server-components-framework",
      "type-safety-validation",
      "unit-testing",
      "integration-testing",
      "explore",
      "verify",
      "memory",
      "worktree-coordination"
    ],
    "agent": null,
    "structure": {
      "references": [
        "agent-phases.md",
        "agent-teams-full-stack.md",
        "agent-teams-phases.md",
        "agent-teams-security-audit.md",
        "cc-enhancements.md",
        "micro-planning-guide.md",
        "orchestration-modes.md",
        "scope-creep-detection.md",
        "team-worktree-setup.md",
        "worktree-workflow.md"
      ],
      "assets": [
        "micro-plan-template.md",
        "reflection-template.md"
      ],
      "scripts": [
        "worktree-setup.sh"
      ],
      "checklists": [
        "implementation-review.md"
      ]
    },
    "content": "# Implement Feature\n\nMaximum utilization of parallel subagent execution for feature implementation with built-in scope control and reflection.\n\n## Quick Start\n\n```bash\n/implement user authentication\n/implement real-time notifications\n/implement dashboard analytics\n```\n\n> **Opus 4.6**: Parallel agents leverage native adaptive thinking and 128K output for comprehensive implementations. Token budgets scale dynamically with context window.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks or doing ANY work**, ask the user to clarify scope:\n\n```python\nAskUserQuestion(\n  questions=[\n    {\n      \"question\": \"What scope for this implementation?\",\n      \"header\": \"Scope\",\n      \"options\": [\n        {\"label\": \"Full-stack (Recommended)\", \"description\": \"Backend + frontend + tests + docs\"},\n        {\"label\": \"Backend only\", \"description\": \"API + database + backend tests\"},\n        {\"label\": \"Frontend only\", \"description\": \"UI components + state + frontend tests\"},\n        {\"label\": \"Quick prototype\", \"description\": \"Minimal working version, skip tests\"}\n      ],\n      \"multiSelect\": false\n    },\n    {\n      \"question\": \"Any constraints I should know about?\",\n      \"header\": \"Constraints\",\n      \"options\": [\n        {\"label\": \"None (Recommended)\", \"description\": \"Use best practices and modern patterns\"},\n        {\"label\": \"Match existing patterns\", \"description\": \"Follow existing codebase conventions exactly\"},\n        {\"label\": \"Minimal dependencies\", \"description\": \"Avoid adding new packages\"},\n        {\"label\": \"Specific tech stack\", \"description\": \"I'll specify the technologies to use\"}\n      ],\n      \"multiSelect\": false\n    }\n  ]\n)\n```\n\n**Based on user's answers, adjust the workflow:**\n- **Full-stack**: All 10 phases, all parallel agents\n- **Backend only**: Skip frontend agents (phases 5b, 6b)\n- **Frontend only**: Skip backend agents (phases 5a, 6a)\n- **Quick prototype**: Skip phases 7-10 (scope check, verification, docs, reflection)\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh, default when available) or **Task tool** (star, fallback):\n- `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` → Agent Teams (default); not set → Task tool\n- When Teams available: complexity < 2.5 → Task tool; >= 2.5 → Agent Teams\n- Override: `ORCHESTKIT_FORCE_TASK_TOOL=1` → always Task tool\n\n> See [Orchestration Modes](references/orchestration-modes.md) for decision logic, comparison table, and fallback strategy.\n\n---\n\n## Opus 4.6: 128K Output Token Advantage\n\nWith 128K output tokens (2x previous 64K), agents can generate **complete artifacts in fewer passes**:\n\n| Artifact | Before (64K) | After (128K) |\n|----------|-------------|--------------|\n| Full API + models | 2 passes | 1 pass |\n| Component + tests | 2 passes | 1 pass |\n| Complete feature (API + UI + tests) | 4-6 passes | 2-3 passes |\n\n**Guidance for agents:** Generate complete, working code in a single pass whenever possible. Don't split implementations across multipl",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "input-validation": {
    "name": "input-validation",
    "description": "Input validation and sanitization patterns. Use when validating user input, preventing injection attacks, implementing allowlists, or sanitizing HTML/SQL/command inputs.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "validation",
      "zod",
      "pydantic"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Write",
      "Edit"
    ],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "zod-v4-api.md"
      ],
      "scripts": [
        "validation-schemas.ts"
      ],
      "checklists": [
        "validation-checklist.md"
      ]
    },
    "content": "# Input Validation\n\nValidate and sanitize all untrusted input using Zod v4 and Pydantic.\n\n## Overview\n\n- Processing user input\n- Query parameters\n- Form submissions\n- API request bodies\n- File uploads\n- URL validation\n\n## Core Principles\n\n1. **Never trust user input**\n2. **Validate on server-side** (client-side is UX only)\n3. **Use allowlists** (not blocklists)\n4. **Validate type, length, format, range**\n\n## Quick Reference\n\n### Zod v4 Schema\n\n```typescript\nimport { z } from 'zod';\n\nconst UserSchema = z.object({\n  email: z.string().email(),\n  name: z.string().min(2).max(100),\n  age: z.coerce.number().int().min(0).max(150),\n  role: z.enum(['user', 'admin']).default('user'),\n});\n\nconst result = UserSchema.safeParse(req.body);\nif (!result.success) {\n  return res.status(400).json({ errors: result.error.flatten() });\n}\n```\n\n### Type Coercion (v4)\n\n```typescript\n// Query params come as strings - coerce to proper types\nz.coerce.number()  // \"123\" → 123\nz.coerce.boolean() // \"true\" → true\nz.coerce.date()    // \"2024-01-01\" → Date\n```\n\n### Discriminated Unions\n\n```typescript\nconst ShapeSchema = z.discriminatedUnion('type', [\n  z.object({ type: z.literal('circle'), radius: z.number() }),\n  z.object({ type: z.literal('rectangle'), width: z.number(), height: z.number() }),\n]);\n```\n\n### Pydantic (Python)\n\n```python\nfrom pydantic import BaseModel, EmailStr, Field\n\nclass User(BaseModel):\n    email: EmailStr\n    name: str = Field(min_length=2, max_length=100)\n    age: int = Field(ge=0, le=150)\n```\n\n## Anti-Patterns (FORBIDDEN)\n\n```typescript\n// ❌ NEVER rely on client-side validation only\nif (formIsValid) submit();  // No server validation\n\n// ❌ NEVER use blocklists\nconst blocked = ['password', 'secret'];  // Easy to miss fields\n\n// ❌ NEVER trust Content-Type header\nif (file.type === 'image/png') {...}  // Can be spoofed\n\n// ❌ NEVER build queries with string concat\n\"SELECT * FROM users WHERE name = '\" + name + \"'\"  // SQL injection\n\n// ✅ ALWAYS validate server-side\nconst result = schema.safeParse(req.body);\n\n// ✅ ALWAYS use allowlists\nconst allowed = ['name', 'email', 'createdAt'];\n\n// ✅ ALWAYS validate file magic bytes\nconst isPng = buffer[0] === 0x89 && buffer[1] === 0x50;\n\n// ✅ ALWAYS use parameterized queries\ndb.query('SELECT * FROM users WHERE name = ?', [name]);\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Validation library | Zod (TS), Pydantic (Python) |\n| Strategy | Allowlist over blocklist |\n| Location | Server-side always |\n| Error messages | Generic (don't leak info) |\n| File validation | Check magic bytes, not just extension |\n\n## Detailed Documentation\n\n| Resource | Description |\n|----------|-------------|\n| [references/zod-v4-api.md](references/zod-v4-api.md) | Zod v4 API with coercion, transforms |\n| [examples/validation-patterns.md](examples/validation-patterns.md) | Complete validation examples |\n| [checklists/validation-checklist.md](checklists/validation-checklist.md) | Implementation checklist |\n| [scri",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ai-safety-auditor",
      "security-auditor",
      "security-layer-auditor"
    ]
  },
  "integration-testing": {
    "name": "integration-testing",
    "description": "Integration testing patterns for APIs and components. Use when testing component interactions, API endpoints with test databases, or service layer integration.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "integration",
      "api",
      "database"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "scripts": [
        "create-integration-test.md",
        "pytest-integration.py",
        "test-plan-template.md"
      ]
    },
    "content": "# Integration Testing\n\nTest how components work together.\n\n## API Integration Test\n\n```typescript\nimport { describe, test, expect } from 'vitest';\nimport request from 'supertest';\nimport { app } from '../app';\n\ndescribe('POST /api/users', () => {\n  test('creates user and returns 201', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({ email: 'test@example.com', name: 'Test' });\n\n    expect(response.status).toBe(201);\n    expect(response.body.id).toBeDefined();\n    expect(response.body.email).toBe('test@example.com');\n  });\n\n  test('returns 400 for invalid email', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({ email: 'invalid', name: 'Test' });\n\n    expect(response.status).toBe(400);\n    expect(response.body.error).toContain('email');\n  });\n});\n```\n\n## FastAPI Integration Test\n\n```python\nimport pytest\nfrom httpx import AsyncClient\nfrom app.main import app\n\n@pytest.fixture\nasync def client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.mark.asyncio\nasync def test_create_user(client: AsyncClient):\n    response = await client.post(\n        \"/api/users\",\n        json={\"email\": \"test@example.com\", \"name\": \"Test\"}\n    )\n\n    assert response.status_code == 201\n    assert response.json()[\"email\"] == \"test@example.com\"\n\n@pytest.mark.asyncio\nasync def test_get_user_not_found(client: AsyncClient):\n    response = await client.get(\"/api/users/nonexistent\")\n\n    assert response.status_code == 404\n```\n\n## Test Database Setup\n\n```python\nimport pytest\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\n@pytest.fixture(scope=\"function\")\ndef db_session():\n    \"\"\"Fresh database per test.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    Base.metadata.create_all(engine)\n    Session = sessionmaker(bind=engine)\n    session = Session()\n\n    yield session\n\n    session.close()\n    Base.metadata.drop_all(engine)\n```\n\n## React Component Integration\n\n```typescript\nimport { render, screen } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\nimport { QueryClientProvider } from '@tanstack/react-query';\n\ntest('form submits and shows success', async () => {\n  const user = userEvent.setup();\n\n  render(\n    <QueryClientProvider client={queryClient}>\n      <UserForm />\n    </QueryClientProvider>\n  );\n\n  await user.type(screen.getByLabelText('Email'), 'test@example.com');\n  await user.click(screen.getByRole('button', { name: /submit/i }));\n\n  expect(await screen.findByText(/success/i)).toBeInTheDocument();\n});\n```\n\n## Coverage Targets\n\n| Area | Target |\n|------|--------|\n| API endpoints | 70%+ |\n| Service layer | 80%+ |\n| Component interactions | 70%+ |\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Database | In-memory SQLite or test container |\n| Execution | < 1s per test |\n| External APIs | MSW (frontend), VCR.py (backend) |\n| Cleanup | Fresh state",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer",
      "test-generator"
    ]
  },
  "issue-progress-tracking": {
    "name": "issue-progress-tracking",
    "description": "Automatic GitHub issue progress updates from commits and sub-task completion. Use when tracking issue progress from commits or automating status updates.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "github",
      "issues",
      "progress",
      "tracking",
      "automation",
      "commits"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "branch-naming.md",
        "gh-api-commands.md"
      ]
    },
    "content": "# Issue Progress Tracking\n\nAutomatic GitHub issue progress tracking that updates issues based on commits and marks sub-tasks as complete.\n\n## Overview\n\n- Working on GitHub issues with checkbox sub-tasks\n- Making commits that reference issue numbers\n- Using issue-prefixed branches (e.g., `issue/123-feature`, `fix/456-bug`)\n- Wanting automatic progress visibility without manual updates\n\n## How It Works\n\n### Automatic Progress Tracking\n\nThe plugin automatically tracks your work through three coordinated hooks:\n\n1. **Commit Detection** (`issue-progress-commenter.sh`)\n   - Extracts issue number from branch name or commit message\n   - Queues commit info for batch commenting\n   - Supports patterns: `issue/123-*`, `fix/123-*`, `feature/123-*`, `#123`\n\n2. **Sub-task Updates** (`issue-subtask-updater.sh`)\n   - Parses commit messages for task completion keywords\n   - Matches against unchecked `- [ ]` items in issue body\n   - Automatically checks off matching tasks via GitHub API\n\n3. **Session Summary** (`issue-work-summary.sh`)\n   - Posts consolidated progress comment when session ends\n   - Includes: commits, files changed, sub-tasks completed, PR link\n\n### Issue Number Extraction\n\n```bash\n# From branch name (priority)\nissue/123-implement-feature  # Extracts: 123\nfix/456-resolve-bug          # Extracts: 456\nfeature/789-add-tests        # Extracts: 789\n123-some-description         # Extracts: 123\n\n# From commit message (fallback)\n\"feat(#123): Add user validation\"     # Extracts: 123\n\"fix: Resolve bug (closes #456)\"      # Extracts: 456\n```\n\n### Sub-task Matching\n\nCommit messages are matched against issue checkboxes using:\n- Normalized text comparison (case-insensitive)\n- Partial matching for task descriptions\n- Keyword detection (Add, Implement, Fix, Test, etc.)\n\n**Example:**\n```markdown\n# Issue body\n- [ ] Add input validation\n- [ ] Write unit tests\n- [ ] Update documentation\n\n# Commit message\n\"feat(#123): Add input validation\"\n\n# Result: First checkbox auto-checked\n- [x] Add input validation\n- [ ] Write unit tests\n- [ ] Update documentation\n```\n\n## Progress Comment Format\n\n```markdown\n## Claude Code Progress Update\n\n**Session**: `abc12345...`\n**Branch**: `issue/123-implement-feature`\n\n### Commits (3)\n- `abc1234`: feat(#123): Add input validation\n- `def5678`: test(#123): Add unit tests\n- `ghi9012`: docs(#123): Update README\n\n### Files Changed\n- `src/validation.ts` (+45, -12)\n- `tests/validation.test.ts` (+89, -0)\n- `README.md` (+5, -2)\n\n### Sub-tasks Completed\n- [x] Add input validation\n- [x] Write unit tests\n\n### Pull Request\nhttps://github.com/owner/repo/pull/42\n\n---\n*Automated by OrchestKit*\n```\n\n## Requirements\n\n- `gh` CLI installed and authenticated\n- Repository with GitHub remote\n- Issue must exist and be accessible\n\n## Configuration\n\nDisable individual hooks in `.claude/config.json`:\n\n```json\n{\n  \"hooks\": {\n    \"issue-progress-commenter.sh\": false,\n    \"issue-subtask-updater.sh\": false,\n    \"issue-work-summary.sh\": false\n  }\n}\n```\n\n## PR-Aware Session",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "git-operations-engineer"
    ]
  },
  "langfuse-observability": {
    "name": "langfuse-observability",
    "description": "LLM observability platform for tracing, evaluation, prompt management, and cost tracking. Use when setting up Langfuse, monitoring LLM costs, tracking token usage, or implementing prompt versioning.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "langfuse",
      "llm",
      "observability",
      "tracing",
      "evaluation",
      "prompts"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "references": [
        "cost-tracking.md",
        "evaluation-scores.md",
        "experiments-api.md",
        "multi-judge-evaluation.md",
        "prompt-management.md",
        "session-tracking.md",
        "tracing-setup.md"
      ],
      "scripts": [
        "callback-handler.py",
        "observe-decorator.py"
      ],
      "checklists": [
        "langfuse-setup-checklist.md"
      ]
    },
    "content": "# Langfuse Observability\n\n## Overview\n\n**Langfuse** is the open-source LLM observability platform that OrchestKit uses for tracing, monitoring, evaluation, and prompt management. Unlike LangSmith (deprecated), Langfuse is self-hosted, free, and designed for production LLM applications.\n\n**When to use this skill:**\n- Setting up LLM observability from scratch\n- Debugging slow or incorrect LLM responses\n- Tracking token usage and costs\n- Managing prompts in production\n- Evaluating LLM output quality\n- Migrating from LangSmith to Langfuse\n\n**OrchestKit Integration:**\n- **Status**: Migrated from LangSmith (Dec 2025)\n- **Location**: `backend/app/shared/services/langfuse/`\n- **MCP Server**: `orchestkit-langfuse` (optional)\n\n---\n\n## Quick Start\n\n### Setup\n\n```python\n# backend/app/shared/services/langfuse/client.py\nfrom langfuse import Langfuse\nfrom app.core.config import settings\n\nlangfuse_client = Langfuse(\n    public_key=settings.LANGFUSE_PUBLIC_KEY,\n    secret_key=settings.LANGFUSE_SECRET_KEY,\n    host=settings.LANGFUSE_HOST  # Self-hosted or cloud\n)\n```\n\n### Basic Tracing with @observe\n\n```python\nfrom langfuse.decorators import observe, langfuse_context\n\n@observe()  # Automatic tracing\nasync def analyze_content(content: str):\n    langfuse_context.update_current_observation(\n        metadata={\"content_length\": len(content)}\n    )\n    return await llm.generate(content)\n```\n\n### Session & User Tracking\n\n```python\nlangfuse.trace(\n    name=\"analysis\",\n    user_id=\"user_123\",\n    session_id=\"session_abc\",\n    metadata={\"content_type\": \"article\", \"agent_count\": 8},\n    tags=[\"production\", \"orchestkit\"]\n)\n```\n\n---\n\n## Core Features Summary\n\n| Feature | Description | Reference |\n|---------|-------------|-----------|\n| Distributed Tracing | Track LLM calls with parent-child spans | `references/tracing-setup.md` |\n| Cost Tracking | Automatic token & cost calculation | `references/cost-tracking.md` |\n| Prompt Management | Version control for prompts | `references/prompt-management.md` |\n| LLM Evaluation | Custom scoring with G-Eval | `references/evaluation-scores.md` |\n| Session Tracking | Group related traces | `references/session-tracking.md` |\n| Experiments API | A/B testing & benchmarks | `references/experiments-api.md` |\n| Multi-Judge Eval | Ensemble LLM evaluation | `references/multi-judge-evaluation.md` |\n\n---\n\n## References\n\n### Tracing Setup\n**See: `references/tracing-setup.md`**\n\nKey topics covered:\n- Initializing Langfuse client with @observe decorator\n- Creating nested traces and spans\n- Tracking LLM generations with metadata\n- LangChain/LangGraph CallbackHandler integration\n- Workflow integration patterns\n\n### Cost Tracking\n**See: `references/cost-tracking.md`**\n\nKey topics covered:\n- Automatic cost calculation from token usage\n- Custom model pricing configuration\n- Monitoring dashboard SQL queries\n- Cost tracking per analysis/user\n- Daily cost trend analysis\n\n### Prompt Management\n**See: `references/prompt-management.md`**\n\nKey topics covered:\n- Pr",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator",
      "metrics-architect",
      "monitoring-engineer",
      "workflow-architect"
    ]
  },
  "langgraph-checkpoints": {
    "name": "langgraph-checkpoints",
    "description": "LangGraph checkpointing and persistence. Use when implementing fault-tolerant workflows, resuming interrupted executions, debugging with state history, or avoiding re-running expensive operations.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "checkpoints",
      "state",
      "persistence"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "evaluations.md",
        "postgres-checkpointer.md",
        "state-inspection.md",
        "state-recovery.md",
        "store-memory.md"
      ],
      "checklists": [
        "checkpoint-checklist.md"
      ]
    },
    "content": "# LangGraph Checkpointing\n\nPersist workflow state for recovery and debugging.\n\n## Checkpointer Options\n\n```python\nfrom langgraph.checkpoint import MemorySaver\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\n# Development: In-memory\nmemory = MemorySaver()\napp = workflow.compile(checkpointer=memory)\n\n# Production: SQLite\ncheckpointer = SqliteSaver.from_conn_string(\"checkpoints.db\")\napp = workflow.compile(checkpointer=checkpointer)\n\n# Production: PostgreSQL\ncheckpointer = PostgresSaver.from_conn_string(\"postgresql://...\")\napp = workflow.compile(checkpointer=checkpointer)\n```\n\n## Using Thread IDs\n\n```python\n# Start new workflow\nconfig = {\"configurable\": {\"thread_id\": \"analysis-123\"}}\nresult = app.invoke(initial_state, config=config)\n\n# Resume interrupted workflow\nconfig = {\"configurable\": {\"thread_id\": \"analysis-123\"}}\nresult = app.invoke(None, config=config)  # Resumes from checkpoint\n```\n\n## PostgreSQL Setup\n\n```python\ndef create_checkpointer():\n    \"\"\"Create PostgreSQL checkpointer for production.\"\"\"\n    return PostgresSaver.from_conn_string(\n        settings.DATABASE_URL,\n        save_every=1  # Save after each node\n    )\n\n# Compile with checkpointing\napp = workflow.compile(\n    checkpointer=create_checkpointer(),\n    interrupt_before=[\"quality_gate\"]  # Manual review point\n)\n```\n\n## Inspecting Checkpoints\n\n```python\n# Get all checkpoints for a workflow\ncheckpoints = app.get_state_history(config)\n\nfor checkpoint in checkpoints:\n    print(f\"Step: {checkpoint.metadata['step']}\")\n    print(f\"Node: {checkpoint.metadata['source']}\")\n    print(f\"State: {checkpoint.values}\")\n\n# Get current state\ncurrent = app.get_state(config)\nprint(current.values)\n```\n\n## Resuming After Crash\n\n```python\nimport logging\n\nasync def run_with_recovery(workflow_id: str, initial_state: dict):\n    \"\"\"Run workflow with automatic recovery.\"\"\"\n    config = {\"configurable\": {\"thread_id\": workflow_id}}\n\n    try:\n        # Try to resume existing workflow\n        state = app.get_state(config)\n        if state.values:\n            logging.info(f\"Resuming workflow {workflow_id}\")\n            return app.invoke(None, config=config)\n    except Exception:\n        pass  # No existing checkpoint\n\n    # Start fresh\n    logging.info(f\"Starting new workflow {workflow_id}\")\n    return app.invoke(initial_state, config=config)\n```\n\n## Step-by-Step Debugging\n\n```python\n# Execute one node at a time\nfor step in app.stream(initial_state, config):\n    print(f\"After {step['node']}: {step['state']}\")\n    input(\"Press Enter to continue...\")\n\n# Rollback to previous checkpoint\nhistory = list(app.get_state_history(config))\nprevious_state = history[1]  # One step back\napp.update_state(config, previous_state.values)\n```\n\n## Store vs Checkpointer (2026 Best Practice)\n\n```python\nfrom langgraph.checkpoint.postgres import PostgresSaver\nfrom langgraph.store.postgres import PostgresStore\n\n# Checkpointer = SHORT-TERM memory (thread-scoped)\n# - Conversation h",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-functional": {
    "name": "langgraph-functional",
    "description": "LangGraph Functional API with @entrypoint and @task decorators. Use when building workflows with the modern LangGraph pattern, enabling parallel execution, persistence, and human-in-the-loop.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "functional",
      "api",
      "patterns"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "determinism-rules.md",
        "evaluations.md",
        "injectable-parameters.md",
        "migration-guide.md",
        "side-effects.md"
      ]
    },
    "content": "# LangGraph Functional API\nBuild workflows using decorators instead of explicit graph construction.\n\n## Overview\n\n- Sequential workflows with conditional branching\n- Orchestrator-worker patterns with parallel execution\n- Workflows needing persistence and checkpointing\n- Human-in-the-loop approval flows\n- Simpler alternative to explicit StateGraph construction\n\n## Core Concepts\n\n### Graph API vs Functional API\n```\nGraph API (explicit):           Functional API (implicit):\nStateGraph → add_node →        @task functions +\nadd_edge → compile              @entrypoint orchestration\n```\n\n**When to Use Functional API**:\n- Sequential workflows with conditional logic\n- Orchestrator-worker patterns\n- Simpler debugging (regular Python functions)\n- Parallel task execution\n\n## Quick Start\n\n### Basic Pattern\n```python\nfrom langgraph.func import entrypoint, task\n\n@task\ndef step_one(data: str) -> str:\n    \"\"\"Task returns a future - call .result() to block\"\"\"\n    return process(data)\n\n@task\ndef step_two(result: str) -> str:\n    return transform(result)\n\n@entrypoint()\ndef my_workflow(input_data: str) -> str:\n    # Tasks return futures - enables parallel execution\n    result1 = step_one(input_data).result()\n    result2 = step_two(result1).result()\n    return result2\n\n# Invoke\noutput = my_workflow.invoke(\"hello\")\n```\n\n### Key Rules\n1. **@task** functions return futures - call `.result()` to get value\n2. **@entrypoint** is the workflow entry point - orchestrates tasks\n3. Tasks inside entrypoint are tracked for persistence/streaming\n4. Regular functions (no decorator) execute normally\n\n## Parallel Execution\n\n### Fan-Out Pattern\n```python\n@task\ndef fetch_source_a(query: str) -> dict:\n    return api_a.search(query)\n\n@task\ndef fetch_source_b(query: str) -> dict:\n    return api_b.search(query)\n\n@task\ndef merge_results(results: list[dict]) -> dict:\n    return {\"combined\": results}\n\n@entrypoint()\ndef parallel_search(query: str) -> dict:\n    # Launch in parallel - futures start immediately\n    future_a = fetch_source_a(query)\n    future_b = fetch_source_b(query)\n\n    # Block on both results\n    results = [future_a.result(), future_b.result()]\n\n    return merge_results(results).result()\n```\n\n### Map Over Collection\n```python\n@task\ndef process_item(item: dict) -> dict:\n    return transform(item)\n\n@entrypoint()\ndef batch_workflow(items: list[dict]) -> list[dict]:\n    # Launch all in parallel\n    futures = [process_item(item) for item in items]\n\n    # Collect results\n    return [f.result() for f in futures]\n```\n\n## Persistence & Checkpointing\n\n### Enable Checkpointing\n```python\nfrom langgraph.checkpoint.memory import InMemorySaver\n\ncheckpointer = InMemorySaver()\n\n@entrypoint(checkpointer=checkpointer)\ndef resumable_workflow(data: str) -> str:\n    # Workflow state is automatically saved after each task\n    result = expensive_task(data).result()\n    return result\n\n# Use thread_id for persistence\nconfig = {\"configurable\": {\"thread_id\": \"session-123\"}}\nresult = resumable_workflow.inv",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-human-in-loop": {
    "name": "langgraph-human-in-loop",
    "description": "LangGraph human-in-the-loop patterns. Use when implementing approval workflows, manual review gates, user feedback integration, or interactive agent supervision.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "human-in-loop",
      "review",
      "approval"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "api-integration.md",
        "approval-gate.md",
        "evaluations.md",
        "feedback-loop.md",
        "interrupt-resume.md"
      ],
      "checklists": [
        "hitl-checklist.md"
      ]
    },
    "content": "# LangGraph Human-in-the-Loop\n\nPause workflows for human intervention and approval.\n\n## Basic Interrupt\n\n```python\nworkflow = StateGraph(State)\nworkflow.add_node(\"draft\", generate_draft)\nworkflow.add_node(\"review\", human_review)\nworkflow.add_node(\"publish\", publish_content)\n\n# Interrupt before review\napp = workflow.compile(interrupt_before=[\"review\"])\n\n# Step 1: Generate draft (stops at review)\nconfig = {\"configurable\": {\"thread_id\": \"doc-123\"}}\nresult = app.invoke({\"topic\": \"AI\"}, config=config)\n# Workflow pauses here\n```\n\n## Dynamic interrupt() Function (2026 Best Practice)\n\nModern approach using `interrupt()` within node logic:\n\n```python\nfrom langgraph.types import interrupt, Command\n\ndef approval_node(state: State):\n    \"\"\"Dynamic interrupt based on conditions.\"\"\"\n    # Only interrupt for high-risk actions\n    if state[\"risk_level\"] == \"high\":\n        response = interrupt({\n            \"question\": \"High-risk action detected. Approve?\",\n            \"action\": state[\"proposed_action\"],\n            \"risk_level\": state[\"risk_level\"],\n            \"details\": state[\"action_details\"]\n        })\n\n        if not response.get(\"approved\"):\n            return {\"status\": \"rejected\", \"action\": None}\n\n    # Low risk or approved - proceed\n    return {\"status\": \"approved\", \"action\": state[\"proposed_action\"]}\n```\n\n## Resume After Approval\n\n```python\n# Step 2: Human reviews and updates state\nstate = app.get_state(config)\nprint(f\"Draft: {state.values['draft']}\")\n\n# Human decision\nstate.values[\"approved\"] = True\nstate.values[\"feedback\"] = \"Looks good\"\napp.update_state(config, state.values)\n\n# Step 3: Resume workflow\nresult = app.invoke(None, config=config)  # Continues to publish\n```\n\n## Command(resume=) Pattern (2026 Best Practice)\n\n```python\nfrom langgraph.types import Command\n\nconfig = {\"configurable\": {\"thread_id\": \"workflow-123\"}}\n\n# Initial invoke - stops at interrupt\nresult = graph.invoke(initial_state, config)\n\n# Check for interrupt\nif \"__interrupt__\" in result:\n    interrupt_info = result[\"__interrupt__\"][0].value\n    print(f\"Action: {interrupt_info['action']}\")\n    print(f\"Question: {interrupt_info['question']}\")\n\n    # Get user decision\n    user_response = {\"approved\": True, \"feedback\": \"Looks good\"}\n\n    # Resume with Command\n    final = graph.invoke(Command(resume=user_response), config)\n```\n\n## Approval Gate Node\n\n```python\ndef approval_gate(state: WorkflowState) -> WorkflowState:\n    \"\"\"Check if human approved.\"\"\"\n    if not state.get(\"human_reviewed\"):\n        # Will pause here due to interrupt_before\n        return state\n\n    if state[\"approved\"]:\n        state[\"next\"] = \"publish\"\n    else:\n        state[\"next\"] = \"revise\"\n\n    return state\n\nworkflow.add_node(\"approval_gate\", approval_gate)\n\n# Pause before this node\napp = workflow.compile(interrupt_before=[\"approval_gate\"])\n```\n\n## Feedback Loop Pattern\n\n```python\nimport uuid\n\nasync def run_with_feedback(initial_state: dict):\n    \"\"\"Run until human approves.\"\"\"\n    config = {\"configurable\": {\"thre",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-parallel": {
    "name": "langgraph-parallel",
    "description": "LangGraph parallel execution patterns. Use when implementing fan-out/fan-in workflows, map-reduce over tasks, or running independent agents concurrently.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "parallel",
      "concurrency",
      "fan-out"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "error-isolation.md",
        "evaluations.md",
        "fanout-fanin.md",
        "map-reduce.md"
      ],
      "scripts": [
        "parallel-agent-fanout.py"
      ],
      "checklists": [
        "parallel-checklist.md"
      ]
    },
    "content": "# LangGraph Parallel Execution\n\nRun independent nodes concurrently for performance.\n\n## Fan-Out/Fan-In Pattern\n\n```python\nfrom langgraph.graph import StateGraph\n\ndef fan_out(state):\n    \"\"\"Split work into parallel tasks.\"\"\"\n    state[\"tasks\"] = [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]\n    return state\n\ndef worker(state):\n    \"\"\"Process one task.\"\"\"\n    task = state[\"current_task\"]\n    result = process(task)\n    return {\"results\": [result]}\n\ndef fan_in(state):\n    \"\"\"Combine parallel results.\"\"\"\n    combined = aggregate(state[\"results\"])\n    return {\"final\": combined}\n\nworkflow = StateGraph(State)\nworkflow.add_node(\"fan_out\", fan_out)\nworkflow.add_node(\"worker\", worker)\nworkflow.add_node(\"fan_in\", fan_in)\n\nworkflow.add_edge(\"fan_out\", \"worker\")\nworkflow.add_edge(\"worker\", \"fan_in\")  # Waits for all workers\n```\n\n## Using Send API\n\n```python\nfrom langgraph.constants import Send\n\ndef router(state):\n    \"\"\"Route to multiple workers in parallel.\"\"\"\n    return [\n        Send(\"worker\", {\"task\": task})\n        for task in state[\"tasks\"]\n    ]\n\nworkflow.add_conditional_edges(\"router\", router)\n```\n\n## Complete Send API Example (2026 Pattern)\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.constants import Send\nfrom typing import TypedDict, Annotated\nfrom operator import add\n\nclass OverallState(TypedDict):\n    subjects: list[str]\n    jokes: Annotated[list[str], add]  # Accumulates from parallel branches\n\nclass JokeState(TypedDict):\n    subject: str\n\ndef generate_topics(state: OverallState) -> dict:\n    \"\"\"Initial node: create list of subjects.\"\"\"\n    return {\"subjects\": [\"cats\", \"dogs\", \"programming\", \"coffee\"]}\n\ndef continue_to_jokes(state: OverallState) -> list[Send]:\n    \"\"\"Fan-out: create parallel branch for each subject.\"\"\"\n    return [\n        Send(\"generate_joke\", {\"subject\": s})\n        for s in state[\"subjects\"]\n    ]\n\ndef generate_joke(state: JokeState) -> dict:\n    \"\"\"Worker: process one subject, return to accumulator.\"\"\"\n    joke = llm.invoke(f\"Tell a short joke about {state['subject']}\")\n    return {\"jokes\": [f\"{state['subject']}: {joke.content}\"]}\n\n# Build graph\nbuilder = StateGraph(OverallState)\nbuilder.add_node(\"generate_topics\", generate_topics)\nbuilder.add_node(\"generate_joke\", generate_joke)\n\nbuilder.add_edge(START, \"generate_topics\")\nbuilder.add_conditional_edges(\"generate_topics\", continue_to_jokes)\nbuilder.add_edge(\"generate_joke\", END)  # All branches converge automatically\n\ngraph = builder.compile()\n\n# Invoke\nresult = graph.invoke({\"subjects\": [], \"jokes\": []})\n# result[\"jokes\"] contains all 4 jokes\n```\n\n## Parallel Agent Analysis\n\n```python\nfrom typing import Annotated\nfrom operator import add\n\nclass AnalysisState(TypedDict):\n    content: str\n    findings: Annotated[list[dict], add]  # Accumulates\n\nasync def run_parallel_agents(state: AnalysisState):\n    \"\"\"Run multiple agents in parallel.\"\"\"\n    agents = [security_agent, tech_agent, quality_agent]\n\n    # Run all concurrently\n    tasks = [agent.analyze(state[\"co",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-routing": {
    "name": "langgraph-routing",
    "description": "LangGraph conditional routing patterns. Use when implementing dynamic routing based on state, creating branching workflows, or building retry loops with conditional edges.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "routing",
      "conditional",
      "branching"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "conditional-edges.md",
        "evaluations.md",
        "retry-loops.md",
        "semantic-routing.md"
      ],
      "scripts": [
        "semantic-router.py"
      ],
      "checklists": [
        "routing-checklist.md"
      ]
    },
    "content": "# LangGraph Conditional Routing\n\nRoute workflow execution dynamically based on state.\n\n## Basic Conditional Edge\n\n```python\nfrom langgraph.graph import StateGraph, END\n\ndef route_based_on_quality(state: WorkflowState) -> str:\n    \"\"\"Decide next step based on quality score.\"\"\"\n    if state[\"quality_score\"] >= 0.8:\n        return \"publish\"\n    elif state[\"retry_count\"] < 3:\n        return \"retry\"\n    else:\n        return \"manual_review\"\n\nworkflow.add_conditional_edges(\n    \"quality_check\",\n    route_based_on_quality,\n    {\n        \"publish\": \"publish_node\",\n        \"retry\": \"generator\",\n        \"manual_review\": \"review_queue\"\n    }\n)\n```\n\n## Quality Gate Pattern\n\n```python\ndef route_after_quality_gate(state: AnalysisState) -> str:\n    \"\"\"Route based on quality gate result.\"\"\"\n    if state[\"quality_passed\"]:\n        return \"compress_findings\"\n    elif state[\"retry_count\"] < 2:\n        return \"supervisor\"  # Retry\n    else:\n        return END  # Return partial results\n\nworkflow.add_conditional_edges(\n    \"quality_gate\",\n    route_after_quality_gate,\n    {\n        \"compress_findings\": \"compress_findings\",\n        \"supervisor\": \"supervisor\",\n        END: END\n    }\n)\n```\n\n## Retry Loop Pattern\n\n```python\ndef llm_call_with_retry(state):\n    \"\"\"Retry failed LLM calls.\"\"\"\n    try:\n        result = call_llm(state[\"input\"])\n        state[\"output\"] = result\n        state[\"retry_count\"] = 0\n        return state\n    except Exception as e:\n        state[\"retry_count\"] += 1\n        state[\"error\"] = str(e)\n        return state\n\ndef should_retry(state) -> str:\n    if state.get(\"output\"):\n        return \"success\"\n    elif state[\"retry_count\"] < 3:\n        return \"retry\"\n    else:\n        return \"failed\"\n\nworkflow.add_conditional_edges(\n    \"llm_call\",\n    should_retry,\n    {\n        \"success\": \"next_step\",\n        \"retry\": \"llm_call\",  # Loop back\n        \"failed\": \"error_handler\"\n    }\n)\n```\n\n## Routing Patterns\n\n```\nSequential:    A → B → C              (simple edges)\nBranching:     A → (B or C)           (conditional edges)\nLooping:       A → B → A              (retry logic)\nConvergence:   (A or B) → C           (multiple inputs)\nDiamond:       A → (B, C) → D         (parallel then merge)\n```\n\n## State-Based Router\n\n```python\ndef dynamic_router(state: WorkflowState) -> str:\n    \"\"\"Route based on multiple state conditions.\"\"\"\n    if state.get(\"error\"):\n        return \"error_handler\"\n    if not state.get(\"validated\"):\n        return \"validator\"\n    if state[\"confidence\"] < 0.5:\n        return \"enhance\"\n    return \"finalize\"\n```\n\n## Command vs Conditional Edges (2026 Best Practice)\n\n```python\nfrom langgraph.types import Command\nfrom typing import Literal\n\n# Use CONDITIONAL EDGES when: Pure routing, no state updates\ndef simple_router(state: WorkflowState) -> str:\n    if state[\"score\"] > 0.8:\n        return \"approve\"\n    return \"reject\"\n\nworkflow.add_conditional_edges(\"evaluate\", simple_router)\n\n# Use COMMAND when: Updating state AND routing together\ndef router_with_s",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-state": {
    "name": "langgraph-state",
    "description": "LangGraph state management patterns. Use when designing workflow state schemas, using TypedDict vs Pydantic, implementing accumulating state with Annotated operators, or managing shared state across nodes.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "state",
      "management",
      "graphs"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "custom-reducers.md",
        "evaluations.md",
        "messages-state.md",
        "pydantic-state.md",
        "typeddict-state.md"
      ],
      "checklists": [
        "state-checklist.md"
      ]
    },
    "content": "# LangGraph State Management\n\nDesign and manage state schemas for LangGraph workflows.\n\n## TypedDict Approach (Simple)\n\n```python\nfrom typing import TypedDict, Annotated\nfrom operator import add\n\nclass WorkflowState(TypedDict):\n    input: str\n    output: str\n    agent_responses: Annotated[list[dict], add]  # Accumulates\n    metadata: dict\n```\n\n## MessagesState Pattern (2026 Best Practice)\n\n```python\nfrom langgraph.graph import MessagesState\nfrom langgraph.graph.message import add_messages\nfrom typing import Annotated\n\n# Option 1: Use built-in MessagesState (recommended)\nclass AgentState(MessagesState):\n    \"\"\"Extends MessagesState with custom fields.\"\"\"\n    user_id: str\n    context: dict\n\n# Option 2: Define messages manually with add_messages reducer\nclass CustomState(TypedDict):\n    messages: Annotated[list, add_messages]  # Smart append/update by ID\n    metadata: dict\n```\n\n**Why `add_messages` matters:**\n- Appends new messages (doesn't overwrite)\n- Updates existing messages by ID\n- Handles message deduplication automatically\n\n> **Note**: `MessageGraph` is deprecated in LangGraph v1.0.0. Use `StateGraph` with a `messages` key instead.\n\n## Pydantic Approach (Validation)\n\n```python\nfrom pydantic import BaseModel, Field\n\nclass WorkflowState(BaseModel):\n    input: str = Field(description=\"User input\")\n    output: str = \"\"\n    agent_responses: list[dict] = Field(default_factory=list)\n\n    def add_response(self, agent: str, result: str):\n        self.agent_responses.append({\"agent\": agent, \"result\": result})\n```\n\n## Accumulating State Pattern\n\n```python\nfrom typing import Annotated\nfrom operator import add\n\nclass AnalysisState(TypedDict):\n    url: str\n    raw_content: str\n\n    # Accumulate agent outputs\n    findings: Annotated[list[Finding], add]\n    embeddings: Annotated[list[Embedding], add]\n\n    # Control flow\n    current_agent: str\n    agents_completed: list[str]\n    quality_passed: bool\n```\n\n**Key Pattern: `Annotated[list[T], add]`**\n- Without `add`: Each node replaces the list\n- With `add`: Each node appends to the list\n- Critical for multi-agent workflows\n\n## Custom Reducers\n\n```python\nfrom typing import Annotated\n\ndef merge_dicts(a: dict, b: dict) -> dict:\n    \"\"\"Custom reducer that merges dictionaries.\"\"\"\n    return {**a, **b}\n\nclass State(TypedDict):\n    config: Annotated[dict, merge_dicts]  # Merges updates\n\ndef last_value(a, b):\n    \"\"\"Keep only the latest value.\"\"\"\n    return b\n\nclass State(TypedDict):\n    status: Annotated[str, last_value]  # Overwrites\n```\n\n## State Immutability\n\n```python\ndef node(state: WorkflowState) -> WorkflowState:\n    \"\"\"Return new state, don't mutate in place.\"\"\"\n    # Wrong: state[\"output\"] = \"result\"\n    # Right:\n    return {\n        **state,\n        \"output\": \"result\"\n    }\n```\n\n## Context Schema (2026 Pattern)\n\nPass runtime configuration without polluting state:\n\n```python\nfrom dataclasses import dataclass\nfrom langgraph.graph import StateGraph\n\n@dataclass\nclass ContextSchema:\n    \"\"\"Runtime configuration, n",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-streaming": {
    "name": "langgraph-streaming",
    "description": "LangGraph streaming patterns for real-time updates. Use when implementing progress indicators, token streaming, custom events, or real-time user feedback in workflows.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "streaming",
      "real-time",
      "events"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "custom-events.md",
        "evaluations.md",
        "llm-token-streaming.md",
        "stream-modes.md",
        "subgraph-streaming.md"
      ]
    },
    "content": "# LangGraph Streaming\n\nReal-time updates and progress tracking for LangGraph workflows.\n\n## 5 Stream Modes\n\n```python\n# Available modes\nfor mode, chunk in graph.stream(inputs, stream_mode=[\"values\", \"updates\", \"messages\", \"custom\", \"debug\"]):\n    print(f\"[{mode}] {chunk}\")\n```\n\n| Mode | Purpose | Use Case |\n|------|---------|----------|\n| **values** | Full state after each step | Debugging, state inspection |\n| **updates** | State deltas after each step | Efficient UI updates |\n| **messages** | LLM tokens + metadata | Chat interfaces, typing indicators |\n| **custom** | User-defined events | Progress bars, status updates |\n| **debug** | Maximum information | Development, troubleshooting |\n\n## Custom Events with StreamWriter\n\n```python\nfrom langgraph.config import get_stream_writer\n\ndef node_with_progress(state: State):\n    \"\"\"Emit custom progress events.\"\"\"\n    writer = get_stream_writer()\n\n    for i, item in enumerate(state[\"items\"]):\n        writer({\n            \"type\": \"progress\",\n            \"current\": i + 1,\n            \"total\": len(state[\"items\"]),\n            \"status\": f\"Processing {item}\"\n        })\n        result = process(item)\n\n    writer({\"type\": \"complete\", \"message\": \"All items processed\"})\n    return {\"results\": results}\n\n# Consume custom events\nfor mode, chunk in graph.stream(inputs, stream_mode=[\"updates\", \"custom\"]):\n    if mode == \"custom\":\n        if chunk.get(\"type\") == \"progress\":\n            print(f\"Progress: {chunk['current']}/{chunk['total']}\")\n    elif mode == \"updates\":\n        print(f\"State updated: {list(chunk.keys())}\")\n```\n\n## LLM Token Streaming\n\n```python\n# Stream tokens from LLM calls\nfor message_chunk, metadata in graph.stream(\n    {\"topic\": \"AI safety\"},\n    stream_mode=\"messages\"\n):\n    if message_chunk.content:\n        print(message_chunk.content, end=\"\", flush=True)\n\n# Filter by node\nfor msg, meta in graph.stream(inputs, stream_mode=\"messages\"):\n    if meta[\"langgraph_node\"] == \"writer_agent\":\n        print(msg.content, end=\"\")\n\n# Filter by tags\nmodel = init_chat_model(\"claude-sonnet-4-20250514\", tags=[\"main_response\"])\n\nfor msg, meta in graph.stream(inputs, stream_mode=\"messages\"):\n    if \"main_response\" in meta.get(\"tags\", []):\n        print(msg.content, end=\"\")\n```\n\n## Subgraph Streaming\n\n```python\n# Enable subgraph visibility\nfor namespace, chunk in graph.stream(\n    inputs,\n    subgraphs=True,\n    stream_mode=\"updates\"\n):\n    # namespace shows graph hierarchy: (), (\"child\",), (\"child\", \"grandchild\")\n    print(f\"[{'/'.join(namespace) or 'root'}] {chunk}\")\n```\n\n## Multiple Modes Simultaneously\n\n```python\n# Combine modes for comprehensive feedback\nasync for mode, chunk in graph.astream(\n    inputs,\n    stream_mode=[\"updates\", \"custom\", \"messages\"]\n):\n    match mode:\n        case \"updates\":\n            update_ui_state(chunk)\n        case \"custom\":\n            show_progress(chunk)\n        case \"messages\":\n            append_to_chat(chunk)\n```\n\n## Non-LangChain LLM Streaming\n\n```python\ndef call_custom_llm(stat",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-subgraphs": {
    "name": "langgraph-subgraphs",
    "description": "LangGraph subgraph patterns for modular workflows. Use when building nested graphs, composing reusable workflow components, or coordinating multi-agent systems with isolated state.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "subgraphs",
      "modular",
      "composition"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "add-as-node-pattern.md",
        "checkpointing-subgraphs.md",
        "evaluations.md",
        "invoke-pattern.md",
        "state-mapping.md"
      ]
    },
    "content": "# LangGraph Subgraphs\n\nCompose modular, reusable workflow components with nested graphs.\n\n## Two Primary Patterns\n\n### Pattern 1: Invoke from Node (Different Schemas)\n\nUse when subgraph needs completely isolated state.\n\n```python\nfrom langgraph.graph import StateGraph, START, END\n\n# Parent state\nclass ParentState(TypedDict):\n    query: str\n    analysis_result: dict\n\n# Subgraph state (completely different)\nclass AnalysisState(TypedDict):\n    input_text: str\n    findings: list[str]\n    score: float\n\n# Build subgraph\nanalysis_builder = StateGraph(AnalysisState)\nanalysis_builder.add_node(\"analyze\", analyze_node)\nanalysis_builder.add_node(\"score\", score_node)\nanalysis_builder.add_edge(START, \"analyze\")\nanalysis_builder.add_edge(\"analyze\", \"score\")\nanalysis_builder.add_edge(\"score\", END)\nanalysis_subgraph = analysis_builder.compile()\n\n# Parent node that invokes subgraph\ndef call_analysis(state: ParentState) -> dict:\n    \"\"\"Transform state at boundaries.\"\"\"\n    # Map parent → subgraph state\n    subgraph_input = {\"input_text\": state[\"query\"], \"findings\": [], \"score\": 0.0}\n\n    # Invoke subgraph\n    subgraph_output = analysis_subgraph.invoke(subgraph_input)\n\n    # Map subgraph → parent state\n    return {\n        \"analysis_result\": {\n            \"findings\": subgraph_output[\"findings\"],\n            \"score\": subgraph_output[\"score\"]\n        }\n    }\n\n# Add to parent graph\nparent_builder = StateGraph(ParentState)\nparent_builder.add_node(\"analysis\", call_analysis)\n```\n\n### Pattern 2: Add as Node (Shared State)\n\nUse when parent and subgraph share state keys.\n\n```python\nfrom langgraph.graph.message import add_messages\n\n# Shared state with messages channel\nclass SharedState(TypedDict):\n    messages: Annotated[list, add_messages]\n    context: dict\n\n# Subgraph uses same state\nagent_builder = StateGraph(SharedState)\nagent_builder.add_node(\"think\", think_node)\nagent_builder.add_node(\"act\", act_node)\nagent_builder.add_edge(START, \"think\")\nagent_builder.add_edge(\"think\", \"act\")\nagent_builder.add_edge(\"act\", END)\nagent_subgraph = agent_builder.compile()\n\n# Add compiled subgraph directly as node\nparent_builder = StateGraph(SharedState)\nparent_builder.add_node(\"agent_team\", agent_subgraph)  # Direct embedding\nparent_builder.add_edge(START, \"agent_team\")\nparent_builder.add_edge(\"agent_team\", END)\n```\n\n## When to Use Each Pattern\n\n| Pattern | Use When |\n|---------|----------|\n| **Invoke** | Different schemas, private message histories, multi-level nesting |\n| **Add as Node** | Shared state keys, agent coordination, message passing |\n\n## Multi-Level Nesting\n\n```python\n# Grandchild subgraph\ngrandchild = grandchild_builder.compile()\n\n# Child subgraph (contains grandchild)\ndef call_grandchild(state: ChildState):\n    result = grandchild.invoke({\"data\": state[\"input\"]})\n    return {\"processed\": result[\"output\"]}\n\nchild_builder.add_node(\"processor\", call_grandchild)\nchild = child_builder.compile()\n\n# Parent (contains child)\ndef call_child(state: ParentState):\n    result = child.inv",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "langgraph-supervisor": {
    "name": "langgraph-supervisor",
    "description": "LangGraph supervisor-worker pattern. Use when building central coordinator agents that route to specialized workers, implementing round-robin or priority-based agent dispatch.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "supervisor",
      "multi-agent",
      "orchestration"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "evaluations.md",
        "llm-supervisor.md",
        "priority-routing.md",
        "round-robin.md"
      ],
      "scripts": [
        "content-analysis-graph.py",
        "supervisor-workflow.py"
      ],
      "checklists": [
        "supervisor-checklist.md"
      ]
    },
    "content": "# LangGraph Supervisor Pattern\n\nCoordinate multiple specialized agents with a central supervisor.\n\n## Overview\n\n- Building central coordinator agents that dispatch to workers\n- Implementing round-robin or priority-based task routing\n- Tracking agent completion and workflow progress\n- Using Command API for combined state update + routing\n\n## Quick Start\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command\nfrom typing import Literal, TypedDict\n\nclass WorkflowState(TypedDict):\n    input: str\n    results: list[str]\n    agents_completed: list[str]\n\ndef supervisor(state) -> Command[Literal[\"worker_a\", \"worker_b\", END]]:\n    if \"worker_a\" not in state[\"agents_completed\"]:\n        return Command(goto=\"worker_a\")\n    elif \"worker_b\" not in state[\"agents_completed\"]:\n        return Command(goto=\"worker_b\")\n    return Command(goto=END)\n\ndef worker_a(state):\n    return {\"results\": [\"A done\"], \"agents_completed\": [\"worker_a\"]}\n\ndef worker_b(state):\n    return {\"results\": [\"B done\"], \"agents_completed\": [\"worker_b\"]}\n\n# Build graph\ngraph = StateGraph(WorkflowState)\ngraph.add_node(\"supervisor\", supervisor)\ngraph.add_node(\"worker_a\", worker_a)\ngraph.add_node(\"worker_b\", worker_b)\ngraph.add_edge(START, \"supervisor\")\ngraph.add_edge(\"worker_a\", \"supervisor\")\ngraph.add_edge(\"worker_b\", \"supervisor\")\n\napp = graph.compile()\nresult = app.invoke({\"input\": \"task\", \"results\": [], \"agents_completed\": []})\n```\n\n## Basic Supervisor\n\n```python\nfrom langgraph.graph import StateGraph, START, END\n\ndef supervisor(state: WorkflowState) -> WorkflowState:\n    \"\"\"Route to next worker based on state.\"\"\"\n    if state[\"needs_analysis\"]:\n        state[\"next\"] = \"analyzer\"\n    elif state[\"needs_validation\"]:\n        state[\"next\"] = \"validator\"\n    else:\n        state[\"next\"] = END\n    return state\n\ndef analyzer(state: WorkflowState) -> WorkflowState:\n    \"\"\"Specialized analysis worker.\"\"\"\n    result = analyze(state[\"input\"])\n    state[\"results\"].append(result)\n    return state\n\n# Build graph\nworkflow = StateGraph(WorkflowState)\nworkflow.add_node(\"supervisor\", supervisor)\nworkflow.add_node(\"analyzer\", analyzer)\nworkflow.add_node(\"validator\", validator)\n\n# Supervisor routes dynamically\nworkflow.add_conditional_edges(\n    \"supervisor\",\n    lambda s: s[\"next\"],\n    {\n        \"analyzer\": \"analyzer\",\n        \"validator\": \"validator\",\n        END: END\n    }\n)\n\n# Workers return to supervisor\nworkflow.add_edge(\"analyzer\", \"supervisor\")\nworkflow.add_edge(\"validator\", \"supervisor\")\n\nworkflow.add_edge(START, \"supervisor\")  # Use START, not set_entry_point()\napp = workflow.compile()\n```\n\n## Command API (2026 Best Practice)\n\nUse Command when you need to update state AND route in the same node:\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import Command\nfrom typing import Literal\n\ndef supervisor_with_command(state: WorkflowState) -> Command[Literal[\"analyzer\", \"validator\", END]]:\n    \"\"\"Use Command for combined state upda",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "workflow-architect"
    ]
  },
  "langgraph-tools": {
    "name": "langgraph-tools",
    "description": "LangGraph tool calling patterns. Use when binding tools to LLMs, implementing ToolNode for execution, dynamic tool selection, or adding approval gates to tool calls.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "langgraph",
      "tools",
      "function-calling",
      "agents"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "bind-tools.md",
        "dynamic-tools.md",
        "evaluations.md",
        "tool-interrupts.md",
        "toolnode.md"
      ]
    },
    "content": "# LangGraph Tool Calling\n\nIntegrate tool calling into LangGraph workflows.\n\n## Basic Tool Binding\n\n```python\nfrom langchain_core.tools import tool\nfrom langchain_anthropic import ChatAnthropic\n\n@tool\ndef search_database(query: str) -> str:\n    \"\"\"Search the database for information.\"\"\"\n    return db.search(query)\n\n@tool\ndef send_email(to: str, subject: str, body: str) -> str:\n    \"\"\"Send an email to a recipient.\"\"\"\n    email_service.send(to, subject, body)\n    return f\"Email sent to {to}\"\n\n# Bind tools to model\ntools = [search_database, send_email]\nmodel = ChatAnthropic(model=\"claude-sonnet-4-20250514\")\nmodel_with_tools = model.bind_tools(tools)\n\n# Agent node\ndef agent_node(state: State):\n    response = model_with_tools.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n```\n\n## ToolNode for Execution\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, START, END\n\n# Create tool execution node\ntool_node = ToolNode(tools)\n\n# Build agent graph\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(\"agent\", agent_node)\nbuilder.add_node(\"tools\", tool_node)\n\n# Routing based on tool calls\ndef should_continue(state: MessagesState) -> str:\n    last_message = state[\"messages\"][-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END\n\nbuilder.add_edge(START, \"agent\")\nbuilder.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\nbuilder.add_edge(\"tools\", \"agent\")  # Return to agent after tool execution\n\ngraph = builder.compile()\n```\n\n## Force Tool Calling\n\n```python\n# Force model to call at least one tool\nmodel.bind_tools(tools, tool_choice=\"any\")\n\n# Force specific tool\nmodel.bind_tools(tools, tool_choice=\"search_database\")\n\n# Structured output via tool (guaranteed schema)\nfrom pydantic import BaseModel\n\nclass SearchResult(BaseModel):\n    query: str\n    results: list[str]\n    confidence: float\n\nmodel.bind_tools([SearchResult], tool_choice=\"SearchResult\")\n```\n\n## Dynamic Tool Selection\n\n```python\nfrom sentence_transformers import SentenceTransformer\n\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# Pre-compute tool embeddings\nTOOL_EMBEDDINGS = {\n    tool.name: embedder.encode(tool.description)\n    for tool in all_tools\n}\n\ndef select_relevant_tools(query: str, all_tools: list, top_k: int = 5) -> list:\n    \"\"\"Select most relevant tools based on query.\"\"\"\n    query_embedding = embedder.encode(query)\n\n    similarities = [\n        (tool, cosine_similarity(query_embedding, TOOL_EMBEDDINGS[tool.name]))\n        for tool in all_tools\n    ]\n\n    sorted_tools = sorted(similarities, key=lambda x: x[1], reverse=True)\n    return [tool for tool, _ in sorted_tools[:top_k]]\n\ndef agent_with_dynamic_tools(state: State):\n    \"\"\"Bind only relevant tools to reduce context.\"\"\"\n    relevant_tools = select_relevant_tools(\n        state[\"messages\"][-1].content,\n        all_tools,\n        top_k=5\n    )\n\n    model_bound = model.bind_tools(relevant_tools)\n    response = model_bound.invoke(state[\"",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "lazy-loading-patterns": {
    "name": "lazy-loading-patterns",
    "description": "Code splitting and lazy loading with React.lazy, Suspense, route-based splitting, intersection observer, and preload strategies for optimal bundle performance. Use when implementing lazy loading or preloading.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "lazy-loading",
      "code-splitting",
      "suspense",
      "dynamic-import",
      "intersection-observer",
      "preload",
      "react-19",
      "performance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "route-splitting.md"
      ],
      "scripts": [
        "lazy-component.tsx"
      ]
    },
    "content": "# Lazy Loading Patterns\n\nCode splitting and lazy loading patterns for React 19 applications using `React.lazy`, `Suspense`, route-based splitting, and intersection observer strategies.\n\n## Overview\n\n- Reducing initial bundle size for faster page loads\n- Route-based code splitting in SPAs\n- Lazy loading heavy components (charts, editors, modals)\n- Below-the-fold content loading\n- Conditional feature loading based on user permissions\n- Progressive image and media loading\n\n## Core Patterns\n\n### 1. React.lazy + Suspense (Standard Pattern)\n\n```tsx\nimport { lazy, Suspense } from 'react';\n\n// Lazy load component - code split at this boundary\nconst HeavyEditor = lazy(() => import('./HeavyEditor'));\n\nfunction EditorPage() {\n  return (\n    <Suspense fallback={<EditorSkeleton />}>\n      <HeavyEditor />\n    </Suspense>\n  );\n}\n\n// With named exports (requires intermediate module)\nconst Chart = lazy(() =>\n  import('./charts').then(module => ({ default: module.LineChart }))\n);\n```\n\n### 2. React 19 `use()` Hook (Modern Pattern)\n\n```tsx\nimport { use, Suspense } from 'react';\n\n// Create promise outside component\nconst dataPromise = fetchData();\n\nfunction DataDisplay() {\n  // Suspense-aware promise unwrapping\n  const data = use(dataPromise);\n  return <div>{data.title}</div>;\n}\n\n// Usage with Suspense\n<Suspense fallback={<Skeleton />}>\n  <DataDisplay />\n</Suspense>\n```\n\n### 3. Route-Based Code Splitting (React Router 7.x)\n\n```tsx\nimport { lazy } from 'react';\nimport { createBrowserRouter, RouterProvider } from 'react-router';\n\n// Lazy load route components\nconst Dashboard = lazy(() => import('./pages/Dashboard'));\nconst Settings = lazy(() => import('./pages/Settings'));\nconst Analytics = lazy(() => import('./pages/Analytics'));\n\nconst router = createBrowserRouter([\n  {\n    path: '/',\n    element: <Layout />,\n    children: [\n      { path: 'dashboard', element: <Dashboard /> },\n      { path: 'settings', element: <Settings /> },\n      { path: 'analytics', element: <Analytics /> },\n    ],\n  },\n]);\n\n// Root with Suspense boundary\nfunction App() {\n  return (\n    <Suspense fallback={<PageSkeleton />}>\n      <RouterProvider router={router} />\n    </Suspense>\n  );\n}\n```\n\n### 4. Intersection Observer Lazy Loading\n\n```tsx\nimport { useRef, useState, useEffect, lazy, Suspense } from 'react';\n\nconst HeavyComponent = lazy(() => import('./HeavyComponent'));\n\nfunction LazyOnScroll({ children }: { children: React.ReactNode }) {\n  const ref = useRef<HTMLDivElement>(null);\n  const [isVisible, setIsVisible] = useState(false);\n\n  useEffect(() => {\n    const observer = new IntersectionObserver(\n      ([entry]) => {\n        if (entry.isIntersecting) {\n          setIsVisible(true);\n          observer.disconnect();\n        }\n      },\n      { rootMargin: '100px' } // Load 100px before visible\n    );\n\n    if (ref.current) observer.observe(ref.current);\n    return () => observer.disconnect();\n  }, []);\n\n  return (\n    <div ref={ref}>\n      {isVisible ? children : <Placeholder />}\n    </div>\n  )",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "performance-engineer"
    ]
  },
  "llm-evaluation": {
    "name": "llm-evaluation",
    "description": "LLM output evaluation and quality assessment. Use when implementing LLM-as-judge patterns, quality gates for AI outputs, or automated evaluation pipelines.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "evaluation",
      "llm",
      "quality",
      "ragas",
      "langfuse"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "evaluation-metrics.md"
      ],
      "scripts": [
        "evaluator-template.py"
      ],
      "checklists": [
        "evaluation-checklist.md"
      ]
    },
    "content": "# LLM Evaluation\n\nEvaluate and validate LLM outputs for quality assurance using RAGAS and LLM-as-judge patterns.\n\n## Quick Reference\n\n### LLM-as-Judge Pattern\n\n```python\nasync def evaluate_quality(input_text: str, output_text: str, dimension: str) -> float:\n    response = await llm.chat([{\n        \"role\": \"user\",\n        \"content\": f\"\"\"Evaluate for {dimension}. Score 1-10.\nInput: {input_text[:500]}\nOutput: {output_text[:1000]}\nRespond with just the number.\"\"\"\n    }])\n    return int(response.content.strip()) / 10\n```\n\n### Quality Gate\n\n```python\nQUALITY_THRESHOLD = 0.7\n\nasync def quality_gate(state: dict) -> dict:\n    scores = await full_quality_assessment(state[\"input\"], state[\"output\"])\n    passed = scores[\"average\"] >= QUALITY_THRESHOLD\n    return {**state, \"quality_passed\": passed}\n```\n\n### Hallucination Detection\n\n```python\nasync def detect_hallucination(context: str, output: str) -> dict:\n    # Check if output contains claims not in context\n    return {\"has_hallucinations\": bool, \"unsupported_claims\": []}\n```\n\n## RAGAS Metrics ()\n\n| Metric | Use Case | Threshold |\n|--------|----------|-----------|\n| Faithfulness | RAG grounding | ≥ 0.8 |\n| Answer Relevancy | Q&A systems | ≥ 0.7 |\n| Context Precision | Retrieval quality | ≥ 0.7 |\n| Context Recall | Retrieval completeness | ≥ 0.7 |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# ❌ NEVER use same model as judge and evaluated\noutput = await gpt4.complete(prompt)\nscore = await gpt4.evaluate(output)  # Same model!\n\n# ❌ NEVER use single dimension\nif relevance_score > 0.7:  # Only checking one thing\n    return \"pass\"\n\n# ❌ NEVER set threshold too high\nTHRESHOLD = 0.95  # Blocks most content\n\n# ✅ ALWAYS use different judge model\nscore = await gpt4_mini.evaluate(claude_output)\n\n# ✅ ALWAYS use multiple dimensions\nscores = await evaluate_all_dimensions(output)\nif scores[\"average\"] > 0.7:\n    return \"pass\"\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Judge model | GPT-5.2-mini or Claude Haiku 4.5 |\n| Threshold | 0.7 for production, 0.6 for drafts |\n| Dimensions | 3-5 most relevant to use case |\n| Sample size | 50+ for reliable metrics |\n\n## Detailed Documentation\n\n| Resource | Description |\n|----------|-------------|\n| [references/evaluation-metrics.md](references/evaluation-metrics.md) | RAGAS & LLM-as-judge metrics |\n| [examples/evaluation-patterns.md](examples/evaluation-patterns.md) | Complete evaluation examples |\n| [checklists/evaluation-checklist.md](checklists/evaluation-checklist.md) | Setup and review checklists |\n| [scripts/evaluator-template.py](scripts/evaluator-template.py) | Starter evaluation template |\n\n## Related Skills\n\n- `quality-gates` - Workflow quality control\n- `langfuse-observability` - Tracking evaluation scores\n- `agent-loops` - Self-correcting with evaluation\n\n## Capability Details\n\n### llm-as-judge\n**Keywords:** LLM judge, judge model, evaluation model, grader LLM\n**Solves:**\n- Use LLM to evaluate other LLM outputs\n- Implement judge prompts f",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator",
      "prompt-engineer"
    ]
  },
  "llm-safety-patterns": {
    "name": "llm-safety-patterns",
    "description": "Security patterns for LLM integrations including prompt injection defense and hallucination prevention. Use when implementing context separation, validating LLM outputs, or protecting against prompt injection attacks.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ai",
      "safety",
      "guardrails",
      "security",
      "llm"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "context-separation.md",
        "output-guardrails.md",
        "post-llm-attribution.md",
        "pre-llm-filtering.md",
        "prompt-audit.md"
      ],
      "scripts": [
        "prompt_builder.py",
        "safe_llm_call.py"
      ],
      "checklists": [
        "pre-llm-call.md",
        "safety-checklist.md"
      ]
    },
    "content": "# LLM Safety Patterns\n\n## The Core Principle\n\n> **Identifiers flow AROUND the LLM, not THROUGH it.**\n> **The LLM sees only content. Attribution happens deterministically.**\n\n## Why This Matters\n\nWhen identifiers appear in prompts, bad things happen:\n\n1. **Hallucination:** LLM invents IDs that don't exist\n2. **Confusion:** LLM mixes up which ID belongs where\n3. **Injection:** Attacker manipulates IDs via prompt injection\n4. **Leakage:** IDs appear in logs, caches, traces\n5. **Cross-tenant:** LLM could reference other users' data\n\n## The Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                                                                         │\n│   SYSTEM CONTEXT (flows around LLM)                                     │\n│   ┌─────────────────────────────────────────────────────────────────┐   │\n│   │ user_id │ tenant_id │ analysis_id │ trace_id │ permissions     │   │\n│   └─────────────────────────────────────────────────────────────────┘   │\n│        │                                                       │        │\n│        │                                                       │        │\n│        ▼                                                       ▼        │\n│   ┌─────────┐                                           ┌─────────┐    │\n│   │ PRE-LLM │       ┌─────────────────────┐            │POST-LLM │    │\n│   │ FILTER  │──────▶│        LLM          │───────────▶│ATTRIBUTE│    │\n│   │         │       │                     │            │         │    │\n│   │ Returns │       │ Sees ONLY:          │            │ Adds:   │    │\n│   │ CONTENT │       │ - content text      │            │ - IDs   │    │\n│   │ (no IDs)│       │ - context text      │            │ - refs  │    │\n│   └─────────┘       │ (NO IDs!)           │            └─────────┘    │\n│                     └─────────────────────┘                            │\n│                                                                         │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n## What NEVER Goes in Prompts\n\n### OrchestKit Forbidden Parameters\n\n| Parameter | Type | Why Forbidden |\n|-----------|------|---------------|\n| `user_id` | UUID | Can be hallucinated, enables cross-user access |\n| `tenant_id` | UUID | Critical for multi-tenant isolation |\n| `analysis_id` | UUID | Job tracking, not for LLM |\n| `document_id` | UUID | Source tracking, not for LLM |\n| `artifact_id` | UUID | Output tracking, not for LLM |\n| `chunk_id` | UUID | RAG reference, not for LLM |\n| `session_id` | str | Auth context, not for LLM |\n| `trace_id` | str | Observability, not for LLM |\n| Any UUID | UUID | Pattern: `[0-9a-f]{8}-...` |\n\n### Detection Pattern\n\n```python\nimport re\n\nFORBIDDEN_PATTERNS = [\n    r'user[_-]?id',\n    r'tenant[_-]?id',\n    r'analysis[_-]?id',\n    r'document[_-]?id',\n    r'artifact[_-]?id',\n    r'chunk[_-]?id',\n    r'session[_-]?id',\n    r'trace[_-]?id',\n    r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ai-safety-auditor",
      "llm-integrator",
      "security-auditor"
    ]
  },
  "llm-streaming": {
    "name": "llm-streaming",
    "description": "LLM streaming response patterns. Use when implementing real-time token streaming, Server-Sent Events for AI responses, or streaming with tool calls.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "llm",
      "streaming",
      "sse",
      "real-time"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "checklists": [
        "streaming-checklist.md"
      ]
    },
    "content": "# LLM Streaming\n\nDeliver LLM responses in real-time for better UX.\n\n## Basic Streaming (OpenAI)\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nasync def stream_response(prompt: str):\n    \"\"\"Stream tokens as they're generated.\"\"\"\n    stream = client.chat.completions.create(\n        model=\"gpt-5.2\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        stream=True\n    )\n\n    for chunk in stream:\n        if chunk.choices[0].delta.content:\n            yield chunk.choices[0].delta.content\n```\n\n## Streaming with Async\n\n```python\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\nasync def async_stream(prompt: str):\n    \"\"\"Async streaming for better concurrency.\"\"\"\n    stream = await client.chat.completions.create(\n        model=\"gpt-5.2\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        stream=True\n    )\n\n    async for chunk in stream:\n        if chunk.choices[0].delta.content:\n            yield chunk.choices[0].delta.content\n```\n\n## FastAPI SSE Endpoint\n\n```python\nfrom fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nfrom sse_starlette.sse import EventSourceResponse\n\napp = FastAPI()\n\n@app.get(\"/chat/stream\")\nasync def stream_chat(prompt: str):\n    \"\"\"Server-Sent Events endpoint for streaming.\"\"\"\n    async def generate():\n        async for token in async_stream(prompt):\n            yield {\n                \"event\": \"token\",\n                \"data\": token\n            }\n        yield {\"event\": \"done\", \"data\": \"\"}\n\n    return EventSourceResponse(generate())\n```\n\n## Frontend SSE Consumer\n\n```typescript\nasync function streamChat(prompt: string, onToken: (t: string) => void) {\n  const response = await fetch(\"/chat/stream?prompt=\" + encodeURIComponent(prompt));\n  const reader = response.body?.getReader();\n  const decoder = new TextDecoder();\n\n  while (reader) {\n    const { done, value } = await reader.read();\n    if (done) break;\n\n    const text = decoder.decode(value);\n    const lines = text.split('\\n');\n\n    for (const line of lines) {\n      if (line.startsWith('data: ')) {\n        const data = line.slice(6);\n        if (data !== '[DONE]') {\n          onToken(data);\n        }\n      }\n    }\n  }\n}\n\n// Usage\nlet fullResponse = '';\nawait streamChat('Hello', (token) => {\n  fullResponse += token;\n  setDisplayText(fullResponse);  // Update UI incrementally\n});\n```\n\n## Streaming with Tool Calls\n\n```python\nasync def stream_with_tools(messages: list, tools: list):\n    \"\"\"Handle streaming responses that include tool calls.\"\"\"\n    stream = await client.chat.completions.create(\n        model=\"gpt-5.2\",\n        messages=messages,\n        tools=tools,\n        stream=True\n    )\n\n    collected_content = \"\"\n    collected_tool_calls = []\n\n    async for chunk in stream:\n        delta = chunk.choices[0].delta\n\n        # Collect content tokens\n        if delta.content:\n            collected_content += delta.content\n            yield {\"type\": \"content\", \"data\": delta.content}\n\n        # Collect tool call chunks\n        i",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator",
      "multimodal-specialist",
      "prompt-engineer"
    ]
  },
  "llm-testing": {
    "name": "llm-testing",
    "description": "Testing patterns for LLM-based applications. Use when testing AI/ML integrations, mocking LLM responses, testing async timeouts, or validating structured outputs from LLMs.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "llm",
      "ai",
      "deepeval",
      "ragas"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "deepeval-ragas-api.md"
      ],
      "scripts": [
        "llm-test-template.py"
      ],
      "checklists": [
        "llm-test-checklist.md"
      ]
    },
    "content": "# LLM Testing Patterns\n\nTest AI applications with deterministic patterns using DeepEval and RAGAS.\n\n## Quick Reference\n\n### Mock LLM Responses\n\n```python\nfrom unittest.mock import AsyncMock, patch\n\n@pytest.fixture\ndef mock_llm():\n    mock = AsyncMock()\n    mock.return_value = {\"content\": \"Mocked response\", \"confidence\": 0.85}\n    return mock\n\n@pytest.mark.asyncio\nasync def test_with_mocked_llm(mock_llm):\n    with patch(\"app.core.model_factory.get_model\", return_value=mock_llm):\n        result = await synthesize_findings(sample_findings)\n    assert result[\"summary\"] is not None\n```\n\n### DeepEval Quality Testing\n\n```python\nfrom deepeval import assert_test\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\n\ntest_case = LLMTestCase(\n    input=\"What is the capital of France?\",\n    actual_output=\"The capital of France is Paris.\",\n    retrieval_context=[\"Paris is the capital of France.\"],\n)\n\nmetrics = [\n    AnswerRelevancyMetric(threshold=0.7),\n    FaithfulnessMetric(threshold=0.8),\n]\n\nassert_test(test_case, metrics)\n```\n\n### Timeout Testing\n\n```python\nimport asyncio\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_respects_timeout():\n    with pytest.raises(asyncio.TimeoutError):\n        async with asyncio.timeout(0.1):\n            await slow_llm_call()\n```\n\n## Quality Metrics ()\n\n| Metric | Threshold | Purpose |\n|--------|-----------|---------|\n| Answer Relevancy | ≥ 0.7 | Response addresses question |\n| Faithfulness | ≥ 0.8 | Output matches context |\n| Hallucination | ≤ 0.3 | No fabricated facts |\n| Context Precision | ≥ 0.7 | Retrieved contexts relevant |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# ❌ NEVER test against live LLM APIs in CI\nresponse = await openai.chat.completions.create(...)\n\n# ❌ NEVER use random seeds (non-deterministic)\nmodel.generate(seed=random.randint(0, 100))\n\n# ❌ NEVER skip timeout handling\nawait llm_call()  # No timeout!\n\n# ✅ ALWAYS mock LLM in unit tests\nwith patch(\"app.llm\", mock_llm):\n    result = await function_under_test()\n\n# ✅ ALWAYS use VCR.py for integration tests\n@pytest.mark.vcr()\nasync def test_llm_integration():\n    ...\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Mock vs VCR | VCR for integration, mock for unit |\n| Timeout | Always test with < 1s timeout |\n| Schema validation | Test both valid and invalid |\n| Edge cases | Test all null/empty paths |\n| Quality metrics | Use multiple dimensions (3-5) |\n\n## Detailed Documentation\n\n| Resource | Description |\n|----------|-------------|\n| [references/deepeval-ragas-api.md](references/deepeval-ragas-api.md) | DeepEval & RAGAS API reference |\n| [examples/test-patterns.md](examples/test-patterns.md) | Complete test examples |\n| [checklists/llm-test-checklist.md](checklists/llm-test-checklist.md) | Setup and review checklists |\n| [scripts/llm-test-template.py](scripts/llm-test-template.py) | Starter test template |\n\n## Related Skills\n\n- `vcr-http-recording` - Record LLM r",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "manim-visualizer": {
    "name": "manim-visualizer",
    "description": "Create Manim animations for demo videos. Use when visualizing agent workflows, skill pipelines, or architecture diagrams as animated MP4 overlays",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "manim",
      "animation",
      "visualization",
      "diagram",
      "video"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "agent-spawning.md",
        "workflow-animation.md"
      ],
      "scripts": [
        "__init__.py",
        "agent_spawning.py",
        "base.py",
        "generate.py",
        "task_dependency.py"
      ]
    },
    "content": "# Manim Visualizer\n\nCreates animated visualizations using Manim (3Blue1Brown's animation engine).\n\n## Quick Start\n\n```bash\n# Install manim\npip install manim\n\n# Generate visualization\npython scripts/visualize.py explore --type=workflow\n```\n\n## Visualization Types\n\n### 1. Workflow Animation\nShows skill execution phases as animated flowchart.\n\n```python\n# Input: SkillMetadata with phases\n# Output: workflow-{skill}.mp4\n\nPhases flow left-to-right with:\n- Phase boxes appearing sequentially\n- Tool icons animating in\n- Parallel phases shown side-by-side\n- Completion checkmarks\n```\n\n### 2. Agent Spawning\nVisualizes parallel agent spawning from Task tool.\n\n```python\n# Shows:\n# - Central orchestrator\n# - Agents spawning outward\n# - Parallel execution lines\n# - Results merging back\n```\n\n### 3. Architecture Diagram\nStatic-to-animated architecture visualization.\n\n```python\n# Components:\n# - Boxes for services/modules\n# - Arrows for data flow\n# - Highlights for focus areas\n```\n\n## Output Specs\n\n| Type | Resolution | Duration | FPS |\n|------|------------|----------|-----|\n| workflow | 1920x400 | 5-10s | 30 |\n| agents | 1920x600 | 3-5s | 30 |\n| architecture | 1920x1080 | 5-8s | 30 |\n\n## Integration with Remotion\n\nManim outputs are imported as overlays:\n\n```tsx\n<Sequence from={hookEnd} durationInFrames={150}>\n  <OffthreadVideo src={staticFile(\"manim/workflow.mp4\")} />\n</Sequence>\n```\n\n## Color Palette\n\nMatches OrchestKit branding:\n- Primary: #8b5cf6 (purple)\n- Success: #22c55e (green)\n- Warning: #f59e0b (amber)\n- Info: #06b6d4 (cyan)\n- Background: #0a0a0f (dark)\n\n## Related Skills\n\n- `remotion-composer`: Combines Manim MP4 outputs with terminal recordings\n- `demo-producer`: Full demo pipeline orchestration\n- `terminal-demo-generator`: Terminal recordings that pair with Manim animations\n- `video-storyboarding`: Scene planning before animation creation",
    "contentTruncated": false,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": [
      "demo-producer"
    ]
  },
  "market-analysis-patterns": {
    "name": "market-analysis-patterns",
    "description": "TAM/SAM/SOM market sizing, Porter's Five Forces, competitive analysis, and SWOT frameworks. Use when sizing market opportunities, analyzing competition, or assessing industry dynamics.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "market",
      "tam",
      "sam",
      "som",
      "porter",
      "competitive",
      "swot"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "market-intelligence",
    "structure": {
      "references": [
        "competitive-analysis-guide.md",
        "tam-sam-som-guide.md"
      ],
      "assets": [
        "market-research-template.md"
      ],
      "checklists": [
        "market-research-checklist.md"
      ]
    },
    "content": "# Market Analysis Patterns\n\nFrameworks for sizing markets, analyzing competition, and understanding industry dynamics.\n\n## TAM SAM SOM Framework\n\nMarket sizing from total opportunity to achievable share.\n\n### Definitions\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                         TAM                              │\n│        Total Addressable Market                         │\n│     (Everyone who could possibly buy)                   │\n│  ┌───────────────────────────────────────────────────┐  │\n│  │                      SAM                           │  │\n│  │       Serviceable Addressable Market              │  │\n│  │    (Segment you can actually reach)               │  │\n│  │  ┌─────────────────────────────────────────────┐  │  │\n│  │  │                   SOM                        │  │  │\n│  │  │     Serviceable Obtainable Market           │  │  │\n│  │  │   (Realistic share you can capture)         │  │  │\n│  │  └─────────────────────────────────────────────┘  │  │\n│  └───────────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────┘\n```\n\n| Metric | Definition | Example |\n|--------|------------|---------|\n| **TAM** | Total market demand globally | All project management software: $10B |\n| **SAM** | Your target segment | Enterprise PM software in North America: $3B |\n| **SOM** | What you can realistically capture | First 3 years with current resources: $50M |\n\n### Calculation Methods\n\n**Top-Down Approach:**\n```\nTAM = (# of potential customers) × (annual value per customer)\nSAM = TAM × (% addressable by your solution)\nSOM = SAM × (realistic market share %)\n```\n\n**Bottom-Up Approach:**\n```\nSOM = (# of customers you can acquire) × (average deal size)\nSAM = SOM / (your expected market share %)\nTAM = SAM / (segment % of total market)\n```\n\n### Example Analysis\n\n```markdown\n## Market Sizing: AI Code Review Tool\n\n### TAM (Total Addressable Market)\n- Global developers: 28 million\n- % using code review tools: 60%\n- Addressable developers: 16.8 million\n- Average annual spend: $300/developer\n- **TAM = $5.04 billion**\n\n### SAM (Serviceable Addressable Market)\n- Focus: Enterprise (>500 employees)\n- Enterprise developers: 8 million (48% of addressable)\n- Willing to pay premium: 40%\n- Target developers: 3.2 million\n- **SAM = $960 million**\n\n### SOM (Serviceable Obtainable Market)\n- Year 1-3 realistic market share: 2%\n- **SOM = $19.2 million**\n```\n\n## Porter's Five Forces\n\nAnalyze industry competitive dynamics.\n\n### The Five Forces\n\n```\n                    ┌─────────────────────┐\n                    │  Threat of New      │\n                    │     Entrants        │\n                    │    (Barrier height) │\n                    └─────────┬───────────┘\n                              │\n                              ▼\n┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n│   Bargaining    │    │   Competitive   │    │   Bargaining    │\n│   Power of      │◄───│    Rivalry      │",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "market-intelligence",
      "product-strategist",
      "web-research-analyst"
    ]
  },
  "mcp-advanced-patterns": {
    "name": "mcp-advanced-patterns",
    "description": "Advanced MCP patterns for tool composition, resource management, and scaling. Build custom MCP servers, compose tools, manage resources efficiently. Use when composing MCP tools or scaling MCP servers.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "mcp",
      "tools",
      "resources",
      "scaling",
      "servers",
      "composition"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "resource-management.md",
        "scaling-strategies.md",
        "server-building-advanced.md",
        "tool-composition.md"
      ],
      "scripts": [
        "mcp-server-template.py"
      ],
      "checklists": [
        "mcp-production.md"
      ]
    },
    "content": "# MCP Advanced Patterns\n\nAdvanced Model Context Protocol patterns for production-grade MCP implementations.\n\n> **FastMCP 2.14.x** (Jan ): Enterprise auth, OpenAPI/FastAPI generation, server composition, proxying. Python 3.10-3.13.\n\n## Overview\n\n- Composing multiple tools into orchestrated workflows\n- Managing resource lifecycle and caching efficiently\n- Scaling MCP servers horizontally with load balancing\n- Building custom MCP servers with middleware and transports\n- Implementing auto-enable thresholds for context management\n\n## Tool Composition Pattern\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Awaitable\n\n@dataclass\nclass ComposedTool:\n    \"\"\"Combine multiple tools into a single pipeline operation.\"\"\"\n    name: str\n    tools: dict[str, Callable[..., Awaitable[Any]]]\n    pipeline: list[str]\n\n    async def execute(self, input_data: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Execute tool pipeline sequentially.\"\"\"\n        result = input_data\n        for tool_name in self.pipeline:\n            tool = self.tools[tool_name]\n            result = await tool(result)\n        return result\n\n# Example: Search + Summarize composition\nsearch_summarize = ComposedTool(\n    name=\"search_and_summarize\",\n    tools={\n        \"search\": search_documents,\n        \"summarize\": summarize_content,\n    },\n    pipeline=[\"search\", \"summarize\"]\n)\n```\n\n## FastMCP Server with Lifecycle\n\n```python\nfrom contextlib import asynccontextmanager\nfrom collections.abc import AsyncIterator\nfrom dataclasses import dataclass\nfrom mcp.server.fastmcp import Context, FastMCP\n\n@dataclass\nclass AppContext:\n    \"\"\"Typed application context with shared resources.\"\"\"\n    db: Database\n    cache: CacheService\n    config: dict\n\n@asynccontextmanager\nasync def app_lifespan(server: FastMCP) -> AsyncIterator[AppContext]:\n    \"\"\"Manage server startup and shutdown lifecycle.\"\"\"\n    # Initialize on startup\n    db = await Database.connect()\n    cache = await CacheService.connect()\n\n    try:\n        yield AppContext(db=db, cache=cache, config={\"timeout\": 30})\n    finally:\n        # Cleanup on shutdown\n        await cache.disconnect()\n        await db.disconnect()\n\nmcp = FastMCP(\"Production Server\", lifespan=app_lifespan)\n\n@mcp.tool()\ndef query_data(sql: str, ctx: Context) -> str:\n    \"\"\"Execute query using shared connection.\"\"\"\n    app_ctx = ctx.request_context.lifespan_context\n    return app_ctx.db.query(sql)\n```\n\n## Auto-Enable Thresholds (CC 2.1.9)\n\nConfigure MCP servers to auto-enable/disable based on context window usage:\n\n```yaml\n# .claude/settings.json\nmcp:\n  context7:\n    enabled: auto:75    # High-value docs, keep available longer\n  sequential-thinking:\n    enabled: auto:60    # Complex reasoning needs room\n  memory:\n    enabled: auto:90    # Knowledge graph - preserve until compaction\n  playwright:\n    enabled: auto:50    # Browser-heavy, disable early\n```\n\n**Threshold Guidelines:**\n| Threshold | Use Case | Rationale |\n|-----------|----------|-----------|\n| aut",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator"
    ]
  },
  "mcp-security-hardening": {
    "name": "mcp-security-hardening",
    "description": "MCP security patterns for prompt injection defense, tool poisoning prevention, and permission management. Use when securing MCP servers, validating tool descriptions, implementing allowlists.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "mcp",
      "security",
      "prompt-injection",
      "tool-poisoning",
      "allowlist",
      "zero-trust"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "prompt-injection-defense.md",
        "session-security.md",
        "tool-permissions.md",
        "tool-poisoning-attacks.md"
      ],
      "scripts": [
        "session-security.py",
        "tool-allowlist.py"
      ],
      "checklists": [
        "mcp-security-audit.md"
      ]
    },
    "content": "# MCP Security Hardening\n\nDefense-in-depth security patterns for Model Context Protocol (MCP) integrations.\n\n## Overview\n\n- Securing MCP server implementations\n- Validating tool descriptions before LLM exposure\n- Implementing zero-trust tool allowlists\n- Detecting tool poisoning attacks (TPA)\n- Managing tool permissions and capabilities\n\n## Core Security Principle\n\n> **Treat ALL tool descriptions as untrusted input.**\n> **Validate tool identity with hash verification.**\n> **Apply least privilege to all tool capabilities.**\n\n## Threat Model Summary\n\n| Attack Vector | Defense | Implementation |\n|---------------|---------|----------------|\n| Tool Poisoning (TPA) | Zero-trust allowlist | Hash verification, mandatory vetting |\n| Prompt Injection | Description sanitization | Regex filtering, encoding detection |\n| Rug Pull | Change detection | Hash comparison on each invocation |\n| Data Exfiltration | Output filtering | Sensitive pattern removal |\n| Session Hijacking | Secure sessions | Cryptographic IDs, no auth in sessions |\n\n## Layer 1: Tool Description Sanitization\n\n```python\nimport re\n\nFORBIDDEN_PATTERNS = [\n    r\"ignore previous\", r\"system prompt\", r\"<.*instruction.*>\",\n    r\"IMPORTANT:\", r\"override\", r\"admin\", r\"sudo\",\n    r\"\\\\x[0-9a-fA-F]{2}\",  # Hex encoding\n    r\"&#x?[0-9a-fA-F]+;\",  # HTML entities\n]\n\ndef sanitize_tool_description(description: str) -> str:\n    \"\"\"Remove instruction-like phrases or encoding tricks.\"\"\"\n    if not description:\n        return \"\"\n    sanitized = description\n    for pattern in FORBIDDEN_PATTERNS:\n        sanitized = re.sub(pattern, \"[REDACTED]\", sanitized, flags=re.I)\n    return sanitized.strip()\n\ndef detect_injection_attempt(description: str) -> str | None:\n    \"\"\"Detect prompt injection patterns.\"\"\"\n    indicators = [\n        (r\"ignore.*previous\", \"instruction_override\"),\n        (r\"you are now\", \"role_hijack\"),\n        (r\"forget.*above\", \"context_wipe\"),\n    ]\n    for pattern, attack_type in indicators:\n        if re.search(pattern, description, re.I):\n            return attack_type\n    return None\n```\n\n## Layer 2: Zero-Trust Tool Allowlist\n\n```python\nfrom hashlib import sha256\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\n\n@dataclass\nclass AllowedTool:\n    name: str\n    description_hash: str\n    capabilities: list[str]\n    approved_at: datetime\n    approved_by: str\n    max_calls_per_minute: int = 60\n    requires_human_approval: bool = False\n\nclass MCPToolAllowlist:\n    \"\"\"Zero-trust allowlist - every tool must be explicitly vetted.\"\"\"\n\n    def __init__(self):\n        self._allowed_tools: dict[str, AllowedTool] = {}\n        self._call_counts: dict[str, list[datetime]] = {}\n\n    def register(self, tool: AllowedTool) -> None:\n        self._allowed_tools[tool.name] = tool\n        self._call_counts[tool.name] = []\n\n    def compute_hash(self, description: str) -> str:\n        return sha256(description.encode('utf-8')).hexdigest()\n\n    def validate(self, tool_name: str, description: str) -",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ai-safety-auditor",
      "security-auditor"
    ]
  },
  "mcp-server-building": {
    "name": "mcp-server-building",
    "description": "Building MCP (Model Context Protocol) servers for Claude extensibility. Use when creating MCP servers, building custom Claude tools, extending Claude with external integrations, or developing tool packages for Claude Desktop.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "mcp",
      "server",
      "tools",
      "integration"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "auto-discovery.md",
        "resource-patterns.md",
        "testing-patterns.md",
        "tool-definitions.md",
        "transport-patterns.md"
      ]
    },
    "content": "# MCP Server Building\n\nBuild custom MCP servers to extend Claude with tools, resources, and prompts.\n\n## Architecture\n\n```\n+-------------+     JSON-RPC      +-------------+\n|   Claude    |<----------------->| MCP Server  |\n|   (Host)    |   stdio/SSE/WS    |  (Tools)    |\n+-------------+                   +-------------+\n```\n\n**Three Primitives:**\n- **Tools**: Functions Claude can call (with user approval)\n- **Resources**: Data Claude can read (files, API responses)\n- **Prompts**: Pre-defined prompt templates\n\n## Quick Start\n\n### Minimal Python Server (stdio)\n\n```python\nfrom mcp.server import Server\nfrom mcp.server.stdio import stdio_server\nfrom mcp.types import Tool, TextContent\n\nserver = Server(\"my-tools\")\n\n@server.list_tools()\nasync def list_tools() -> list[Tool]:\n    return [\n        Tool(\n            name=\"greet\",\n            description=\"Greet a user by name\",\n            inputSchema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": {\"type\": \"string\", \"description\": \"Name to greet\"}\n                },\n                \"required\": [\"name\"]\n            }\n        )\n    ]\n\n@server.call_tool()\nasync def call_tool(name: str, arguments: dict) -> list[TextContent]:\n    if name == \"greet\":\n        return [TextContent(type=\"text\", text=f\"Hello, {arguments['name']}!\")]\n    raise ValueError(f\"Unknown tool: {name}\")\n\nasync def main():\n    async with stdio_server() as (read, write):\n        await server.run(read, write, server.create_initialization_options())\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n```\n\n### TypeScript Server (production)\n\n```typescript\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport {\n  CallToolRequestSchema,\n  ListToolsRequestSchema,\n} from \"@modelcontextprotocol/sdk/types.js\";\n\nconst server = new Server(\n  { name: \"my-tools\", version: \"1.0.0\" },\n  { capabilities: { tools: {} } }\n);\n\nserver.setRequestHandler(ListToolsRequestSchema, async () => ({\n  tools: [{\n    name: \"fetch_url\",\n    description: \"Fetch content from a URL\",\n    inputSchema: {\n      type: \"object\",\n      properties: { url: { type: \"string\" } },\n      required: [\"url\"],\n    },\n  }],\n}));\n\nserver.setRequestHandler(CallToolRequestSchema, async (request) => {\n  if (request.params.name === \"fetch_url\") {\n    const { url } = request.params.arguments as { url: string };\n    const response = await fetch(url);\n    return { content: [{ type: \"text\", text: await response.text() }] };\n  }\n  throw new Error(\"Unknown tool\");\n});\n\nawait server.connect(new StdioServerTransport());\n```\n\n## Detailed Guides\n\n- **Transport patterns**: See [references/transport-patterns.md](references/transport-patterns.md) for stdio, SSE, WebSocket\n- **Tool definitions**: See [references/tool-definitions.md](references/tool-definitions.md) for schemas, error handling, caching\n- **Resource patterns**: See [references/resource",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "mem0-memory": {
    "name": "mem0-memory",
    "description": "Long-term semantic memory across sessions using Mem0. Use when you need to remember, recall, or forget information across sessions, or when referencing what we discussed last time or in a previous session.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "memory",
      "mem0",
      "persistence",
      "context"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Bash",
      "Read"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "agent-user-architecture.md",
        "data-structure.md",
        "metadata-filtered-architecture.md",
        "visualization.md"
      ],
      "scripts": [
        "batch",
        "create",
        "crud",
        "export",
        "graph",
        "lib",
        "requirements.txt",
        "setup",
        "setup.py",
        "utils",
        "validation",
        "visualization",
        "webhooks"
      ]
    },
    "content": "# Mem0 Memory Management\n\nPersist and retrieve semantic memories across Claude sessions.\n\n## Memory Scopes\n\nOrganize memories by scope for efficient retrieval:\n\n\n| Scope                | Purpose                           | Examples                                    |\n| -------------------- | --------------------------------- | ------------------------------------------- |\n| `project-decisions`  | Architecture and design decisions | \"Use PostgreSQL with pgvector for RAG\"      |\n| `project-patterns`   | Code patterns and conventions     | \"Components use kebab-case filenames\"       |\n| `project-continuity` | Session handoff context           | \"Working on auth refactor, PR #123 pending\" |\n\n## Project Isolation\n\nMemories are isolated by project name extracted from `CLAUDE_PROJECT_DIR`:\n\n- Project name: `basename($CLAUDE_PROJECT_DIR)` (sanitized to lowercase, dashes)\n- Format: `{project-name}-{scope}`\n\n**Edge Case:** If two different repositories have the same directory name, they will share the same `user_id` scope. To avoid this:\n\n1. Use unique directory names for each project\n2. Or use `MEM0_ORG_ID` environment variable for additional namespace\n\n**Example:**\n- `/Users/alice/my-app` → `my-app-decisions` ✅\n- `/Users/bob/my-app` → `my-app-decisions` ⚠️ (collision if same mem0.ai project)\n- With `MEM0_ORG_ID=acme`: `/Users/alice/my-app` → `acme-my-app-decisions` ✅\n\n## Memory Categories\n\nMemories are automatically categorized based on content. Available categories:\n\n| Category | Keywords | Use Case |\n|----------|----------|----------|\n| `pagination` | pagination, cursor, offset | API pagination patterns |\n| `security` | security, vulnerability, OWASP | Security patterns and vulnerabilities |\n| `authentication` | auth, JWT, OAuth, token | Authentication patterns |\n| `testing` | test, pytest, jest, coverage | Testing strategies |\n| `deployment` | deploy, CI/CD, Docker, Kubernetes | Deployment patterns |\n| `observability` | monitoring, logging, tracing, metrics | Observability patterns |\n| `performance` | performance, cache, optimize | Performance optimization |\n| `ai-ml` | LLM, RAG, embedding, LangChain | AI/ML patterns |\n| `data-pipeline` | ETL, streaming, batch processing | Data pipeline patterns |\n| `database` | database, SQL, PostgreSQL, schema | Database patterns |\n| `api` | API, endpoint, REST, GraphQL | API design patterns |\n| `frontend` | React, component, UI, CSS | Frontend patterns |\n| `architecture` | architecture, design, system | Architecture patterns |\n| `pattern` | pattern, convention, style | General patterns |\n| `blocker` | blocked, issue, bug | Blockers and issues |\n| `constraint` | must, cannot, required | Constraints |\n| `decision` | chose, decided, selected | Decisions (default) |\n\n## Cross-Tool Memory\n\nMemories include `source_tool` metadata to support cross-tool memory sharing:\n\n- `source_tool: \"orchestkit-claude\"` - Memories from Claude Code\n- `source_tool: \"orchestkit-cursor\"` - Memories from Cursor (future)\n\nQuery memories by t",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "memory": {
    "name": "memory",
    "description": "Read-side memory operations: search, load, sync, history, visualize. Use when searching past decisions, loading session context, or viewing the knowledge graph.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "memory",
      "graph",
      "session",
      "context",
      "sync",
      "visualization",
      "history",
      "search"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash",
      "AskUserQuestion",
      "mcp__memory__search_nodes",
      "mcp__memory__read_graph"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "mermaid-patterns.md"
      ],
      "scripts": [
        "graph-utils.mjs",
        "playground-template.html",
        "render-graph.mjs",
        "render-playground.mjs"
      ]
    },
    "content": "# Memory - Read & Access Operations\n\nUnified read-side memory skill with subcommands for searching, loading, syncing, history, and visualization.\n\n## Usage\n\n```bash\n/ork:memory search <query>  # Search knowledge graph\n/ork:memory load             # Load context at session start\n/ork:memory sync             # Sync to mem0 cloud\n/ork:memory history          # View decision timeline\n/ork:memory viz              # Visualize knowledge graph\n/ork:memory status           # Show memory system health\n```\n\n---\n\n## CRITICAL: Use AskUserQuestion When No Subcommand\n\nIf invoked without a subcommand, ask the user what they want:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What memory operation do you need?\",\n    \"header\": \"Operation\",\n    \"options\": [\n      {\"label\": \"search\", \"description\": \"Search decisions and patterns in knowledge graph\"},\n      {\"label\": \"load\", \"description\": \"Load relevant context for this session\"},\n      {\"label\": \"sync\", \"description\": \"Sync decisions to mem0 cloud\"},\n      {\"label\": \"history\", \"description\": \"View decision timeline\"},\n      {\"label\": \"viz\", \"description\": \"Visualize knowledge graph as Mermaid\"},\n      {\"label\": \"status\", \"description\": \"Check memory system health\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n---\n\n## Subcommands\n\n### `search` - Search Knowledge Graph\n\nSearch past decisions, patterns, and entities from the knowledge graph with optional cloud semantic search.\n\n**Usage:**\n```bash\n/ork:memory search <query>                    # Search knowledge graph\n/ork:memory search --category <cat> <query>   # Filter by category\n/ork:memory search --limit <n> <query>        # Limit results (default: 10)\n/ork:memory search --mem0 <query>             # Search BOTH graph AND mem0 cloud\n/ork:memory search --agent <agent-id> <query> # Filter by agent scope\n/ork:memory search --global <query>           # Search cross-project best practices\n```\n\n**Flags:**\n\n| Flag | Behavior |\n|------|----------|\n| (default) | Search graph only |\n| `--mem0` | Search BOTH graph and mem0 cloud |\n| `--limit <n>` | Max results (default: 10) |\n| `--category <cat>` | Filter by category |\n| `--agent <agent-id>` | Filter results to a specific agent's memories |\n| `--global` | Search cross-project best practices |\n\n**Context-Aware Result Limits:**\n\nResult limits automatically adjust based on `context_window.used_percentage`:\n\n| Context Usage | Default Limit | Behavior |\n|---------------|---------------|----------|\n| 0-70% | 10 results | Full results with details |\n| 70-85% | 5 results | Reduced, summarized results |\n| >85% | 3 results | Minimal with \"more available\" hint |\n\n**Search Workflow:**\n\n1. Parse flags (--category, --limit, --mem0, --agent, --global)\n2. Build filters from flags:\n   ```\n   Check for --category <cat> flag → metadata.category: \"<cat>\"\n   Check for --agent <agent-id> flag → agent_id: \"ork:{agent-id}\"\n   Check for --global flag → user_id: \"orchestkit-global-best-practices\"\n   ```\n3. Search knowledge graph via `mcp_",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "ai-safety-auditor",
      "backend-system-architect",
      "business-case-builder",
      "ci-cd-engineer",
      "code-quality-reviewer",
      "data-pipeline-engineer",
      "database-engineer",
      "debug-investigator",
      "demo-producer",
      "deployment-manager",
      "documentation-specialist",
      "event-driven-architect",
      "frontend-ui-developer",
      "git-operations-engineer",
      "infrastructure-architect",
      "llm-integrator",
      "market-intelligence",
      "metrics-architect",
      "monitoring-engineer",
      "multimodal-specialist",
      "performance-engineer",
      "prioritization-analyst",
      "product-strategist",
      "prompt-engineer",
      "python-performance-engineer",
      "rapid-ui-designer",
      "release-engineer",
      "requirements-translator",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer",
      "test-generator",
      "ux-researcher",
      "web-research-analyst",
      "workflow-architect"
    ]
  },
  "memory-fabric": {
    "name": "memory-fabric",
    "description": "Graph-first memory orchestration - knowledge graph (PRIMARY, always available) with optional mem0 cloud enhancement for semantic search. Use when designing memory orchestration or combining graph and mem0.",
    "version": "2.1.0",
    "author": "OrchestKit",
    "tags": [
      "memory",
      "orchestration",
      "graph-first",
      "graph",
      "unified-search",
      "deduplication",
      "cross-reference"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [
      "Read",
      "Bash",
      "mcp__memory__search_nodes"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "entity-extraction.md",
        "query-merging.md"
      ]
    },
    "content": "# Memory Fabric - Graph-First Orchestration\n\nGraph-first architecture: mcp__memory__* (knowledge graph) is PRIMARY and always available. mem0 scripts (semantic cloud) are an OPTIONAL enhancement for semantic search when configured.\n\n## Overview\n\n- Comprehensive memory retrieval across both systems\n- Cross-referencing entities between semantic and graph storage\n- Ensuring no relevant memories are missed from either source\n- Building unified context from heterogeneous memory stores\n\n## Architecture Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Memory Fabric Layer                      │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│   ┌─────────────┐              ┌─────────────┐              │\n│   │   Query     │              │   Query     │              │\n│   │   Parser    │              │   Executor  │              │\n│   └──────┬──────┘              └──────┬──────┘              │\n│          │                            │                     │\n│          ▼                            ▼                     │\n│   ┌──────────────────────────────────────────────┐          │\n│   │           Parallel Query Dispatch            │          │\n│   └──────────────┬───────────────────┬───────────┘          │\n│                  │                   │                      │\n│        ┌─────────▼─────────┐  ┌──────▼──────────┐           │\n│        │  mem0 scripts      │  │  mcp__memory__* │           │\n│        │  (Semantic Cloud)  │  │  (Local Graph)  │           │\n│        └─────────┬─────────┘  └──────┬──────────┘           │\n│                  │                   │                      │\n│                  ▼                   ▼                      │\n│        ┌─────────────────────────────────────────┐          │\n│        │        Result Normalizer                │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │     Deduplication Engine (>85% sim)     │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │  Cross-Reference Booster                │          │\n│        │  (mem0 mentions graph entity → boost)   │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │  Final Ranking: recency × relevance     │          │\n│        │                 × source_authority     ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "message-queues": {
    "name": "message-queues",
    "description": "Message queue patterns with RabbitMQ, Redis Streams, and Kafka. Use when implementing async communication, pub/sub systems, event-driven microservices, or reliable message delivery.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "message-queue",
      "rabbitmq",
      "redis-streams",
      "kafka",
      "faststream",
      "pub-sub",
      "async",
      "event-driven"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "event-driven-architect",
    "structure": {
      "references": [
        "faststream-patterns.md",
        "kafka-patterns.md",
        "rabbitmq-patterns.md"
      ],
      "scripts": [
        "queue-consumer-template.py"
      ],
      "checklists": [
        "message-queue-checklist.md"
      ]
    },
    "content": "# Message Queue Patterns ()\n\nAsynchronous communication patterns for distributed systems using RabbitMQ, Redis Streams, Kafka, and FastStream.\n\n## Overview\n\n- Decoupling services in microservices architecture\n- Implementing pub/sub and work queue patterns\n- Building event-driven systems with reliable delivery\n- Load leveling and buffering between services\n- Task distribution across multiple workers\n- High-throughput event streaming (Kafka)\n\n## Quick Reference\n\n### FastStream: Unified API ( Recommended)\n\n```python\n# pip install faststream[kafka,rabbit,redis]\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom pydantic import BaseModel\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\nclass OrderCreated(BaseModel):\n    order_id: str\n    customer_id: str\n    total: float\n\n@broker.subscriber(\"orders.created\")\nasync def handle_order(event: OrderCreated):\n    \"\"\"Automatic Pydantic validation and deserialization.\"\"\"\n    print(f\"Processing order {event.order_id}\")\n    await process_order(event)\n\n@broker.publisher(\"orders.processed\")\nasync def publish_processed(order_id: str) -> dict:\n    return {\"order_id\": order_id, \"status\": \"processed\"}\n\n# Run with: faststream run app:app\n```\n\n### Kafka Producer (aiokafka)\n\n```python\nfrom aiokafka import AIOKafkaProducer\nimport json\n\nclass KafkaPublisher:\n    def __init__(self, bootstrap_servers: str):\n        self.bootstrap_servers = bootstrap_servers\n        self._producer: AIOKafkaProducer | None = None\n\n    async def start(self):\n        self._producer = AIOKafkaProducer(\n            bootstrap_servers=self.bootstrap_servers,\n            value_serializer=lambda v: json.dumps(v).encode(),\n            acks=\"all\",  # Wait for all replicas\n            enable_idempotence=True,  # Exactly-once semantics\n        )\n        await self._producer.start()\n\n    async def publish(\n        self,\n        topic: str,\n        value: dict,\n        key: str | None = None,\n    ):\n        await self._producer.send_and_wait(\n            topic,\n            value=value,\n            key=key.encode() if key else None,\n        )\n\n    async def stop(self):\n        await self._producer.stop()\n```\n\n### Kafka Consumer with Consumer Group\n\n```python\nfrom aiokafka import AIOKafkaConsumer\nfrom aiokafka.errors import OffsetOutOfRangeError\n\nclass KafkaConsumer:\n    def __init__(\n        self,\n        topic: str,\n        group_id: str,\n        bootstrap_servers: str,\n    ):\n        self.consumer = AIOKafkaConsumer(\n            topic,\n            bootstrap_servers=bootstrap_servers,\n            group_id=group_id,\n            auto_offset_reset=\"earliest\",\n            enable_auto_commit=False,  # Manual commit for reliability\n            value_deserializer=lambda v: json.loads(v.decode()),\n        )\n\n    async def consume(self, handler):\n        await self.consumer.start()\n        try:\n            async for msg in self.consumer:\n                try:\n                    await handler(msg.value, msg.key, msg.parti",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "event-driven-architect"
    ]
  },
  "monorepo-context": {
    "name": "monorepo-context",
    "description": "Multi-directory context patterns for monorepos. Use when working with --add-dir, per-service CLAUDE.md, or separating root vs service context",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "monorepo",
      "multi-directory",
      "context",
      "workspace",
      "add-dir"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {},
    "content": "# Monorepo Context Patterns\n\n## Overview\n\nClaude Code 2.1.20 introduces `--add-dir` for multi-directory context, enabling monorepo-aware sessions where each service maintains its own CLAUDE.md instructions.\n\n## Monorepo Detection\n\nIndicators that a project is a monorepo:\n\n| Indicator | Tool |\n|-----------|------|\n| `pnpm-workspace.yaml` | pnpm |\n| `lerna.json` | Lerna |\n| `nx.json` | Nx |\n| `turbo.json` | Turborepo |\n| `rush.json` | Rush |\n| 3+ nested `package.json` files | Generic |\n\n## Per-Service CLAUDE.md\n\nEach service can have its own context instructions:\n\n```\nmonorepo/\n  CLAUDE.md               # Root context (workspace-wide rules)\n  packages/\n    api/\n      CLAUDE.md           # API-specific patterns\n      package.json\n    web/\n      CLAUDE.md           # Frontend-specific patterns\n      package.json\n    shared/\n      CLAUDE.md           # Shared library context\n      package.json\n```\n\n## --add-dir Usage\n\nStart Claude Code with additional directory context:\n\n```bash\n# From api service, add shared library context\nclaude --add-dir ../shared\n\n# Multiple directories\nclaude --add-dir ../shared --add-dir ../web\n```\n\n## Environment Variable\n\nEnable automatic CLAUDE.md loading from additional directories:\n\n```bash\nexport CLAUDE_CODE_ADDITIONAL_DIRECTORIES_CLAUDE_MD=1\n```\n\nWhen set, Claude Code reads CLAUDE.md from all `--add-dir` directories.\n\n## Root vs Service Context Separation\n\n### Root CLAUDE.md\n\n- Workspace-wide conventions (commit messages, branch naming)\n- Cross-service dependency rules\n- CI/CD pipeline overview\n- Shared tooling configuration\n\n### Service CLAUDE.md\n\n- Service-specific patterns and frameworks\n- Local test commands\n- API contracts and schemas\n- Service-specific environment variables\n\n## Related Skills\n\n- `configure` - OrchestKit configuration including monorepo detection\n- `project-structure-enforcer` - Folder structure enforcement",
    "contentTruncated": false,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "motion-animation-patterns": {
    "name": "motion-animation-patterns",
    "description": "Implements Motion (Framer Motion) animations in React applications. Covers animation presets, page transitions, modals, stagger effects, and skeleton loaders. Use when adding animations, transitions, or interactive hover effects.",
    "version": "1.0.0",
    "author": "Yonatan Gross",
    "tags": [
      "motion",
      "framer-motion",
      "animation",
      "react",
      "ux",
      "transitions",
      "hover",
      "stagger",
      "skeleton"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "rapid-ui-designer",
    "structure": {
      "references": [
        "animation-presets.md"
      ]
    },
    "content": "# Motion Animation Patterns\n\n## Overview\n\nThis skill provides comprehensive guidance for implementing Motion (Framer Motion) animations in React 19 applications. It ensures consistent, performant, and accessible animations across the UI using centralized animation presets.\n\n**When to use this skill:**\n- Adding page transition animations\n- Implementing modal/dialog entrance/exit animations\n- Creating staggered list animations\n- Adding hover and tap micro-interactions\n- Implementing skeleton loading states\n- Creating collapse/expand animations\n- Building toast/notification animations\n\n**Bundled Resources:**\n- `references/animation-presets.md` - Complete preset API reference\n- `examples/component-patterns.md` - Common animation patterns\n\n---\n\n## Core Architecture\n\n### Animation Presets Library (`frontend/src/lib/animations.ts`)\n\nAll animations MUST use the centralized `animations.ts` presets. This ensures:\n- Consistent motion language across the app\n- RTL-aware animations (Hebrew support)\n- Performance optimization\n- Easy maintainability\n\n```typescript\n// ✅ CORRECT: Import from animations.ts\nimport { motion, AnimatePresence } from 'motion/react';\nimport { fadeIn, slideUp, staggerContainer, modalContent } from '@/lib/animations';\n\n// ❌ WRONG: Inline animation values\n<motion.div initial={{ opacity: 0 }} animate={{ opacity: 1 }}>\n```\n\n---\n\n## Available Presets\n\n### Transition Timing\n\n| Preset | Duration | Ease | Use For |\n|--------|----------|------|---------|\n| `transitions.fast` | 0.15s | easeOut | Micro-interactions |\n| `transitions.normal` | 0.2s | easeOut | Most animations |\n| `transitions.slow` | 0.3s | easeInOut | Emphasis effects |\n| `transitions.spring` | spring | 300/25 | Playful elements |\n| `transitions.gentleSpring` | spring | 200/20 | Modals/overlays |\n\n### Basic Animations\n\n| Preset | Effect | Use For |\n|--------|--------|---------|\n| `fadeIn` | Opacity fade | Simple reveal |\n| `fadeScale` | Fade + slight scale | Subtle emphasis |\n| `scaleIn` | Fade + scale from center | Badges, buttons |\n\n### Slide Animations (RTL-Aware)\n\n| Preset | Direction | Use For |\n|--------|-----------|---------|\n| `slideInRight` | Right to center | RTL Hebrew UI (natural) |\n| `slideInLeft` | Left to center | LTR content |\n| `slideUp` | Bottom to center | Cards, panels |\n| `slideDown` | Top to center | Dropdowns |\n\n### List/Stagger Animations\n\n| Preset | Effect | Use For |\n|--------|--------|---------|\n| `staggerContainer` | Parent with stagger | List wrappers |\n| `staggerContainerFast` | Fast stagger | Quick lists |\n| `staggerItem` | Fade + slide child | List items |\n| `staggerItemRight` | RTL slide child | Hebrew lists |\n\n### Modal/Dialog Animations\n\n| Preset | Effect | Use For |\n|--------|--------|---------|\n| `modalBackdrop` | Overlay fade | Modal background |\n| `modalContent` | Scale + fade | Modal body |\n| `sheetContent` | Slide from bottom | Mobile sheets |\n| `dropdownDown` | Scale from top | Dropdown menus |\n| `dropdownUp` | Scale from bottom | Context me",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer",
      "rapid-ui-designer"
    ]
  },
  "msw-mocking": {
    "name": "msw-mocking",
    "description": "Mock Service Worker (MSW) 2.x for API mocking. Use when testing frontend components with network mocking, simulating API errors, or creating deterministic API responses in tests.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "msw",
      "testing",
      "mocking",
      "frontend"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "msw-2x-api.md"
      ],
      "scripts": [
        "create-msw-handler.md",
        "handlers-template.ts"
      ],
      "checklists": [
        "msw-setup-checklist.md"
      ]
    },
    "content": "# MSW (Mock Service Worker) 2.x\n\nNetwork-level API mocking for frontend tests using MSW 2.x.\n\n## Quick Reference\n\n```typescript\n// Core imports\nimport { http, HttpResponse, graphql, ws, delay, passthrough } from 'msw';\nimport { setupServer } from 'msw/node';\n\n// Basic handler\nhttp.get('/api/users/:id', ({ params }) => {\n  return HttpResponse.json({ id: params.id, name: 'User' });\n});\n\n// Error response\nhttp.get('/api/fail', () => {\n  return HttpResponse.json({ error: 'Not found' }, { status: 404 });\n});\n\n// Delay simulation\nhttp.get('/api/slow', async () => {\n  await delay(2000);\n  return HttpResponse.json({ data: 'response' });\n});\n\n// Passthrough (NEW in 2.x)\nhttp.get('/api/real', () => passthrough());\n```\n\n## Test Setup\n\n```typescript\n// vitest.setup.ts\nimport { beforeAll, afterEach, afterAll } from 'vitest';\nimport { server } from './src/mocks/server';\n\nbeforeAll(() => server.listen({ onUnhandledRequest: 'error' }));\nafterEach(() => server.resetHandlers());\nafterAll(() => server.close());\n```\n\n## Runtime Override\n\n```typescript\nimport { http, HttpResponse } from 'msw';\nimport { server } from '../mocks/server';\n\ntest('shows error on API failure', async () => {\n  server.use(\n    http.get('/api/users/:id', () => {\n      return HttpResponse.json({ error: 'Not found' }, { status: 404 });\n    })\n  );\n\n  render(<UserProfile id=\"123\" />);\n  expect(await screen.findByText(/not found/i)).toBeInTheDocument();\n});\n```\n\n## Anti-Patterns (FORBIDDEN)\n\n```typescript\n// ❌ NEVER mock fetch directly\njest.spyOn(global, 'fetch').mockResolvedValue(...)\n\n// ❌ NEVER mock axios module\njest.mock('axios')\n\n// ❌ NEVER test implementation details\nexpect(fetch).toHaveBeenCalledWith('/api/...')\n\n// ✅ ALWAYS use MSW\nserver.use(http.get('/api/...', () => HttpResponse.json({...})))\n\n// ✅ ALWAYS test user-visible behavior\nexpect(await screen.findByText('Success')).toBeInTheDocument()\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Handler location | `src/mocks/handlers.ts` |\n| Default behavior | Return success |\n| Override scope | Per-test with `server.use()` |\n| Unhandled requests | Error (catch missing mocks) |\n| GraphQL | Use `graphql.query/mutation` |\n| WebSocket | Use `ws.link()` for WS mocking |\n\n## Detailed Documentation\n\n| Resource | Description |\n|----------|-------------|\n| [references/msw-2x-api.md](references/msw-2x-api.md) | Complete MSW 2.x API reference |\n| [examples/handler-patterns.md](examples/handler-patterns.md) | CRUD, auth, error, and upload examples |\n| [checklists/msw-setup-checklist.md](checklists/msw-setup-checklist.md) | Setup and review checklists |\n| [scripts/handlers-template.ts](scripts/handlers-template.ts) | Starter template for new handlers |\n\n## Related Skills\n\n- `unit-testing` - Component isolation\n- `integration-testing` - Full integration tests\n- `vcr-http-recording` - Python equivalent\n\n## Capability Details\n\n### http-request-mocking\n**Keywords:** http.get, http.post, http handler, REST mock\n**Solves:*",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "multi-agent-orchestration": {
    "name": "multi-agent-orchestration",
    "description": "Multi-agent coordination and synthesis patterns. Use when orchestrating multiple specialized agents, implementing fan-out/fan-in workflows, or synthesizing outputs from parallel agents.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ai",
      "agents",
      "orchestration",
      "multi-agent"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "coordination-patterns.md"
      ],
      "checklists": [
        "orchestration-checklist.md"
      ]
    },
    "content": "# Multi-Agent Orchestration\n\nCoordinate multiple specialized agents for complex tasks.\n\n## Fan-Out/Fan-In Pattern\n\n```python\nasync def multi_agent_analysis(content: str) -> dict:\n    \"\"\"Fan-out to specialists, fan-in to synthesize.\"\"\"\n    agents = [\n        (\"security\", security_agent),\n        (\"performance\", performance_agent),\n        (\"code_quality\", quality_agent),\n        (\"architecture\", architecture_agent),\n    ]\n\n    # Fan-out: Run all agents in parallel\n    tasks = [agent(content) for _, agent in agents]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Filter successful results\n    findings = [\n        {\"agent\": name, \"result\": result}\n        for (name, _), result in zip(agents, results)\n        if not isinstance(result, Exception)\n    ]\n\n    # Fan-in: Synthesize findings\n    return await synthesize_findings(findings)\n```\n\n## Supervisor Pattern\n\n```python\nclass Supervisor:\n    \"\"\"Central coordinator that routes to specialists.\"\"\"\n\n    def __init__(self, agents: dict):\n        self.agents = agents  # {\"security\": agent, \"performance\": agent}\n        self.completed = []\n\n    async def run(self, task: str) -> dict:\n        \"\"\"Route task through appropriate agents.\"\"\"\n        # 1. Determine which agents to use\n        plan = await self.plan_routing(task)\n\n        # 2. Execute in dependency order\n        results = {}\n        for agent_name in plan.execution_order:\n            if plan.can_parallelize(agent_name):\n                # Run parallel batch\n                batch = plan.get_parallel_batch(agent_name)\n                batch_results = await asyncio.gather(*[\n                    self.agents[name](task, context=results)\n                    for name in batch\n                ])\n                results.update(dict(zip(batch, batch_results)))\n            else:\n                # Run sequential\n                results[agent_name] = await self.agents[agent_name](\n                    task, context=results\n                )\n\n        return results\n\n    async def plan_routing(self, task: str) -> RoutingPlan:\n        \"\"\"Use LLM to determine agent routing.\"\"\"\n        response = await llm.chat([{\n            \"role\": \"user\",\n            \"content\": f\"\"\"Task: {task}\n\nAvailable agents: {list(self.agents.keys())}\n\nWhich agents should handle this task?\nWhat order? Can any run in parallel?\"\"\"\n        }])\n        return parse_routing_plan(response.content)\n```\n\n## Conflict Resolution\n\n```python\nasync def resolve_conflicts(findings: list[dict]) -> list[dict]:\n    \"\"\"When agents disagree, resolve by confidence or LLM.\"\"\"\n    conflicts = detect_conflicts(findings)\n\n    if not conflicts:\n        return findings\n\n    for conflict in conflicts:\n        # Option 1: Higher confidence wins\n        winner = max(conflict.agents, key=lambda a: a.confidence)\n\n        # Option 2: LLM arbitration\n        resolution = await llm.chat([{\n            \"role\": \"user\",\n            \"content\": f\"\"\"Two agents disagree:\n\nAgent A ({conflict.agent_a.name}): {con",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "multi-scenario-orchestration": {
    "name": "multi-scenario-orchestration",
    "description": "Orchestrates single user-invocable skill across 3 parallel scenarios with synchronized state and progressive difficulty. Use when running multi-scenario demos, comparative testing, or progressive validation workflows.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "orchestration",
      "parallel",
      "supervisor",
      "state-machine",
      "scenario",
      "testing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "architectural-patterns.md",
        "claude-code-instance-management.md",
        "langgraph-implementation.md",
        "skill-agnostic-template.md",
        "state-machine-design.md"
      ]
    },
    "content": "# Multi-Scenario Orchestration\n\n**Design patterns for showcasing one skill across 3 parallel scenarios with synchronized execution and progressive difficulty.**\n\n## Core Pattern\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                   MULTI-SCENARIO ORCHESTRATOR                        │\n├─────────────────────────────────────────────────────────────────────┤\n│                                                                     │\n│  [Coordinator] ──┬─→ [Scenario 1: Simple]       (Easy)            │\n│       ▲          │      └─→ [Skill Instance 1]                    │\n│       │          ├─→ [Scenario 2: Medium]       (Intermediate)    │\n│       │          │      └─→ [Skill Instance 2]                    │\n│       │          └─→ [Scenario 3: Complex]      (Advanced)        │\n│       │                 └─→ [Skill Instance 3]                    │\n│       │                                                             │\n│   [State Manager] ◄──── All instances report progress              │\n│   [Aggregator] ─→ Cross-scenario synthesis                         │\n│                                                                     │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\n## When to Use\n\n| Scenario | Example |\n|----------|---------|\n| **Skill demos** | Show `/implement` on simple, medium, complex tasks |\n| **Progressive testing** | Validate skill scales with complexity |\n| **Comparative analysis** | How does approach differ by difficulty? |\n| **Training/tutorials** | Show skill progression from easy to hard |\n\n## Quick Start\n\n```python\nfrom langgraph.graph import StateGraph\n\n# 1. Define 3 scenarios with progressive difficulty\nscenarios = [\n    {\"name\": \"simple\", \"complexity\": 1.0, \"input_size\": 10},\n    {\"name\": \"medium\", \"complexity\": 3.0, \"input_size\": 50},\n    {\"name\": \"complex\", \"complexity\": 8.0, \"input_size\": 200},\n]\n\n# 2. Fan out to parallel execution\n# 3. Aggregate results\n# 4. Report comparative metrics\n```\n\n## Scenario Difficulty Scaling\n\n| Level | Complexity | Input Size | Time Budget | Quality |\n|-------|------------|------------|-------------|---------|\n| Simple | 1x | Small (10) | 30s | Basic |\n| Medium | 3x | Medium (50) | 90s | Good |\n| Complex | 8x | Large (200) | 300s | Excellent |\n\n## Synchronization Modes\n\n| Mode | Description | Use When |\n|------|-------------|----------|\n| **Free-running** | All run independently | Demo videos |\n| **Milestone-sync** | Wait at 30%, 70%, 100% | Comparative analysis |\n| **Lock-step** | All proceed together | Training |\n\n## Key Components\n\n1. **Coordinator** - Spawns and monitors 3 instances\n2. **State Manager** - Tracks progress per scenario\n3. **Aggregator** - Merges results, extracts patterns\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Synchronization mode | Free-running with checkpoints |\n| Scenario count | Always 3: simple, medium, complex |\n| Input scaling | 1x, 3x, 8x (exponential) |\n| Tim",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "multimodal-rag": {
    "name": "multimodal-rag",
    "description": "CLIP, SigLIP 2, Voyage multimodal-3 patterns for image+text retrieval, cross-modal search, and multimodal document chunking. Use when building RAG with images, implementing visual search, or hybrid retrieval.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "multimodal",
      "image-retrieval",
      "clip",
      "embeddings",
      "vector-search"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "multimodal-specialist",
    "structure": {
      "references": [
        "clip-embeddings.md",
        "multimodal-chunking.md"
      ],
      "checklists": [
        "implementation.md"
      ]
    },
    "content": "# Multimodal RAG ()\n\nBuild retrieval-augmented generation systems that handle images, text, and mixed content.\n\n## Overview\n\n- Image + text retrieval (product search, documentation)\n- Cross-modal search (text query -> image results)\n- Multimodal document processing (PDFs with charts)\n- Visual question answering with context\n- Image similarity and deduplication\n- Hybrid search pipelines\n\n## Architecture Approaches\n\n| Approach | Pros | Cons | Best For |\n|----------|------|------|----------|\n| **Joint Embedding** (CLIP) | Direct comparison | Limited context | Pure image search |\n| **Caption-based** | Works with text LLMs | Lossy conversion | Existing text RAG |\n| **Hybrid** | Best accuracy | More complex | Production systems |\n\n## Embedding Models ()\n\n| Model | Context | Modalities | Best For |\n|-------|---------|------------|----------|\n| **Voyage multimodal-3** | 32K tokens | Text + Image | Long documents |\n| **SigLIP 2** | Standard | Text + Image | Large-scale retrieval |\n| **CLIP ViT-L/14** | 77 tokens | Text + Image | General purpose |\n| **ImageBind** | Standard | 6 modalities | Audio/video included |\n| **ColPali** | Document | Text + Image | PDF/document RAG |\n\n## CLIP-Based Image Embeddings\n\n```python\nimport torch\nfrom PIL import Image\nfrom transformers import CLIPProcessor, CLIPModel\n\n# Load CLIP model\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n\ndef embed_image(image_path: str) -> list[float]:\n    \"\"\"Generate CLIP embedding for an image.\"\"\"\n    image = Image.open(image_path)\n    inputs = processor(images=image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        embeddings = model.get_image_features(**inputs)\n\n    # Normalize for cosine similarity\n    embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n    return embeddings[0].tolist()\n\ndef embed_text(text: str) -> list[float]:\n    \"\"\"Generate CLIP embedding for text query.\"\"\"\n    inputs = processor(text=[text], return_tensors=\"pt\", padding=True)\n\n    with torch.no_grad():\n        embeddings = model.get_text_features(**inputs)\n\n    embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n    return embeddings[0].tolist()\n\n# Cross-modal search: text -> images\ndef search_images(query: str, image_embeddings: list, top_k: int = 5):\n    \"\"\"Search images using text query.\"\"\"\n    query_embedding = embed_text(query)\n\n    # Compute similarities (cosine)\n    similarities = [\n        np.dot(query_embedding, img_emb)\n        for img_emb in image_embeddings\n    ]\n\n    top_indices = np.argsort(similarities)[-top_k:][::-1]\n    return top_indices, [similarities[i] for i in top_indices]\n```\n\n## Voyage Multimodal-3 (Long Context)\n\n```python\nimport voyageai\n\nclient = voyageai.Client()\n\ndef embed_multimodal_voyage(\n    texts: list[str] = None,\n    images: list[str] = None  # File paths or URLs\n) -> list[list[float]]:\n    \"\"\"Embed text and/or images with 32K token context.\"\"\"\n    inputs = []\n",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "multimodal-specialist"
    ]
  },
  "music-sfx-selection": {
    "name": "music-sfx-selection",
    "description": "Audio selection for tech demo videos. Use when choosing background music, timing SFX, setting volume levels, or matching mood to content",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "audio",
      "music",
      "sfx",
      "sound-design",
      "mixing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "audio-mixing.md",
        "music-matching-guide.md",
        "sfx-library.md"
      ]
    },
    "content": "# Music and SFX Selection for Tech Demo Videos\n\nComprehensive guide for selecting, timing, and mixing audio elements in technology demonstration videos.\n\n## Music Matching Matrix\n\nMatch your content type to the appropriate audio style:\n\n| Content Type | Audio Style | BPM Range | Key Characteristics |\n|--------------|-------------|-----------|---------------------|\n| AI/ML Demo | Electronic Ambient | 80-100 | Subtle synths, minimal percussion, futuristic pads |\n| Code Tutorial | Lo-fi/Chill | 70-90 | Relaxed beats, non-intrusive, study-music feel |\n| Product Launch | Uplifting Corporate | 100-120 | Building energy, positive resolution |\n| Bug Fix/Debug | Tense to Resolution | 90-110 | Minor key start, major key resolution |\n| Performance Demo | High Energy Electronic | 120-140 | Driving beats, impressive feel |\n| API Integration | Tech Corporate | 95-115 | Professional, modern, clean |\n| Security Feature | Dark Electronic | 85-105 | Suspenseful undertones, protective feel |\n| Success Story | Inspirational | 100-120 | Emotional build, triumphant finish |\n\n## BPM Guidelines by Mood\n\n### Calm/Professional (70-90 BPM)\n- Documentation walkthroughs\n- Slow-paced tutorials\n- Thoughtful explanations\n\n### Moderate/Engaging (90-110 BPM)\n- Standard demos\n- Feature overviews\n- Most tech content\n\n### Energetic/Exciting (110-130 BPM)\n- Product launches\n- Performance comparisons\n- Call-to-action sections\n\n### High Energy (130-150 BPM)\n- Speed demonstrations\n- Competitive comparisons\n- Hype moments (use sparingly)\n\n## SFX Categories for Tech Videos\n\n### Typing/Keyboard SFX\n- **Mechanical keyboard**: Satisfying tactile sound for code input\n- **Soft membrane**: Subtle for background typing\n- **Terminal beep**: Old-school computer feel\n- **Recommended**: Layer 2-3 variations to avoid repetition\n\n### UI Interaction SFX\n- **Click/Tap**: Button interactions, menu selections\n- **Hover**: Subtle whoosh for cursor movement\n- **Toggle**: Switch on/off sounds\n- **Scroll**: Gentle movement indicator\n\n### Transition SFX\n- **Whoosh**: Scene changes, fast movements\n- **Sweep**: Gradual transitions\n- **Glitch**: Error states, interruptions\n- **Portal/Warp**: Teleportation between views\n\n### Feedback SFX\n- **Success chime**: Task completion, green checkmarks\n- **Error buzz**: Failed operations, red indicators\n- **Warning tone**: Caution states, yellow alerts\n- **Notification ping**: New messages, updates\n\n### Ambient SFX\n- **Data flow**: Background processing sound\n- **Server hum**: Infrastructure ambiance\n- **Digital rain**: Matrix-style atmosphere\n- **Circuit pulse**: Electronic heartbeat\n\n## SFX Timing Patterns\n\n### Typing Sequence\n```\nFrame 0: First keystroke SFX\nFrame 3-5: Subsequent keystrokes (randomize timing)\nEvery 15-20 frames: Brief pause\nFinal frame: Enter key or completion sound\n```\n\n### Success Animation\n```\nFrame 0: Action initiated (subtle click)\nFrame 15-30: Processing indicator (soft loop)\nFrame X: Completion (rising chime, 200-400ms)\nFrame X+10: Visual confirmat",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "narration-scripting": {
    "name": "narration-scripting",
    "description": "Scene-by-scene narration scripts for videos. Use when writing voiceover scripts, adding timing markers, or creating CTA patterns for demos",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "narration",
      "script",
      "timing",
      "pacing",
      "copywriting"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "pacing-guidelines.md",
        "script-templates.md",
        "timing-markers.md"
      ]
    },
    "content": "# Narration Scripting\n\nComprehensive guide to writing narration scripts optimized for video production, TTS synthesis, and audience engagement.\n\n## Overview\n\n- Writing scene-by-scene narration for demo videos\n- Timing synchronization between visuals and voice\n- Pacing narration for optimal comprehension\n- CTA scripting that converts viewers\n- TTS-optimized script formatting\n- Multi-format narration (horizontal, vertical, square)\n\n## Core Principle\n\n**Narration = Visual Support + Comprehension Timing + Emotional Arc**\n\nNarration should enhance visuals, not compete with them. Words must land precisely when viewers need context, and pacing must match cognitive load.\n\n## Timing Fundamentals\n\n### Frame to Milliseconds Conversion\n\n```\nFrame Rate    1 Frame    15 Frames    30 Frames    60 Frames\n─────────────────────────────────────────────────────────────\n24 fps        41.67ms    625ms        1250ms       2500ms\n30 fps        33.33ms    500ms        1000ms       2000ms\n60 fps        16.67ms    250ms        500ms        1000ms\n\nCommon Timing Shortcuts:\n├── 30fps: Frame# x 33.33 = milliseconds\n├── 24fps: Frame# x 41.67 = milliseconds\n└── 60fps: Frame# / 60 x 1000 = milliseconds\n```\n\n### Sync Point Types\n\n```\nType            Symbol    Usage                   Precision\n──────────────────────────────────────────────────────────────\nHard Sync       [!]       Word lands on action    +/- 2 frames\nSoft Sync       [~]       Word near action        +/- 10 frames\nWindow Sync     [...]     Word during scene       Flexible\nLead Sync       [>]       Word before action      100-300ms early\nLag Sync        [<]       Word after action       100-500ms late\n```\n\n## Words Per Minute (WPM) Guidelines\n\n### Comprehension-Based Pacing\n\n```\nContent Type          WPM Range    Pause Frequency    Use Case\n─────────────────────────────────────────────────────────────────\nTechnical Demo        120-140      Every 8-10 words   Complex UI, code\nTutorial              130-150      Every 10-12 words  Step-by-step\nProduct Feature       140-160      Every 12-15 words  Marketing, benefits\nQuick Overview        150-170      Every 15-20 words  Intro sequences\nHigh Energy           170-190      Minimal pauses     TikTok, Reels\nDocumentary           110-130      Natural pauses     Storytelling\n```\n\n### Platform-Specific WPM\n\n```\nPlatform       WPM Range    Why\n────────────────────────────────────────────────────\nTikTok         160-180      Fast scroll, hook fast\nReels          150-170      Slightly slower aesthetic\nYouTube Shorts 140-160      More value-focused\nYouTube Long   130-150      Comprehension over speed\nLinkedIn       120-140      Professional, clear\nTwitter/X      150-170      Quick engagement\n```\n\n### Calculating Script Length\n\n```\nFormula: (Video Duration in seconds) x (WPM / 60) = Word Count\n\nExamples:\n├── 15s video @ 150 WPM = 37 words\n├── 30s video @ 140 WPM = 70 words\n├── 60s video @ 130 WPM = 130 words\n├── 5m video @ 140 WPM = 700 words\n└── 10m video @ 135 WPM = 1350 words\n\nInc",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "observability-monitoring": {
    "name": "observability-monitoring",
    "description": "Use when adding logging, metrics, tracing, or alerting to applications. Observability & Monitoring covers structured logging, Prometheus metrics, OpenTelemetry tracing, and alerting strategies.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "observability",
      "monitoring",
      "metrics",
      "logging",
      "tracing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "references": [
        "alerting-dashboards.md",
        "alerting-strategies.md",
        "dashboards.md",
        "distributed-tracing.md",
        "logging-patterns.md",
        "metrics-collection.md",
        "structured-logging.md"
      ],
      "scripts": [
        "alerting-rules.yml",
        "health-checks.ts",
        "opentelemetry-tracing.ts",
        "prometheus-metrics.ts",
        "structured-logging.ts"
      ],
      "checklists": [
        "monitoring-implementation-checklist.md"
      ]
    },
    "content": "# Observability & Monitoring Skill\n\nComprehensive frameworks for implementing observability including structured logging, metrics, distributed tracing, and alerting.\n\n## Overview\n\n- Setting up application monitoring\n- Implementing structured logging\n- Adding metrics and dashboards\n- Configuring distributed tracing\n- Creating alerting rules\n- Debugging production issues\n\n## Three Pillars of Observability\n\n```\n+-----------------+-----------------+-----------------+\n|     LOGS        |     METRICS     |     TRACES      |\n+-----------------+-----------------+-----------------+\n| What happened   | How is system   | How do requests |\n| at specific     | performing      | flow through    |\n| point in time   | over time       | services        |\n+-----------------+-----------------+-----------------+\n```\n\n## References\n\n### Logging Patterns\n**See: `references/logging-patterns.md`**\n\nKey topics covered:\n- Correlation IDs for cross-service request tracking\n- Log sampling strategies for high-traffic systems\n- LogQL queries for Loki log aggregation\n- OrchestKit structlog configuration example\n\n### Metrics Collection\n**See: `references/metrics-collection.md`**\n\nKey topics covered:\n- Counter, Gauge, Histogram, Summary metric types\n- Cardinality management and limits\n- Custom business metrics (LLM tokens, cache hit rates)\n- LLM cost tracking with Prometheus\n\n### Distributed Tracing\n**See: `references/distributed-tracing.md`**\n\nKey topics covered:\n- OpenTelemetry setup and auto-instrumentation\n- Span relationships (parent/child, parallel)\n- Head-based and tail-based sampling strategies\n- Trace context propagation across services\n\n### Alerting and Dashboards\n**See: `references/alerting-dashboards.md`**\n\nKey topics covered:\n- Alert severity levels and response times\n- Alert grouping and inhibition rules\n- Escalation policies and runbook links\n- Golden Signals dashboard design\n- SLO/SLI definitions and error budgets\n\n## Quick Reference\n\n### Log Levels\n\n| Level | Use Case |\n|-------|----------|\n| **ERROR** | Unhandled exceptions, failed operations |\n| **WARN** | Deprecated API, retry attempts |\n| **INFO** | Business events, successful operations |\n| **DEBUG** | Development troubleshooting |\n\n### RED Method (Rate, Errors, Duration)\n\nEssential metrics for any service:\n- **Rate** - Requests per second\n- **Errors** - Failed requests per second\n- **Duration** - Request latency distribution\n\n### Prometheus Buckets\n\n```typescript\n// HTTP request latency\nbuckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5]\n\n// Database query latency\nbuckets: [0.001, 0.01, 0.05, 0.1, 0.5, 1]\n```\n\n### Key Alerts\n\n| Alert | Condition | Severity |\n|-------|-----------|----------|\n| ServiceDown | `up == 0` for 1m | Critical |\n| HighErrorRate | 5xx > 5% for 5m | Critical |\n| HighLatency | p95 > 2s for 5m | High |\n| LowCacheHitRate | < 70% for 10m | Medium |\n\n### Health Checks (Kubernetes)\n\n| Probe | Purpose | Endpoint |\n|-------|---------|----------|\n| **Liveness** | Is app running? | `/health` |\n| **Readine",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "ci-cd-engineer",
      "debug-investigator",
      "deployment-manager",
      "infrastructure-architect",
      "metrics-architect",
      "monitoring-engineer",
      "performance-engineer",
      "prompt-engineer",
      "python-performance-engineer",
      "workflow-architect"
    ]
  },
  "okr-kpi-patterns": {
    "name": "okr-kpi-patterns",
    "description": "OKR framework, KPI trees, leading/lagging indicators, and success metrics patterns. Use when defining goals, measuring outcomes, or building measurement frameworks.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "metrics",
      "okr",
      "kpi",
      "goals",
      "measurement"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "references": [
        "okr-workshop-guide.md"
      ],
      "assets": [
        "metrics-definition-template.md"
      ],
      "checklists": [
        "metrics-framework-checklist.md"
      ]
    },
    "content": "# OKR & KPI Patterns\n\nFrameworks for defining goals, measuring success, and building metrics-driven organizations.\n\n## OKR Framework\n\nObjectives and Key Results align teams around ambitious goals with measurable outcomes.\n\n### OKR Structure\n\n```\nObjective: Qualitative, inspiring goal\n├── Key Result 1: Quantitative measure of progress\n├── Key Result 2: Quantitative measure of progress\n└── Key Result 3: Quantitative measure of progress\n```\n\n### Writing Good Objectives\n\n| Characteristic | Good | Bad |\n|---------------|------|-----|\n| Qualitative | \"Delight enterprise customers\" | \"Increase NPS to 50\" |\n| Inspiring | \"Become the go-to platform\" | \"Ship 10 features\" |\n| Time-bound | Implied quarterly | Vague timeline |\n| Ambitious | Stretch goal (70% achievable) | Sandbagged (100% easy) |\n\n### Writing Good Key Results\n\n| Characteristic | Good | Bad |\n|---------------|------|-----|\n| Quantitative | \"Reduce churn from 8% to 4%\" | \"Improve retention\" |\n| Measurable | \"Ship to 10,000 beta users\" | \"Launch beta\" |\n| Outcome-focused | \"Increase conversion by 20%\" | \"Add 5 features\" |\n| Leading indicators | \"Weekly active users reach 50K\" | \"Revenue hits $1M\" (lagging) |\n\n### OKR Example\n\n```markdown\n## Q1  OKRs\n\n### Objective 1: Become the #1 choice for enterprise teams\n\n**Key Results:**\n- KR1: Increase enterprise NPS from 32 to 50\n- KR2: Reduce time-to-value from 14 days to 3 days\n- KR3: Achieve 95% feature adoption in first 30 days\n- KR4: Win 5 competitive displacements from [Competitor]\n\n### Objective 2: Build a world-class engineering culture\n\n**Key Results:**\n- KR1: Reduce deploy-to-production time from 4 hours to 15 minutes\n- KR2: Achieve 90% code coverage on critical paths\n- KR3: Zero P0 incidents lasting longer than 30 minutes\n- KR4: Engineering satisfaction score reaches 4.5/5\n```\n\n## Leading vs. Lagging Indicators\n\nUnderstanding the difference is crucial for effective measurement.\n\n### Definitions\n\n| Type | Definition | Characteristics |\n|------|------------|-----------------|\n| **Leading** | Predictive, can be directly influenced | Real-time feedback, actionable |\n| **Lagging** | Results of past actions | Confirms outcomes, hard to change |\n\n### Examples by Domain\n\n```\nSales Pipeline:\n  Leading: # of qualified meetings this week\n  Lagging: Quarterly revenue\n\nCustomer Success:\n  Leading: Product usage frequency\n  Lagging: Customer churn rate\n\nEngineering:\n  Leading: Code review turnaround time\n  Lagging: Production incidents\n\nMarketing:\n  Leading: Website traffic, MQLs\n  Lagging: Customer acquisition cost (CAC)\n```\n\n### The Leading-Lagging Chain\n\n```\nLeading                                           Lagging\n─────────────────────────────────────────────────────────►\n\nBlog posts    Website     MQLs      SQLs      Deals     Revenue\npublished  →  traffic  →  generated → created → closed → booked\n   │            │           │          │         │         │\n   ▼            ▼           ▼          ▼         ▼         ▼\n Actionable  Actionable   Somewhat  ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "metrics-architect"
    ]
  },
  "ollama-local": {
    "name": "ollama-local",
    "description": "Local LLM inference with Ollama. Use when setting up local models for development, CI pipelines, or cost reduction. Covers model selection, LangChain integration, and performance tuning.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "llm",
      "ollama",
      "local",
      "self-hosted"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "references": [
        "model-selection.md"
      ],
      "scripts": [
        "ollama-provider-template.py"
      ]
    },
    "content": "# Ollama Local Inference\n\nRun LLMs locally for cost savings, privacy, and offline development.\n\n## Quick Start\n\n```bash\n# Install Ollama\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Pull models\nollama pull deepseek-r1:70b      # Reasoning (GPT-4 level)\nollama pull qwen2.5-coder:32b    # Coding\nollama pull nomic-embed-text     # Embeddings\n\n# Start server\nollama serve\n```\n\n## Recommended Models (M4 Max 256GB)\n\n| Task | Model | Size | Notes |\n|------|-------|------|-------|\n| Reasoning | `deepseek-r1:70b` | ~42GB | GPT-4 level |\n| Coding | `qwen2.5-coder:32b` | ~35GB | 73.7% Aider benchmark |\n| Embeddings | `nomic-embed-text` | ~0.5GB | 768 dims, fast |\n| General | `llama3.3:70b` | ~40GB | Good all-around |\n\n## LangChain Integration\n\n```python\nfrom langchain_ollama import ChatOllama, OllamaEmbeddings\n\n# Chat model\nllm = ChatOllama(\n    model=\"deepseek-r1:70b\",\n    base_url=\"http://localhost:11434\",\n    temperature=0.0,\n    num_ctx=32768,      # Context window\n    keep_alive=\"5m\",    # Keep model loaded\n)\n\n# Embeddings\nembeddings = OllamaEmbeddings(\n    model=\"nomic-embed-text\",\n    base_url=\"http://localhost:11434\",\n)\n\n# Generate\nresponse = await llm.ainvoke(\"Explain async/await\")\nvector = await embeddings.aembed_query(\"search text\")\n```\n\n## Tool Calling with Ollama\n\n```python\nfrom langchain_core.tools import tool\n\n@tool\ndef search_docs(query: str) -> str:\n    \"\"\"Search the document database.\"\"\"\n    return f\"Found results for: {query}\"\n\n# Bind tools\nllm_with_tools = llm.bind_tools([search_docs])\nresponse = await llm_with_tools.ainvoke(\"Search for Python patterns\")\n```\n\n## Structured Output\n\n```python\nfrom pydantic import BaseModel, Field\n\nclass CodeAnalysis(BaseModel):\n    language: str = Field(description=\"Programming language\")\n    complexity: int = Field(ge=1, le=10)\n    issues: list[str] = Field(description=\"Found issues\")\n\nstructured_llm = llm.with_structured_output(CodeAnalysis)\nresult = await structured_llm.ainvoke(\"Analyze this code: ...\")\n# result is typed CodeAnalysis object\n```\n\n## Provider Factory Pattern\n\n```python\nimport os\n\ndef get_llm_provider(task_type: str = \"general\"):\n    \"\"\"Auto-switch between Ollama and cloud APIs.\"\"\"\n    if os.getenv(\"OLLAMA_ENABLED\") == \"true\":\n        models = {\n            \"reasoning\": \"deepseek-r1:70b\",\n            \"coding\": \"qwen2.5-coder:32b\",\n            \"general\": \"llama3.3:70b\",\n        }\n        return ChatOllama(\n            model=models.get(task_type, \"llama3.3:70b\"),\n            keep_alive=\"5m\"\n        )\n    else:\n        # Fall back to cloud API\n        return ChatOpenAI(model=\"gpt-5.2\")\n\n# Usage\nllm = get_llm_provider(task_type=\"coding\")\n```\n\n## Environment Configuration\n\n```bash\n# .env.local\nOLLAMA_ENABLED=true\nOLLAMA_HOST=http://localhost:11434\nOLLAMA_MODEL_REASONING=deepseek-r1:70b\nOLLAMA_MODEL_CODING=qwen2.5-coder:32b\nOLLAMA_MODEL_EMBED=nomic-embed-text\n\n# Performance tuning (Apple Silicon)\nOLLAMA_MAX_LOADED_MODELS=3    # Keep 3 models in memory\nOLLAMA_KEEP_ALIVE=5m          # 5 minute k",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator"
    ]
  },
  "outbox-pattern": {
    "name": "outbox-pattern",
    "description": "Transactional outbox pattern for reliable event publishing. Use when implementing atomic writes with event delivery, ensuring exactly-once semantics, or building event-driven microservices.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "event-driven",
      "outbox",
      "transactions",
      "reliability",
      "microservices",
      "cdc",
      "idempotency"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob",
      "Bash"
    ],
    "skills": [],
    "agent": "event-driven-architect",
    "structure": {
      "references": [
        "cdc-debezium.md",
        "idempotency-patterns.md",
        "outbox-delivery-patterns.md"
      ],
      "scripts": [
        "outbox-publisher-template.py"
      ],
      "checklists": [
        "outbox-checklist.md"
      ]
    },
    "content": "# Outbox Pattern ()\n\nEnsure atomic state changes and event publishing by writing both to a database transaction, then publishing asynchronously.\n\n## Overview\n\n- Ensuring database writes and event publishing are atomic\n- Building reliable event-driven microservices\n- Implementing exactly-once message delivery semantics\n- Avoiding dual-write problems (DB + message broker)\n- Decoupling domain logic from message infrastructure\n- High-throughput systems needing CDC-based publishing\n\n## Quick Reference\n\n### Outbox Table Schema\n\n```sql\nCREATE TABLE outbox (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    aggregate_type VARCHAR(100) NOT NULL,\n    aggregate_id UUID NOT NULL,\n    event_type VARCHAR(100) NOT NULL,\n    payload JSONB NOT NULL,\n    idempotency_key VARCHAR(255) UNIQUE,  -- For consumer deduplication\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    published_at TIMESTAMPTZ,\n    retry_count INT DEFAULT 0,\n    last_error TEXT\n);\n\n-- Index for polling unpublished messages\nCREATE INDEX idx_outbox_unpublished ON outbox(created_at)\n    WHERE published_at IS NULL;\n\n-- Index for aggregate ordering\nCREATE INDEX idx_outbox_aggregate ON outbox(aggregate_id, created_at);\n\n-- Index for idempotency key lookups\nCREATE INDEX idx_outbox_idempotency ON outbox(idempotency_key)\n    WHERE idempotency_key IS NOT NULL;\n```\n\n### SQLAlchemy Model\n\n```python\nfrom sqlalchemy.dialects.postgresql import UUID, JSONB\nimport hashlib\n\nclass OutboxMessage(Base):\n    __tablename__ = \"outbox\"\n\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    aggregate_type = Column(String(100), nullable=False)\n    aggregate_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n    event_type = Column(String(100), nullable=False)\n    payload = Column(JSONB, nullable=False)\n    idempotency_key = Column(String(255), unique=True, nullable=True)\n    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc))\n    published_at = Column(DateTime, nullable=True)\n    retry_count = Column(Integer, default=0)\n    last_error = Column(Text, nullable=True)\n\n    @staticmethod\n    def generate_idempotency_key(aggregate_id: str, event_type: str, payload: dict) -> str:\n        \"\"\"Generate deterministic idempotency key for deduplication.\"\"\"\n        content = f\"{aggregate_id}:{event_type}:{json.dumps(payload, sort_keys=True)}\"\n        return hashlib.sha256(content.encode()).hexdigest()[:32]\n```\n\n### Write to Outbox in Transaction\n\n```python\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nclass OrderService:\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create_order(self, order_data: OrderCreate) -> Order:\n        \"\"\"Create order AND outbox message in single transaction.\"\"\"\n        # Create the order\n        order = Order(**order_data.model_dump())\n        self.db.add(order)\n\n        # Create outbox message in SAME transaction\n        outbox_msg = OutboxMessage(\n            aggregate_type=\"Order\",\n            aggregate_id=ord",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "event-driven-architect"
    ]
  },
  "owasp-top-10": {
    "name": "owasp-top-10",
    "description": "OWASP Top 10 security vulnerabilities and mitigations. Use when conducting security audits, implementing security controls, or reviewing code for common vulnerabilities.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "owasp",
      "vulnerabilities",
      "audit"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "vulnerability-demos.md"
      ]
    },
    "content": "# OWASP Top 10\n\nProtect against the most critical web security risks.\n\n## 1. Broken Access Control\n\n```python\n# ❌ Bad: No authorization check\n@app.route('/api/users/<user_id>')\ndef get_user(user_id):\n    return db.query(f\"SELECT * FROM users WHERE id = {user_id}\")\n\n# ✅ Good: Verify user can access resource\n@app.route('/api/users/<user_id>')\n@login_required\ndef get_user(user_id):\n    if current_user.id != user_id and not current_user.is_admin:\n        abort(403)\n    return db.query(\"SELECT * FROM users WHERE id = ?\", [user_id])\n```\n\n## 2. Cryptographic Failures\n\n```python\n# ❌ Bad: Weak hashing\nimport hashlib\npassword_hash = hashlib.md5(password.encode()).hexdigest()\n\n# ✅ Good: Strong hashing\nfrom argon2 import PasswordHasher\nph = PasswordHasher()\npassword_hash = ph.hash(password)\n```\n\n## 3. Injection\n\n```python\n# ❌ Bad: SQL injection vulnerable\nquery = f\"SELECT * FROM users WHERE email = '{email}'\"\n\n# ✅ Good: Parameterized query\nquery = \"SELECT * FROM users WHERE email = ?\"\ndb.execute(query, [email])\n```\n\n## 4. Insecure Design\n\n- No rate limiting on login\n- Sequential/guessable IDs\n- No CAPTCHA on sensitive operations\n\n**Fix:** Use UUIDs, implement rate limiting, threat model early.\n\n## 5. Security Misconfiguration\n\n```python\n# ❌ Bad: Debug mode in production\napp.debug = True\n\n# ✅ Good: Environment-based config\napp.debug = os.getenv('FLASK_ENV') == 'development'\n```\n\n## 6. Vulnerable Components\n\n```bash\n# Scan for vulnerabilities\nnpm audit\npip-audit\n\n# Fix vulnerabilities\nnpm audit fix\n```\n\n## 7. Authentication Failures\n\n```python\n# ✅ Strong password requirements\ndef validate_password(password):\n    if len(password) < 12:\n        return \"Password must be 12+ characters\"\n    if not re.search(r\"[A-Z]\", password):\n        return \"Must contain uppercase\"\n    if not re.search(r\"[0-9]\", password):\n        return \"Must contain number\"\n    return None\n```\n\n## JWT Security (OWASP Best Practices)\n\n```python\nimport jwt\nimport hashlib\nimport secrets\nfrom datetime import datetime, timezone, timedelta\n\n# ❌ Bad: Trust algorithm from header\npayload = jwt.decode(token, SECRET, algorithms=jwt.get_unverified_header(token)['alg'])\n\n# ✅ Good: Hardcode expected algorithm (prevents algorithm confusion attacks)\ndef verify_jwt(token: str) -> dict:\n    try:\n        payload = jwt.decode(\n            token,\n            SECRET_KEY,\n            algorithms=['HS256'],  # NEVER read from header\n            options={\n                'require': ['exp', 'iat', 'iss', 'aud'],  # Required claims\n            }\n        )\n\n        # Validate issuer and audience\n        if payload['iss'] != EXPECTED_ISSUER:\n            raise jwt.InvalidIssuerError()\n        if payload['aud'] != EXPECTED_AUDIENCE:\n            raise jwt.InvalidAudienceError()\n\n        return payload\n    except jwt.ExpiredSignatureError:\n        raise AuthError(\"Token expired\")\n    except jwt.InvalidTokenError as e:\n        raise AuthError(f\"Invalid token: {e}\")\n\n# Token sidejacking protection (OWASP recommended)\ndef create_",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "ai-safety-auditor",
      "backend-system-architect",
      "code-quality-reviewer",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer"
    ]
  },
  "performance-optimization": {
    "name": "performance-optimization",
    "description": "Use when application is slow, bundle is too large, or investigating performance issues. Performance optimization covers profiling, React concurrent features, bundle analysis, and optimization patterns.",
    "version": "1.2.0",
    "author": "OrchestKit",
    "tags": [
      "performance",
      "optimization",
      "profiling",
      "caching"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "caching-strategies.md",
        "core-web-vitals.md",
        "database-optimization.md",
        "frontend-performance.md",
        "profiling.md"
      ],
      "scripts": [
        "api-optimization.ts",
        "caching-patterns.ts",
        "database-optimization.ts",
        "frontend-optimization.tsx",
        "performance-metrics.ts"
      ],
      "checklists": [
        "performance-audit-checklist.md"
      ]
    },
    "content": "# Performance Optimization Skill\n\nComprehensive frameworks for analyzing and optimizing application performance across the entire stack.\n\n## Overview\n\n- Application feels slow or unresponsive\n- Database queries taking too long\n- Frontend bundle size too large\n- API response times exceed targets\n- Core Web Vitals need improvement\n- Preparing for scale or high traffic\n\n## Performance Targets\n\n### Core Web Vitals (Frontend)\n\n| Metric | Good | Needs Work |\n|--------|------|------------|\n| **LCP** (Largest Contentful Paint) | < 2.5s | < 4s |\n| **INP** (Interaction to Next Paint) | < 200ms | < 500ms |\n| **CLS** (Cumulative Layout Shift) | < 0.1 | < 0.25 |\n| **TTFB** (Time to First Byte) | < 200ms | < 600ms |\n\n### Backend Targets\n\n| Operation | Target |\n|-----------|--------|\n| Simple reads | < 100ms |\n| Complex queries | < 500ms |\n| Write operations | < 200ms |\n| Index lookups | < 10ms |\n\n## Bottleneck Categories\n\n| Category | Symptoms | Tools |\n|----------|----------|-------|\n| **Network** | High TTFB, slow loading | Network tab, WebPageTest |\n| **Database** | Slow queries, pool exhaustion | EXPLAIN ANALYZE, pg_stat_statements |\n| **CPU** | High usage, slow compute | Profiler, flame graphs |\n| **Memory** | Leaks, GC pauses | Heap snapshots |\n| **Rendering** | Layout thrashing | React DevTools, Performance tab |\n\n---\n\n## Protocol References\n\n### Database Optimization\n**See: `references/database-optimization.md`**\n\nKey topics covered:\n- N+1 query detection and fixes with SQLAlchemy `selectinload`\n- Index selection strategies (B-tree, GIN, HNSW, Hash)\n- EXPLAIN ANALYZE interpretation\n- Connection pooling configuration\n- Cursor vs offset pagination\n\n### Caching Strategies\n**See: `references/caching-strategies.md`**\n\nKey topics covered:\n- Multi-level cache hierarchy (L1-L4)\n- Cache-aside and write-through patterns\n- Cache invalidation strategies (TTL, event-based, tag-based)\n- Redis patterns (strings, hashes, lists, sets)\n- Cache stampede prevention\n- HTTP caching headers and ETags\n\n### Core Web Vitals\n**See: `references/core-web-vitals.md`**\n\nKey topics covered:\n- LCP optimization (images, SSR, critical CSS)\n- INP optimization (debounce, Web Workers, task splitting)\n- CLS optimization (image dimensions, font loading)\n- Measuring with web-vitals library\n- Lighthouse auditing\n\n### Frontend Performance\n**See: `references/frontend-performance.md`**\n\nKey topics covered:\n- Code splitting with React.lazy()\n- Tree shaking and import optimization\n- Image optimization (WebP, AVIF, lazy loading)\n- Memoization (memo, useMemo, useCallback)\n- List virtualization with @tanstack/react-virtual\n- Bundle analysis tools\n\n### Profiling Tools\n**See: `references/profiling.md`**\n\nKey topics covered:\n- Python profiling (cProfile, py-spy, memory_profiler)\n- Chrome DevTools Performance and Memory tabs\n- React DevTools Profiler\n- PostgreSQL query profiling (pg_stat_statements)\n- Flame graph interpretation\n- Load testing with k6 and Locust\n\n---\n\n## Quick Diagnostics\n\n### Database\n\n``",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "database-engineer",
      "system-design-reviewer"
    ]
  },
  "performance-testing": {
    "name": "performance-testing",
    "description": "Performance and load testing with k6 and Locust. Use when validating system performance under load, stress testing, identifying bottlenecks, or establishing performance baselines.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "performance",
      "load",
      "stress"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "metrics-architect",
    "structure": {
      "references": [
        "k6-patterns.md"
      ],
      "scripts": [
        "k6-script.js"
      ],
      "checklists": [
        "performance-checklist.md"
      ]
    },
    "content": "# Performance Testing\n\nValidate system behavior under load.\n\n## k6 Load Test (JavaScript)\n\n```javascript\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '30s', target: 20 },  // Ramp up\n    { duration: '1m', target: 20 },   // Steady\n    { duration: '30s', target: 0 },   // Ramp down\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<500'],  // 95% under 500ms\n    http_req_failed: ['rate<0.01'],    // <1% errors\n  },\n};\n\nexport default function () {\n  const res = http.get('http://localhost:8500/api/health');\n\n  check(res, {\n    'status is 200': (r) => r.status === 200,\n    'response time < 200ms': (r) => r.timings.duration < 200,\n  });\n\n  sleep(1);\n}\n```\n\n## Locust Load Test (Python)\n\n```python\nfrom locust import HttpUser, task, between\n\nclass APIUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def get_analyses(self):\n        self.client.get(\"/api/analyses\")\n\n    @task(1)\n    def create_analysis(self):\n        self.client.post(\n            \"/api/analyses\",\n            json={\"url\": \"https://example.com\"}\n        )\n\n    def on_start(self):\n        \"\"\"Login before tasks.\"\"\"\n        self.client.post(\"/api/auth/login\", json={\n            \"email\": \"test@example.com\",\n            \"password\": \"password\"\n        })\n```\n\n## Test Types\n\n### Load Test\n```javascript\n// Normal expected load\nexport const options = {\n  vus: 50,           // Virtual users\n  duration: '5m',    // Duration\n};\n```\n\n### Stress Test\n```javascript\n// Find breaking point\nexport const options = {\n  stages: [\n    { duration: '2m', target: 100 },\n    { duration: '2m', target: 200 },\n    { duration: '2m', target: 300 },\n    { duration: '2m', target: 400 },\n  ],\n};\n```\n\n### Spike Test\n```javascript\n// Sudden traffic surge\nexport const options = {\n  stages: [\n    { duration: '10s', target: 10 },\n    { duration: '1s', target: 1000 },  // Spike!\n    { duration: '3m', target: 1000 },\n    { duration: '10s', target: 10 },\n  ],\n};\n```\n\n### Soak Test\n```javascript\n// Sustained load (memory leaks)\nexport const options = {\n  vus: 50,\n  duration: '4h',\n};\n```\n\n## Metrics to Track\n\n```javascript\nimport { Trend, Counter, Rate } from 'k6/metrics';\n\nconst responseTime = new Trend('response_time');\nconst errors = new Counter('errors');\nconst successRate = new Rate('success_rate');\n\nexport default function () {\n  const start = Date.now();\n  const res = http.get('http://localhost:8500/api/data');\n\n  responseTime.add(Date.now() - start);\n\n  if (res.status !== 200) {\n    errors.add(1);\n    successRate.add(false);\n  } else {\n    successRate.add(true);\n  }\n}\n```\n\n## CI Integration\n\n```yaml\n# GitHub Actions\n- name: Run k6 load test\n  run: |\n    k6 run --out json=results.json tests/load/api.js\n\n- name: Check thresholds\n  run: |\n    if [ $(jq '.thresholds | .[] | select(.ok == false)' results.json | wc -l) -gt 0 ]; then\n      exit 1\n    fi\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Tool | k6",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "metrics-architect",
      "monitoring-engineer",
      "python-performance-engineer",
      "test-generator"
    ]
  },
  "persona-journey-mapping": {
    "name": "persona-journey-mapping",
    "description": "User personas, customer journey maps, empathy maps, and experience mapping patterns. Use when synthesizing research into actionable models, understanding user experiences, or aligning teams on customer needs.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ux",
      "personas",
      "journey-map",
      "empathy-map",
      "experience"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "ux-researcher",
    "structure": {
      "references": [
        "journey-map-workshop.md"
      ],
      "assets": [
        "persona-template.md"
      ],
      "checklists": [
        "persona-quality-checklist.md"
      ]
    },
    "content": "# Persona & Journey Mapping\n\nFrameworks for synthesizing research into actionable user models and experience maps.\n\n## User Personas\n\n### Persona vs. Empathy Map\n\n| Aspect | Persona | Empathy Map |\n|--------|---------|-------------|\n| Based on | Fictional composite | Real individuals |\n| Scope | Full user profile | Specific moment/scenario |\n| Purpose | Shared understanding | Build empathy quickly |\n| Creation | After research synthesis | During/after research |\n\n### Persona Template\n\n```markdown\n## Persona: [Name]\n\n### Photo & Demographics\n[Include representative image]\n- Age: [Range]\n- Role: [Job title]\n- Company: [Type/size]\n- Location: [Geographic]\n- Tech savviness: [Low/Medium/High]\n\n### Quote\n> \"[Characteristic statement that captures their mindset]\"\n\n### Background\n[2-3 sentences about their professional context]\n\n### Goals\n1. [Primary goal - what success looks like]\n2. [Secondary goal]\n3. [Tertiary goal]\n\n### Pain Points\n1. [Frustration with current state]\n2. [Obstacle they face]\n3. [Risk or concern]\n\n### Behaviors\n- [Typical workflow or habit]\n- [Tool preferences]\n- [Information sources]\n\n### Motivations\n- [What drives their decisions]\n- [What they value most]\n\n### Scenario\n[Brief story of how they might use your product]\n\n### Key Insight\n[The most important thing to remember about this persona]\n```\n\n### Persona Example\n\n```markdown\n## Persona: DevOps Dana\n\n### Demographics\n- Age: 32\n- Role: Senior DevOps Engineer\n- Company: Mid-size SaaS (200 employees)\n- Location: Austin, TX\n- Tech savviness: Expert\n\n### Quote\n> \"I don't have time for tools that create more work than they save.\"\n\n### Background\nDana manages CI/CD pipelines and infrastructure for a growing\nengineering team. She's responsible for reliability and developer\nproductivity, and is constantly balancing new requests with\nmaintaining existing systems.\n\n### Goals\n1. Reduce deployment failures and rollback frequency\n2. Give developers self-service capabilities without chaos\n3. Spend less time on repetitive tasks, more on improvements\n\n### Pain Points\n1. Alert fatigue from too many false positives\n2. Lack of visibility into who changed what and when\n3. Context switching between 10+ different tools\n\n### Behaviors\n- Checks Slack and monitoring dashboards first thing\n- Automates anything she does more than twice\n- Documents decisions in ADRs and runbooks\n\n### Motivations\n- Professional reputation for reliability\n- Autonomy to solve problems her way\n- Continuous learning and skill growth\n\n### Key Insight\nDana evaluates tools by \"time saved vs. time invested\"—she needs\nimmediate value with minimal onboarding.\n```\n\n## Empathy Maps\n\n### Standard Empathy Map\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                                                         │\n│                     [User/Persona]                      │\n│                                                         │\n├─────────────────────────┬───────────────────────────────┤\n│         SAYS            │     ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "ux-researcher"
    ]
  },
  "pgvector-search": {
    "name": "pgvector-search",
    "description": "Production hybrid search combining PGVector HNSW with BM25 using Reciprocal Rank Fusion. Use when implementing hybrid search, semantic + keyword retrieval, vector search optimization, metadata filtering, or choosing between HNSW and IVFFlat indexes.",
    "version": "1.2.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "pgvector-0.8",
      "hybrid-search",
      "bm25",
      "rrf",
      "semantic-search",
      "retrieval"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "database-engineer",
    "structure": {
      "references": [
        "hybrid-search-rrf.md",
        "indexing-strategies.md",
        "metadata-filtering.md"
      ],
      "scripts": [
        "chunk-repository.py",
        "search-service.py"
      ],
      "checklists": [
        "search-implementation-checklist.md"
      ]
    },
    "content": "# PGVector Hybrid Search\n\n**Production-grade semantic + keyword search using PostgreSQL**\n\n## Overview\n\n**Architecture:**\n```\nQuery\n  |\n[Generate embedding] --> Vector Search (PGVector) --> Top 30 results\n  |\n[Generate ts_query]  --> Keyword Search (BM25)    --> Top 30 results\n  |\n[Reciprocal Rank Fusion (RRF)] --> Merge & re-rank --> Top 10 final results\n```\n\n**When to use this skill:**\n- Building semantic search (RAG, knowledge bases, recommendations)\n- Implementing hybrid retrieval (vector + keyword)\n- Optimizing PGVector performance\n- Working with large document collections (1M+ chunks)\n\n---\n\n## Quick Reference\n\n### Search Type Comparison\n\n| Aspect | Semantic (Vector) | Keyword (BM25) |\n|--------|-------------------|----------------|\n| **Query** | Embedding similarity | Exact word matches |\n| **Strengths** | Synonyms, concepts | Exact phrases, rare terms |\n| **Weaknesses** | Exact matches, technical terms | No semantic understanding |\n| **Index** | HNSW (pgvector) | GIN (tsvector) |\n\n### Index Comparison\n\n| Metric | IVFFlat | HNSW |\n|--------|---------|------|\n| **Query speed** | 50ms | 3ms (17x faster) |\n| **Index time** | 2 min | 20 min |\n| **Best for** | < 100k vectors | 100k+ vectors |\n| **Recall@10** | 0.85-0.95 | 0.95-0.99 |\n\n**Recommendation:** Use HNSW for production (scales to millions).\n\n### RRF Formula\n\n```python\nrrf_score = 1/(k + vector_rank) + 1/(k + keyword_rank)  # k=60 (standard)\n```\n\n---\n\n## Database Schema\n\n```sql\nCREATE TABLE chunks (\n    id UUID PRIMARY KEY,\n    document_id UUID REFERENCES documents(id),\n    content TEXT NOT NULL,\n    embedding vector(1024),  -- PGVector\n    content_tsvector tsvector GENERATED ALWAYS AS (\n        to_tsvector('english', content)\n    ) STORED,\n    section_title TEXT,\n    content_type TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Indexes\nCREATE INDEX idx_chunks_embedding ON chunks\n    USING hnsw (embedding vector_cosine_ops)\n    WITH (m = 16, ef_construction = 64);\n\nCREATE INDEX idx_chunks_content_tsvector ON chunks\n    USING gin (content_tsvector);\n```\n\n---\n\n## Hybrid Search Query (SQLAlchemy)\n\n```python\nasync def hybrid_search(\n    query: str,\n    query_embedding: list[float],\n    top_k: int = 10\n) -> list[Chunk]:\n    FETCH_MULTIPLIER = 3  # Fetch 30 for better RRF coverage\n    K = 60  # RRF smoothing constant\n\n    # Vector search subquery\n    vector_subq = (\n        select(Chunk.id,\n            func.row_number().over(\n                order_by=Chunk.embedding.cosine_distance(query_embedding)\n            ).label(\"vector_rank\"))\n        .limit(top_k * FETCH_MULTIPLIER)\n        .subquery()\n    )\n\n    # Keyword search subquery\n    ts_query = func.plainto_tsquery(\"english\", query)\n    keyword_subq = (\n        select(Chunk.id,\n            func.row_number().over(\n                order_by=func.ts_rank_cd(Chunk.content_tsvector, ts_query).desc()\n            ).label(\"keyword_rank\"))\n        .where(Chunk.content_tsvector.op(\"@@\")(ts_query))\n        .limit(top_k * FETCH_MULTIPLIER)\n        .subq",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "database-engineer"
    ]
  },
  "pii-masking-patterns": {
    "name": "pii-masking-patterns",
    "description": "PII detection and masking for LLM observability. Use when logging prompts/responses, tracing with Langfuse, or protecting sensitive data in production LLM pipelines.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "pii",
      "masking",
      "privacy",
      "security",
      "langfuse",
      "presidio",
      "gdpr"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "monitoring-engineer",
    "structure": {
      "references": [
        "langfuse-mask-callback.md",
        "llm-guard-sanitization.md",
        "logging-redaction.md",
        "presidio-integration.md"
      ]
    },
    "content": "# PII Masking Patterns\n\nProtect sensitive data in LLM observability pipelines with automated PII detection and redaction.\n\n## Overview\n\n- Masking PII before logging prompts and responses\n- Integrating with Langfuse tracing via mask callbacks\n- Using Microsoft Presidio for enterprise-grade detection\n- Implementing LLM Guard for input/output sanitization\n- Pre-logging redaction with structlog/loguru\n\n## Quick Reference\n\n### Langfuse Mask Callback (Recommended)\n\n```python\nimport re\nfrom langfuse import Langfuse\n\ndef mask_pii(data, **kwargs):\n    \"\"\"Mask PII before sending to Langfuse.\"\"\"\n    if isinstance(data, str):\n        # Credit cards\n        data = re.sub(r'\\b(?:\\d[ -]*?){13,19}\\b', '[REDACTED_CC]', data)\n        # Emails\n        data = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', '[REDACTED_EMAIL]', data)\n        # Phone numbers\n        data = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '[REDACTED_PHONE]', data)\n        # SSN\n        data = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[REDACTED_SSN]', data)\n    return data\n\n# Initialize with masking\nlangfuse = Langfuse(mask=mask_pii)\n```\n\n### Microsoft Presidio Pipeline\n\n```python\nfrom presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\n\nanalyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\n\ndef anonymize_text(text: str, language: str = \"en\") -> str:\n    \"\"\"Detect and anonymize PII using Presidio.\"\"\"\n    results = analyzer.analyze(text=text, language=language)\n    anonymized = anonymizer.anonymize(text=text, analyzer_results=results)\n    return anonymized.text\n```\n\n### LLM Guard Sanitization\n\n```python\nfrom llm_guard.input_scanners import Anonymize\nfrom llm_guard.output_scanners import Sensitive\nfrom llm_guard.vault import Vault\n\nvault = Vault()  # Stores original values for deanonymization\n\n# Input sanitization\ninput_scanner = Anonymize(vault, preamble=\"\", language=\"en\")\nsanitized_prompt, is_valid, risk_score = input_scanner.scan(prompt)\n\n# Output sanitization\noutput_scanner = Sensitive(entity_types=[\"PERSON\", \"EMAIL\"], redact=True)\nsanitized_output, is_valid, risk_score = output_scanner.scan(prompt, response)\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Detection engine | Presidio (enterprise), regex (simple), LLM Guard (LLM pipelines) |\n| Masking strategy | Replace with type tokens `[REDACTED_EMAIL]` for debuggability |\n| Performance | Use async/batch processing for high-throughput |\n| Langfuse integration | Use `mask=` callback at client initialization |\n| Reversibility | Use LLM Guard Vault for deanonymization when needed |\n\n## Anti-Patterns\n\n```python\n# ❌ NEVER log raw PII\nlogger.info(f\"User email: {user.email}\")  # PII leakage!\n\n# ❌ NEVER send unmasked data to observability\nlangfuse.trace(input=raw_prompt)  # May contain PII!\n\n# ✅ ALWAYS mask before logging\nlogger.info(f\"User email: {mask_email(user.email)}\")\n\n# ✅ ALWAYS use mask callback\nlangfuse = Langfuse(mask=mask_pii)\n```\n\n## Detailed Documentation\n\n| Resource | Descripti",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "platform-upgrade-knowledge": {
    "name": "platform-upgrade-knowledge",
    "description": "Platform upgrade evaluation criteria and compatibility knowledge. Use when assessing model or CC version upgrades.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "upgrade",
      "assessment",
      "compatibility",
      "platform",
      "migration"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "deployment-manager",
    "structure": {
      "references": [
        "compatibility-matrix.md",
        "scoring-rubric.md"
      ]
    },
    "content": "# Platform Upgrade Knowledge\n\nComprehensive reference for evaluating Claude model transitions, Claude Code version bumps, and OrchestKit plugin upgrades. Provides the evaluation criteria, compatibility matrices, and migration effort estimates used by the `upgrade-assessment` skill.\n\n## Overview\n\nPlatform upgrades span three independent axes, each with distinct compatibility concerns:\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                   Platform Upgrade Axes                  │\n├─────────────────┬─────────────────┬─────────────────────┤\n│  Claude Model   │  Claude Code    │  OrchestKit Plugin  │\n│  (AI backend)   │  (CLI runtime)  │  (skills/hooks/     │\n│                 │                 │   agents layer)     │\n├─────────────────┼─────────────────┼─────────────────────┤\n│  Context window │  Hook types     │  Skill format       │\n│  Output limits  │  Skill format   │  Agent format       │\n│  Capabilities   │  Agent format   │  Hook source        │\n│  Model ID       │  Tool registry  │  Manifest schema    │\n│  Pricing        │  Permission fmt │  Build system       │\n└─────────────────┴─────────────────┴─────────────────────┘\n```\n\nEach axis can be upgraded independently, but interactions between them must be validated.\n\n## When to Use\n\n- As reference knowledge for the `upgrade-assessment` command skill\n- When planning a migration strategy across model or platform versions\n- When estimating effort for a platform upgrade\n- When classifying breaking changes by severity\n\n---\n\n## Model Capability Evolution\n\n### Context Windows\n\n| Model | Context Window | Max Output | Released |\n|-------|---------------|------------|----------|\n| Claude 3 Haiku | 200K | 4,096 | Mar 2024 |\n| Claude 3.5 Sonnet | 200K | 8,192 | Jun 2024 |\n| Claude 3.5 Sonnet v2 | 200K | 8,192 | Oct 2024 |\n| Claude 3.5 Haiku | 200K | 8,192 | Nov 2024 |\n| Claude Sonnet 4 | 200K | 64,000 | May 2025 |\n| Claude Opus 4 | 200K | 32,000 | May 2025 |\n| Claude Sonnet 4.5 | 1,000K | 64,000 | Sep 2025 |\n| Claude Opus 4.6 | 1,000K | 128,000 | Jan 2026 |\n\n### Feature Evolution\n\n| Feature | First Available | Notes |\n|---------|----------------|-------|\n| Tool use | Claude 3 | All current models |\n| Vision (image input) | Claude 3 | All current models |\n| Extended thinking | Claude Sonnet 4 | Opus 4, Sonnet 4.5, Opus 4.6 |\n| Computer use | Claude Sonnet 4 | Beta, not all models |\n| PDF input | Claude 3.5 Sonnet v2 | All newer models |\n| Token counting API | Claude 3.5 | All current models |\n| Prompt caching | Claude 3.5 | Automatic on Anthropic API |\n| Batch API | Claude 3.5 | All current models |\n| Citations | Claude Sonnet 4 | API feature |\n| Code execution | Claude Opus 4 | Sandbox environment |\n| MCP (Model Context Protocol) | Claude Sonnet 4 | Via Claude Code / Desktop |\n| Files API | Claude Opus 4.6 | Direct file attachment |\n| Data residency (`inference_geo`) | Claude Opus 4.6 | `\"global\"` or `\"us\"` for enterprise compliance |\n\n### Data Residency Controls (Enterprise)\n",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "prioritization-frameworks": {
    "name": "prioritization-frameworks",
    "description": "RICE, ICE, WSJF, MoSCoW and other prioritization frameworks for product backlogs. Use when scoring features, ranking initiatives, or deciding what to build next.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "prioritization",
      "rice",
      "ice",
      "wsjf",
      "moscow",
      "backlog"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "prioritization-analyst",
    "structure": {
      "references": [
        "rice-scoring-guide.md",
        "wsjf-guide.md"
      ],
      "assets": [
        "rice-scoring-spreadsheet.md"
      ],
      "checklists": [
        "prioritization-session-checklist.md"
      ]
    },
    "content": "# Prioritization Frameworks\n\nQuantitative and qualitative frameworks for ranking features, initiatives, and backlog items.\n\n## RICE Framework\n\nDeveloped by Intercom, RICE provides a data-driven score for comparing features.\n\n### Formula\n\n```\nRICE Score = (Reach × Impact × Confidence) / Effort\n```\n\n### Factors\n\n| Factor | Definition | Scale |\n|--------|------------|-------|\n| **Reach** | Users/customers affected per quarter | Actual number |\n| **Impact** | Effect on individual user | 0.25 (minimal) to 3 (massive) |\n| **Confidence** | How sure are you? | 0.5 (low) to 1.0 (high) |\n| **Effort** | Person-months required | Actual estimate |\n\n### Impact Scale\n\n| Score | Level | Description |\n|-------|-------|-------------|\n| 3 | Massive | Fundamental improvement |\n| 2 | High | Significant improvement |\n| 1 | Medium | Noticeable improvement |\n| 0.5 | Low | Minor improvement |\n| 0.25 | Minimal | Barely noticeable |\n\n### Confidence Scale\n\n| Score | Level | Evidence |\n|-------|-------|----------|\n| 1.0 | High | Strong data, validated |\n| 0.8 | Medium | Some data, reasonable assumptions |\n| 0.5 | Low | Gut feeling, little data |\n\n### Example Calculation\n\n```markdown\nFeature: Smart search with AI suggestions\n\nReach: 50,000 users/quarter (active searchers)\nImpact: 2 (high - significantly better results)\nConfidence: 0.8 (tested in prototype)\nEffort: 3 person-months\n\nRICE = (50,000 × 2 × 0.8) / 3 = 26,667\n```\n\n### RICE Template\n\n```markdown\n| Feature | Reach | Impact | Confidence | Effort | RICE Score |\n|---------|-------|--------|------------|--------|------------|\n| Feature A | 10,000 | 2 | 0.8 | 2 | 8,000 |\n| Feature B | 50,000 | 1 | 1.0 | 4 | 12,500 |\n| Feature C | 5,000 | 3 | 0.5 | 1 | 7,500 |\n```\n\n## ICE Framework\n\nSimpler than RICE, ICE is ideal for fast prioritization.\n\n### Formula\n\n```\nICE Score = Impact × Confidence × Ease\n```\n\n### Factors (All 1-10 Scale)\n\n| Factor | Question |\n|--------|----------|\n| **Impact** | How much will this move the metric? |\n| **Confidence** | How sure are we this will work? |\n| **Ease** | How easy is this to implement? |\n\n### Example\n\n```markdown\nFeature: One-click checkout\n\nImpact: 9 (directly increases conversion)\nConfidence: 7 (similar features work elsewhere)\nEase: 4 (requires payment integration work)\n\nICE = 9 × 7 × 4 = 252\n```\n\n### ICE vs RICE\n\n| Aspect | RICE | ICE |\n|--------|------|-----|\n| Complexity | More detailed | Simpler |\n| Reach consideration | Explicit | Implicit in Impact |\n| Effort | Person-months | 1-10 Ease scale |\n| Best for | Data-driven teams | Fast decisions |\n\n## WSJF (Weighted Shortest Job First)\n\nSAFe framework optimizing for economic value delivery.\n\n### Formula\n\n```\nWSJF = Cost of Delay / Job Size\n```\n\n### Cost of Delay Components\n\n```\nCost of Delay = User Value + Time Criticality + Risk Reduction\n```\n\n| Component | Question | Scale |\n|-----------|----------|-------|\n| **User Value** | How much do users/business want this? | 1-21 (Fibonacci) |\n| **Time Criticality** | Does value decay over tim",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "prioritization-analyst"
    ]
  },
  "product-strategy-frameworks": {
    "name": "product-strategy-frameworks",
    "description": "Value Proposition Canvas, Jobs-to-be-Done (JTBD), Build/Buy/Partner decisions, and strategic product frameworks. Use when validating value propositions, understanding customer needs, or making strategic technology decisions.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "strategy",
      "jtbd",
      "value-proposition",
      "build-buy-partner"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "product-strategist",
    "structure": {
      "references": [
        "build-buy-partner-decision.md",
        "value-prop-canvas-guide.md"
      ],
      "assets": [
        "strategy-assessment-template.md"
      ],
      "checklists": [
        "strategy-review-checklist.md"
      ]
    },
    "content": "# Product Strategy Frameworks\n\nStrategic frameworks for validating value propositions, understanding customer jobs, and making build/buy/partner decisions.\n\n## Jobs-to-be-Done (JTBD) Framework\n\nJTBD shifts focus from what a product is to why it's used. People don't buy products—they hire them to do specific jobs.\n\n### JTBD Statement Format\n\n```\nWhen [situation], I want to [motivation], so I can [expected outcome].\n```\n\n**Example:**\n```\nWhen I'm commuting to work, I want to catch up on industry news,\nso I can appear informed in morning meetings.\n```\n\n### Job Dimensions\n\n| Dimension | Description | Example |\n|-----------|-------------|---------|\n| **Functional** | Practical task to accomplish | \"Transfer money to a friend\" |\n| **Emotional** | How user wants to feel | \"Feel confident I didn't make a mistake\" |\n| **Social** | How user wants to be perceived | \"Appear tech-savvy to peers\" |\n\n### JTBD Discovery Process\n\n```markdown\n## Step 1: Identify Target Customer\n- Who struggles most with this job?\n- Who pays the most to get this job done?\n\n## Step 2: Define the Core Job\n- What is the customer ultimately trying to accomplish?\n- Strip away solutions—focus on the outcome\n\n## Step 3: Map Job Steps\n1. Define what success looks like\n2. Locate inputs needed\n3. Prepare for the job\n4. Confirm readiness\n5. Execute the job\n6. Monitor progress\n7. Modify as needed\n8. Conclude the job\n\n## Step 4: Identify Pain Points\n- Where do customers struggle?\n- What causes anxiety or frustration?\n- What workarounds exist?\n\n## Step 5: Quantify Opportunity\n- Importance: How important is this job? (1-10)\n- Satisfaction: How satisfied with current solutions? (1-10)\n- Opportunity = Importance + (Importance - Satisfaction)\n```\n\n## Value Proposition Canvas\n\nThe VPC aligns what you offer with what customers actually need.\n\n### Customer Profile (Right Side)\n\n```\n┌─────────────────────────────────────┐\n│         CUSTOMER PROFILE            │\n├─────────────────────────────────────┤\n│  JOBS                               │\n│  • Functional jobs (tasks)          │\n│  • Social jobs (how seen)           │\n│  • Emotional jobs (how feel)        │\n│                                     │\n│  PAINS                              │\n│  • Undesired outcomes               │\n│  • Obstacles                        │\n│  • Risks                            │\n│                                     │\n│  GAINS                              │\n│  • Required outcomes                │\n│  • Expected outcomes                │\n│  • Desired outcomes                 │\n│  • Unexpected outcomes              │\n└─────────────────────────────────────┘\n```\n\n### Value Map (Left Side)\n\n```\n┌─────────────────────────────────────┐\n│           VALUE MAP                 │\n├─────────────────────────────────────┤\n│  PRODUCTS & SERVICES                │\n│  • What we offer                    │\n│  • Features and capabilities        │\n│                                     │\n│  PAIN RELIEVERS                     │\n│  • How we eliminate pain",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "product-strategist"
    ]
  },
  "project-structure-enforcer": {
    "name": "project-structure-enforcer",
    "description": "Enforce 2026 folder structure standards - feature-based organization, max nesting depth, unidirectional imports. Blocks structural violations. Use when creating files or reviewing project architecture.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "structure",
      "architecture",
      "enforcement",
      "blocking",
      "imports",
      "organization"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "code-quality-reviewer",
    "structure": {
      "references": [
        "violation-examples.md"
      ]
    },
    "content": "Enforce 2026 folder structure best practices with **BLOCKING** validation.\n\n## Validation Rules\n\n### BLOCKING Rules (exit 1)\n\n| Rule | Check | Example Violation |\n|------|-------|-------------------|\n| **Max Nesting** | Max 4 levels from src/ or app/ | `src/a/b/c/d/e/file.ts` |\n| **No Barrel Files** | No index.ts re-exports | `src/components/index.ts` |\n| **Component Location** | React components in components/ or features/ | `src/utils/Button.tsx` |\n| **Hook Location** | Custom hooks in hooks/ directory | `src/components/useAuth.ts` |\n| **Import Direction** | Unidirectional: shared → features → app | `features/` importing from `app/` |\n\n## Expected Folder Structures\n\n### React/Next.js (Frontend)\n\n```\nsrc/\n├── app/              # Next.js App Router (pages)\n│   ├── (auth)/       # Route groups\n│   ├── api/          # API routes\n│   └── layout.tsx\n├── components/       # Reusable UI components\n│   ├── ui/           # Primitive components\n│   └── forms/        # Form components\n├── features/         # Feature modules (self-contained)\n│   ├── auth/\n│   │   ├── components/\n│   │   ├── hooks/\n│   │   ├── services/\n│   │   └── types.ts\n│   └── dashboard/\n├── hooks/            # Global custom hooks\n├── lib/              # Third-party integrations\n├── services/         # API clients\n├── types/            # Global TypeScript types\n└── utils/            # Pure utility functions\n```\n\n### FastAPI (Backend)\n\n```\napp/\n├── routers/          # API route handlers\n│   ├── router_users.py\n│   ├── router_auth.py\n│   └── deps.py       # Shared dependencies\n├── services/         # Business logic layer\n│   ├── user_service.py\n│   └── auth_service.py\n├── repositories/     # Data access layer\n│   ├── user_repository.py\n│   └── base_repository.py\n├── schemas/          # Pydantic models\n│   ├── user_schema.py\n│   └── auth_schema.py\n├── models/           # SQLAlchemy models\n│   ├── user_model.py\n│   └── base.py\n├── core/             # Config, security, deps\n│   ├── config.py\n│   ├── security.py\n│   └── database.py\n└── utils/            # Utility functions\n```\n\n## Nesting Depth Rules\n\nMaximum 4 levels from `src/` or `app/`:\n\n```\nALLOWED (4 levels):\n  src/features/auth/components/LoginForm.tsx\n  app/routers/v1/users/router_users.py\n\nBLOCKED (5+ levels):\n  src/features/dashboard/widgets/charts/line/LineChart.tsx\n  ↳ Flatten to: src/features/dashboard/charts/LineChart.tsx\n```\n\n## No Barrel Files\n\nBarrel files (`index.ts` that only re-export) cause tree-shaking issues with Vite/webpack:\n\n```typescript\n// BLOCKED: src/components/index.ts\nexport { Button } from './Button';\nexport { Input } from './Input';\nexport { Modal } from './Modal';\n\n// GOOD: Import directly\nimport { Button } from '@/components/Button';\nimport { Input } from '@/components/Input';\n```\n\n**Why?** Barrel files:\n- Break tree-shaking (entire barrel is imported)\n- Cause circular dependency issues\n- Slow down build times\n- Make debugging harder\n\n## Import Direction (Unidirectional Architecture)\n\nCode must flow in ONE ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "prompt-caching": {
    "name": "prompt-caching",
    "description": "Provider-native prompt caching for Claude and OpenAI. Use when optimizing LLM costs with cache breakpoints, caching system prompts, or reducing token costs for repeated prefixes.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "llm",
      "caching",
      "cost-optimization",
      "anthropic"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "llm-integrator",
    "structure": {
      "scripts": [
        "prompt-cache-wrapper.py"
      ]
    },
    "content": "# Prompt Caching\n\nCache LLM prompt prefixes for 90% token savings.\n\n## Supported Models (2026)\n\n| Provider | Models |\n|----------|--------|\n| Claude | Opus 4.1, Opus 4, Sonnet 4.5, Sonnet 4, Sonnet 3.7, Haiku 4.5, Haiku 3.5, Haiku 3 |\n| OpenAI | gpt-5.2, gpt-5.2-mini, o3, o3-mini (automatic caching) |\n\n## Claude Prompt Caching\n\n```python\ndef build_cached_messages(\n    system_prompt: str,\n    few_shot_examples: str | None,\n    user_content: str,\n    use_extended_cache: bool = False\n) -> list[dict]:\n    \"\"\"Build messages with cache breakpoints.\n\n    Cache structure (processing order: tools → system → messages):\n    1. System prompt (cached)\n    2. Few-shot examples (cached)\n    ─────── CACHE BREAKPOINT ───────\n    3. User content (NOT cached)\n    \"\"\"\n    # TTL: \"5m\" (default, 1.25x write cost) or \"1h\" (extended, 2x write cost)\n    ttl = \"1h\" if use_extended_cache else \"5m\"\n\n    content_parts = []\n\n    # Breakpoint 1: System prompt\n    content_parts.append({\n        \"type\": \"text\",\n        \"text\": system_prompt,\n        \"cache_control\": {\"type\": \"ephemeral\", \"ttl\": ttl}\n    })\n\n    # Breakpoint 2: Few-shot examples (up to 4 breakpoints allowed)\n    if few_shot_examples:\n        content_parts.append({\n            \"type\": \"text\",\n            \"text\": few_shot_examples,\n            \"cache_control\": {\"type\": \"ephemeral\", \"ttl\": ttl}\n        })\n\n    # Dynamic content (NOT cached)\n    content_parts.append({\n        \"type\": \"text\",\n        \"text\": user_content\n    })\n\n    return [{\"role\": \"user\", \"content\": content_parts}]\n```\n\n## Cache Pricing (2026)\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Cache Cost Multipliers (relative to base input price)      │\n├─────────────────────────────────────────────────────────────┤\n│  5-minute cache write:  1.25x base input price              │\n│  1-hour cache write:    2.00x base input price              │\n│  Cache read:            0.10x base input price (90% off!)   │\n└─────────────────────────────────────────────────────────────┘\n\nExample: Claude Sonnet 4 @ $3/MTok input\n\nWithout Prompt Caching:\nSystem prompt:     2,000 tokens @ $3/MTok  = $0.006\nFew-shot examples: 5,000 tokens @ $3/MTok  = $0.015\nUser content:     10,000 tokens @ $3/MTok  = $0.030\n───────────────────────────────────────────────────\nTotal:            17,000 tokens            = $0.051\n\nWith 5m Caching (first request = cache write):\nCached prefix:     7,000 tokens @ $3.75/MTok = $0.02625 (1.25x)\nUser content:     10,000 tokens @ $3/MTok    = $0.03000\nTotal first req:                             = $0.05625\n\nWith 5m Caching (subsequent = cache read):\nCached prefix:     7,000 tokens @ $0.30/MTok = $0.0021 (0.1x)\nUser content:     10,000 tokens @ $3/MTok    = $0.0300\nTotal cached req:                            = $0.0321\n\nSavings: 37% per cached request, break-even after 2 requests\n```\n\n## Extended Cache (1-hour TTL)\n\nUse 1-hour cache when:\n- Prompt reused > 10 times per hour\n- System prompts are highly stable\n- Token count > 10k ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "llm-integrator"
    ]
  },
  "prompt-engineering-suite": {
    "name": "prompt-engineering-suite",
    "description": "Comprehensive prompt engineering with Chain-of-Thought, few-shot learning, prompt versioning, and optimization. Use when designing prompts, improving accuracy, managing prompt lifecycle.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "prompts",
      "cot",
      "few-shot",
      "versioning",
      "optimization",
      "langfuse",
      "dspy"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "prompt-engineer",
    "structure": {
      "references": [
        "chain-of-thought.md",
        "few-shot-patterns.md",
        "prompt-optimization.md",
        "prompt-versioning.md"
      ],
      "scripts": [
        "cot-template.py",
        "few-shot-template.py",
        "jinja2-prompts.py"
      ],
      "checklists": [
        "prompt-design.md"
      ]
    },
    "content": "# Prompt Engineering Suite\n\nDesign, version, and optimize prompts for production LLM applications.\n\n## Overview\n\n- Designing prompts for new LLM features\n- Improving accuracy with Chain-of-Thought reasoning\n- Few-shot learning with example selection\n- Managing prompts in production (versioning, A/B testing)\n- Automatic prompt optimization with DSPy\n\n## Quick Reference\n\n### Chain-of-Thought Pattern\n\n```python\nfrom langchain_core.prompts import ChatPromptTemplate\n\nCOT_SYSTEM = \"\"\"You are a helpful assistant that solves problems step-by-step.\n\nWhen solving problems:\n1. Break down the problem into clear steps\n2. Show your reasoning for each step\n3. Verify your answer before responding\n4. If uncertain, acknowledge limitations\n\nFormat your response as:\nSTEP 1: [description]\nReasoning: [your thought process]\n\nSTEP 2: [description]\nReasoning: [your thought process]\n\n...\n\nFINAL ANSWER: [your conclusion]\"\"\"\n\ncot_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", COT_SYSTEM),\n    (\"human\", \"Problem: {problem}\\n\\nThink through this step-by-step.\"),\n])\n```\n\n### Few-Shot with Dynamic Examples\n\n```python\nfrom langchain_core.prompts import FewShotChatMessagePromptTemplate\n\nexamples = [\n    {\"input\": \"What is 2+2?\", \"output\": \"4\"},\n    {\"input\": \"What is the capital of France?\", \"output\": \"Paris\"},\n]\n\nfew_shot = FewShotChatMessagePromptTemplate(\n    examples=examples,\n    example_prompt=ChatPromptTemplate.from_messages([\n        (\"human\", \"{input}\"),\n        (\"ai\", \"{output}\"),\n    ]),\n)\n\nfinal_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant. Answer concisely.\"),\n    few_shot,\n    (\"human\", \"{input}\"),\n])\n```\n\n### Prompt Versioning with Langfuse SDK v3\n\n```python\nfrom langfuse import Langfuse\n# Note: Langfuse SDK v3 is OTEL-native (acquired by ClickHouse Jan )\n\nlangfuse = Langfuse()\n\n# Get versioned prompt with label\nprompt = langfuse.get_prompt(\n    name=\"customer-support-v2\",\n    label=\"production\",  # production, staging, canary\n    cache_ttl_seconds=300,\n)\n\n# Compile with variables\ncompiled = prompt.compile(\n    customer_name=\"John\",\n    issue=\"billing question\"\n)\n```\n\n### DSPy 3.1.0 Automatic Optimization\n\n```python\nimport dspy\n\nclass OptimizedQA(dspy.Module):\n    def __init__(self):\n        self.generate = dspy.Predict(\"question -> answer\")\n\n    def forward(self, question):\n        return self.generate(question=question)\n\n# Optimize with MIPROv2 (recommended) or BootstrapFewShot\noptimizer = dspy.MIPROv2(metric=answer_match)  # Data+demo-aware Bayesian optimization\noptimized = optimizer.compile(OptimizedQA(), trainset=examples)\n\n# Alternative: GEPA (July 2025) - Reflective Prompt Evolution\n# Uses model introspection to analyze failures and propose better prompts\n```\n\n## Pattern Selection Guide\n\n| Pattern | When to Use | Example Use Case |\n|---------|-------------|------------------|\n| Zero-shot | Simple, well-defined tasks | Classification, extraction |\n| Few-shot | Complex tasks needing examples | Format conve",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "prompt-engineer"
    ]
  },
  "property-based-testing": {
    "name": "property-based-testing",
    "description": "Property-based testing with Hypothesis for discovering edge cases automatically. Use when testing invariants, finding boundary conditions, implementing stateful testing, or validating data transformations.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "hypothesis",
      "property-testing",
      "fuzzing",
      "python",
      "testing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "stateful-testing.md",
        "strategies-guide.md"
      ],
      "scripts": [
        "hypothesis-conftest.py"
      ],
      "checklists": [
        "property-testing-checklist.md"
      ]
    },
    "content": "# Property-Based Testing with Hypothesis\n\nDiscover edge cases automatically by testing properties instead of examples.\n\n## Overview\n\n- Testing functions with many possible inputs\n- Validating invariants that must hold for all inputs\n- Finding boundary conditions and edge cases\n- Testing serialization/deserialization roundtrips\n- Stateful testing of APIs and state machines\n\n## Quick Reference\n\n### Example-Based vs Property-Based\n\n```python\n# Example-based: Test specific inputs\ndef test_sort_examples():\n    assert sort([3, 1, 2]) == [1, 2, 3]\n    # But what about [-1], [1.5, 2.5], ...?\n\n# Property-based: Test properties for ALL inputs\nfrom hypothesis import given\nfrom hypothesis import strategies as st\n\n@given(st.lists(st.integers()))\ndef test_sort_properties(lst):\n    result = sort(lst)\n    assert len(result) == len(lst)  # Same length\n    assert all(result[i] <= result[i+1] for i in range(len(result)-1))  # Ordered\n```\n\nSee [strategies-guide.md](references/strategies-guide.md) for complete strategy reference.\n\n### Common Strategies\n\n```python\nfrom hypothesis import strategies as st\n\nst.integers(min_value=0, max_value=100)  # Bounded integers\nst.text(min_size=1, max_size=50)         # Bounded text\nst.lists(st.integers(), max_size=10)     # Bounded lists\nst.from_regex(r\"[a-z]+@[a-z]+\\.[a-z]+\")  # Pattern-based\n\n# Composite for domain objects\n@st.composite\ndef user_strategy(draw):\n    return User(\n        name=draw(st.text(min_size=1, max_size=50)),\n        age=draw(st.integers(min_value=0, max_value=150)),\n    )\n```\n\n### Common Properties\n\n```python\n# Roundtrip (encode/decode)\n@given(st.dictionaries(st.text(), st.integers()))\ndef test_json_roundtrip(data):\n    assert json.loads(json.dumps(data)) == data\n\n# Idempotence\n@given(st.text())\ndef test_normalize_idempotent(text):\n    assert normalize(normalize(text)) == normalize(text)\n\n# Oracle (compare to known implementation)\n@given(st.lists(st.integers()))\ndef test_sort_matches_builtin(lst):\n    assert our_sort(lst) == sorted(lst)\n```\n\nSee [stateful-testing.md](references/stateful-testing.md) for state machine testing.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Strategy design | Composite strategies for domain objects |\n| Example count | 100 for CI, 10 for dev, 1000 for release |\n| Database tests | Use explicit mode, limit examples |\n| Deadline | Disable for slow tests, 200ms default |\n| Stateful tests | RuleBasedStateMachine for state machines |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER ignore failing examples\n@given(st.integers())\ndef test_bad(x):\n    if x == 42:\n        return  # WRONG - hiding failure!\n\n# NEVER use filter with low hit rate\nst.integers().filter(lambda x: x % 1000 == 0)  # WRONG - very slow\n\n# NEVER test with unbounded inputs\n@given(st.text())  # WRONG - includes 10MB strings\ndef test_username(name):\n    User(name=name)\n\n# NEVER mutate strategy results\n@given(st.lists(st.integers()))\ndef test_mutating(lst):\n    lst.append(42)  # WRONG - mu",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "pwa-patterns": {
    "name": "pwa-patterns",
    "description": "Progressive Web App patterns with Workbox 7.x, service worker lifecycle, offline-first strategies, and installability. Use when building PWAs, service workers, or offline support.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "pwa",
      "service-worker",
      "workbox",
      "offline-first",
      "cache-api",
      "push-notifications",
      "manifest",
      "installable"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "workbox-strategies.md"
      ]
    },
    "content": "# PWA Patterns\n\nProgressive Web App patterns using Workbox 7.x for service worker management, offline-first strategies, and app-like experiences.\n\n## Service Worker Lifecycle\n\n```\nInstalling -> Waiting -> Active\n     │           │           │\n  install    activated    fetch events\n (precache)  when old SW  (runtime cache)\n              is gone\n```\n\n## Workbox: Generate Service Worker\n\n```javascript\n// build-sw.js (Node.js)\nconst { generateSW } = require('workbox-build');\n\nasync function buildServiceWorker() {\n  await generateSW({\n    globDirectory: 'dist/',\n    globPatterns: ['**/*.{html,js,css,png,jpg,json,woff2}'],\n    swDest: 'dist/sw.js',\n    clientsClaim: true,\n    skipWaiting: true,\n    navigateFallback: '/index.html',\n    navigateFallbackDenylist: [/^\\/api\\//],\n    runtimeCaching: [\n      {\n        urlPattern: /^https:\\/\\/api\\.example\\.com\\//,\n        handler: 'NetworkFirst',\n        options: { cacheName: 'api-cache', networkTimeoutSeconds: 10 },\n      },\n      {\n        urlPattern: /\\.(?:png|jpg|jpeg|svg|gif|webp)$/,\n        handler: 'CacheFirst',\n        options: { cacheName: 'images', expiration: { maxEntries: 60, maxAgeSeconds: 30 * 24 * 60 * 60 } },\n      },\n    ],\n  });\n}\n```\n\n## Caching Strategies\n\n```javascript\n// CacheFirst: Static assets that rarely change\nregisterRoute(/\\.(?:js|css|woff2)$/, new CacheFirst({\n  cacheName: 'static-v1',\n  plugins: [new ExpirationPlugin({ maxEntries: 100, maxAgeSeconds: 365 * 24 * 60 * 60 })],\n}));\n\n// NetworkFirst: API calls (fresh data preferred)\nregisterRoute(/\\/api\\//, new NetworkFirst({\n  cacheName: 'api-cache',\n  networkTimeoutSeconds: 10,\n  plugins: [new CacheableResponsePlugin({ statuses: [0, 200] })],\n}));\n\n// StaleWhileRevalidate: User avatars, non-critical images\nregisterRoute(/\\/avatars\\//, new StaleWhileRevalidate({ cacheName: 'avatars' }));\n\n// NetworkOnly: Auth endpoints\nregisterRoute(/\\/auth\\//, new NetworkOnly());\n```\n\n## VitePWA Integration\n\n```typescript\n// vite.config.ts\nimport { VitePWA } from 'vite-plugin-pwa';\n\nexport default defineConfig({\n  plugins: [\n    VitePWA({\n      registerType: 'autoUpdate',\n      workbox: {\n        globPatterns: ['**/*.{js,css,html,ico,png,svg,woff2}'],\n        runtimeCaching: [{ urlPattern: /^https:\\/\\/api\\./, handler: 'NetworkFirst' }],\n      },\n      manifest: {\n        name: 'My PWA App',\n        short_name: 'MyPWA',\n        theme_color: '#4f46e5',\n        icons: [\n          { src: '/icon-192.png', sizes: '192x192', type: 'image/png' },\n          { src: '/icon-512.png', sizes: '512x512', type: 'image/png' },\n        ],\n      },\n    }),\n  ],\n});\n```\n\n## Web App Manifest\n\n```json\n{\n  \"name\": \"My Progressive Web App\",\n  \"short_name\": \"MyPWA\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#ffffff\",\n  \"theme_color\": \"#4f46e5\",\n  \"icons\": [\n    { \"src\": \"/icons/icon-192.png\", \"sizes\": \"192x192\", \"type\": \"image/png\", \"purpose\": \"maskable\" },\n    { \"src\": \"/icons/icon-512.png\", \"sizes\": \"512x512\", \"type\": \"image/png\" }\n  ]\n}\n```\n\n",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "pytest-advanced": {
    "name": "pytest-advanced",
    "description": "Advanced pytest patterns including custom markers, plugins, hooks, parallel execution, and pytest-xdist. Use when implementing custom test infrastructure, optimizing test execution, or building reusable test utilities.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "pytest",
      "testing",
      "python",
      "markers",
      "plugins",
      "xdist"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "custom-plugins.md",
        "xdist-parallel.md"
      ],
      "scripts": [
        "conftest-template.py"
      ],
      "checklists": [
        "pytest-production-checklist.md"
      ]
    },
    "content": "# Advanced Pytest Patterns\n\nMaster pytest's advanced features for scalable, maintainable test suites.\n\n## Overview\n\n- Building custom test markers for categorization\n- Writing pytest plugins and hooks\n- Configuring parallel test execution with pytest-xdist\n- Creating reusable fixture patterns\n- Optimizing test collection and execution\n\n## Quick Reference\n\n### Custom Markers\n\n```toml\n# pyproject.toml\n[tool.pytest.ini_options]\nmarkers = [\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: marks tests requiring external services\",\n    \"smoke: critical path tests for CI/CD\",\n]\n```\n\n```python\nimport pytest\n\n@pytest.mark.slow\ndef test_complex_analysis():\n    result = perform_complex_analysis(large_dataset)\n    assert result.is_valid\n\n# Run: pytest -m \"not slow\"  # Skip slow tests\n# Run: pytest -m smoke       # Only smoke tests\n```\n\nSee [custom-plugins.md](references/custom-plugins.md) for plugin development.\n\n### Parallel Execution (pytest-xdist)\n\n```toml\n[tool.pytest.ini_options]\naddopts = [\"-n\", \"auto\", \"--dist\", \"loadscope\"]\n```\n\n```python\n@pytest.fixture(scope=\"session\")\ndef db_engine(worker_id):\n    \"\"\"Isolate database per worker.\"\"\"\n    db_name = \"test_db\" if worker_id == \"master\" else f\"test_db_{worker_id}\"\n    engine = create_engine(f\"postgresql://localhost/{db_name}\")\n    yield engine\n```\n\nSee [xdist-parallel.md](references/xdist-parallel.md) for distribution modes.\n\n### Factory Fixtures\n\n```python\n@pytest.fixture\ndef user_factory(db_session) -> Callable[..., User]:\n    \"\"\"Factory fixture for creating users.\"\"\"\n    created = []\n\n    def _create(**kwargs) -> User:\n        user = User(**{\"email\": f\"u{len(created)}@test.com\", **kwargs})\n        db_session.add(user)\n        created.append(user)\n        return user\n\n    yield _create\n    for u in created:\n        db_session.delete(u)\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Parallel execution | pytest-xdist with `--dist loadscope` |\n| Marker strategy | Category (smoke, integration) + Resource (db, llm) |\n| Fixture scope | Function default, session for expensive setup |\n| Plugin location | conftest.py for project, package for reuse |\n| Async testing | pytest-asyncio with auto mode |\n\n## Anti-Patterns (FORBIDDEN)\n\n```python\n# NEVER use expensive fixtures without session scope\n@pytest.fixture  # WRONG - loads every test\ndef model():\n    return load_ml_model()  # 5s each time!\n\n# NEVER mutate global state\n@pytest.fixture\ndef counter():\n    global _counter\n    _counter += 1  # WRONG - leaks between tests\n\n# NEVER skip cleanup\n@pytest.fixture\ndef temp_db():\n    db = create_db()\n    yield db\n    # WRONG - missing db.drop()!\n\n# NEVER use time.sleep (use mocking)\ndef test_timeout():\n    time.sleep(5)  # WRONG - slows tests\n```\n\n## Related Skills\n\n- `unit-testing` - Basic pytest patterns and AAA structure\n- `integration-testing` - Database and API testing patterns\n- `property-based-testing` - Hypothesis integration with pytest\n\n## ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "quality-gates": {
    "name": "quality-gates",
    "description": "Use when assessing task complexity, before starting complex tasks, or when stuck after multiple attempts. Provides quality-gates scoring (1-5) and escalation workflows.",
    "version": "1.1.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "quality",
      "complexity",
      "planning",
      "escalation",
      "blocking"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "code-quality-reviewer",
    "structure": {
      "references": [
        "blocking-thresholds.md",
        "complexity-scoring.md",
        "gate-patterns.md",
        "llm-quality-validation.md",
        "workflows.md"
      ],
      "scripts": [
        "analyze-codebase.sh",
        "assess-complexity.md",
        "complexity-assessment.md",
        "count-dependencies.py",
        "gate-check-template.md",
        "requirements-checklist.md"
      ],
      "checklists": [
        "quality-gate-checklist.md"
      ]
    },
    "content": "# Quality Gates\n\nThis skill teaches agents how to assess task complexity, enforce quality gates, and prevent wasted work on incomplete or poorly-defined tasks.\n\n**Key Principle:** Stop and clarify before proceeding with incomplete information. Better to ask questions than to waste cycles on the wrong solution.\n\n---\n\n## Overview\n\n### Auto-Activate Triggers\n- Receiving a new task assignment\n- Starting a complex feature implementation\n- Before allocating work in Squad mode\n- When requirements seem unclear or incomplete\n- After 3 failed attempts at the same task\n- When blocked by dependencies\n\n### Manual Activation\n- User asks for complexity assessment\n- Planning a multi-step project\n- Before committing to a timeline\n\n---\n\n## Core Concepts\n\n### Complexity Scoring (1-5 Scale)\n\n| Level | Files | Lines | Time | Characteristics |\n|-------|-------|-------|------|-----------------|\n| 1 - Trivial | 1 | < 50 | < 30 min | No deps, no unknowns |\n| 2 - Simple | 1-3 | 50-200 | 30 min - 2 hr | 0-1 deps, minimal unknowns |\n| 3 - Moderate | 3-10 | 200-500 | 2-8 hr | 2-3 deps, some unknowns |\n| 4 - Complex | 10-25 | 500-1500 | 8-24 hr | 4-6 deps, significant unknowns |\n| 5 - Very Complex | 25+ | 1500+ | 24+ hr | 7+ deps, many unknowns |\n\n**See:** `references/complexity-scoring.md` for detailed examples and assessment formulas.\n\n### Blocking Thresholds\n\n| Condition | Threshold | Action |\n|-----------|-----------|--------|\n| Critical Questions | > 3 unanswered | BLOCK |\n| Missing Dependencies | Any blocking | BLOCK |\n| Failed Attempts | >= 3 | BLOCK & ESCALATE |\n| Evidence Failure | 2 fix attempts | BLOCK |\n| Complexity Overflow | Level 4-5 no plan | BLOCK |\n\n**WARNING Conditions** (proceed with caution):\n- Level 3 complexity\n- 1-2 unanswered questions\n- 1-2 failed attempts\n\n**See:** `references/blocking-thresholds.md` for escalation protocols and decision logic.\n\n---\n\n## References\n\n### Complexity Scoring\n**See:** `references/complexity-scoring.md`\n\nKey topics covered:\n- Detailed Level 1-5 characteristics and examples\n- Quick assessment formula\n- Assessment checklist\n\n### Blocking Thresholds & Escalation\n**See:** `references/blocking-thresholds.md`\n\nKey topics covered:\n- BLOCKING vs WARNING conditions\n- Escalation protocol and message templates\n- Gate decision logic\n- Attempt tracking\n\n### Quality Gate Workflows\n**See:** `references/workflows.md`\n\nKey topics covered:\n- Pre-task gate validation workflow\n- Stuck detection and escalation workflow\n- Complexity breakdown workflow (Level 4-5)\n- Requirements completeness check\n\n### Gate Patterns\n**See:** `references/gate-patterns.md`\n\nKey topics covered:\n- Gate validation process templates\n- Integration with context system\n- Common pitfalls\n\n### LLM Quality Validation\n**See:** `references/llm-quality-validation.md`\n\nKey topics covered:\n- LLM-as-judge patterns\n- Quality aspects (relevance, depth, coherence, accuracy, completeness)\n- Fail-open vs fail-closed strategies\n- Graceful degradation patterns\n- Triple-consumer artifac",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer"
    ]
  },
  "query-decomposition": {
    "name": "query-decomposition",
    "description": "Query decomposition for multi-concept retrieval. Use when handling complex queries spanning multiple topics, implementing multi-hop retrieval, or improving coverage for compound questions.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "retrieval",
      "query",
      "decomposition"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {},
    "content": "# Query Decomposition\nBreak complex queries into independent concepts for parallel retrieval and fusion.\n\n## Overview\n\n- Complex queries spanning multiple topics or concepts\n- Multi-hop questions requiring chained reasoning\n- Queries where single retrieval misses relevant documents\n- Improving recall for compound questions\n\nBreak complex queries into independent concepts for parallel retrieval and fusion.\n\n## The Problem\n\nComplex queries span multiple topics that may not co-occur in single documents:\n```\nQuery: \"How do chunking strategies affect reranking in RAG?\"\n→ Single search may miss docs about chunking OR reranking\n→ Poor coverage across all concepts\n```\n\n## The Solution\n\nDecompose into independent concepts, retrieve separately, then fuse:\n```\nQuery: \"How do chunking strategies affect reranking in RAG?\"\n→ Concepts: [\"chunking strategies\", \"reranking methods\", \"RAG pipeline\"]\n→ Search each concept independently\n→ Fuse results with Reciprocal Rank Fusion (RRF)\n→ Full coverage across all topics\n```\n\n## Implementation\n\n### 1. Heuristic Detection (Fast Path)\n\n```python\nMULTI_CONCEPT_INDICATORS = [\n    \" vs \", \" versus \", \" compared to \", \" or \",\n    \" and \", \" with \", \" affect \", \" impact \",\n    \"difference between\", \"relationship between\",\n]\n\ndef is_multi_concept_heuristic(query: str) -> bool:\n    \"\"\"Fast check for multi-concept indicators (<1ms).\"\"\"\n    query_lower = query.lower()\n    return any(ind in query_lower for ind in MULTI_CONCEPT_INDICATORS)\n```\n\n### 2. LLM Decomposition\n\n```python\nfrom pydantic import BaseModel, Field\nfrom openai import AsyncOpenAI\n\nclass ConceptExtraction(BaseModel):\n    \"\"\"LLM output schema for concept extraction.\"\"\"\n    concepts: list[str] = Field(\n        ...,\n        min_length=1,\n        max_length=5,\n        description=\"Distinct concepts from the query\",\n    )\n    reasoning: str | None = None\n\nasync def decompose_query(\n    query: str,\n    llm: AsyncOpenAI,\n) -> list[str]:\n    \"\"\"Extract independent concepts using LLM.\"\"\"\n\n    response = await llm.chat.completions.create(\n        model=\"gpt-5.2-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"\"\"\nExtract 2-4 independent concepts from this query.\nEach concept should be searchable on its own.\nOutput JSON: {\"concepts\": [\"concept1\", \"concept2\"], \"reasoning\": \"...\"}\n\"\"\"},\n            {\"role\": \"user\", \"content\": query}\n        ],\n        response_format={\"type\": \"json_object\"},\n        temperature=0,\n    )\n\n    result = ConceptExtraction.model_validate_json(\n        response.choices[0].message.content\n    )\n    return result.concepts\n```\n\n### 3. Parallel Retrieval + RRF Fusion\n\n```python\nimport asyncio\nfrom collections import defaultdict\n\nasync def decomposed_search(\n    query: str,\n    search_fn: callable,\n    llm: AsyncOpenAI,\n    top_k: int = 10,\n) -> list[dict]:\n    \"\"\"Search with query decomposition and RRF fusion.\"\"\"\n\n    # Check if decomposition needed\n    if not is_multi_concept_heuristic(query):\n        return await search_fn(query, limi",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "radix-primitives": {
    "name": "radix-primitives",
    "description": "Radix UI unstyled accessible primitives for dialogs, popovers, dropdowns, and more. Use when building custom accessible components, understanding shadcn internals, or needing polymorphic composition.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "radix",
      "ui",
      "primitives",
      "accessibility",
      "dialog",
      "popover",
      "dropdown",
      "aschild",
      "a11y"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "aschild-composition.md",
        "dialog-modal-patterns.md",
        "dropdown-menu-patterns.md",
        "focus-management.md",
        "popover-tooltip-patterns.md"
      ],
      "scripts": [
        "composed-trigger.tsx",
        "custom-dialog.tsx",
        "custom-dropdown.tsx"
      ],
      "checklists": [
        "accessibility-audit.md"
      ]
    },
    "content": "# Radix Primitives\n\nUnstyled, accessible React components for building high-quality design systems.\n\n## Overview\n\n- Building custom styled components with full accessibility\n- Understanding how shadcn/ui works under the hood\n- Need polymorphic composition without wrapper divs\n- Implementing complex UI patterns (modals, menus, tooltips)\n\n## Primitives Catalog\n\n### Overlay Components\n| Primitive | Use Case |\n|-----------|----------|\n| **Dialog** | Modal dialogs, forms, confirmations |\n| **AlertDialog** | Destructive action confirmations |\n| **Sheet** | Side panels, mobile drawers |\n\n### Popover Components\n| Primitive | Use Case |\n|-----------|----------|\n| **Popover** | Rich content on trigger |\n| **Tooltip** | Simple text hints |\n| **HoverCard** | Preview cards on hover |\n| **ContextMenu** | Right-click menus |\n\n### Menu Components\n| Primitive | Use Case |\n|-----------|----------|\n| **DropdownMenu** | Action menus |\n| **Menubar** | Application menubars |\n| **NavigationMenu** | Site navigation |\n\n### Form Components\n| Primitive | Use Case |\n|-----------|----------|\n| **Select** | Custom select dropdowns |\n| **RadioGroup** | Single selection groups |\n| **Checkbox** | Boolean toggles |\n| **Switch** | On/off toggles |\n| **Slider** | Range selection |\n\n### Disclosure Components\n| Primitive | Use Case |\n|-----------|----------|\n| **Accordion** | Expandable sections |\n| **Collapsible** | Single toggle content |\n| **Tabs** | Tabbed interfaces |\n\n## Core Pattern: asChild\n\nThe `asChild` prop enables polymorphic rendering without wrapper divs:\n\n```tsx\n// Without asChild - creates nested elements\n<Button>\n  <Link href=\"/about\">About</Link>\n</Button>\n\n// With asChild - merges into single element\n<Button asChild>\n  <Link href=\"/about\">About</Link>\n</Button>\n```\n\n**How it works:**\n- Uses Radix's internal `Slot` component\n- Merges props from parent to child\n- Forwards refs correctly\n- Combines event handlers (both fire)\n- Merges classNames\n\n## Built-in Accessibility\n\nEvery primitive includes:\n- **Keyboard navigation**: Arrow keys, Escape, Enter, Tab\n- **Focus management**: Trap, return, visible focus rings\n- **ARIA attributes**: Roles, states, properties\n- **Screen reader**: Proper announcements\n\n## Styling with Data Attributes\n\nRadix exposes state via data attributes:\n\n```css\n/* Style based on state */\n[data-state=\"open\"] { /* open styles */ }\n[data-state=\"closed\"] { /* closed styles */ }\n[data-disabled] { /* disabled styles */ }\n[data-highlighted] { /* keyboard focus */ }\n```\n\n```tsx\n// Tailwind arbitrary variants\n<Dialog.Content className=\"data-[state=open]:animate-in data-[state=closed]:animate-out\">\n```\n\n## Quick Reference\n\n```tsx\nimport { Dialog, DropdownMenu, Tooltip } from 'radix-ui'\n\n// Basic Dialog\n<Dialog.Root>\n  <Dialog.Trigger>Open</Dialog.Trigger>\n  <Dialog.Portal>\n    <Dialog.Overlay />\n    <Dialog.Content>\n      <Dialog.Title>Title</Dialog.Title>\n      <Dialog.Description>Description</Dialog.Description>\n      <Dialog.Close>Close</Dialog.Close>\n  ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "rapid-ui-designer"
    ]
  },
  "rag-retrieval": {
    "name": "rag-retrieval",
    "description": "Retrieval-Augmented Generation patterns for grounded LLM responses. Use when building RAG pipelines, constructing context from retrieved documents, adding citations, or implementing hybrid search.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "retrieval",
      "llm",
      "context",
      "grounding"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "advanced-rag.md"
      ],
      "scripts": [
        "rag-pipeline-template.ts"
      ]
    },
    "content": "# RAG Retrieval\n\nCombine vector search with LLM generation for accurate, grounded responses.\n\n## Basic RAG Pattern\n\n```python\nasync def rag_query(question: str, top_k: int = 5) -> str:\n    \"\"\"Basic RAG: retrieve then generate.\"\"\"\n    # 1. Retrieve relevant documents\n    docs = await vector_db.search(question, limit=top_k)\n\n    # 2. Construct context\n    context = \"\\n\\n\".join([\n        f\"[{i+1}] {doc.text}\"\n        for i, doc in enumerate(docs)\n    ])\n\n    # 3. Generate with context\n    response = await llm.chat([\n        {\"role\": \"system\", \"content\":\n            \"Answer using ONLY the provided context. \"\n            \"If not in context, say 'I don't have that information.'\"},\n        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}\n    ])\n\n    return response.content\n```\n\n## RAG with Citations\n\n```python\nasync def rag_with_citations(question: str) -> dict:\n    \"\"\"RAG with inline citations [1], [2], etc.\"\"\"\n    docs = await vector_db.search(question, limit=5)\n\n    context = \"\\n\\n\".join([\n        f\"[{i+1}] {doc.text}\\nSource: {doc.metadata['source']}\"\n        for i, doc in enumerate(docs)\n    ])\n\n    response = await llm.chat([\n        {\"role\": \"system\", \"content\":\n            \"Answer with inline citations like [1], [2]. \"\n            \"End with a Sources section.\"},\n        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}\n    ])\n\n    return {\n        \"answer\": response.content,\n        \"sources\": [doc.metadata['source'] for doc in docs]\n    }\n```\n\n## Hybrid Search (Semantic + Keyword)\n\n```python\ndef reciprocal_rank_fusion(\n    semantic_results: list,\n    keyword_results: list,\n    k: int = 60\n) -> list:\n    \"\"\"Combine semantic and keyword search with RRF.\"\"\"\n    scores = {}\n\n    for rank, doc in enumerate(semantic_results):\n        scores[doc.id] = scores.get(doc.id, 0) + 1 / (k + rank + 1)\n\n    for rank, doc in enumerate(keyword_results):\n        scores[doc.id] = scores.get(doc.id, 0) + 1 / (k + rank + 1)\n\n    # Sort by combined score\n    ranked_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n    return [get_doc(id) for id in ranked_ids]\n```\n\n## Context Window Management\n\n```python\ndef fit_context(docs: list, max_tokens: int = 6000) -> list:\n    \"\"\"Truncate context to fit token budget.\"\"\"\n    total_tokens = 0\n    selected = []\n\n    for doc in docs:\n        doc_tokens = count_tokens(doc.text)\n        if total_tokens + doc_tokens > max_tokens:\n            break\n        selected.append(doc)\n        total_tokens += doc_tokens\n\n    return selected\n```\n\n**Guidelines:**\n- Keep context under 75% of model limit\n- Reserve tokens for system prompt + response\n- Prioritize highest-relevance documents\n\n## Context Sufficiency Check (2026 Best Practice)\n\n```python\nfrom pydantic import BaseModel\n\nclass SufficiencyCheck(BaseModel):\n    \"\"\"Pre-generation context validation.\"\"\"\n    is_sufficient: bool\n    confidence: float  # 0.0-1.0\n    missing_info: str | None = None\n\nasync def rag_with_suffici",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "web-research-analyst"
    ]
  },
  "rate-limiting": {
    "name": "rate-limiting",
    "description": "API rate limiting with token bucket, sliding window, and Redis distributed patterns. Use when implementing rate limits, throttling requests, handling 429 Too Many Requests, protecting against API abuse, or configuring SlowAPI with Redis.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rate-limiting",
      "redis",
      "token-bucket",
      "fastapi",
      "security"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "token-bucket-algorithm.md"
      ],
      "scripts": [
        "redis-rate-limiter.py"
      ],
      "checklists": [
        "rate-limiting-checklist.md"
      ]
    },
    "content": "# Rate Limiting Patterns\n\nProtect APIs with distributed rate limiting using Redis and modern algorithms.\n\n## Overview\n\n- Protecting public APIs from abuse\n- Implementing tiered rate limits (free/pro/enterprise)\n- Scaling rate limiting across multiple instances\n- Preventing brute force attacks on auth endpoints\n- Managing third-party API consumption\n\n## Algorithm Selection\n\n| Algorithm | Use Case | Burst Handling |\n|-----------|----------|----------------|\n| Token Bucket | General API, allows bursts | Excellent |\n| Sliding Window | Precise, no burst spikes | Good |\n| Leaky Bucket | Steady rate, queue excess | None |\n| Fixed Window | Simple, some edge issues | Moderate |\n\n## SlowAPI + Redis (FastAPI)\n\n### Basic Setup\n\n```python\nfrom slowapi import Limiter\nfrom slowapi.util import get_remote_address\nfrom slowapi.middleware import SlowAPIMiddleware\n\nlimiter = Limiter(\n    key_func=get_remote_address,\n    storage_uri=\"redis://localhost:6379\",\n    strategy=\"moving-window\",  # sliding window\n)\n\napp = FastAPI()\napp.state.limiter = limiter\napp.add_middleware(SlowAPIMiddleware)\n```\n\n### Endpoint Limits\n\n```python\nfrom slowapi import Limiter\n\n@router.post(\"/api/v1/auth/login\")\n@limiter.limit(\"10/minute\")  # Strict for auth\nasync def login(request: Request, credentials: LoginRequest):\n    ...\n\n@router.get(\"/api/v1/analyses\")\n@limiter.limit(\"100/minute\")  # Normal for reads\nasync def list_analyses(request: Request):\n    ...\n\n@router.post(\"/api/v1/analyses\")\n@limiter.limit(\"20/minute\")  # Moderate for writes\nasync def create_analysis(request: Request, data: AnalysisCreate):\n    ...\n```\n\n### User-Based Limits\n\n```python\ndef get_user_identifier(request: Request) -> str:\n    \"\"\"Rate limit by user ID if authenticated, else IP.\"\"\"\n    if hasattr(request.state, \"user\"):\n        return f\"user:{request.state.user.id}\"\n    return f\"ip:{get_remote_address(request)}\"\n\nlimiter = Limiter(key_func=get_user_identifier)\n```\n\n## Token Bucket with Redis (Custom)\n\n```python\nimport redis.asyncio as redis\nfrom datetime import datetime, timezone\n\nclass TokenBucketLimiter:\n    def __init__(\n        self,\n        redis_client: redis.Redis,\n        capacity: int = 100,\n        refill_rate: float = 10.0,  # tokens per second\n    ):\n        self.redis = redis_client\n        self.capacity = capacity\n        self.refill_rate = refill_rate\n\n    async def is_allowed(self, key: str, tokens: int = 1) -> bool:\n        \"\"\"Check if request is allowed, consume tokens atomically.\"\"\"\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local capacity = tonumber(ARGV[1])\n        local refill_rate = tonumber(ARGV[2])\n        local tokens_requested = tonumber(ARGV[3])\n        local now = tonumber(ARGV[4])\n\n        local bucket = redis.call('HMGET', key, 'tokens', 'last_update')\n        local current_tokens = tonumber(bucket[1]) or capacity\n        local last_update = tonumber(bucket[2]) or now\n\n        -- Calculate refill\n        local elapsed = now - last_update\n        local refill = elapsed",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "react-aria-patterns": {
    "name": "react-aria-patterns",
    "description": "React Aria (Adobe) accessible component patterns for building WCAG-compliant interactive UI with hooks. Use when implementing buttons, dialogs, comboboxes, menus, and other accessible components in React applications.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "accessibility",
      "react",
      "aria",
      "a11y",
      "react-aria",
      "wcag",
      "hooks",
      "adobe"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob",
      "Bash"
    ],
    "skills": [],
    "agent": "accessibility-specialist",
    "structure": {
      "references": [
        "react-aria-hooks.md"
      ],
      "scripts": [
        "accessible-component-template.tsx"
      ],
      "checklists": [
        "react-aria-checklist.md"
      ]
    },
    "content": "# React Aria Patterns\n\nBuild accessible UI components using Adobe's React Aria hooks library with React 19 patterns.\n\n## Overview\n\n- Building accessible buttons, links, and toggles with keyboard/screen reader support\n- Implementing modal dialogs with proper focus management and trapping\n- Creating autocomplete/combobox components with filtering and selection\n- Building menu systems with roving tabindex and proper ARIA roles\n- Implementing accessible tables, listboxes, and selection patterns\n\n## Quick Reference\n\n### useButton - Accessible Button Component\n\n```tsx\nimport { useRef } from 'react';\nimport { useButton, useFocusRing, mergeProps } from 'react-aria';\nimport type { AriaButtonProps } from 'react-aria';\n\nfunction Button(props: AriaButtonProps & { className?: string }) {\n  const ref = useRef<HTMLButtonElement>(null);\n  const { focusProps, isFocusVisible } = useFocusRing();\n  const { buttonProps } = useButton(props, ref);\n\n  return (\n    <button\n      {...mergeProps(buttonProps, focusProps)}\n      ref={ref}\n      className={`${props.className ?? ''} ${isFocusVisible ? 'ring-2 ring-blue-500' : ''}`}\n    >\n      {props.children}\n    </button>\n  );\n}\n```\n\n### useDialog - Modal Dialog with Focus Management\n\n```tsx\nimport { useRef } from 'react';\nimport { useDialog, useModalOverlay, FocusScope, mergeProps } from 'react-aria';\nimport { useOverlayTriggerState } from 'react-stately';\n\nfunction Modal({ state, title, children }) {\n  const ref = useRef<HTMLDivElement>(null);\n  const { modalProps, underlayProps } = useModalOverlay({}, state, ref);\n  const { dialogProps, titleProps } = useDialog({ 'aria-label': title }, ref);\n\n  return (\n    <div {...underlayProps} className=\"fixed inset-0 z-50 bg-black/50 flex items-center justify-center\">\n      <FocusScope contain restoreFocus autoFocus>\n        <div {...mergeProps(modalProps, dialogProps)} ref={ref} className=\"bg-white rounded-lg p-6\">\n          <h2 {...titleProps} className=\"text-xl font-semibold mb-4\">{title}</h2>\n          {children}\n        </div>\n      </FocusScope>\n    </div>\n  );\n}\n```\n\n### useComboBox - Accessible Autocomplete\n\n```tsx\nimport { useRef } from 'react';\nimport { useComboBox, useFilter } from 'react-aria';\nimport { useComboBoxState } from 'react-stately';\n\nfunction ComboBox(props) {\n  const { contains } = useFilter({ sensitivity: 'base' });\n  const state = useComboBoxState({ ...props, defaultFilter: contains });\n  const inputRef = useRef(null), buttonRef = useRef(null), listBoxRef = useRef(null);\n\n  const { buttonProps, inputProps, listBoxProps, labelProps } = useComboBox(\n    { ...props, inputRef, buttonRef, listBoxRef }, state\n  );\n\n  return (\n    <div className=\"relative inline-flex flex-col\">\n      <label {...labelProps}>{props.label}</label>\n      <div className=\"flex\">\n        <input {...inputProps} ref={inputRef} className=\"border rounded-l px-3 py-2\" />\n        <button {...buttonProps} ref={buttonRef} className=\"border rounded-r px-2\">&#9660;</button>\n      </div>\n      {stat",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer"
    ]
  },
  "react-server-components-framework": {
    "name": "react-server-components-framework",
    "description": "Use when building Next.js 16+ apps with React Server Components. Covers App Router, Cache Components (replacing experimental_ppr), streaming SSR, Server Actions, and React 19 patterns for server-first architecture.",
    "version": "1.4.0",
    "author": "AI Agent Hub",
    "tags": [
      "frontend",
      "react",
      "react-19.2",
      "nextjs-16",
      "server-components",
      "streaming",
      "cache-components"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "cache-components.md",
        "client-components.md",
        "component-patterns.md",
        "data-fetching.md",
        "migration-guide.md",
        "nextjs-16-upgrade.md",
        "react-19-patterns.md",
        "routing-patterns.md",
        "server-actions.md",
        "server-components.md",
        "streaming-patterns.md",
        "tanstack-router-patterns.md"
      ],
      "scripts": [
        "client-component-template.tsx",
        "create-server-component.md",
        "server-action-template.ts",
        "server-component-template.tsx"
      ],
      "checklists": [
        "rsc-implementation-checklist.md"
      ]
    },
    "content": "# React Server Components Framework\n\n## Overview\n\nReact Server Components (RSC) enable server-first rendering with client-side interactivity. This skill covers Next.js 16 App Router patterns, Server Components, Server Actions, and streaming.\n\n**When to use this skill:**\n- Building Next.js 16+ applications with the App Router\n- Designing component boundaries (Server vs Client Components)\n- Implementing data fetching with caching and revalidation\n- Creating mutations with Server Actions\n- Optimizing performance with streaming and Suspense\n\n---\n\n## Quick Reference\n\n### Server vs Client Components\n\n| Feature | Server Component | Client Component |\n|---------|-----------------|------------------|\n| Directive | None (default) | `'use client'` |\n| Async/await | Yes | No |\n| Hooks | No | Yes |\n| Browser APIs | No | Yes |\n| Database access | Yes | No |\n| Client JS bundle | Zero | Ships to client |\n\n**Key Rule**: Server Components can render Client Components, but Client Components cannot directly import Server Components (use `children` prop instead).\n\n### Data Fetching Quick Reference\n\n**Next.js 16 Cache Components (Recommended):**\n\n```tsx\nimport { cacheLife, cacheTag } from 'next/cache'\n\n// Cached component with duration\nasync function CachedProducts() {\n  'use cache'\n  cacheLife('hours')\n  cacheTag('products')\n  return await db.product.findMany()\n}\n\n// Invalidate cache\nimport { revalidateTag } from 'next/cache'\nrevalidateTag('products')\n```\n\n**Legacy Fetch Options (Next.js 15):**\n\n```tsx\n// Static (cached indefinitely)\nawait fetch(url, { cache: 'force-cache' })\n\n// Revalidate every 60 seconds\nawait fetch(url, { next: { revalidate: 60 } })\n\n// Always fresh\nawait fetch(url, { cache: 'no-store' })\n\n// Tag-based revalidation\nawait fetch(url, { next: { tags: ['posts'] } })\n```\n\n### Server Actions Quick Reference\n\n```tsx\n'use server'\n\nexport async function createPost(formData: FormData) {\n  const title = formData.get('title') as string\n  const post = await db.post.create({ data: { title } })\n  revalidatePath('/posts')\n  redirect(\"/posts/\" + post.id)\n}\n```\n\n### Async Params/SearchParams (Next.js 16)\n\nRoute parameters and search parameters are now Promises that must be awaited:\n\n```tsx\n// app/posts/[slug]/page.tsx\nexport default async function PostPage({\n  params,\n  searchParams,\n}: {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ page?: string }>\n}) {\n  const { slug } = await params\n  const { page } = await searchParams\n  return <Post slug={slug} page={page} />\n}\n```\n\n**Note:** Also applies to `layout.tsx`, `generateMetadata()`, and route handlers. See `references/nextjs-16-upgrade.md` for complete migration guide.\n\n---\n\n## References\n\n### Server Components\n**See: `references/server-components.md`**\n\nKey topics covered:\n- Async server components and direct database access\n- Data fetching patterns (parallel, sequential, cached)\n- Route segment config (dynamic, revalidate, PPR)\n- generateStaticParams for SSG\n- Error handling and composition patte",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "recharts-patterns": {
    "name": "recharts-patterns",
    "description": "Data visualization with Recharts 3.x including responsive charts, custom tooltips, animations, and accessibility for React applications. Use when building charts or dashboards with Recharts.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "recharts",
      "charts",
      "data-visualization",
      "react",
      "svg",
      "accessibility",
      "responsive",
      "d3"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "chart-types.md"
      ]
    },
    "content": "# Recharts Patterns\n\nData visualization patterns using Recharts 3.x - a composable charting library built with React and D3.\n\n## Core Chart Types\n\n### Line Chart\n\n```tsx\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts';\n\nconst data = [\n  { date: '2024-01', revenue: 4000, expenses: 2400 },\n  { date: '2024-02', revenue: 3000, expenses: 1398 },\n];\n\nfunction RevenueChart() {\n  return (\n    <ResponsiveContainer width=\"100%\" height={400}>\n      <LineChart data={data} margin={{ top: 5, right: 30, left: 20, bottom: 5 }}>\n        <CartesianGrid strokeDasharray=\"3 3\" />\n        <XAxis dataKey=\"date\" />\n        <YAxis />\n        <Tooltip />\n        <Legend />\n        <Line type=\"monotone\" dataKey=\"revenue\" stroke=\"#8884d8\" strokeWidth={2} />\n        <Line type=\"monotone\" dataKey=\"expenses\" stroke=\"#82ca9d\" strokeDasharray=\"5 5\" />\n      </LineChart>\n    </ResponsiveContainer>\n  );\n}\n```\n\n### Bar Chart\n\n```tsx\nimport { BarChart, Bar, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer } from 'recharts';\n\nfunction SalesChart({ data }: { data: SalesData[] }) {\n  return (\n    <ResponsiveContainer width=\"100%\" height={300}>\n      <BarChart data={data}>\n        <CartesianGrid strokeDasharray=\"3 3\" />\n        <XAxis dataKey=\"name\" />\n        <YAxis />\n        <Tooltip />\n        <Bar dataKey=\"sales\" fill=\"#8884d8\" radius={[4, 4, 0, 0]} />\n        <Bar dataKey=\"target\" fill=\"#82ca9d\" radius={[4, 4, 0, 0]} />\n      </BarChart>\n    </ResponsiveContainer>\n  );\n}\n```\n\n### Pie/Donut Chart\n\n```tsx\nimport { PieChart, Pie, Cell, ResponsiveContainer, Tooltip, Legend } from 'recharts';\n\nconst COLORS = ['#0088FE', '#00C49F', '#FFBB28', '#FF8042'];\n\nfunction DeviceChart({ data }: { data: { name: string; value: number }[] }) {\n  return (\n    <ResponsiveContainer width=\"100%\" height={300}>\n      <PieChart>\n        <Pie\n          data={data}\n          cx=\"50%\"\n          cy=\"50%\"\n          innerRadius={60}\n          outerRadius={100}\n          paddingAngle={2}\n          dataKey=\"value\"\n          label={({ name, percent }) => `${name} ${(percent * 100).toFixed(0)}%`}\n        >\n          {data.map((entry, index) => (\n            <Cell key={entry.name} fill={COLORS[index % COLORS.length]} />\n          ))}\n        </Pie>\n        <Tooltip />\n        <Legend />\n      </PieChart>\n    </ResponsiveContainer>\n  );\n}\n```\n\n### Area Chart with Gradient\n\n```tsx\nfunction TrafficChart({ data }: { data: TrafficData[] }) {\n  return (\n    <ResponsiveContainer width=\"100%\" height={300}>\n      <AreaChart data={data}>\n        <defs>\n          <linearGradient id=\"colorUv\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">\n            <stop offset=\"5%\" stopColor=\"#8884d8\" stopOpacity={0.8} />\n            <stop offset=\"95%\" stopColor=\"#8884d8\" stopOpacity={0} />\n          </linearGradient>\n        </defs>\n        <CartesianGrid strokeDasharray=\"3 3\" />\n        <XAxis dataKey=\"time\" />\n        <YAxis />\n        <Tooltip />\n        <Area type=\"monotone\" dataKey=\"",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "release-management": {
    "name": "release-management",
    "description": "GitHub release workflow with semantic versioning, changelogs, and release automation using gh CLI. Use when creating releases, tagging versions, or publishing changelogs.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "github",
      "releases",
      "versioning",
      "changelog",
      "automation"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "semver.md"
      ],
      "scripts": [
        "create-release.md",
        "release-scripts.sh",
        "version-manager.py"
      ]
    },
    "content": "# Release Management\n\nAutomate releases with `gh release`, semantic versioning, and changelog generation.\n\n## Quick Reference\n\n### Create Release\n\n```bash\n# Auto-generate notes from PRs\ngh release create v1.2.0 --generate-notes\n\n# With custom title\ngh release create v1.2.0 --title \"Version 1.2.0: Performance Update\" --generate-notes\n\n# Draft release (review before publishing)\ngh release create v1.2.0 --draft --generate-notes\n\n# Pre-release (beta, rc)\ngh release create v1.2.0-beta.1 --prerelease --generate-notes\n\n# With custom notes\ngh release create v1.2.0 --notes \"## Highlights\n- New auth system\n- 50% faster search\"\n\n# From notes file\ngh release create v1.2.0 --notes-file RELEASE_NOTES.md\n```\n\n### List & View Releases\n\n```bash\n# List all releases\ngh release list\n\n# View specific release\ngh release view v1.2.0\n\n# View in browser\ngh release view v1.2.0 --web\n\n# JSON output\ngh release list --json tagName,publishedAt,isPrerelease\n```\n\n### Verify Releases (gh CLI 2.86.0+)\n\n```bash\n# Verify release attestation (sigstore)\ngh release verify v1.2.0\n\n# Verify specific asset\ngh release verify-asset v1.2.0 ./dist/app.zip\n\n# Verify with custom trust policy\ngh release verify v1.2.0 --owner myorg\n```\n\n### Manage Releases\n\n```bash\n# Edit release\ngh release edit v1.2.0 --title \"New Title\" --notes \"Updated notes\"\n\n# Delete release\ngh release delete v1.2.0\n\n# Upload assets\ngh release upload v1.2.0 ./dist/app.zip ./dist/app.tar.gz\n```\n\n---\n\n## Semantic Versioning\n\n```\nMAJOR.MINOR.PATCH\n  │     │     │\n  │     │     └── Bug fixes (backwards compatible)\n  │     └──────── New features (backwards compatible)\n  └────────────── Breaking changes\n\nExamples:\n  1.0.0 → 1.0.1  (patch: bug fix)\n  1.0.1 → 1.1.0  (minor: new feature)\n  1.1.0 → 2.0.0  (major: breaking change)\n\nPre-release:\n  2.0.0-alpha.1  (early testing)\n  2.0.0-beta.1   (feature complete)\n  2.0.0-rc.1     (release candidate)\n```\n\n---\n\n## Release Workflow\n\n### Standard Release\n\n```bash\n# 1. Ensure main is up to date\ngit checkout main\ngit pull origin main\n\n# 2. Determine version bump\n# Check commits since last release\ngh release view --json tagName -q .tagName  # Current: v1.2.3\ngit log v1.2.3..HEAD --oneline\n\n# 3. Create and push tag\ngit tag -a v1.3.0 -m \"Release v1.3.0\"\ngit push origin v1.3.0\n\n# 4. Create GitHub release\ngh release create v1.3.0 \\\n  --title \"v1.3.0: Feature Name\" \\\n  --generate-notes\n\n# 5. Close milestone if used\ngh api -X PATCH repos/:owner/:repo/milestones/5 -f state=closed\n```\n\n### Hotfix Release\n\n```bash\n# 1. Branch from release tag\ngit checkout -b hotfix/v1.2.4 v1.2.3\n\n# 2. Fix and commit\ngit commit -m \"fix: Critical security patch\"\n\n# 3. Tag and release\ngit tag -a v1.2.4 -m \"Hotfix: Security patch\"\ngit push origin v1.2.4\ngh release create v1.2.4 --title \"v1.2.4: Security Hotfix\" \\\n  --notes \"Critical security fix for authentication bypass\"\n\n# 4. Merge fix to main\ngit checkout main\ngit cherry-pick <commit-sha>\ngit push origin main\n```\n\n---\n\n## Changelog Generation\n\n### Auto-Generated (from ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "deployment-manager",
      "documentation-specialist",
      "git-operations-engineer",
      "release-engineer"
    ]
  },
  "remember": {
    "name": "remember",
    "description": "Stores decisions and patterns in knowledge graph. Use when saving patterns, remembering outcomes, or recording decisions.",
    "version": "3.0.0",
    "author": "OrchestKit",
    "tags": [
      "memory",
      "decisions",
      "patterns",
      "best-practices",
      "graph-memory"
    ],
    "userInvocable": true,
    "context": "none",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash",
      "mcp__memory__create_entities",
      "mcp__memory__create_relations",
      "mcp__memory__add_observations",
      "mcp__memory__search_nodes"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "category-detection.md"
      ]
    },
    "content": "# Remember - Store Decisions and Patterns\n\nStore important decisions, patterns, or context in the knowledge graph for future sessions. Supports tracking success/failure outcomes for building a Best Practice Library.\n\n## Graph-First Architecture (v2.1)\n\nThe remember skill uses **graph memory as PRIMARY** storage:\n\n1. **Knowledge Graph (PRIMARY)**: Entity and relationship storage via `mcp__memory__create_entities` and `mcp__memory__create_relations` - FREE, zero-config, always works\n2. **Semantic Memory (mem0)**: Optional cloud storage via `add-memory.py` script - requires MEM0_API_KEY\n\n**Benefits of Graph-First:**\n- Zero configuration required - works out of the box\n- Explicit relationship queries (e.g., \"what does X use?\")\n- Cross-referencing between entities\n- No cloud dependency for basic operation\n- Optional cloud enhancement with `--mem0` flag\n\n**Automatic Entity Extraction:**\n- Extracts capitalized terms as potential entities (PostgreSQL, React, pgvector)\n- Detects agent names (database-engineer, backend-system-architect)\n- Identifies pattern names (cursor-pagination, connection-pooling)\n- Recognizes \"X uses Y\", \"X recommends Y\", \"X requires Y\" relationship patterns\n\n## Usage\n\n### Store Decisions (Default)\n```\n/remember <text>\n/remember --category <category> <text>\n/remember --success <text>     # Mark as successful pattern\n/remember --failed <text>      # Mark as anti-pattern\n/remember --success --category <category> <text>\n\n# Cloud sync (v2.1.0+)\n/remember --mem0 <text>                    # Write to BOTH graph AND mem0 cloud\n/remember --mem0 --success <text>          # Success pattern synced to cloud\n\n# Agent-scoped memory\n/remember --agent <agent-id> <text>         # Store in agent-specific scope\n/remember --global <text>                   # Store as cross-project best practice\n```\n\n## Flags\n\n| Flag | Behavior |\n|------|----------|\n| (default) | Write to graph only |\n| `--mem0` | Write to BOTH graph and mem0 cloud |\n| `--success` | Mark as successful pattern |\n| `--failed` | Mark as anti-pattern |\n| `--category <cat>` | Set category |\n| `--agent <agent-id>` | Scope memory to a specific agent |\n| `--global` | Store as cross-project best practice |\n\n## Categories\n\n- `decision` - Why we chose X over Y (default)\n- `architecture` - System design and patterns\n- `pattern` - Code conventions and standards\n- `blocker` - Known issues and workarounds\n- `constraint` - Limitations and requirements\n- `preference` - User/team preferences\n- `pagination` - Pagination strategies\n- `database` - Database patterns\n- `authentication` - Auth approaches\n- `api` - API design patterns\n- `frontend` - Frontend patterns\n- `performance` - Performance optimizations\n\n## Outcome Flags\n\n- `--success` - Pattern that worked well (positive outcome)\n- `--failed` - Pattern that caused problems (anti-pattern)\n\nIf neither flag is provided, the memory is stored as neutral (informational).\n\n## Workflow\n\n### 1. Parse Input\n\n```\nCheck for --success flag → outcome: success\nCheck for ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "ai-safety-auditor",
      "backend-system-architect",
      "business-case-builder",
      "ci-cd-engineer",
      "code-quality-reviewer",
      "data-pipeline-engineer",
      "database-engineer",
      "debug-investigator",
      "demo-producer",
      "deployment-manager",
      "documentation-specialist",
      "event-driven-architect",
      "frontend-ui-developer",
      "git-operations-engineer",
      "infrastructure-architect",
      "llm-integrator",
      "market-intelligence",
      "metrics-architect",
      "monitoring-engineer",
      "multimodal-specialist",
      "performance-engineer",
      "prioritization-analyst",
      "product-strategist",
      "prompt-engineer",
      "python-performance-engineer",
      "rapid-ui-designer",
      "release-engineer",
      "requirements-translator",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer",
      "test-generator",
      "ux-researcher",
      "web-research-analyst",
      "workflow-architect"
    ]
  },
  "remotion-composer": {
    "name": "remotion-composer",
    "description": "Compose final demo videos using Remotion. Use when combining terminal recordings with animations, adding branded overlays, or rendering multi-format video exports",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "remotion",
      "video",
      "composition",
      "marketing",
      "demo",
      "animation",
      "data-viz",
      "charts"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "3d-graphics.md",
        "animation-presets.md",
        "audio-layer.md",
        "captions-subtitles.md",
        "cinematic-scenes.md",
        "composition-patterns.md",
        "data-viz-patterns.md",
        "effects-library.md",
        "folder-organization.md",
        "lottie-animations.md",
        "showcase-templates.md"
      ]
    },
    "content": "# Remotion Composer\n\nProduction-quality video composition with AnimStats-level animations. Supports data visualization, spring physics, easing presets, and cinematic transitions.\n\n## Quick Start\n\n```bash\n# Install enhanced packages\ncd orchestkit-demos && npm install\n\n# Add composition for a skill\n./scripts/add-composition.sh explore\n\n# Render\nnpx remotion render ExploreDemo out/ExploreDemo.mp4\n```\n\n## Package Library (v2.1)\n\n### Core Animation\n```json\n{\n  \"@remotion/shapes\": \"^4.0.0\",      // Geometric primitives (pie, rect, triangle)\n  \"@remotion/paths\": \"^4.0.0\",       // SVG path animations (evolvePath)\n  \"@remotion/noise\": \"^4.0.0\",       // Procedural noise (noise2D, noise3D)\n  \"@remotion/transitions\": \"^4.0.0\", // Scene transitions (fade, slide, wipe)\n  \"@remotion/motion-blur\": \"^4.0.0\", // Motion trails and blur\n  \"@remotion/gif\": \"^4.0.0\",         // GIF synchronization\n  \"@remotion/animated-emoji\": \"^4.0.0\", // Lottie emojis\n  \"@remotion/layout-utils\": \"^4.0.0\"   // Text fitting and layout\n}\n```\n\n### Advanced Capabilities\n```json\n{\n  \"@remotion/three\": \"^4.0.0\",       // Three.js 3D graphics\n  \"@remotion/lottie\": \"^4.0.0\",      // After Effects animations\n  \"@remotion/rive\": \"^4.0.0\",        // Rive interactive animations\n  \"@remotion/captions\": \"^4.0.0\",    // Subtitles and captions\n  \"@remotion/player\": \"^4.0.0\",      // Embeddable player\n  \"@remotion/renderer\": \"^4.0.0\",    // Server-side rendering\n  \"@remotion/media-utils\": \"^4.0.0\"  // Audio/video metadata\n}\n```\n\n### 3D & Animation Runtimes\n```json\n{\n  \"three\": \"^0.175.0\",                    // Three.js core\n  \"@react-three/fiber\": \"^9.1.0\",         // React Three Fiber\n  \"@react-three/drei\": \"^10.3.0\",         // Three.js helpers\n  \"@lottiefiles/react-lottie-player\": \"^3.5.4\", // Lottie player\n  \"@rive-app/react-canvas\": \"^4.21.0\"     // Rive runtime\n}\n```\n\n## Animation Presets\n\n### Easing Reference\n| Preset | Use Case | Feel |\n|--------|----------|------|\n| `bounce` | Success celebrations | Playful |\n| `elastic` | Attention grab | Energetic |\n| `back` | Entry animations | Anticipation |\n| `snappy` | Quick UI | Overshoot |\n| `spring` | Default | Natural |\n\n### Spring Configs\n| Name | damping | stiffness | Use |\n|------|---------|-----------|-----|\n| Bouncy | 10-12 | 100-120 | Playful enters |\n| Snappy | 15-20 | 150-200 | Quick UI |\n| Smooth | 80 | 200 | Subtle moves |\n| Heavy | 15 | 50 | Large elements |\n\n## Data Visualization Components\n\n### StatCounter (Enhanced)\n```tsx\n<StatCounter\n  value={168}\n  label=\"Skills\"\n  color=\"#8b5cf6\"\n  easing=\"bounce\"           // bounce, elastic, back, snappy, spring\n  digitMorph                // Individual digit animation\n  gradientColors={[\"#8b5cf6\", \"#22c55e\"]}  // Animated gradient\n  celebrateOnComplete       // Particle burst\n  size=\"lg\"                 // sm, md, lg\n/>\n```\n\n### ProgressRing\n```tsx\n<ProgressRing\n  progress={85}\n  color=\"#22c55e\"\n  size={120}\n  delay={15}\n  showLabel\n  easing=\"spring\"\n/>\n```\n\n### BarChart\n```tsx\n<BarChart\n  da",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": [
      "demo-producer"
    ]
  },
  "render-optimization": {
    "name": "render-optimization",
    "description": "React render performance patterns including React Compiler integration, memoization strategies, TanStack Virtual, and DevTools profiling. Use when debugging slow renders, optimizing large lists, or reducing unnecessary re-renders.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "react",
      "performance",
      "optimization",
      "react-compiler",
      "virtualization",
      "memo",
      "profiler"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "devtools-profiler-workflow.md",
        "memoization-escape-hatches.md",
        "react-compiler-migration.md",
        "state-colocation.md",
        "tanstack-virtual-patterns.md"
      ],
      "scripts": [
        "optimized-context.tsx",
        "virtualized-list.tsx"
      ],
      "checklists": [
        "performance-audit.md"
      ]
    },
    "content": "# React Render Optimization\n\nModern render performance patterns for React 19+.\n\n## Decision Tree: React Compiler First (2026)\n\n```\nIs React Compiler enabled?\n├─ YES → Let compiler handle memoization automatically\n│        Only use useMemo/useCallback as escape hatches\n│        DevTools shows \"Memo ✨\" badge\n│\n└─ NO → Profile first, then optimize\n         1. React DevTools Profiler\n         2. Identify actual bottlenecks\n         3. Apply targeted optimizations\n```\n\n## React Compiler (Primary Approach)\n\nReact 19's compiler automatically memoizes:\n- Component re-renders\n- Intermediate values (like useMemo)\n- Callback references (like useCallback)\n- JSX elements\n\n```tsx\n// next.config.js (Next.js 16+)\nconst nextConfig = {\n  reactCompiler: true,\n}\n\n// Expo SDK 54+ enables by default\n```\n\n**Verification**: Open React DevTools → Look for \"Memo ✨\" badge\n\n## When Manual Memoization Still Needed\n\nUse `useMemo`/`useCallback` as escape hatches when:\n\n```tsx\n// 1. Effect dependencies that shouldn't trigger re-runs\nconst stableConfig = useMemo(() => ({\n  apiUrl: process.env.API_URL\n}), [])\n\nuseEffect(() => {\n  initializeSDK(stableConfig)\n}, [stableConfig])\n\n// 2. Third-party libraries without compiler support\nconst memoizedValue = useMemo(() =>\n  expensiveThirdPartyComputation(data), [data])\n\n// 3. Precise control over memoization boundaries\nconst handleClick = useCallback(() => {\n  // Critical callback that must be stable\n}, [dependency])\n```\n\n## Virtualization Thresholds\n\n| Item Count | Recommendation |\n|------------|----------------|\n| < 100 | Regular rendering usually fine |\n| 100-500 | Consider virtualization |\n| 500+ | Virtualization required |\n\n```tsx\nimport { useVirtualizer } from '@tanstack/react-virtual'\n\nconst virtualizer = useVirtualizer({\n  count: items.length,\n  getScrollElement: () => parentRef.current,\n  estimateSize: () => 50,\n  overscan: 5,\n})\n```\n\n## State Colocation\n\nMove state as close to where it's used as possible:\n\n```tsx\n// ❌ State too high - causes unnecessary re-renders\nfunction App() {\n  const [filter, setFilter] = useState('')\n  return (\n    <Header />  {/* Re-renders on filter change! */}\n    <FilterInput value={filter} onChange={setFilter} />\n    <List filter={filter} />\n  )\n}\n\n// ✅ State colocated - minimal re-renders\nfunction App() {\n  return (\n    <Header />\n    <FilterableList />  {/* State inside */}\n  )\n}\n```\n\n## Profiling Workflow\n\n1. **React DevTools Profiler**: Record, interact, analyze\n2. **Identify**: Components with high render counts or duration\n3. **Verify**: Is the re-render actually causing perf issues?\n4. **Fix**: Apply targeted optimization\n5. **Measure**: Confirm improvement\n\n## Quick Wins\n\n1. **Key prop**: Stable, unique keys for lists\n2. **Lazy loading**: `React.lazy()` for code splitting\n3. **Debounce**: Input handlers with `useDeferredValue`\n4. **Suspense**: Streaming with proper boundaries\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Memoization | Let React Compiler hand",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "performance-engineer"
    ]
  },
  "requirements-engineering": {
    "name": "requirements-engineering",
    "description": "User stories, acceptance criteria, PRDs, and requirements documentation patterns. Use when translating product vision to engineering specs, writing user stories, or creating requirements documents.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "product",
      "requirements",
      "user-stories",
      "prd",
      "acceptance-criteria",
      "agile"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "requirements-translator",
    "structure": {
      "references": [
        "user-story-workshop-guide.md"
      ],
      "assets": [
        "prd-template.md"
      ],
      "checklists": [
        "prd-review-checklist.md"
      ]
    },
    "content": "# Requirements Engineering\n\nPatterns for translating product vision into clear, actionable engineering specifications.\n\n## User Stories\n\n### Standard Format\n\n```\nAs a [type of user],\nI want [goal/desire],\nso that [benefit/value].\n```\n\n### INVEST Criteria\n\nGood user stories are:\n\n| Criterion | Description | Example Check |\n|-----------|-------------|---------------|\n| **I**ndependent | Can be developed separately | No hard dependencies on other stories |\n| **N**egotiable | Details can be discussed | Not a contract, a conversation starter |\n| **V**aluable | Delivers user/business value | Answers \"so what?\" |\n| **E**stimable | Can be sized by the team | Clear enough to estimate |\n| **S**mall | Fits in a sprint | 1-5 days of work typically |\n| **T**estable | Has clear acceptance criteria | Know when it's done |\n\n### Story Examples\n\n**Good:**\n```markdown\nAs a sales manager,\nI want to see my team's pipeline by stage,\nso that I can identify bottlenecks and coach accordingly.\n\nAcceptance Criteria:\n- [ ] Shows deals grouped by stage (Lead, Qualified, Proposal, Negotiation, Closed)\n- [ ] Displays deal count and total value per stage\n- [ ] Filters by date range (default: current quarter)\n- [ ] Updates in real-time when deals move stages\n```\n\n**Bad (too vague):**\n```markdown\nAs a user, I want better reporting.\n```\n\n**Bad (solution-focused):**\n```markdown\nAs a user, I want a pie chart on the dashboard.\n```\n\n## Acceptance Criteria\n\n### Given-When-Then Format (Gherkin)\n\n```gherkin\nFeature: User Login\n\nScenario: Successful login with valid credentials\n  Given I am on the login page\n  And I have a valid account\n  When I enter my email \"user@example.com\"\n  And I enter my password \"validpass123\"\n  And I click the \"Sign In\" button\n  Then I should be redirected to the dashboard\n  And I should see \"Welcome back\" message\n\nScenario: Failed login with invalid password\n  Given I am on the login page\n  When I enter my email \"user@example.com\"\n  And I enter my password \"wrongpassword\"\n  And I click the \"Sign In\" button\n  Then I should see \"Invalid credentials\" error\n  And I should remain on the login page\n```\n\n### Checklist Format\n\n```markdown\n## Acceptance Criteria: Password Reset\n\n### Functional\n- [ ] User can request reset via email\n- [ ] Reset link expires after 24 hours\n- [ ] Reset link is single-use\n- [ ] New password must meet complexity requirements\n- [ ] User receives confirmation email after reset\n\n### Edge Cases\n- [ ] Handles non-existent email gracefully (no user enumeration)\n- [ ] Rate limits requests (max 3 per hour per email)\n- [ ] Works with SSO-enabled accounts (shows appropriate message)\n\n### Non-Functional\n- [ ] Reset email sent within 30 seconds\n- [ ] Page loads in < 2 seconds\n- [ ] Accessible (WCAG 2.1 AA)\n```\n\n## Product Requirements Document (PRD)\n\n### PRD Template\n\n```markdown\n# PRD: [Feature Name]\n\n**Author:** [Name]\n**Last Updated:** [Date]\n**Status:** Draft | In Review | Approved | Shipped\n\n---\n\n## Overview\n\n### Problem Statement\n[1-2 paragraphs d",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "requirements-translator"
    ]
  },
  "reranking-patterns": {
    "name": "reranking-patterns",
    "description": "Reranking patterns for improving search precision. Use when implementing cross-encoder reranking, LLM-based relevance scoring, or improving retrieval quality in RAG pipelines.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "rag",
      "retrieval",
      "reranking",
      "relevance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {},
    "content": "# Reranking Patterns\nImprove search precision by re-scoring retrieved documents with more powerful models.\n\n## Overview\n\n- Improving precision after initial retrieval\n- When bi-encoder embeddings miss semantic nuance\n- Combining multiple relevance signals\n- Production RAG systems requiring high accuracy\n\nImprove search precision by re-scoring retrieved documents with more powerful models.\n\n## Why Rerank?\n\nInitial retrieval (bi-encoder) prioritizes speed over accuracy:\n- Bi-encoder: Embeds query and docs separately → fast but approximate\n- Cross-encoder/LLM: Processes query+doc together → slow but accurate\n\n**Solution**: Retrieve many (top-50), rerank few (top-10)\n\n## Pattern 1: Cross-Encoder Reranking\n\n```python\nfrom sentence_transformers import CrossEncoder\n\nclass CrossEncoderReranker:\n    def __init__(self, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n        self.model = CrossEncoder(model_name)\n\n    def rerank(\n        self,\n        query: str,\n        documents: list[dict],\n        top_k: int = 10,\n    ) -> list[dict]:\n        \"\"\"Rerank documents using cross-encoder.\"\"\"\n\n        # Create query-document pairs\n        pairs = [(query, doc[\"content\"]) for doc in documents]\n\n        # Score all pairs\n        scores = self.model.predict(pairs)\n\n        # Sort by score\n        scored_docs = list(zip(documents, scores))\n        scored_docs.sort(key=lambda x: x[1], reverse=True)\n\n        # Return top-k with updated scores\n        return [\n            {**doc, \"score\": float(score)}\n            for doc, score in scored_docs[:top_k]\n        ]\n```\n\n## Pattern 2: LLM Reranking (Batch)\n\n```python\nfrom openai import AsyncOpenAI\n\nasync def llm_rerank(\n    query: str,\n    documents: list[dict],\n    llm: AsyncOpenAI,\n    top_k: int = 10,\n) -> list[dict]:\n    \"\"\"Rerank using LLM relevance scoring.\"\"\"\n\n    # Build prompt with all candidates\n    docs_text = \"\\n\\n\".join([\n        f\"[Doc {i+1}]\\n{doc['content'][:300]}...\"\n        for i, doc in enumerate(documents)\n    ])\n\n    response = await llm.chat.completions.create(\n        model=\"gpt-5.2-mini\",  # Fast, cheap\n        messages=[\n            {\"role\": \"system\", \"content\": \"\"\"\nRate each document's relevance to the query (0.0-1.0).\nOutput one score per line, in order:\n0.95\n0.72\n0.45\n...\"\"\"},\n            {\"role\": \"user\", \"content\": f\"Query: {query}\\n\\nDocuments:\\n{docs_text}\"}\n        ],\n        temperature=0,\n    )\n\n    # Parse scores\n    scores = parse_scores(response.choices[0].message.content, len(documents))\n\n    # Sort and return\n    scored_docs = list(zip(documents, scores))\n    scored_docs.sort(key=lambda x: x[1], reverse=True)\n\n    return [\n        {**doc, \"score\": score}\n        for doc, score in scored_docs[:top_k]\n    ]\n\n\ndef parse_scores(response: str, expected_count: int) -> list[float]:\n    \"\"\"Parse LLM response into scores.\"\"\"\n    scores = []\n    for line in response.strip().split(\"\\n\"):\n        try:\n            score = float(line.strip())\n            scores.append(max(0.0, min(1.0, s",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer"
    ]
  },
  "resilience-patterns": {
    "name": "resilience-patterns",
    "description": "Production-grade fault tolerance for distributed systems. Use when implementing circuit breakers, retry with exponential backoff, bulkhead isolation patterns, or building resilience into LLM API integrations.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "resilience",
      "circuit-breaker",
      "bulkhead",
      "retry",
      "fault-tolerance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "bulkhead-pattern.md",
        "circuit-breaker.md",
        "error-classification.md",
        "llm-resilience.md",
        "retry-strategies.md"
      ],
      "scripts": [
        "bulkhead.py",
        "circuit-breaker.py",
        "llm-fallback-chain.py",
        "retry-handler.py",
        "token-budget.py"
      ],
      "checklists": [
        "circuit-breaker-setup.md",
        "pre-deployment-resilience.md"
      ]
    },
    "content": "# Resilience Patterns Skill\n\nProduction-grade resilience patterns for distributed systems and LLM-based workflows. Covers circuit breakers, bulkheads, retry strategies, and LLM-specific resilience techniques.\n\n## Overview\n\n- Building fault-tolerant multi-agent systems\n- Implementing LLM API integrations with proper error handling\n- Designing distributed workflows that need graceful degradation\n- Adding observability to failure scenarios\n- Protecting systems from cascade failures\n\n## Core Patterns\n\n### 1. Circuit Breaker Pattern (reference: circuit-breaker.md)\n\nPrevents cascade failures by \"tripping\" when a service exceeds failure thresholds.\n\n```\n+-------------------------------------------------------------------+\n|                    Circuit Breaker States                         |\n+-------------------------------------------------------------------+\n|                                                                   |\n|    +----------+     failures >= threshold    +----------+         |\n|    |  CLOSED  | ----------------------------> |   OPEN   |        |\n|    | (normal) |                              | (reject) |         |\n|    +----+-----+                              +----+-----+         |\n|         |                                         |               |\n|         | success                    timeout      |               |\n|         |                            expires      |               |\n|         |         +------------+                  |               |\n|         |         | HALF_OPEN  |<-----------------+               |\n|         +---------+  (probe)   |                                  |\n|                   +------------+                                  |\n|                                                                   |\n|   CLOSED:    Allow requests, count failures                       |\n|   OPEN:      Reject immediately, return fallback                  |\n|   HALF_OPEN: Allow probe request to test recovery                 |\n|                                                                   |\n+-------------------------------------------------------------------+\n```\n\n**Key Configuration:**\n- `failure_threshold`: Failures before opening (default: 5)\n- `recovery_timeout`: Seconds before attempting recovery (default: 30)\n- `half_open_requests`: Probes to allow in half-open (default: 1)\n\n### 2. Bulkhead Pattern (reference: bulkhead-pattern.md)\n\nIsolates failures by partitioning resources into independent pools.\n\n```\n+-------------------------------------------------------------------+\n|                      Bulkhead Isolation                           |\n+-------------------------------------------------------------------+\n|                                                                   |\n|   +------------------+  +------------------+                      |\n|   | TIER 1: Critical |  | TIER 2: Standard |                      |\n|   |  (5 workers)     |  |  (3 workers)     |                      |\n|   |  +-+ +-+ +-+     |  | ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "code-quality-reviewer",
      "deployment-manager",
      "event-driven-architect",
      "infrastructure-architect",
      "llm-integrator"
    ]
  },
  "responsive-patterns": {
    "name": "responsive-patterns",
    "description": "Responsive design with Container Queries, fluid typography, cqi/cqb units, and mobile-first patterns for React applications. Use when building responsive layouts or container queries.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "responsive",
      "container-queries",
      "fluid-typography",
      "mobile-first",
      "css-grid",
      "clamp",
      "cqi",
      "breakpoints"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "container-queries.md",
        "fluid-typography.md"
      ]
    },
    "content": "# Responsive Patterns\n\nModern responsive design patterns using Container Queries, fluid typography, and mobile-first strategies for React applications (2026 best practices).\n\n## Overview\n\n- Building reusable components that adapt to their container\n- Implementing fluid typography that scales smoothly\n- Creating responsive layouts without media query overload\n- Building design system components for multiple contexts\n- Optimizing for variable container sizes (sidebars, modals, grids)\n\n## Core Concepts\n\n### Container Queries vs Media Queries\n\n| Feature | Media Queries | Container Queries |\n|---------|---------------|-------------------|\n| Responds to | Viewport size | Container size |\n| Component reuse | Context-dependent | Truly portable |\n| Browser support | Universal | Baseline 2023+ |\n| Use case | Page layouts | Component layouts |\n\n## CSS Patterns\n\n### 1. Container Query Basics\n\n```css\n/* Define a query container */\n.card-container {\n  container-type: inline-size;\n  container-name: card;\n}\n\n/* Style based on container width */\n@container card (min-width: 400px) {\n  .card {\n    display: grid;\n    grid-template-columns: 200px 1fr;\n  }\n}\n\n@container card (max-width: 399px) {\n  .card {\n    display: flex;\n    flex-direction: column;\n  }\n}\n```\n\n### 2. Container Query Units (cqi, cqb)\n\n```css\n/* Use cqi (container query inline) over cqw */\n.card-title {\n  /* 5% of container's inline size */\n  font-size: clamp(1rem, 5cqi, 2rem);\n}\n\n.card-content {\n  /* Responsive padding based on container */\n  padding: 2cqi;\n}\n\n/* cqb for block dimension (height-aware containers) */\n.sidebar-item {\n  height: 10cqb;\n}\n```\n\n### 3. Fluid Typography with clamp()\n\n```css\n/* Accessible fluid typography */\n:root {\n  /* Base font respects user preferences (rem) */\n  --font-size-base: 1rem;\n\n  /* Fluid scale with min/max bounds */\n  --font-size-sm: clamp(0.875rem, 0.8rem + 0.25vw, 1rem);\n  --font-size-md: clamp(1rem, 0.9rem + 0.5vw, 1.25rem);\n  --font-size-lg: clamp(1.25rem, 1rem + 1vw, 2rem);\n  --font-size-xl: clamp(1.5rem, 1rem + 2vw, 3rem);\n  --font-size-2xl: clamp(2rem, 1rem + 3vw, 4rem);\n}\n\nh1 { font-size: var(--font-size-2xl); }\nh2 { font-size: var(--font-size-xl); }\nh3 { font-size: var(--font-size-lg); }\np { font-size: var(--font-size-md); }\nsmall { font-size: var(--font-size-sm); }\n```\n\n### 4. Container-Based Fluid Typography\n\n```css\n/* For component-scoped fluid text */\n.widget {\n  container-type: inline-size;\n}\n\n.widget-title {\n  /* Fluid within container, respecting user rem */\n  font-size: clamp(1rem, 0.5rem + 5cqi, 2rem);\n}\n\n.widget-body {\n  font-size: clamp(0.875rem, 0.5rem + 3cqi, 1.125rem);\n}\n```\n\n### 5. Mobile-First Breakpoints\n\n```css\n/* Mobile-first: start small, add complexity */\n.layout {\n  display: flex;\n  flex-direction: column;\n  gap: 1rem;\n}\n\n/* Tablet and up */\n@media (min-width: 768px) {\n  .layout {\n    flex-direction: row;\n  }\n}\n\n/* Desktop */\n@media (min-width: 1024px) {\n  .layout {\n    max-width: 1200px;\n    margin-inline: auto;\n  }\n}\n```\n\n### 6. ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "review-pr": {
    "name": "review-pr",
    "description": "PR review with parallel specialized agents. Use when reviewing pull requests or code.",
    "version": "1.4.0",
    "author": "OrchestKit",
    "tags": [
      "code-review",
      "pull-request",
      "quality",
      "security",
      "testing"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "code-review-playbook",
      "security-scanning",
      "type-safety-validation",
      "memory"
    ],
    "agent": null,
    "structure": {
      "references": [
        "review-template.md"
      ]
    },
    "content": "# Review PR\n\nDeep code review using 6-7 parallel specialized agents.\n\n## Quick Start\n\n```bash\n/review-pr 123\n/review-pr feature-branch\n```\n\n> **Opus 4.6**: Parallel agents use native adaptive thinking for deeper analysis. Complexity-aware routing matches agent model to review difficulty.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify review focus:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of review do you need?\",\n    \"header\": \"Focus\",\n    \"options\": [\n      {\"label\": \"Full review (Recommended)\", \"description\": \"Security + code quality + tests + architecture\"},\n      {\"label\": \"Security focus\", \"description\": \"Prioritize security vulnerabilities\"},\n      {\"label\": \"Performance focus\", \"description\": \"Focus on performance implications\"},\n      {\"label\": \"Quick review\", \"description\": \"High-level review, skip deep analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full review**: All 6-7 parallel agents\n- **Security focus**: Prioritize security-auditor, reduce other agents\n- **Performance focus**: Add performance-engineer agent\n- **Quick review**: Single code-quality-reviewer agent only\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — reviewers cross-reference findings) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Full review with 6+ agents and cross-cutting concerns → recommend **Agent Teams**; Quick/focused review → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Communication | All reviewers report to lead | Reviewers cross-reference findings |\n| Security + quality overlap | Lead deduplicates | security-auditor messages code-quality-reviewer directly |\n| Cost | ~200K tokens | ~500K tokens |\n| Best for | Quick/focused reviews | Full reviews with cross-cutting concerns |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining review.\n\n---\n\n## ⚠️ CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n**BEFORE doing ANYTHING else, create tasks to track progress:**\n\n```python\n# 1. Create main review task IMMEDIATELY\nTaskCreate(\n  subject=\"Review PR #{number}\",\n  description=\"Comprehensive code review with parallel agents\",\n  activeForm=\"Reviewing PR #{number}\"\n)\n\n# 2. Create subtasks for each phase\nTaskCreate(subject=\"Gather PR information\", activeForm=\"Gathering PR information\")\nTaskCreate(subject=\"Launch review agents\", activeForm=\"Dispatching review agents\")\nTaskCreate(subject=\"Run validation checks\", activeForm=\"Running validation checks\")\nTaskCreate(subject=\"Synthesize review\", activeForm=\"Synthesizing review\")\nTaskCreate(subject=\"Submit review\", activeForm=\"Submitting review\")\n\n# 3. Update status as you progress\nTaskUpdate(taskId=\"2\", status=\"in_progress\")  # When starting\nTaskUpdate(taskId=\"2\", status=\"c",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "root-cause-analysis": {
    "name": "root-cause-analysis",
    "description": "5 Whys, Fishbone diagrams, Fault Tree Analysis, and systematic debugging approaches. Use when investigating bugs, analyzing incidents, or identifying root causes of problems.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "debugging",
      "rca",
      "5-whys",
      "fishbone",
      "fault-tree",
      "incident"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "debug-investigator",
    "structure": {
      "references": [
        "5-whys-workshop.md",
        "fishbone-template.md"
      ],
      "assets": [
        "rca-report-template.md"
      ],
      "checklists": [
        "rca-quality-checklist.md"
      ]
    },
    "content": "# Root Cause Analysis\n\nSystematic approaches for identifying the true source of problems, not just symptoms.\n\n## RCA Methods Overview\n\n| Method | Best For | Complexity | Time |\n|--------|----------|------------|------|\n| 5 Whys | Simple, linear problems | Low | 15-30 min |\n| Fishbone | Multi-factor problems | Medium | 30-60 min |\n| Fault Tree | Critical systems, safety | High | 1-4 hours |\n| Timeline Analysis | Incident investigation | Medium | 30-90 min |\n\n## 5 Whys Method\n\nIteratively ask \"why\" to drill down from symptom to root cause.\n\n### Process\n\n```\nProblem Statement: [Clear description of the issue]\n    │\n    ▼\nWhy #1: [First level cause]\n    │\n    ▼\nWhy #2: [Deeper cause]\n    │\n    ▼\nWhy #3: [Even deeper]\n    │\n    ▼\nWhy #4: [Getting to root]\n    │\n    ▼\nWhy #5: [Root cause identified]\n    │\n    ▼\nAction: [Fix that addresses root cause]\n```\n\n### Example: Production Outage\n\n```markdown\n**Problem:** Website was down for 2 hours\n\n**Why 1:** Why was the website down?\n→ The application server ran out of memory and crashed.\n\n**Why 2:** Why did the server run out of memory?\n→ A memory leak in the image processing service accumulated over time.\n\n**Why 3:** Why was there a memory leak?\n→ The service wasn't releasing image buffers after processing.\n\n**Why 4:** Why weren't buffers being released?\n→ The cleanup code had a bug introduced in last week's release.\n\n**Why 5:** Why wasn't the bug caught before release?\n→ We don't have automated memory leak detection in our test suite.\n\n**Root Cause:** Missing automated memory leak testing\n**Action:** Add memory profiling to CI pipeline, add cleanup tests\n```\n\n### 5 Whys Best Practices\n\n| Do | Don't |\n|----|-------|\n| Base answers on evidence | Guess or assume |\n| Stay focused on one causal chain | Branch too early |\n| Keep asking until actionable | Stop at symptoms |\n| Involve people closest to issue | Assign blame |\n| Document your reasoning | Skip steps |\n\n### When 5 Whys Falls Short\n\n- Multiple contributing factors (use Fishbone)\n- Complex system interactions (use Fault Tree)\n- Organizational/process issues (need broader analysis)\n\n## Fishbone Diagram (Ishikawa)\n\nVisualize multiple potential causes organized by category.\n\n### Standard Categories (6 M's)\n\n```\n                    ┌─────────────┐\n        Methods ────┤             │\n                    │             │\n      Machines ─────┤             │\n                    │             ├──── PROBLEM\n     Materials ─────┤             │\n                    │             │\n    Measurement ────┤             │\n                    │             │\n    Environment ────┤             │\n                    │             │\n       People ──────┤             │\n                    └─────────────┘\n```\n\n### Software-Specific Categories\n\n```\n                    ┌─────────────┐\n          Code ─────┤             │\n                    │             │\n Infrastructure ────┤             │\n                    │             ├──── BUG/INCIDENT\n   Dependencies ────┤             │\n   ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "debug-investigator"
    ]
  },
  "run-tests": {
    "name": "run-tests",
    "description": "Comprehensive test execution with parallel analysis and coverage reporting. Use when running test suites or troubleshooting failures with the run-tests workflow.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "pytest",
      "coverage",
      "test-execution"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "test-commands.md"
      ]
    },
    "content": "# Run Tests\n\nTest execution with parallel analysis agents for failures.\n\n## Quick Start\n\n```bash\n/run-tests\n/run-tests backend\n/run-tests frontend\n/run-tests tests/unit/test_auth.py\n```\n\n## Test Scope\n\n| Argument | Scope |\n|----------|-------|\n| Empty/`all` | All tests |\n| `backend` | Backend only |\n| `frontend` | Frontend only |\n| `path/to/test.py` | Specific file |\n| `test_name` | Specific test |\n\n## Phase 1: Execute Tests\n\n```bash\n# Backend with coverage\ncd backend\npoetry run pytest tests/unit/ -v --tb=short \\\n  --cov=app --cov-report=term-missing\n\n# Frontend with coverage\ncd frontend\nnpm run test -- --coverage\n```\n\n## Phase 2: Failure Analysis\n\nIf tests fail, launch 3 parallel analyzers:\n1. **Backend Failure Analysis** - Root cause, fix suggestions\n2. **Frontend Failure Analysis** - Component issues, mock problems\n3. **Coverage Gap Analysis** - Low coverage areas\n\n## Phase 3: Generate Report\n\n```markdown\n# Test Results Report\n\n## Summary\n| Suite | Total | Passed | Failed | Coverage |\n|-------|-------|--------|--------|----------|\n| Backend | X | Y | Z | XX% |\n| Frontend | X | Y | Z | XX% |\n\n## Status: [ALL PASS | SOME FAILURES]\n\n## Failures (if any)\n| Test | Error | Fix |\n|------|-------|-----|\n| test_name | AssertionError | [suggestion] |\n```\n\n## Quick Commands\n\n```bash\n# All backend tests\npoetry run pytest tests/unit/ -v --tb=short\n\n# With coverage\npoetry run pytest tests/unit/ --cov=app\n\n# Quick (no tracebacks)\npoetry run pytest tests/unit/ --tb=no -q\n\n# Specific test\npoetry run pytest tests/unit/ -k \"test_name\" -v\n\n# Frontend\nnpm run test -- --coverage\n\n# Watch mode\nnpm run test -- --watch\n```\n\n## Key Options\n\n| Option | Purpose |\n|--------|---------|\n| `--maxfail=3` | Stop after 3 failures |\n| `-x` | Stop on first failure |\n| `--lf` | Run only last failed |\n| `-v` | Verbose output |\n| `--tb=short` | Shorter tracebacks |\n\n## Related Skills\n\n- `unit-testing` - Unit test patterns and best practices\n- `integration-testing` - Integration test patterns for component interactions\n- `e2e-testing` - End-to-end testing with Playwright\n- `test-data-management` - Test data fixtures and factories\n\n## Key Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Parallel Analyzers | 3 agents | Backend, frontend, and coverage analysis in parallel |\n| Default Traceback | `--tb=short` | Balance between detail and readability |\n| Stop Threshold | `--maxfail=3` | Quick feedback without overwhelming output |\n| Coverage Tool | pytest-cov / jest | Native integration with test frameworks |\n\n## References\n\n- [Test Commands](references/test-commands.md)",
    "contentTruncated": false,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "saga-patterns": {
    "name": "saga-patterns",
    "description": "Saga patterns for distributed transactions with orchestration and choreography approaches. Use when implementing multi-service transactions, handling partial failures, or building systems requiring eventual consistency with compensation.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "saga",
      "distributed-transactions",
      "orchestration",
      "choreography",
      "compensation",
      "microservices"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "event-driven-architect",
    "structure": {
      "references": [
        "choreography-deep-dive.md",
        "compensation-strategies.md",
        "orchestration-deep-dive.md",
        "state-machine-saga.md"
      ],
      "scripts": [
        "event-router-template.py",
        "saga-orchestrator-template.py",
        "saga-step-template.py"
      ],
      "checklists": [
        "compensation-checklist.md",
        "saga-design-checklist.md",
        "saga-implementation-checklist.md"
      ]
    },
    "content": "# Saga Patterns for Distributed Transactions\n\nMaintain consistency across microservices without distributed locks.\n\n## Overview\n\n- Multi-service business transactions (order -> payment -> inventory -> shipping)\n- Operations that must eventually succeed or roll back completely\n- Long-running business processes (minutes to days)\n- Microservices avoiding 2PC (two-phase commit)\n\n## When NOT to Use\n\n- Single database operations (use transactions)\n- Real-time consistency requirements (use synchronous calls)\n- When eventual consistency is unacceptable\n\n## Orchestration vs Choreography\n\n| Aspect | Orchestration | Choreography |\n|--------|---------------|--------------|\n| Control | Central orchestrator | Distributed events |\n| Coupling | Services depend on orchestrator | Loosely coupled |\n| Visibility | Single point of observation | Requires distributed tracing |\n| Best for | Complex, ordered workflows | Simple, parallel flows |\n\n## Orchestration Pattern\n\n```python\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import Callable, Any\nfrom datetime import datetime, timezone\n\nclass SagaStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    COMPENSATING = \"compensating\"\n    COMPENSATED = \"compensated\"\n    FAILED = \"failed\"\n\n@dataclass\nclass SagaStep:\n    name: str\n    action: Callable\n    compensation: Callable\n    status: SagaStatus = SagaStatus.PENDING\n    result: Any = None\n\n@dataclass\nclass SagaContext:\n    saga_id: str\n    data: dict = field(default_factory=dict)\n    steps: list[SagaStep] = field(default_factory=list)\n    status: SagaStatus = SagaStatus.PENDING\n    current_step: int = 0\n\nclass SagaOrchestrator:\n    def __init__(self, saga_repository, event_publisher):\n        self.repo = saga_repository\n        self.publisher = event_publisher\n\n    async def execute(self, saga: SagaContext) -> SagaContext:\n        saga.status = SagaStatus.RUNNING\n        await self.repo.save(saga)\n\n        for i, step in enumerate(saga.steps):\n            saga.current_step = i\n            try:\n                step.result = await step.action(saga.data)\n                saga.data.update(step.result or {})\n                step.status = SagaStatus.COMPLETED\n            except Exception:\n                step.status = SagaStatus.FAILED\n                await self._compensate(saga, i)\n                return saga\n\n        saga.status = SagaStatus.COMPLETED\n        await self.repo.save(saga)\n        return saga\n\n    async def _compensate(self, saga: SagaContext, failed_step: int):\n        saga.status = SagaStatus.COMPENSATING\n        for i in range(failed_step - 1, -1, -1):\n            step = saga.steps[i]\n            if step.status == SagaStatus.COMPLETED:\n                try:\n                    await step.compensation(saga.data)\n                    step.status = SagaStatus.COMPENSATED\n                except Exception as e:\n                    step.error = f\"Compensation failed: {e}\"\n        saga.status = SagaStatu",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "event-driven-architect"
    ]
  },
  "scene-intro-cards": {
    "name": "scene-intro-cards",
    "description": "Transitional intro cards between video scenes. Use when adding \"Coming Up Next\" cards, scene transitions, or visual breathing room in demos",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "remotion",
      "transitions",
      "cards",
      "animation",
      "scenes"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "animation-presets.md",
        "card-templates.md",
        "timing-patterns.md"
      ]
    },
    "content": "# Scene Intro Cards\n\nTransitional intro cards that appear between video scenes to prepare viewers for upcoming content. These \"Coming up next\" style cards increase engagement by building anticipation and providing visual breathing room.\n\n## Core Principle\n\n**Intro Cards = Anticipation Builder + Cognitive Reset**\n\nScene intro cards serve two purposes:\n1. **Build anticipation** for the next segment\n2. **Provide cognitive reset** between dense information sections\n\n```\nVIEWER JOURNEY\n==============\n\n[Dense Content A]\n       |\n       v\n+------------------+\n|  INTRO CARD      |  <-- 2-4 seconds\n|  \"Coming Up...\"  |      Viewer anticipation peaks\n+------------------+\n       |\n       v\n[Dense Content B]     <-- Viewer re-engages with fresh attention\n```\n\n## When to Use Intro Cards\n\n| Use Case | Card Duration | Style |\n|----------|---------------|-------|\n| Major topic change | 3-4 seconds | Bold, high contrast |\n| Section within topic | 2-3 seconds | Minimal, subtle |\n| Returning from tangent | 2 seconds | Quick reminder |\n| Before key reveal | 3-4 seconds | Building tension |\n| Tutorial steps | 2 seconds | Numbered, clear |\n\n## Card Anatomy\n\n```\n+------------------------------------------+\n|                                          |\n|     [ICON/EMOJI]                         |\n|                                          |\n|     PRIMARY TEXT                         |\n|     \"Coming Up Next\"                     |\n|                                          |\n|     Secondary text (optional)            |\n|     Brief description                    |\n|                                          |\n|     ---------=--------- (progress bar)   |\n|                                          |\n+------------------------------------------+\n```\n\n### Required Elements\n- **Primary text**: 2-4 words maximum\n- **Visual anchor**: Icon, emoji, or simple graphic\n\n### Optional Elements\n- Secondary descriptive text\n- Progress indicator\n- Section number\n- Estimated time\n\n## Style Variations\n\n### 1. Minimal\n\nClean and fast, ideal for short-form content.\n\n```\n+------------------------------------------+\n|                                          |\n|                                          |\n|              NEXT UP                     |\n|              --------                    |\n|                                          |\n|                                          |\n+------------------------------------------+\n\nColors: Muted background, high-contrast text\nAnimation: Simple fade\nUse: Professional, educational content, TikTok/Reels\nDuration: 1.5-2 seconds\n```\n\n### 2. Bold\n\nHigh impact, attention-grabbing for major transitions.\n\n```\n+------------------------------------------+\n|  ////////////////////////////////////////|\n|  //                                    //|\n|  //       COMING UP                    //|\n|  //       THE GOOD STUFF               //|\n|  //                                    //|\n|  ////////////////////////////////////////|\n+------------------------------------------+\n",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "scroll-driven-animations": {
    "name": "scroll-driven-animations",
    "description": "CSS Scroll-Driven Animations with ScrollTimeline, ViewTimeline, parallax effects, and progressive enhancement for performant scroll effects. Use when implementing scroll-linked animations or parallax.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "scroll-animation",
      "scroll-timeline",
      "view-timeline",
      "parallax",
      "css-animation",
      "scroll-driven",
      "performance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "css-scroll-timeline.md"
      ]
    },
    "content": "# Scroll-Driven Animations\n\nCSS Scroll-Driven Animations API provides performant, declarative scroll-linked animations without JavaScript. Supported in Chrome 115+, Edge 115+, Safari 18.4+.\n\n## Overview\n\n- Progress indicators tied to scroll position\n- Parallax effects without JavaScript jank\n- Element reveal animations on scroll into view\n- Sticky header animations based on scroll\n- Reading progress bars\n- Scroll-triggered image/content reveals\n\n## Core Concepts\n\n### Timeline Types\n\n| Timeline | CSS Function | Use Case |\n|----------|--------------|----------|\n| **Scroll Progress** | `scroll()` | Tied to scroll container position (0-100%) |\n| **View Progress** | `view()` | Tied to element visibility in viewport |\n\n## CSS Patterns\n\n### 1. Scroll Progress Timeline (Reading Progress)\n\n```css\n/* Progress bar that fills as page scrolls */\n.progress-bar {\n  position: fixed;\n  top: 0;\n  left: 0;\n  height: 4px;\n  background: var(--color-primary);\n  transform-origin: left;\n\n  /* Animate based on root scroll */\n  animation: grow-progress linear;\n  animation-timeline: scroll(root block);\n}\n\n@keyframes grow-progress {\n  from { transform: scaleX(0); }\n  to { transform: scaleX(1); }\n}\n```\n\n### 2. View Timeline (Reveal on Scroll)\n\n```css\n/* Fade in when element enters viewport */\n.reveal-on-scroll {\n  animation: fade-slide-up linear both;\n  animation-timeline: view();\n  animation-range: entry 0% entry 100%;\n}\n\n@keyframes fade-slide-up {\n  from {\n    opacity: 0;\n    transform: translateY(50px);\n  }\n  to {\n    opacity: 1;\n    transform: translateY(0);\n  }\n}\n```\n\n### 3. Animation Range Control\n\n```css\n/* Fine-tune when animation runs */\n.card {\n  animation: scale-up linear both;\n  animation-timeline: view();\n\n  /* Start at 25% entry, complete at 75% entry */\n  animation-range: entry 25% entry 75%;\n}\n\n/* Full visibility animation */\n.hero-image {\n  animation: parallax linear both;\n  animation-timeline: view();\n\n  /* Animate through entire visibility */\n  animation-range: cover 0% cover 100%;\n}\n\n@keyframes parallax {\n  from { transform: translateY(-20%); }\n  to { transform: translateY(20%); }\n}\n```\n\n### 4. Named Scroll Timelines\n\n```css\n/* Define timeline on scroll container */\n.scroll-container {\n  overflow-y: auto;\n  scroll-timeline-name: --container-scroll;\n  scroll-timeline-axis: block;\n}\n\n/* Use timeline in descendant */\n.progress-indicator {\n  animation: progress linear;\n  animation-timeline: --container-scroll;\n}\n\n@keyframes progress {\n  from { width: 0%; }\n  to { width: 100%; }\n}\n```\n\n### 5. Named View Timelines with Scope\n\n```css\n/* Parent sets up the timeline scope */\n.gallery {\n  timeline-scope: --card-timeline;\n}\n\n/* Each card defines its view timeline */\n.gallery-card {\n  view-timeline-name: --card-timeline;\n  view-timeline-axis: block;\n}\n\n/* Animate based on card visibility */\n.gallery-card .image {\n  animation: zoom-in linear both;\n  animation-timeline: --card-timeline;\n  animation-range: entry 0% cover 50%;\n}\n\n@keyframes zoom-in {\n  from { transform: ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "security-scanning": {
    "name": "security-scanning",
    "description": "Automated security scanning for dependencies and code. Use when running npm audit, pip-audit, Semgrep, secret detection, or integrating security checks into CI/CD.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "security",
      "scanning",
      "vulnerabilities",
      "audit"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Grep",
      "Glob",
      "Bash  # For running security scanners only"
    ],
    "skills": [],
    "agent": "security-auditor",
    "structure": {
      "references": [
        "tool-configs.md"
      ],
      "scripts": [
        "security-audit-template.md"
      ]
    },
    "content": "# Security Scanning\n\nAutomate vulnerability detection in code and dependencies.\n\n## Dependency Scanning\n\n### JavaScript (npm)\n\n```bash\n# Run audit\nnpm audit --json > security-audit.json\n\n# Check severity counts\nCRITICAL=$(npm audit --json | jq '.metadata.vulnerabilities.critical')\nHIGH=$(npm audit --json | jq '.metadata.vulnerabilities.high')\n\nif [ \"$CRITICAL\" -gt 0 ] || [ \"$HIGH\" -gt 0 ]; then\n  echo \"🚨 $CRITICAL critical, $HIGH high vulnerabilities\"\nfi\n\n# Auto-fix\nnpm audit fix\n```\n\n### Python (pip-audit)\n\n```bash\npip-audit --format=json > security-audit.json\n\n# Using safety\nsafety check --json > security-audit.json\n```\n\n## Static Analysis (SAST)\n\n### Semgrep\n\n```bash\n# Run with security rules\nsemgrep --config=auto --json > semgrep-results.json\n\n# Count findings\nCRITICAL=$(cat semgrep-results.json | jq '[.results[] | select(.extra.severity == \"ERROR\")] | length')\n```\n\n### Bandit (Python)\n\n```bash\nbandit -r . -f json -o bandit-report.json\n\nHIGH=$(cat bandit-report.json | jq '[.results[] | select(.issue_severity == \"HIGH\")] | length')\n```\n\n## Secret Detection\n\n```bash\n# TruffleHog\ntrufflehog git file://. --json > secrets-scan.json\n\n# Gitleaks\ngitleaks detect --source . --report-format json\n\n# Check results\nSECRET_COUNT=$(cat secrets-scan.json | jq '. | length')\nif [ \"$SECRET_COUNT\" -gt 0 ]; then\n  echo \"🚨 $SECRET_COUNT secrets detected!\"\nfi\n```\n\n## Container Scanning\n\n```bash\n# Trivy\ntrivy image myapp:latest --format json > trivy-scan.json\n\nCRITICAL=$(cat trivy-scan.json | jq '[.Results[].Vulnerabilities[]? | select(.Severity == \"CRITICAL\")] | length')\n```\n\n## Pre-commit Hooks (2026 Best Practice)\n\nShift-left security by catching issues before commit:\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  # Secret detection - MUST HAVE\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.18.0\n    hooks:\n      - id: gitleaks\n\n  # Python security\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.7\n    hooks:\n      - id: bandit\n        args: [\"-c\", \"pyproject.toml\", \"-r\", \".\"]\n        exclude: ^tests/\n\n  # Semgrep for SAST\n  - repo: https://github.com/semgrep/semgrep\n    rev: v1.52.0\n    hooks:\n      - id: semgrep\n        args: [\"--config\", \"auto\", \"--error\"]\n\n  # Detect AWS credentials, private keys\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: [\"--baseline\", \".secrets.baseline\"]\n```\n\n```bash\n# Install and setup\npip install pre-commit\npre-commit install\n\n# Run on all files (first time)\npre-commit run --all-files\n\n# Update hooks to latest versions\npre-commit autoupdate\n```\n\n**Baseline for detect-secrets (ignore false positives):**\n```bash\n# Generate baseline\ndetect-secrets scan > .secrets.baseline\n\n# Audit false positives\ndetect-secrets audit .secrets.baseline\n```\n\n## CI Integration\n\n```yaml\n# GitHub Actions\n- name: Security scan\n  run: |\n    npm audit --json > audit.json\n    CRITICAL=$(jq '.metadata.vulnerabilities.critical' audit.json)\n    if [ \"$CRITICAL\" -gt 0 ]; then\n     ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "ci-cd-engineer",
      "code-quality-reviewer",
      "infrastructure-architect",
      "security-auditor",
      "security-layer-auditor",
      "system-design-reviewer"
    ]
  },
  "semantic-caching": {
    "name": "semantic-caching",
    "description": "Redis semantic caching for LLM applications. Use when implementing vector similarity caching, optimizing LLM costs through cached responses, or building multi-level cache hierarchies.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "caching",
      "semantic",
      "redis",
      "llm",
      "cost"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "data-pipeline-engineer",
    "structure": {
      "references": [
        "cache-strategies.md"
      ],
      "scripts": [
        "redis-cache.py",
        "semantic-cache-service.py"
      ]
    },
    "content": "# Semantic Caching\n\nCache LLM responses by semantic similarity.\n\n> **Redis 8 Note:** Redis 8+ includes Search, JSON, TimeSeries, and Bloom modules built-in. No separate Redis Stack installation is required. Use `redis:8` in Docker or any Redis 8+ deployment.\n\n## Cache Hierarchy\n\n```\nRequest → L1 (Exact) → L2 (Semantic) → L3 (Prompt) → L4 (LLM)\n           ~1ms         ~10ms           ~2s          ~3s\n         100% save    100% save       90% save    Full cost\n```\n\n## Redis Semantic Cache\n\n```python\nfrom redisvl.index import SearchIndex\nfrom redisvl.query import VectorQuery\n\nclass SemanticCacheService:\n    def __init__(self, redis_url: str, threshold: float = 0.92):\n        self.client = Redis.from_url(redis_url)\n        self.threshold = threshold\n\n    async def get(self, content: str, agent_type: str) -> dict | None:\n        embedding = await embed_text(content[:2000])\n\n        query = VectorQuery(\n            vector=embedding,\n            vector_field_name=\"embedding\",\n            filter_expression=f\"@agent_type:{{{agent_type}}}\",\n            num_results=1\n        )\n\n        results = self.index.query(query)\n\n        if results:\n            distance = float(results[0].get(\"vector_distance\", 1.0))\n            if distance <= (1 - self.threshold):\n                return json.loads(results[0][\"response\"])\n\n        return None\n\n    async def set(self, content: str, response: dict, agent_type: str):\n        embedding = await embed_text(content[:2000])\n        key = f\"cache:{agent_type}:{hash_content(content)}\"\n\n        self.client.hset(key, mapping={\n            \"agent_type\": agent_type,\n            \"embedding\": embedding,\n            \"response\": json.dumps(response),\n            \"created_at\": time.time(),\n        })\n        self.client.expire(key, 86400)  # 24h TTL\n```\n\n## Similarity Thresholds\n\n| Threshold | Distance | Use Case |\n|-----------|----------|----------|\n| 0.98-1.00 | 0.00-0.02 | Nearly identical |\n| 0.95-0.98 | 0.02-0.05 | Very similar |\n| 0.92-0.95 | 0.05-0.08 | Similar (default) |\n| 0.85-0.92 | 0.08-0.15 | Moderately similar |\n\n## Multi-Level Lookup\n\n```python\nasync def get_llm_response(query: str, agent_type: str) -> dict:\n    # L1: Exact match (in-memory LRU)\n    cache_key = hash_content(query)\n    if cache_key in lru_cache:\n        return lru_cache[cache_key]\n\n    # L2: Semantic similarity (Redis)\n    similar = await semantic_cache.get(query, agent_type)\n    if similar:\n        lru_cache[cache_key] = similar  # Promote to L1\n        return similar\n\n    # L3/L4: LLM call with prompt caching\n    response = await llm.generate(query)\n\n    # Store in caches\n    await semantic_cache.set(query, response, agent_type)\n    lru_cache[cache_key] = response\n\n    return response\n```\n\n## Redis 8.4+ Hybrid Search (FT.HYBRID)\n\nRedis 8.4 introduces native hybrid search combining semantic (vector) and exact (keyword) matching in a single query. This is ideal for caches that need both similarity and metadata filtering.\n\n```python\n# Redis 8.4 native hybr",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "data-pipeline-engineer",
      "llm-integrator"
    ]
  },
  "shadcn-patterns": {
    "name": "shadcn-patterns",
    "description": "shadcn/ui component patterns including CVA variants, OKLCH theming, cn() utility, and composition. Use when adding shadcn components, building variant systems, or customizing themes.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "shadcn",
      "ui",
      "cva",
      "variants",
      "tailwind",
      "theming",
      "oklch",
      "components"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "cn-utility-patterns.md",
        "component-extension.md",
        "cva-variant-system.md",
        "dark-mode-toggle.md",
        "oklch-theming.md"
      ],
      "scripts": [
        "custom-theme.css",
        "cva-component.tsx",
        "extended-button.tsx"
      ],
      "checklists": [
        "shadcn-setup.md"
      ]
    },
    "content": "# shadcn/ui Patterns\n\nBeautifully designed, accessible components you own and customize.\n\n## Core Pattern: CVA (Class Variance Authority)\n\nDeclarative, type-safe variant definitions:\n\n```tsx\nimport { cva, type VariantProps } from 'class-variance-authority'\n\nconst buttonVariants = cva(\n  // Base classes (always applied)\n  'inline-flex items-center justify-center rounded-md font-medium transition-colors',\n  {\n    variants: {\n      variant: {\n        default: 'bg-primary text-primary-foreground hover:bg-primary/90',\n        destructive: 'bg-destructive text-destructive-foreground',\n        outline: 'border border-input bg-background hover:bg-accent',\n        ghost: 'hover:bg-accent hover:text-accent-foreground',\n      },\n      size: {\n        default: 'h-10 px-4 py-2',\n        sm: 'h-9 px-3',\n        lg: 'h-11 px-8',\n        icon: 'h-10 w-10',\n      },\n    },\n    compoundVariants: [\n      { variant: 'outline', size: 'lg', className: 'border-2' },\n    ],\n    defaultVariants: {\n      variant: 'default',\n      size: 'default',\n    },\n  }\n)\n\n// Type-safe props\ninterface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {}\n```\n\n## Core Pattern: cn() Utility\n\nCombines `clsx` + `tailwind-merge` for conflict resolution:\n\n```tsx\nimport { clsx, type ClassValue } from 'clsx'\nimport { twMerge } from 'tailwind-merge'\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n}\n\n// Usage - later classes win\ncn('px-4 py-2', 'px-6') // => 'py-2 px-6'\ncn('text-red-500', condition && 'text-blue-500')\n```\n\n## OKLCH Theming (2026 Standard)\n\nModern perceptually uniform color space:\n\n```css\n:root {\n  --background: oklch(1 0 0);\n  --foreground: oklch(0.145 0 0);\n  --primary: oklch(0.205 0 0);\n  --primary-foreground: oklch(0.985 0 0);\n  --destructive: oklch(0.577 0.245 27.325);\n  --border: oklch(0.922 0 0);\n  --ring: oklch(0.708 0 0);\n  --radius: 0.625rem;\n}\n\n.dark {\n  --background: oklch(0.145 0 0);\n  --foreground: oklch(0.985 0 0);\n  --primary: oklch(0.985 0 0);\n  --destructive: oklch(0.396 0.141 25.723);\n}\n```\n\n**Why OKLCH?**\n- Perceptually uniform (equal steps look equal)\n- Better dark mode contrast\n- Wide gamut support\n- Format: `oklch(lightness chroma hue)`\n\n## Component Extension Strategy\n\n**Wrap, don't modify source:**\n\n```tsx\nimport { Button as ShadcnButton } from '@/components/ui/button'\n\n// Extend with new variants\nconst Button = React.forwardRef<\n  React.ElementRef<typeof ShadcnButton>,\n  React.ComponentPropsWithoutRef<typeof ShadcnButton> & {\n    loading?: boolean\n  }\n>(({ loading, children, disabled, ...props }, ref) => (\n  <ShadcnButton ref={ref} disabled={disabled || loading} {...props}>\n    {loading && <Spinner className=\"mr-2\" />}\n    {children}\n  </ShadcnButton>\n))\n```\n\n## Quick Reference\n\n```bash\n# Add components\nnpx shadcn@latest add button\nnpx shadcn@latest add dialog\n\n# Initialize in project\nnpx shadcn@latest init\n```\n\n## Key Decisions\n\n| Decision | Recommendation |\n|------",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer",
      "rapid-ui-designer"
    ]
  },
  "silent-failure-detection": {
    "name": "silent-failure-detection",
    "description": "Detect quiet failures in LLM agents - tool skipping, gibberish outputs, infinite loops, and degraded quality. Use when agents appear to work but produce incorrect results.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "monitoring",
      "alerting",
      "anomaly",
      "silent-failure",
      "observability",
      "agents"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "monitoring-engineer",
    "structure": {
      "references": [
        "baseline-comparison.md",
        "gibberish-detection.md",
        "loop-detection.md",
        "tool-skipping-detection.md"
      ]
    },
    "content": "# Silent Failure Detection\n\nDetect when LLM agents fail silently - appearing to work while producing incorrect results.\n\n## Overview\n\n- Detecting when agents skip expected tool calls\n- Identifying gibberish or degraded output quality\n- Monitoring for infinite loops and token consumption spikes\n- Setting up statistical baselines for anomaly detection\n- Alerting on non-error failures (service up but logic broken)\n\n## Quick Reference\n\n### Tool Skipping Detection\n\n```python\nfrom langfuse import Langfuse\n\ndef check_tool_usage(trace_id: str, expected_tools: list[str]) -> dict:\n    \"\"\"\n    Detect when agent skips expected tool calls.\n\n    Based on Akamai's middleware bug: agents stopped using tools\n    when hidden middleware injected unexpected instructions.\n    \"\"\"\n    langfuse = Langfuse()\n    trace = langfuse.fetch_trace(trace_id)\n\n    # Extract tool calls from trace\n    actual_tools = [\n        span.name for span in trace.observations\n        if span.type == \"tool\"\n    ]\n\n    missing_tools = set(expected_tools) - set(actual_tools)\n\n    if missing_tools:\n        return {\n            \"alert\": True,\n            \"type\": \"tool_skipping\",\n            \"missing\": list(missing_tools),\n            \"message\": f\"Agent skipped expected tools: {missing_tools}\"\n        }\n    return {\"alert\": False}\n```\n\n### Gibberish/Quality Detection\n\n```python\nfrom langfuse.decorators import observe, langfuse_context\n\n@observe(name=\"quality_check\")\nasync def detect_gibberish(response: str) -> dict:\n    \"\"\"\n    Detect low-quality or gibberish outputs using LLM-as-judge.\n    \"\"\"\n    # Quick heuristics first\n    if len(response) < 10:\n        return {\"alert\": True, \"type\": \"too_short\"}\n\n    if len(set(response.split())) / len(response.split()) < 0.3:\n        return {\"alert\": True, \"type\": \"repetitive\"}\n\n    # LLM-as-judge for quality\n    judge_prompt = f\"\"\"\n    Rate this response quality (0-1):\n    - 0: Gibberish, nonsensical, or completely wrong\n    - 0.5: Partially correct but missing key information\n    - 1: High quality, accurate, complete\n\n    Response: {response[:1000]}\n\n    Score (just the number):\n    \"\"\"\n\n    score = await llm.generate(judge_prompt)\n    score_value = float(score.strip())\n\n    langfuse_context.score(name=\"quality_check\", value=score_value)\n\n    if score_value < 0.5:\n        return {\"alert\": True, \"type\": \"low_quality\", \"score\": score_value}\n    return {\"alert\": False, \"score\": score_value}\n```\n\n### Loop Detection\n\n```python\nclass LoopDetector:\n    \"\"\"Detect infinite loops and token consumption spikes.\"\"\"\n\n    def __init__(\n        self,\n        max_iterations: int = 10,\n        token_spike_multiplier: float = 3.0,\n        baseline_tokens: int = 2000\n    ):\n        self.max_iterations = max_iterations\n        self.token_spike_multiplier = token_spike_multiplier\n        self.baseline_tokens = baseline_tokens\n        self.iteration_count = 0\n        self.total_tokens = 0\n\n    def check(self, tokens_used: int) -> dict:\n        self.iteration_count += 1\n        ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "skill-analyzer": {
    "name": "skill-analyzer",
    "description": "Reference patterns for parsing skill metadata. Use when extracting phases, examples, or features from SKILL.md files for demo generation",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "skill",
      "metadata",
      "parser",
      "analysis",
      "reference"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "frontmatter-parsing.md",
        "phase-extraction.md"
      ]
    },
    "content": "# Skill Analyzer\n\nReference patterns for extracting structured metadata from SKILL.md files.\n\n> **Note**: Actual analysis is performed by `demo-producer/scripts/generate.sh`. This skill provides reference patterns.\n\n## Output Structure\n\n```typescript\ninterface SkillMetadata {\n  name: string;\n  description: string;\n  tags: string[];\n  version: string;\n  userInvocable: boolean;\n  context: 'fork' | 'inherit' | 'none';\n\n  // Extracted content\n  phases: WorkflowPhase[];\n  examples: CodeExample[];\n  keyFeatures: string[];\n  relatedSkills: string[];\n}\n\ninterface WorkflowPhase {\n  name: string;\n  description: string;\n  tools: string[];\n  isParallel: boolean;\n}\n\ninterface CodeExample {\n  language: string;\n  code: string;\n  description: string;\n}\n```\n\n## Extraction Rules\n\n### Frontmatter Parsing (Bash)\n```bash\n# Extract name\nname=$(grep \"^name:\" SKILL.md | head -1 | cut -d: -f2- | xargs)\n\n# Extract description\ndescription=$(grep \"^description:\" SKILL.md | head -1 | cut -d: -f2- | xargs)\n\n# Extract tags\ntags=$(grep \"^tags:\" SKILL.md | sed 's/tags: \\[//' | sed 's/\\]//' | tr -d '\"')\n```\n\n### Phase Detection\n- Look for `## Phase N:` or `### Phase N:` headers\n- Extract tools from code blocks (Grep, Glob, Read, Task, etc.)\n- Detect parallel execution from \"PARALLEL\" comments or multiple tool calls\n\n### Example Detection\n- Find code blocks with language tags\n- Extract surrounding context as description\n- Identify quick start examples\n\n### Feature Detection\n- Parse bullet points after \"Key Features\" or \"What it does\"\n- Extract from description field\n- Identify from tags\n\n## Usage in Demo Pipeline\n\n```bash\n# Integrated into demo-producer\n./skills/demo-producer/scripts/generate.sh skill explore\n\n# Internally calls extraction functions to:\n# 1. Parse SKILL.md frontmatter\n# 2. Extract phases from ## headers\n# 3. Identify related skills\n# 4. Generate demo script with extracted content\n```\n\n## Related Skills\n\n- `demo-producer`: Uses skill-analyzer output for script generation\n- `terminal-demo-generator`: Creates recordings based on extracted phases\n- `content-type-recipes`: Templates that consume analyzed metadata\n\n## References\n\nSee `references/` for detailed extraction patterns:\n- `frontmatter-parsing.md` - YAML frontmatter extraction\n- `phase-extraction.md` - Workflow phase detection",
    "contentTruncated": false,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "skill-evolution": {
    "name": "skill-evolution",
    "description": "Evolves skills based on usage patterns. Use when improving or rolling back skill definitions.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "skill-management",
      "evolution",
      "versioning",
      "analytics"
    ],
    "userInvocable": true,
    "context": "inherit",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "evolution-analysis.md",
        "version-management.md"
      ]
    },
    "content": "# Skill Evolution Manager\n\nEnables skills to automatically improve based on usage patterns, user edits, and success rates. Provides version control with safe rollback capability.\n\n## Overview\n\n- Reviewing how skills are performing across sessions\n- Identifying patterns in user edits to skill outputs\n- Applying learned improvements to skill templates\n- Rolling back problematic skill changes\n- Tracking skill version history and success rates\n\n## Quick Reference\n\n| Command | Description |\n|---------|-------------|\n| `/ork:skill-evolution` | Show evolution report for all skills |\n| `/ork:skill-evolution analyze <skill-id>` | Analyze specific skill patterns |\n| `/ork:skill-evolution evolve <skill-id>` | Review and apply suggestions |\n| `/ork:skill-evolution history <skill-id>` | Show version history |\n| `/ork:skill-evolution rollback <skill-id> <version>` | Restore previous version |\n\n---\n\n## How It Works\n\nThe skill evolution system operates in three phases:\n\n```\nCOLLECT                    ANALYZE                    ACT\n───────                    ───────                    ───\n┌─────────────┐           ┌─────────────┐           ┌─────────────┐\n│ PostTool    │──────────▶│ Evolution   │──────────▶│ /ork:skill  │\n│ Edit        │  patterns │ Analyzer    │ suggest   │ evolve      │\n│ Tracker     │           │ Engine      │           │ command     │\n└─────────────┘           └─────────────┘           └─────────────┘\n     │                          │                          │\n     ▼                          ▼                          ▼\n┌─────────────┐           ┌─────────────┐           ┌─────────────┐\n│ edit-       │           │ evolution-  │           │ versions/   │\n│ patterns.   │           │ registry.   │           │ snapshots   │\n│ jsonl       │           │ json        │           │             │\n└─────────────┘           └─────────────┘           └─────────────┘\n```\n\n### Edit Pattern Categories\n\nThe system tracks these common edit patterns:\n\n| Pattern | Description | Detection |\n|---------|-------------|-----------|\n| `add_pagination` | User adds pagination to API responses | `limit.*offset`, `cursor.*pagination` |\n| `add_rate_limiting` | User adds rate limiting | `rate.?limit`, `throttl` |\n| `add_error_handling` | User adds try/catch blocks | `try.*catch`, `except` |\n| `add_types` | User adds TypeScript/Python types | `interface\\s`, `Optional` |\n| `add_validation` | User adds input validation | `validate`, `Pydantic`, `Zod` |\n| `add_logging` | User adds logging/observability | `logger\\.`, `console.log` |\n| `remove_comments` | User removes generated comments | Pattern removal detection |\n| `add_auth_check` | User adds authentication checks | `@auth`, `@require_auth` |\n\n### Suggestion Thresholds\n\n| Threshold | Default | Description |\n|-----------|---------|-------------|\n| Minimum Samples | 5 | Uses before generating suggestions |\n| Add Threshold | 70% | Frequency to suggest adding pattern |\n| Auto-Apply Confidence | 85% | Confidence for auto-applicat",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": []
  },
  "sqlalchemy-2-async": {
    "name": "sqlalchemy-2-async",
    "description": "SQLAlchemy 2.0 async patterns with AsyncSession, async_sessionmaker, and FastAPI integration. Use when implementing async database operations, connection pooling, or async ORM queries.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "sqlalchemy",
      "async",
      "database",
      "orm",
      "fastapi",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Edit",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "eager-loading.md",
        "fastapi-integration.md"
      ],
      "scripts": [
        "repository-template.py"
      ],
      "checklists": [
        "sqlalchemy-async-checklist.md"
      ]
    },
    "content": "# SQLAlchemy 2.0 Async Patterns ()\n\nModern async database patterns with SQLAlchemy 2.0, AsyncSession, and FastAPI integration.\n\n## Overview\n\n- Building async FastAPI applications with database access\n- Implementing async repository patterns\n- Configuring async connection pooling\n- Running concurrent database queries\n- Avoiding N+1 queries in async context\n\n## Quick Reference\n\n### Engine and Session Factory\n\n```python\nfrom sqlalchemy.ext.asyncio import (\n    create_async_engine,\n    async_sessionmaker,\n    AsyncSession,\n)\n\n# Create async engine - ONE per application\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@localhost/db\",\n    pool_size=20,\n    max_overflow=10,\n    pool_pre_ping=True,  # Verify connections before use\n    pool_recycle=3600,   # Recycle connections after 1 hour\n    echo=False,          # Set True for SQL logging in dev\n)\n\n# Session factory - use this to create sessions\nasync_session_factory = async_sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,  # Prevent lazy load issues\n    autoflush=False,         # Explicit flush control\n)\n```\n\n### FastAPI Dependency Injection\n\n```python\nfrom typing import AsyncGenerator\nfrom fastapi import Depends\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nasync def get_db() -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"Dependency that provides async database session.\"\"\"\n    async with async_session_factory() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n# Usage in route\n@router.get(\"/users/{user_id}\")\nasync def get_user(\n    user_id: UUID,\n    db: AsyncSession = Depends(get_db),\n) -> UserResponse:\n    result = await db.execute(\n        select(User).where(User.id == user_id)\n    )\n    user = result.scalar_one_or_none()\n    if not user:\n        raise HTTPException(404, \"User not found\")\n    return UserResponse.model_validate(user)\n```\n\n### Async Model Definition\n\n```python\nfrom sqlalchemy import String, ForeignKey\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom datetime import datetime, timezone\nimport uuid\n\nclass Base(DeclarativeBase):\n    pass\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True),\n        primary_key=True,\n        default=uuid.uuid4,\n    )\n    email: Mapped[str] = mapped_column(String(255), unique=True, index=True)\n    created_at: Mapped[datetime] = mapped_column(default=lambda: datetime.now(timezone.utc))\n\n    # Relationship with explicit lazy loading strategy\n    orders: Mapped[list[\"Order\"]] = relationship(\n        back_populates=\"user\",\n        lazy=\"raise\",  # Prevent accidental lazy loads - MUST use selectinload\n    )\n\nclass Order(Base):\n    __tablename__ = \"orders\"\n\n    id: Mapped[uuid.UUID] = mapped_column(UUID(as_uuid=True), primary_key=True)\n    user_id: Map",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "database-engineer",
      "python-performance-engineer"
    ]
  },
  "stacked-prs": {
    "name": "stacked-prs",
    "description": "Multi-PR development for large features. Stack dependent PRs, manage rebases, and get faster reviews on smaller changes. Use when creating stacked PRs.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "git",
      "pull-request",
      "stacked",
      "workflow",
      "code-review"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "stack-management.md"
      ],
      "scripts": [
        "create-stacked-pr.md",
        "stack-scripts.sh"
      ]
    },
    "content": "# Stacked PRs\n\nBreak large features into small, reviewable PRs that depend on each other. Merge in order for clean history.\n\n## Quick Reference\n\n```\nmain ──────────────────────────────────────────●\n                                              /\nPR #3 (final)  ─────────────────────────●────┘   ← Merge last\n                                       /\nPR #2 (middle) ────────────────────●──┘          ← Depends on #1\n                                  /\nPR #1 (base)   ────────────────●──                ← Merge first\n                              /\nfeature/auth ──────●────●────●                    ← Development\n```\n\n---\n\n## Workflow\n\n### 1. Plan the Stack\n\n```bash\n# Identify logical chunks\n# Example: Auth feature\n# PR 1: Add User model + migrations\n# PR 2: Add auth service + tests\n# PR 3: Add login UI + integration tests\n```\n\n### 2. Create Base Branch\n\n```bash\ngit checkout main\ngit pull origin main\ngit checkout -b feature/auth-base\n\n# Implement first chunk\ngit add -p\ngit commit -m \"feat(#100): Add User model\"\ngit commit -m \"feat(#100): Add user migrations\"\n\n# Push and create first PR\ngit push -u origin feature/auth-base\ngh pr create --base main --title \"feat(#100): Add User model [1/3]\" \\\n  --body \"## Stack\n- PR 1/3: User model (this PR)\n- PR 2/3: Auth service (depends on this)\n- PR 3/3: Login UI (depends on #2)\n\n## Changes\n- Add User model with validation\n- Add database migrations\"\n```\n\n### 3. Stack Next PR\n\n```bash\n# Branch from first PR's branch (not main!)\ngit checkout -b feature/auth-service\n\n# Implement second chunk\ngit add -p\ngit commit -m \"feat(#100): Add auth service\"\ngit commit -m \"test(#100): Add auth service tests\"\n\n# Push and create PR targeting FIRST branch\ngit push -u origin feature/auth-service\ngh pr create --base feature/auth-base \\\n  --title \"feat(#100): Add auth service [2/3]\" \\\n  --body \"## Stack\n- PR 1/3: User model (#101)\n- PR 2/3: Auth service (this PR)\n- PR 3/3: Login UI (depends on this)\n\n**Depends on #101** - merge that first\"\n```\n\n### 4. Continue Stacking\n\n```bash\ngit checkout -b feature/auth-ui\n\n# Implement third chunk\ngit commit -m \"feat(#100): Add login form\"\ngit commit -m \"test(#100): Add login integration tests\"\n\ngit push -u origin feature/auth-ui\ngh pr create --base feature/auth-service \\\n  --title \"feat(#100): Add login UI [3/3]\"\n```\n\n---\n\n## Managing the Stack\n\n### When Base PR Gets Feedback\n\n```bash\n# Make changes to base PR\ngit checkout feature/auth-base\ngit add -p\ngit commit -m \"fix: Address review feedback\"\ngit push\n\n# Rebase dependent PRs\ngit checkout feature/auth-service\ngit rebase feature/auth-base\ngit push --force-with-lease\n\ngit checkout feature/auth-ui\ngit rebase feature/auth-service\ngit push --force-with-lease\n```\n\n### When Base PR Merges\n\n```bash\n# After PR #1 merges to main\ngit checkout main\ngit pull origin main\n\n# Update PR #2 to target main now\ngh pr edit 102 --base main\n\n# Rebase PR #2 on main\ngit checkout feature/auth-service\ngit rebase main\ngit push --force-with-lease\n\n# Repeat for PR #3 after #2 merges",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "git-operations-engineer"
    ]
  },
  "strawberry-graphql": {
    "name": "strawberry-graphql",
    "description": "Strawberry GraphQL library for Python with FastAPI integration, type-safe resolvers, DataLoader patterns, and subscriptions. Use when building GraphQL APIs with Python, implementing real-time features, or creating federated schemas.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "graphql",
      "strawberry",
      "fastapi",
      "dataloader",
      "subscriptions",
      "federation",
      "python"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "backend-system-architect",
    "structure": {
      "references": [
        "dataloader-patterns.md",
        "federation-patterns.md",
        "permission-classes.md",
        "subscription-setup.md"
      ],
      "scripts": [
        "dataloader-template.py",
        "strawberry-fastapi-template.py",
        "strawberry-schema-template.py",
        "subscription-template.py"
      ],
      "checklists": [
        "graphql-production-checklist.md",
        "performance-checklist.md",
        "schema-design-checklist.md"
      ]
    },
    "content": "# Strawberry GraphQL Patterns\n\nType-safe GraphQL in Python with code-first schema definition.\n\n## Overview\n\n- Complex data relationships (nested queries, multiple entities)\n- Client-driven data fetching (mobile apps, SPAs)\n- Real-time features (subscriptions for live updates)\n- Federated microservice architecture\n\n## When NOT to Use\n\n- Simple CRUD APIs (REST is simpler)\n- Internal microservice communication (use gRPC)\n\n## Schema Definition\n\n```python\nimport strawberry\nfrom datetime import datetime\nfrom strawberry import Private\n\n@strawberry.enum\nclass UserStatus:\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n\n@strawberry.type\nclass User:\n    id: strawberry.ID\n    email: str\n    name: str\n    status: UserStatus\n    password_hash: Private[str]  # Not exposed in schema\n\n    @strawberry.field\n    def display_name(self) -> str:\n        return f\"{self.name} ({self.email})\"\n\n    @strawberry.field\n    async def posts(self, info: strawberry.Info, limit: int = 10) -> list[\"Post\"]:\n        return await info.context.post_loader.load_by_user(self.id, limit)\n\n@strawberry.type\nclass Post:\n    id: strawberry.ID\n    title: str\n    content: str\n    author_id: strawberry.ID\n\n    @strawberry.field\n    async def author(self, info: strawberry.Info) -> User:\n        return await info.context.user_loader.load(self.author_id)\n\n@strawberry.input\nclass CreateUserInput:\n    email: str\n    name: str\n    password: str\n```\n\n## Query and Mutation\n\n```python\n@strawberry.type\nclass Query:\n    @strawberry.field\n    async def user(self, info: strawberry.Info, id: strawberry.ID) -> User | None:\n        return await info.context.user_service.get(id)\n\n    @strawberry.field\n    async def me(self, info: strawberry.Info) -> User | None:\n        user_id = info.context.current_user_id\n        return await info.context.user_service.get(user_id) if user_id else None\n\n@strawberry.type\nclass Mutation:\n    @strawberry.mutation\n    async def create_user(self, info: strawberry.Info, input: CreateUserInput) -> User:\n        return await info.context.user_service.create(\n            email=input.email, name=input.name, password=input.password\n        )\n\n    @strawberry.mutation\n    async def delete_user(self, info: strawberry.Info, id: strawberry.ID) -> bool:\n        await info.context.user_service.delete(id)\n        return True\n```\n\n## DataLoader (N+1 Prevention)\n\n```python\nfrom strawberry.dataloader import DataLoader\n\nclass UserLoader(DataLoader[str, User]):\n    def __init__(self, user_repo):\n        super().__init__(load_fn=self.batch_load)\n        self.user_repo = user_repo\n\n    async def batch_load(self, keys: list[str]) -> list[User]:\n        users = await self.user_repo.get_many(keys)\n        user_map = {u.id: u for u in users}\n        return [user_map.get(key) for key in keys]\n\nclass GraphQLContext:\n    def __init__(self, request, user_service, user_repo, post_repo):\n        self.request = request\n        self.user_service = user_service\n        self.user_loader = UserLoader(user_repo)\n   ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "backend-system-architect"
    ]
  },
  "streaming-api-patterns": {
    "name": "streaming-api-patterns",
    "description": "Real-time data streaming with SSE, WebSockets, and ReadableStream. Use when implementing streaming responses, real-time data updates, Server-Sent Events, WebSocket setup, live notifications, push updates, or chat server backends.",
    "version": "1.0.0",
    "author": "AI Agent Hub",
    "tags": [
      "streaming",
      "sse",
      "websocket",
      "real-time",
      "api"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "sse-deep-dive.md"
      ],
      "scripts": [
        "sse-endpoint-template.ts"
      ],
      "checklists": [
        "streaming-checklist.md"
      ]
    },
    "content": "# Streaming API Patterns\n\n## Overview\n\n**When to use this skill:**\n- Streaming LLM responses (ChatGPT-style interfaces)\n- Real-time notifications and updates\n- Live data feeds (stock prices, analytics)\n- Chat applications\n- Progress updates for long-running tasks\n- Collaborative editing features\n\n## Core Technologies\n\n### 1. Server-Sent Events (SSE)\n\n**Best for**: Server-to-client streaming (LLM responses, notifications)\n\n```typescript\n// Next.js Route Handler\nexport async function GET(req: Request) {\n  const encoder = new TextEncoder()\n\n  const stream = new ReadableStream({\n    async start(controller) {\n      // Send data\n      controller.enqueue(encoder.encode('data: Hello\\n\\n'))\n\n      // Keep connection alive\n      const interval = setInterval(() => {\n        controller.enqueue(encoder.encode(': keepalive\\n\\n'))\n      }, 30000)\n\n      // Cleanup\n      req.signal.addEventListener('abort', () => {\n        clearInterval(interval)\n        controller.close()\n      })\n    }\n  })\n\n  return new Response(stream, {\n    headers: {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache',\n      'Connection': 'keep-alive',\n    }\n  })\n}\n\n// Client\nconst eventSource = new EventSource('/api/stream')\neventSource.onmessage = (event) => {\n  console.log(event.data)\n}\n```\n\n### 2. WebSockets\n\n**Best for**: Bidirectional real-time communication (chat, collaboration)\n\n```typescript\n// WebSocket Server (Next.js with ws)\nimport { WebSocketServer } from 'ws'\n\nconst wss = new WebSocketServer({ port: 8080 })\n\nwss.on('connection', (ws) => {\n  ws.on('message', (data) => {\n    // Broadcast to all clients\n    wss.clients.forEach((client) => {\n      if (client.readyState === WebSocket.OPEN) {\n        client.send(data)\n      }\n    })\n  })\n})\n\n// Client\nconst ws = new WebSocket('ws://localhost:8080')\nws.onmessage = (event) => console.log(event.data)\nws.send(JSON.stringify({ type: 'message', text: 'Hello' }))\n```\n\n### 3. ReadableStream API\n\n**Best for**: Processing large data streams with backpressure\n\n```typescript\nasync function* generateData() {\n  for (let i = 0; i < 1000; i++) {\n    await new Promise(resolve => setTimeout(resolve, 100))\n    yield \"data-\" + i\n  }\n}\n\nconst stream = new ReadableStream({\n  async start(controller) {\n    for await (const chunk of generateData()) {\n      controller.enqueue(new TextEncoder().encode(chunk + '\\n'))\n    }\n    controller.close()\n  }\n})\n```\n\n## LLM Streaming Pattern\n\n```typescript\n// Server\nimport OpenAI from 'openai'\n\nconst openai = new OpenAI()\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json()\n\n  const stream = await openai.chat.completions.create({\n    model: 'gpt-5.2',\n    messages,\n    stream: true\n  })\n\n  const encoder = new TextEncoder()\n\n  return new Response(\n    new ReadableStream({\n      async start(controller) {\n        for await (const chunk of stream) {\n          const content = chunk.choices[0]?.delta?.content\n          if (content) {\n            controller.enqueue(enco",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "backend-system-architect",
      "event-driven-architect",
      "frontend-ui-developer",
      "llm-integrator",
      "multimodal-specialist"
    ]
  },
  "system-design-interrogation": {
    "name": "system-design-interrogation",
    "description": "Use when planning system architecture to ensure nothing is missed. Provides structured questions covering scalability, security, data, and operational dimensions before implementation.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "architecture",
      "design",
      "review",
      "questions"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "system-design-reviewer",
    "structure": {
      "references": [
        "coherence-questions.md",
        "scale-questions.md",
        "security-questions.md"
      ],
      "checklists": [
        "before-implementation.md"
      ]
    },
    "content": "# System Design Interrogation\n\n## The Problem\n\nRushing to implementation without systematic design thinking leads to:\n- Scalability issues discovered too late\n- Security holes from missing tenant isolation\n- Data model mismatches\n- Frontend/backend contract conflicts\n- Poor user experience\n\n## The Solution: Question Before Implementing\n\n```\n┌────────────────────────────────────────────────────────────────────────────┐\n│                    SYSTEM DESIGN INTERROGATION                             │\n├────────────────────────────────────────────────────────────────────────────┤\n│                                                                            │\n│                        ┌─────────────┐                                     │\n│                        │   FEATURE   │                                     │\n│                        │   REQUEST   │                                     │\n│                        └──────┬──────┘                                     │\n│                               │                                            │\n│    ┌──────────────────────────┼──────────────────────────┐                │\n│    │                          │                          │                │\n│    ▼                          ▼                          ▼                │\n│  ┌────────┐             ┌────────┐              ┌────────┐               │\n│  │ SCALE  │             │  DATA  │              │SECURITY│               │\n│  └───┬────┘             └───┬────┘              └───┬────┘               │\n│      │                      │                       │                     │\n│  • Users?               • Where?               • Who access?              │\n│  • Volume?              • Pattern?             • Isolation?               │\n│  • Growth?              • Search?              • Attacks?                 │\n│      │                      │                       │                     │\n│      └──────────────────────┼───────────────────────┘                     │\n│                             │                                             │\n│    ┌────────────────────────┼────────────────────────┐                   │\n│    │                        │                        │                   │\n│    ▼                        ▼                        ▼                   │\n│  ┌────────┐           ┌──────────┐            ┌────────┐                │\n│  │   UX   │           │COHERENCE │            │ TRADE- │                │\n│  └───┬────┘           └────┬─────┘            │  OFFS  │                │\n│      │                     │                  └───┬────┘                │\n│  • Latency?           • Contracts?           • Speed?                    │\n│  • Feedback?          • Types?               • Quality?                  │\n│  • Errors?            • API?                 • Cost?                     │\n│      │                     │                      │                      │\n│      └─────────────────────┴──────────────────────┘                      │\n│              ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "system-design-reviewer"
    ]
  },
  "tanstack-query-advanced": {
    "name": "tanstack-query-advanced",
    "description": "Advanced TanStack Query v5 patterns for infinite queries, optimistic updates, prefetching, gcTime, and queryOptions. Use when building data fetching, caching, or optimistic updates.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "tanstack-query",
      "react-query",
      "caching",
      "infinite-scroll",
      "optimistic-updates",
      "prefetching",
      "suspense"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "cache-strategies.md"
      ],
      "scripts": [
        "query-hooks-template.ts"
      ],
      "checklists": [
        "tanstack-checklist.md"
      ]
    },
    "content": "# TanStack Query Advanced\n\nProduction patterns for TanStack Query v5 - server state management done right.\n\n## Overview\n\n- Infinite scroll / pagination\n- Optimistic UI updates\n- Prefetching for instant navigation\n- Complex cache invalidation\n- Dependent/parallel queries\n- Mutations with rollback\n\n## Core Patterns\n\n### 1. Infinite Queries (Cursor-Based)\n\n```typescript\nimport { useInfiniteQuery } from '@tanstack/react-query';\n\ninterface Page {\n  items: Item[];\n  nextCursor: string | null;\n}\n\nfunction useInfiniteItems() {\n  return useInfiniteQuery({\n    queryKey: ['items'],\n    queryFn: async ({ pageParam }): Promise<Page> => {\n      const res = await fetch(`/api/items?cursor=${pageParam ?? ''}`);\n      return res.json();\n    },\n    initialPageParam: null as string | null,\n    getNextPageParam: (lastPage) => lastPage.nextCursor,\n    getPreviousPageParam: (firstPage) => firstPage.prevCursor,\n  });\n}\n\n// Component\nfunction ItemList() {\n  const { data, fetchNextPage, hasNextPage, isFetchingNextPage } = useInfiniteItems();\n\n  return (\n    <>\n      {data?.pages.flatMap((page) => page.items.map((item) => (\n        <ItemCard key={item.id} item={item} />\n      )))}\n      <button\n        onClick={() => fetchNextPage()}\n        disabled={!hasNextPage || isFetchingNextPage}\n      >\n        {isFetchingNextPage ? 'Loading...' : hasNextPage ? 'Load More' : 'No more'}\n      </button>\n    </>\n  );\n}\n```\n\n### 2. Optimistic Updates\n\n```typescript\nimport { useMutation, useQueryClient } from '@tanstack/react-query';\n\nfunction useUpdateTodo() {\n  const queryClient = useQueryClient();\n\n  return useMutation({\n    mutationFn: updateTodo,\n    onMutate: async (newTodo) => {\n      // Cancel outgoing refetches\n      await queryClient.cancelQueries({ queryKey: ['todos', newTodo.id] });\n\n      // Snapshot previous value\n      const previousTodo = queryClient.getQueryData(['todos', newTodo.id]);\n\n      // Optimistically update\n      queryClient.setQueryData(['todos', newTodo.id], newTodo);\n\n      // Return context for rollback\n      return { previousTodo };\n    },\n    onError: (err, newTodo, context) => {\n      // Rollback on error\n      queryClient.setQueryData(['todos', newTodo.id], context?.previousTodo);\n    },\n    onSettled: (data, error, variables) => {\n      // Always refetch after error or success\n      queryClient.invalidateQueries({ queryKey: ['todos', variables.id] });\n    },\n  });\n}\n```\n\n### 3. Prefetching Patterns\n\n```typescript\n// Prefetch on hover\nfunction UserLink({ userId }: { userId: string }) {\n  const queryClient = useQueryClient();\n\n  const prefetchUser = () => {\n    queryClient.prefetchQuery({\n      queryKey: ['user', userId],\n      queryFn: () => fetchUser(userId),\n      staleTime: 5 * 60 * 1000, // 5 minutes\n    });\n  };\n\n  return (\n    <Link to={`/users/${userId}`} onMouseEnter={prefetchUser}>\n      View User\n    </Link>\n  );\n}\n\n// Prefetch in loader (React Router)\nexport const loader = (queryClient: QueryClient) => async ({ params }) => {\n  await queryCl",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "task-dependency-patterns": {
    "name": "task-dependency-patterns",
    "description": "CC 2.1.16 Task Management patterns with TaskCreate, TaskUpdate, TaskGet, TaskList tools. Decompose complex work into trackable tasks with dependency chains. Use when managing multi-step implementations, coordinating parallel work, or tracking completion status.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "task-management",
      "dependencies",
      "orchestration",
      "cc-2.1.16",
      "workflow",
      "coordination"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "dependency-tracking.md",
        "multi-agent-coordination.md",
        "status-workflow.md"
      ],
      "scripts": [
        "task-tree-visualizer.py"
      ],
      "checklists": [
        "dependency-checklist.md",
        "task-design-checklist.md"
      ]
    },
    "content": "# Task Dependency Patterns\n\n## Overview\n\nClaude Code 2.1.16 introduces a native Task Management System with four tools:\n- **TaskCreate**: Create new tasks with subject, description, and activeForm\n- **TaskUpdate**: Update status (pending → in_progress → completed), set dependencies\n- **TaskGet**: Retrieve full task details including blockers\n- **TaskList**: View all tasks with status and dependency summary\n\nTasks enable structured work tracking, parallel coordination, and clear progress visibility.\n\n## When to Use\n\n- Breaking down complex multi-step implementations\n- Coordinating parallel work across multiple files\n- Tracking progress on large features\n- Managing dependencies between related changes\n- Providing visibility into work status\n\n## Key Patterns\n\n### 1. Task Decomposition\n\nBreak complex work into atomic, trackable units:\n\n```\nFeature: Add user authentication\n\nTasks:\n#1. [pending] Create User model\n#2. [pending] Add auth endpoints (blockedBy: #1)\n#3. [pending] Implement JWT tokens (blockedBy: #2)\n#4. [pending] Add auth middleware (blockedBy: #3)\n#5. [pending] Write integration tests (blockedBy: #4)\n```\n\n### 2. Dependency Chains\n\nUse `addBlockedBy` to create execution order:\n\n```json\n// Task #3 cannot start until #1 and #2 complete\n{\"taskId\": \"3\", \"addBlockedBy\": [\"1\", \"2\"]}\n```\n\n### 3. Status Workflow\n\n```\npending → in_progress → completed\n   ↓           ↓\n(unblocked)  (active)\n\npending/in_progress → deleted (CC 2.1.20)\n```\n\n- **pending**: Task created but not started\n- **in_progress**: Actively being worked on\n- **completed**: Work finished and verified\n- **deleted**: Task removed (CC 2.1.20) - permanently removes the task\n\n### Task Deletion (CC 2.1.20)\n\nCC 2.1.20 adds `status: \"deleted\"` to permanently remove tasks:\n\n```json\n// Delete a task\n{\"taskId\": \"3\", \"status\": \"deleted\"}\n```\n\n**When to delete:**\n- Orphaned tasks whose blockers have all failed\n- Tasks superseded by a different approach\n- Duplicate tasks created in error\n- Tasks from a cancelled pipeline\n\n**When NOT to delete:**\n- Tasks that might be retried later (keep as pending)\n- Tasks with useful history (mark completed instead)\n- Tasks blocked by in_progress work (wait for resolution)\n\n### 4. activeForm Pattern\n\nProvide present-continuous form for spinner display:\n\n| subject (imperative) | activeForm (continuous) |\n|---------------------|------------------------|\n| Run tests | Running tests |\n| Update schema | Updating schema |\n| Fix authentication | Fixing authentication |\n\n## Agent Teams (CC 2.1.33+)\n\nCC 2.1.33 introduces Agent Teams for multi-agent coordination with shared task lists and peer-to-peer messaging.\n\n### Team Workflow\n\n```\n1. TeamCreate(\"my-feature\")           → Creates team + shared task list\n2. TaskCreate(subject, description)    → Add tasks to shared list\n3. Task(prompt, team_name, name)       → Spawn teammates\n4. TaskUpdate(owner: \"teammate-name\")  → Assign tasks\n5. SendMessage(type: \"message\")        → Direct teammate communication\n6. SendMessage(type: \"s",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "backend-system-architect",
      "ci-cd-engineer",
      "data-pipeline-engineer",
      "database-engineer",
      "demo-producer",
      "deployment-manager",
      "event-driven-architect",
      "frontend-ui-developer",
      "git-operations-engineer",
      "infrastructure-architect",
      "llm-integrator",
      "monitoring-engineer",
      "multimodal-specialist",
      "performance-engineer",
      "prompt-engineer",
      "python-performance-engineer",
      "rapid-ui-designer",
      "release-engineer",
      "security-auditor",
      "test-generator",
      "workflow-architect"
    ]
  },
  "temporal-io": {
    "name": "temporal-io",
    "description": "Temporal.io workflow orchestration for durable, fault-tolerant distributed applications. Use when implementing long-running workflows, saga patterns, microservice orchestration, or systems requiring exactly-once execution guarantees.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "temporal",
      "workflow",
      "orchestration",
      "durable-execution",
      "saga",
      "microservices"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "workflow-architect",
    "structure": {
      "references": [
        "activity-best-practices.md",
        "signals-queries-updates.md",
        "versioning-strategies.md",
        "workflow-patterns.md"
      ],
      "scripts": [
        "saga-workflow-template.py",
        "scheduled-workflow-template.py",
        "temporal-worker-template.py"
      ],
      "checklists": [
        "production-deployment-checklist.md",
        "temporal-production-checklist.md",
        "workflow-design-checklist.md"
      ]
    },
    "content": "# Temporal.io Workflow Orchestration\n\nDurable execution engine for reliable distributed applications.\n\n## Overview\n\n- Long-running business processes (days/weeks/months)\n- Saga patterns requiring compensation/rollback\n- Microservice orchestration with retries\n- Systems requiring exactly-once execution guarantees\n- Complex state machines with human-in-the-loop\n- Scheduled and recurring workflows\n\n## Workflow Definition\n\n```python\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom datetime import timedelta\n\n@workflow.defn\nclass OrderWorkflow:\n    def __init__(self):\n        self._status = \"pending\"\n        self._order_id: str | None = None\n\n    @workflow.run\n    async def run(self, order_data: OrderInput) -> OrderResult:\n        self._order_id = await workflow.execute_activity(\n            create_order, order_data,\n            start_to_close_timeout=timedelta(seconds=30),\n            retry_policy=RetryPolicy(maximum_attempts=3, initial_interval=timedelta(seconds=1)),\n        )\n        self._status = \"processing\"\n\n        # Parallel activities\n        payment, inventory = await asyncio.gather(\n            workflow.execute_activity(process_payment, PaymentInput(order_id=self._order_id), start_to_close_timeout=timedelta(minutes=5)),\n            workflow.execute_activity(reserve_inventory, InventoryInput(order_id=self._order_id), start_to_close_timeout=timedelta(minutes=2)),\n        )\n\n        self._status = \"completed\"\n        return OrderResult(order_id=self._order_id, payment_id=payment.id)\n\n    @workflow.query\n    def get_status(self) -> str:\n        return self._status\n\n    @workflow.signal\n    async def cancel_order(self, reason: str):\n        self._status = \"cancelling\"\n        await workflow.execute_activity(cancel_order_activity, CancelInput(order_id=self._order_id), start_to_close_timeout=timedelta(seconds=30))\n        self._status = \"cancelled\"\n```\n\n## Activity Definition\n\n```python\nfrom temporalio import activity\nfrom temporalio.exceptions import ApplicationError\n\n@activity.defn\nasync def process_payment(input: PaymentInput) -> PaymentResult:\n    activity.logger.info(f\"Processing payment for order {input.order_id}\")\n    try:\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\"https://payments.example.com/charge\", json={\"order_id\": input.order_id, \"amount\": input.amount})\n            response.raise_for_status()\n            return PaymentResult(**response.json())\n    except httpx.HTTPStatusError as e:\n        if e.response.status_code == 402:\n            raise ApplicationError(\"Payment declined\", non_retryable=True, type=\"PaymentDeclined\")\n        raise\n\n@activity.defn\nasync def send_notification(input: NotificationInput) -> None:\n    for i, recipient in enumerate(input.recipients):\n        activity.heartbeat(f\"Sending {i+1}/{len(input.recipients)}\")  # For long operations\n        await send_email(recipient, input.subject, input.body)\n```\n\n## Worker and Client\n\n```python\nfrom",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "workflow-architect"
    ]
  },
  "terminal-demo-generator": {
    "name": "terminal-demo-generator",
    "description": "Terminal recording for demo videos. Use when recording CLI sessions with VHS or asciinema, simulating Claude Code output, or converting casts to MP4",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "demo",
      "video",
      "vhs",
      "asciinema",
      "terminal",
      "recording",
      "cli"
    ],
    "userInvocable": false,
    "context": "inherit",
    "allowedTools": [],
    "skills": [],
    "agent": null,
    "structure": {
      "references": [
        "asciinema-recording.md",
        "cc-simulation.md",
        "vhs-tape-format.md"
      ]
    },
    "content": "# Terminal Demo Generator\n\nTwo approaches for terminal demo recordings:\n\n| Method | Best For | Authenticity |\n|--------|----------|--------------|\n| **asciinema** | Real CC sessions, actual output | ⭐⭐⭐⭐⭐ |\n| **VHS scripts** | Controlled demos, reproducible | ⭐⭐⭐ |\n\n## Quick Start\n\n### Real Session (Recommended)\n```bash\n# Record actual Claude Code session\nasciinema rec --cols 120 --rows 35 -i 2 demo.cast\n\n# Convert to MP4 via VHS\nvhs << 'EOF'\nOutput demo.mp4\nSet Width 1400\nSet Height 800\nSource demo.cast\nEOF\n```\n\n### Scripted Demo\n```bash\n# Generate script via demo-producer\n./skills/demo-producer/scripts/generate.sh skill verify\n\n# Record with VHS\nvhs orchestkit-demos/tapes/sim-verify.tape\n```\n\n## Recording Methods\n\n### 1. Asciinema (Real Sessions)\n\nRecord actual Claude Code usage:\n\n```bash\n# Start recording\nasciinema rec \\\n  --cols 120 \\\n  --rows 35 \\\n  --idle-time-limit 2 \\\n  session.cast\n\n# Inside recording:\nclaude\n> /verify\n# ... real Claude output ...\n> exit\n```\n\nSee `references/asciinema-recording.md` for editing and conversion.\n\n### 2. VHS Scripts (Controlled)\n\nPre-scripted terminal simulations:\n\n```tape\nOutput demo.mp4\nSet Shell \"bash\"\nSet FontFamily \"Menlo\"\nSet FontSize 16\nSet Width 1400\nSet Height 800\nSet Theme \"Dracula\"\nSet Framerate 30\n\nType \"./demo-script.sh\"\nEnter\nSleep 15s\n```\n\n## Claude Code CLI Patterns\n\n### Status Bar (CC 2.1.16+)\n```\n[Opus 4.6] ████████░░ 42% | ~/project git:(main) | ● 3m\n✓ Bash ×3 | ✓ Read ×5 | ✓ Grep ×2 | ✓ Task ×∞\n>> bypass permissions on (shift+Tab to cycle)\n```\n\n### Task Management\n```\n◆ TaskCreate #1 \"Analyze codebase\"\n◆ TaskCreate #2 \"Security scan\"\n◆ TaskCreate #3 \"Generate report\" blockedBy: #1, #2\n◆ TaskUpdate: #1, #2 → in_progress (PARALLEL)\n✓ Task #1 completed\n✓ Task #2 completed\n◆ Task #3 unblocked (2/2 resolved)\n```\n\n### Agent Spawning\n```\n⚡ Spawning 6 parallel agents via Task tool\n  ▸ code-reviewer spawned\n  ▸ security-auditor spawned\n  ▸ test-generator spawned\n```\n\n## Color Codes\n\n```bash\nP=\"\\033[35m\"  # Purple - skills, agents\nC=\"\\033[36m\"  # Cyan - info, tasks\nG=\"\\033[32m\"  # Green - success\nY=\"\\033[33m\"  # Yellow - warnings, progress\nR=\"\\033[31m\"  # Red - errors\nD=\"\\033[90m\"  # Gray - dim/secondary\nB=\"\\033[1m\"   # Bold\nN=\"\\033[0m\"   # Reset\n```\n\n## Pipeline Integration\n\nTerminal recordings feed into the full demo pipeline:\n\n```\nterminal-demo-generator     →  demo-producer  →  remotion-composer\n(asciinema/VHS recording)      (orchestration)    (final composition)\n                                    ↓\n                            manim-visualizer\n                            (animations)\n```\n\n## Related Skills\n\n- `demo-producer`: Full pipeline orchestration that uses terminal recordings\n- `remotion-composer`: Combines terminal recordings with animations\n- `manim-visualizer`: Animated diagrams that complement terminal demos\n- `video-pacing`: Timing patterns for terminal output display\n\n## References\n\n- `references/asciinema-recording.md` - Real session recording\n- See `demo-producer` for full pipe",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": [
      "demo-producer"
    ]
  },
  "test-data-management": {
    "name": "test-data-management",
    "description": "Test data management with fixtures and factories. Use when creating test data strategies, implementing data factories, managing fixtures, or seeding test databases.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "fixtures",
      "factories",
      "data"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "factory-patterns.md"
      ],
      "scripts": [
        "factory-boy.py"
      ],
      "checklists": [
        "test-data-checklist.md"
      ]
    },
    "content": "# Test Data Management\n\nCreate and manage test data effectively.\n\n## Factory Pattern (Python)\n\n```python\nfrom factory import Factory, Faker, SubFactory, LazyAttribute\nfrom app.models import User, Analysis\n\nclass UserFactory(Factory):\n    class Meta:\n        model = User\n\n    email = Faker('email')\n    name = Faker('name')\n    created_at = Faker('date_time_this_year')\n\nclass AnalysisFactory(Factory):\n    class Meta:\n        model = Analysis\n\n    url = Faker('url')\n    status = 'pending'\n    user = SubFactory(UserFactory)\n\n    @LazyAttribute\n    def title(self):\n        return f\"Analysis of {self.url}\"\n\n# Usage\nuser = UserFactory()\nanalysis = AnalysisFactory(user=user, status='completed')\n```\n\n## Factory Pattern (TypeScript)\n\n```typescript\nimport { faker } from '@faker-js/faker';\n\ninterface User {\n  id: string;\n  email: string;\n  name: string;\n}\n\nconst createUser = (overrides: Partial<User> = {}): User => ({\n  id: faker.string.uuid(),\n  email: faker.internet.email(),\n  name: faker.person.fullName(),\n  ...overrides,\n});\n\nconst createAnalysis = (overrides = {}) => ({\n  id: faker.string.uuid(),\n  url: faker.internet.url(),\n  status: 'pending',\n  userId: createUser().id,\n  ...overrides,\n});\n\n// Usage\nconst user = createUser({ name: 'Test User' });\nconst analysis = createAnalysis({ userId: user.id, status: 'completed' });\n```\n\n## JSON Fixtures\n\n```json\n// fixtures/users.json\n{\n  \"admin\": {\n    \"id\": \"user-001\",\n    \"email\": \"admin@example.com\",\n    \"role\": \"admin\"\n  },\n  \"basic\": {\n    \"id\": \"user-002\",\n    \"email\": \"user@example.com\",\n    \"role\": \"user\"\n  }\n}\n```\n\n```python\nimport json\nimport pytest\n\n@pytest.fixture\ndef users():\n    with open('fixtures/users.json') as f:\n        return json.load(f)\n\ndef test_admin_access(users):\n    admin = users['admin']\n    assert admin['role'] == 'admin'\n```\n\n## Database Seeding\n\n```python\n# seeds/test_data.py\nasync def seed_test_database(db: AsyncSession):\n    \"\"\"Seed database with test data.\"\"\"\n    # Create users\n    users = [\n        UserFactory.build(email=f\"user{i}@test.com\")\n        for i in range(10)\n    ]\n    db.add_all(users)\n\n    # Create analyses for each user\n    for user in users:\n        analyses = [\n            AnalysisFactory.build(user_id=user.id)\n            for _ in range(5)\n        ]\n        db.add_all(analyses)\n\n    await db.commit()\n\n@pytest.fixture\nasync def seeded_db(db_session):\n    await seed_test_database(db_session)\n    yield db_session\n```\n\n## Fixture Composition\n\n```python\n@pytest.fixture\ndef user():\n    return UserFactory()\n\n@pytest.fixture\ndef user_with_analyses(user):\n    analyses = [AnalysisFactory(user=user) for _ in range(3)]\n    return {\"user\": user, \"analyses\": analyses}\n\n@pytest.fixture\ndef completed_workflow(user_with_analyses):\n    for analysis in user_with_analyses[\"analyses\"]:\n        analysis.status = \"completed\"\n    return user_with_analyses\n```\n\n## Test Data Isolation\n\n```python\n@pytest.fixture(autouse=True)\nasync def clean_database(db_session):\n    \"\"\"Reset database bet",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "test-standards-enforcer": {
    "name": "test-standards-enforcer",
    "description": "Enforce testing best practices - AAA pattern, naming conventions, isolation, coverage thresholds. Blocks non-compliant tests. Use when writing or reviewing tests.",
    "version": "1.0.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "testing",
      "quality",
      "enforcement",
      "blocking",
      "aaa-pattern",
      "coverage"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "naming-conventions.md"
      ]
    },
    "content": "Enforce 2026 testing best practices with **BLOCKING** validation.\n\n## Validation Rules\n\n### BLOCKING Rules (exit 1)\n\n| Rule | Check | Example Violation |\n|------|-------|-------------------|\n| **Test Location** | Tests must be in `tests/` or `__tests__/` | `src/utils/helper.test.ts` |\n| **AAA Pattern** | Tests must have Arrange/Act/Assert structure | No clear sections |\n| **Descriptive Names** | Test names must describe behavior | `test('test1')` |\n| **No Shared State** | Tests must not share mutable state | `let globalVar = []` without reset |\n| **Coverage Threshold** | Coverage must be ≥ 80% | 75% coverage |\n\n### File Location Rules\n\n```\nALLOWED:\n  tests/unit/user.test.ts\n  tests/integration/api.test.ts\n  __tests__/components/Button.test.tsx\n  app/tests/test_users.py\n  tests/conftest.py\n\nBLOCKED:\n  src/utils/helper.test.ts      # Tests in src/\n  components/Button.test.tsx    # Tests outside test dir\n  app/routers/test_routes.py    # Tests mixed with source\n```\n\n### Naming Conventions\n\n**TypeScript/JavaScript:**\n```typescript\n// GOOD - Descriptive, behavior-focused\ntest('should return empty array when no items exist', () => {})\ntest('throws ValidationError when email is invalid', () => {})\nit('renders loading spinner while fetching', () => {})\n\n// BLOCKED - Too short, not descriptive\ntest('test1', () => {})\ntest('works', () => {})\nit('test', () => {})\n```\n\n**Python:**\n```python\n# GOOD - snake_case, descriptive\ndef test_should_return_user_when_id_exists():\ndef test_raises_not_found_when_user_missing():\n\n# BLOCKED - Not descriptive, wrong case\ndef testUser():      # camelCase\ndef test_1():        # Not descriptive\n```\n\n## AAA Pattern (Required)\n\nEvery test must follow Arrange-Act-Assert:\n\n### TypeScript Example\n\n```typescript\ndescribe('calculateDiscount', () => {\n  test('should apply 10% discount for orders over $100', () => {\n    // Arrange\n    const order = createOrder({ total: 150 });\n    const calculator = new DiscountCalculator();\n\n    // Act\n    const discount = calculator.calculate(order);\n\n    // Assert\n    expect(discount).toBe(15);\n  });\n});\n```\n\n### Python Example\n\n```python\nclass TestCalculateDiscount:\n    def test_applies_10_percent_discount_over_threshold(self):\n        # Arrange\n        order = Order(total=150)\n        calculator = DiscountCalculator()\n\n        # Act\n        discount = calculator.calculate(order)\n\n        # Assert\n        assert discount == 15\n```\n\n## Test Isolation (Required)\n\nTests must not share mutable state:\n\n```typescript\n// BLOCKED - Shared mutable state\nlet items = [];\n\ntest('adds item', () => {\n  items.push('a');\n  expect(items).toHaveLength(1);\n});\n\ntest('removes item', () => {\n  // FAILS - items already has 'a' from previous test\n  expect(items).toHaveLength(0);\n});\n\n// GOOD - Reset state in beforeEach\ndescribe('ItemList', () => {\n  let items: string[];\n\n  beforeEach(() => {\n    items = []; // Fresh state each test\n  });\n\n  test('adds item', () => {\n    items.push('a');\n    expect(items).toHaveLength(1);\n",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer",
      "test-generator"
    ]
  },
  "thumbnail-first-frame": {
    "name": "thumbnail-first-frame",
    "description": "Thumbnail and first-frame optimization for CTR. Use when designing thumbnails, fixing frame-0 visibility issues, or optimizing for platform requirements",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "thumbnail",
      "first-frame",
      "ctr",
      "design",
      "marketing"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "first-frame-optimization.md",
        "platform-requirements.md",
        "thumbnail-formulas.md"
      ]
    },
    "content": "# Thumbnail and First-Frame Optimization\n\nMaximize click-through rates with proven thumbnail design formulas, text rules, and platform-specific optimization.\n\n## Core Principle: The 3-Second Test\n\nThumbnails must communicate value in under 3 seconds. Users scroll at 300+ items/hour.\n\n```\nATTENTION FUNNEL\n================\n\n  Scroll Speed: ~300 items/hour\n           |\n           v\n  +------------------+\n  |   THUMBNAIL      |  <-- 0.5s: Pattern interrupt (face/color)\n  |   VISIBLE        |\n  +------------------+\n           |\n           v\n  +------------------+\n  |   TEXT READ      |  <-- 1.0s: Value proposition (3-4 words)\n  +------------------+\n           |\n           v\n  +------------------+\n  |   CLICK          |  <-- 2.0s: Curiosity/benefit decision\n  |   DECISION       |\n  +------------------+\n```\n\n## Thumbnail Composition Formulas\n\n### Formula 1: Face + Text + Context\n\nThe most effective formula for tutorial/educational content.\n\n```\n+------------------------------------------+\n|                                          |\n|  +--------+                              |\n|  |        |     \"3 TRICKS               |\n|  |  FACE  |      YOU MISSED\"            |\n|  | (40%)  |                              |\n|  +--------+          +-------+           |\n|                      | ICON  |           |\n|                      +-------+           |\n|                                          |\n+------------------------------------------+\n     LEFT THIRD          RIGHT TWO-THIRDS\n```\n\n### Formula 2: Before/After Split\n\nEffective for transformation content, tutorials, comparisons.\n\n```\n+-------------------+-------------------+\n|                   |                   |\n|     BEFORE        |      AFTER        |\n|  - Muted colors   |  - Vibrant colors |\n|  - Problem state  |  - Solution state |\n|                   |                   |\n+-------------------+-------------------+\n```\n\n### Formula 3: Number + Benefit\n\nHigh-performing for listicles and how-to content.\n\n```\n+------------------------------------------+\n|     +-----+                              |\n|     | 7   |   \"MISTAKES\"                 |\n|     +-----+   \"KILLING YOUR CODE\"        |\n|    (large                                |\n|     number)    [relevant icon/visual]    |\n+------------------------------------------+\n```\n\n## Text Rules for Thumbnails\n\n### The 3-4 Word Maximum\n\n```\nGOOD                          BAD\n====                          ===\n\"FIX THIS NOW\"                \"Here's How To Fix This Common\n\"STOP DOING THIS\"              Problem That Many Developers\n\"10X FASTER\"                   Face When Building Apps\"\n```\n\n### High-Contrast Text Techniques\n\n```\nTECHNIQUE 1: Stroke/Outline\n+---------------------------+\n|  █ WHITE TEXT      █      |\n|  █ BLACK OUTLINE   █      |\n+---------------------------+\n\nTECHNIQUE 2: Background Bar\n+---------------------------+\n|  | DARK BAR        |      |\n|  | Light text here |      |\n+---------------------------+\n```\n\n## Color Psychology for CTR\n\n### Color Performan",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "type-safety-validation": {
    "name": "type-safety-validation",
    "description": "End-to-end type safety with Zod, tRPC, Prisma, and TypeScript 5.7+ patterns. Use when creating Zod schemas, setting up tRPC, validating input, implementing exhaustive switch statements, branded types, or type checking with ty.",
    "version": "1.1.0",
    "author": "AI Agent Hub",
    "tags": [
      "typescript",
      "zod",
      "trpc",
      "prisma",
      "type-safety",
      "validation",
      "exhaustive-types",
      "branded-types"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "prisma-types.md",
        "trpc-setup.md",
        "ty-type-checker-patterns.md",
        "typescript-5-features.md",
        "typescript-advanced.md",
        "zod-patterns.md"
      ],
      "scripts": [
        "trpc-router.ts",
        "zod-schema.ts"
      ],
      "checklists": [
        "type-safety-checklist.md"
      ]
    },
    "content": "# Type Safety & Validation\n\n## Overview\n\n**When to use this skill:**\n- Building type-safe APIs (REST, RPC, GraphQL)\n- Validating user input and external data\n- Ensuring database queries are type-safe\n- Creating end-to-end typed full-stack applications\n- Implementing strict validation rules\n\n## Core Stack Quick Reference\n\n| Tool | Purpose | Key Pattern |\n|------|---------|-------------|\n| **Zod** | Runtime validation | `z.object({}).safeParse(data)` |\n| **tRPC** | Type-safe APIs | `t.procedure.input(schema).query()` |\n| **Prisma** | Type-safe ORM | Auto-generated types from schema |\n| **TypeScript 5.7+** | Compile-time safety | `satisfies`, const params, decorators |\n\n## Zod Essentials\n\n```typescript\nimport { z } from 'zod'\n\n// Define schema\nconst UserSchema = z.object({\n  id: z.string().uuid(),\n  email: z.string().email(),\n  age: z.number().int().positive().max(120),\n  role: z.enum(['admin', 'user', 'guest']),\n  createdAt: z.date().default(() => new Date())\n})\n\n// Infer TypeScript type\ntype User = z.infer<typeof UserSchema>\n\n// Validate with error handling\nconst result = UserSchema.safeParse(data)\nif (result.success) {\n  const user: User = result.data\n} else {\n  console.error(result.error.issues)\n}\n```\n\n**See:** `references/zod-patterns.md` for transforms, refinements, discriminated unions, and recursive types.\n\n## tRPC Essentials\n\n```typescript\nimport { initTRPC } from '@trpc/server'\nimport { z } from 'zod'\n\nconst t = initTRPC.create()\n\nexport const appRouter = t.router({\n  getUser: t.procedure\n    .input(z.object({ id: z.string() }))\n    .query(async ({ input }) => {\n      return await db.user.findUnique({ where: { id: input.id } })\n    }),\n\n  createUser: t.procedure\n    .input(z.object({ email: z.string().email(), name: z.string() }))\n    .mutation(async ({ input }) => {\n      return await db.user.create({ data: input })\n    })\n})\n\nexport type AppRouter = typeof appRouter\n```\n\n**See:** `references/trpc-setup.md` for middleware, authentication, React integration, and error handling.\n\n## Exhaustive Type Checking\n\n```typescript\n// ALWAYS use assertNever for compile-time exhaustiveness\nfunction assertNever(x: never): never {\n  throw new Error(\"Unexpected value: \" + x)\n}\n\ntype Status = 'pending' | 'running' | 'completed' | 'failed'\n\nfunction getStatusColor(status: Status): string {\n  switch (status) {\n    case 'pending': return 'gray'\n    case 'running': return 'blue'\n    case 'completed': return 'green'\n    case 'failed': return 'red'\n    default: return assertNever(status) // Compile-time check!\n  }\n}\n\n// Exhaustive record mapping\nconst statusColors = {\n  pending: 'gray',\n  running: 'blue',\n  completed: 'green',\n  failed: 'red',\n} as const satisfies Record<Status, string>\n```\n\n**See:** `references/typescript-advanced.md` for handler objects, type guards, and anti-patterns.\n\n## Branded Types\n\n**TypeScript (with Zod):**\n```typescript\nconst UserId = z.string().uuid().brand<'UserId'>()\nconst AnalysisId = z.string().uuid().brand<'AnalysisId'>()\n\ntype ",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "unit-testing": {
    "name": "unit-testing",
    "description": "Unit testing patterns and best practices. Use when writing isolated unit tests, implementing AAA pattern, designing test isolation, or setting coverage targets for business logic.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "unit",
      "tdd",
      "coverage"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "aaa-pattern.md"
      ],
      "scripts": [
        "create-test-case.md",
        "create-test-fixture.md",
        "pytest-fixture.py",
        "test-case-template.md"
      ]
    },
    "content": "# Unit Testing\n\nTest isolated business logic with fast, deterministic tests.\n\n## AAA Pattern (Arrange-Act-Assert)\n\n```typescript\ndescribe('calculateDiscount', () => {\n  test('applies 10% discount for orders over $100', () => {\n    // Arrange\n    const order = { items: [{ price: 150 }] };\n\n    // Act\n    const result = calculateDiscount(order);\n\n    // Assert\n    expect(result).toBe(15);\n  });\n});\n```\n\n## Test Isolation\n\n```typescript\ndescribe('UserService', () => {\n  let service: UserService;\n  let mockRepo: MockRepository;\n\n  beforeEach(() => {\n    // Fresh instances per test\n    mockRepo = createMockRepository();\n    service = new UserService(mockRepo);\n  });\n\n  afterEach(() => {\n    // Clean up\n    vi.clearAllMocks();\n  });\n});\n```\n\n## Coverage Targets\n\n| Area | Target |\n|------|--------|\n| Business logic | 90%+ |\n| Critical paths | 100% |\n| New features | 100% |\n| Utilities | 80%+ |\n\n## Parameterized Tests\n\n```typescript\ndescribe('isValidEmail', () => {\n  test.each([\n    ['test@example.com', true],\n    ['invalid', false],\n    ['@missing.com', false],\n    ['user@domain.co.uk', true],\n  ])('isValidEmail(%s) returns %s', (email, expected) => {\n    expect(isValidEmail(email)).toBe(expected);\n  });\n});\n```\n\n## Python Example\n\n```python\nimport pytest\n\nclass TestCalculateDiscount:\n    def test_applies_discount_over_threshold(self):\n        # Arrange\n        order = Order(total=150)\n\n        # Act\n        discount = calculate_discount(order)\n\n        # Assert\n        assert discount == 15\n\n    @pytest.mark.parametrize(\"total,expected\", [\n        (100, 0),\n        (101, 10.1),\n        (200, 20),\n    ])\n    def test_discount_thresholds(self, total, expected):\n        order = Order(total=total)\n        assert calculate_discount(order) == expected\n```\n\n## Fixture Scoping (2026 Best Practice)\n\n```python\nimport pytest\n\n# Function scope (default): Fresh instance per test - ISOLATED\n@pytest.fixture(scope=\"function\")\ndef db_session():\n    \"\"\"Each test gets clean database state.\"\"\"\n    session = create_session()\n    yield session\n    session.rollback()  # Cleanup\n\n# Module scope: Shared across all tests in file - EFFICIENT\n@pytest.fixture(scope=\"module\")\ndef expensive_model():\n    \"\"\"Load once per test file (expensive setup).\"\"\"\n    return load_large_ml_model()  # 5 seconds to load\n\n# Session scope: Shared across ALL tests - MOST EFFICIENT\n@pytest.fixture(scope=\"session\")\ndef db_engine():\n    \"\"\"Single connection pool for entire test run.\"\"\"\n    engine = create_engine(TEST_DB_URL)\n    Base.metadata.create_all(engine)\n    yield engine\n    Base.metadata.drop_all(engine)\n```\n\n**When to use each scope:**\n| Scope | Use Case | Example |\n|-------|----------|---------|\n| function | Isolated tests, mutable state | db_session, mock objects |\n| module | Expensive setup, read-only | ML model, compiled regex |\n| session | Very expensive, immutable | DB engine, external service |\n\n## Indirect Parametrization\n\n```python\n# Defer expensive setup from collection to runtime\n@pyt",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer",
      "frontend-ui-developer",
      "test-generator"
    ]
  },
  "upgrade-assessment": {
    "name": "upgrade-assessment",
    "description": "Assess platform upgrade readiness for Claude model and CC version changes. Use when evaluating upgrades.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "upgrade",
      "assessment",
      "platform",
      "compatibility",
      "migration"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Read",
      "Grep",
      "Glob",
      "Task",
      "WebSearch",
      "WebFetch"
    ],
    "skills": [
      "platform-upgrade-knowledge",
      "explore",
      "verify",
      "remember",
      "memory"
    ],
    "agent": null,
    "structure": {},
    "content": "# Upgrade Assessment\n\nEvaluate platform upgrade readiness for Claude model transitions, Claude Code version bumps, and OrchestKit plugin updates. Produces a structured JSON assessment report with a 0-10 readiness score across 6 dimensions.\n\n## When to Use\n\n- Before upgrading the Claude model (e.g., Sonnet 4 to Opus 4.6)\n- Before upgrading Claude Code to a new major/minor version\n- Before upgrading OrchestKit to a new major version\n- When evaluating whether a team environment is ready for a platform change\n- As part of release planning for model or platform migrations\n\n## Quick Start\n\n```bash\n/ork:upgrade-assessment           # Interactive assessment\n/ork:upgrade-assessment --json    # Machine-readable output\n```\n\n---\n\n## 6-Phase Workflow\n\n### Phase 0: Scope Definition\n\n**Tool:** `AskUserQuestion`\n\nDetermine the assessment scope before scanning. Ask the user:\n\n> What type of upgrade are you assessing?\n> 1. **Full platform** - Model + CC version + OrchestKit (comprehensive)\n> 2. **Model only** - Switching Claude model (e.g., Sonnet 4.5 to Opus 4.6)\n> 3. **CC version only** - Claude Code version bump (e.g., 2.1.32 to 2.1.33)\n> 4. **OrchestKit only** - Plugin version upgrade (e.g., 5.x to 6.x)\n\nRecord the scope and target versions. If the user does not specify target versions, research the latest available in Phase 2.\n\n---\n\n### Phase 1: Detection\n\n**Tools:** `Bash`, `Read`, `Grep`, `Glob`\n\n#### Precondition Checks\n\nBefore scanning, verify the environment is assessable:\n\n```bash\n# Verify we're in an OrchestKit project\n[ -f CLAUDE.md ] || { echo \"ERROR: No CLAUDE.md found — not an OrchestKit project\"; exit 1; }\n[ -d src/skills ] || { echo \"ERROR: No src/skills/ directory\"; exit 1; }\n[ -d src/agents ] || { echo \"ERROR: No src/agents/ directory\"; exit 1; }\n[ -f src/hooks/hooks.json ] || { echo \"WARNING: No hooks.json — hook assessment will be skipped\"; }\n```\n\nIf any required directory is missing, abort with a clear error. If optional components (hooks) are missing, continue with reduced scope and note it in the report.\n\n#### Environment Detection\n\nDetect the current environment state:\n\n```bash\n# 1. Current Claude model\n# Check CLAUDE.md, settings, or environment for model references\ngrep -r \"claude-\" CLAUDE.md .claude/ 2>/dev/null | head -20\n\n# 2. Claude Code version\nclaude --version 2>/dev/null || echo \"CC version not detectable from CLI\"\n\n# 3. OrchestKit version\n# Check CLAUDE.md or package.json for version field\ngrep \"Current.*:\" CLAUDE.md | head -5\n\n# 4. Hooks configuration\ncat src/hooks/hooks.json | python3 -c \"import sys,json; d=json.load(sys.stdin); print(f'Hooks: {len(d.get(\\\"hooks\\\",[]))} entries')\" 2>/dev/null\n\n# 5. Skill and agent counts\nls src/skills/ | wc -l\nls src/agents/ | wc -l\n```\n\n**Output:** Environment snapshot including:\n- Current model ID (e.g., `claude-sonnet-4-5`)\n- Current CC version (e.g., `2.1.33`)\n- Current OrchestKit version (e.g., `6.0.0`)\n- Hook count and bundle count\n- Skill count and agent count\n\n---\n\n### Phase 2: Researc",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "user-research-methods": {
    "name": "user-research-methods",
    "description": "User interviews, usability testing, surveys, card sorting, and qualitative research methods. Use when gathering user insights, validating designs, or understanding user behavior.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "ux",
      "research",
      "interviews",
      "usability",
      "surveys",
      "card-sorting"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "ux-researcher",
    "structure": {
      "references": [
        "interview-guide-template.md"
      ],
      "assets": [
        "research-report-template.md"
      ],
      "checklists": [
        "research-study-checklist.md"
      ]
    },
    "content": "# User Research Methods\n\nMethods for understanding user needs, validating designs, and gathering actionable insights.\n\n## Research Methods Overview\n\n### Method Selection Matrix\n\n| Method | When to Use | Sample Size | Time | Output |\n|--------|-------------|-------------|------|--------|\n| User Interviews | Early discovery, deep understanding | 5-8 | 2-3 weeks | Qualitative insights |\n| Usability Testing | Validate designs, find issues | 5-10 | 1-2 weeks | Actionable fixes |\n| Surveys | Quantify attitudes, preferences | 100+ | 1-2 weeks | Statistical data |\n| Card Sorting | Information architecture | 15-30 | 1 week | IA recommendations |\n| Diary Studies | Longitudinal behavior | 10-15 | 2-4 weeks | Behavior patterns |\n| A/B Testing | Compare alternatives | 1000+ | 2-4 weeks | Statistical winner |\n\n### Qualitative vs. Quantitative\n\n```\nQualitative                              Quantitative\n(Why & How)                              (What & How Many)\n───────────────────────────────────────────────────────►\nInterviews  Focus    Usability  Surveys  Analytics  A/B\n            Groups   Testing                        Tests\n\nSmall sample                              Large sample\nRich insights                             Statistical confidence\nExploratory                               Validating\n```\n\n## User Interviews\n\n### Interview Planning\n\n```markdown\n## Interview Plan: [Project Name]\n\n### Research Questions\n1. What problem are we trying to understand?\n2. What decisions will this research inform?\n3. What do we already know/assume?\n\n### Participant Criteria\n- Must have: [Required characteristics]\n- Nice to have: [Preferred characteristics]\n- Exclude: [Disqualifying factors]\n\n### Recruitment\n- Target: 6-8 participants\n- Incentive: $[X] gift card\n- Channels: [How to recruit]\n\n### Interview Guide\n- Duration: 45-60 minutes\n- Format: Video call / In-person\n\n### Logistics\n- Researcher: [Name]\n- Note-taker: [Name]\n- Recording: [Consent process]\n```\n\n### Interview Structure\n\n```markdown\n## Interview Guide\n\n### Warm-up (5 min)\n- Introduction and consent\n- \"Tell me about your role and what you do day-to-day\"\n\n### Context Setting (10 min)\n- \"Walk me through the last time you [relevant activity]\"\n- \"What tools or methods do you currently use?\"\n\n### Deep Dive (25 min)\n- \"What's the hardest part about [task]?\"\n- \"Can you show me how you typically [action]?\"\n- \"What would your ideal solution look like?\"\n\n### Concept Testing (optional, 15 min)\n- Show prototype/concept\n- \"What are your initial reactions?\"\n- \"How would this fit into your workflow?\"\n\n### Wrap-up (5 min)\n- \"Is there anything else you'd like to share?\"\n- \"Who else should we talk to?\"\n- Thank you and incentive\n```\n\n### Interview Best Practices\n\n| Do | Don't |\n|----|-------|\n| Ask open-ended questions | Ask leading questions |\n| Listen more than talk | Interrupt or fill silences |\n| Follow interesting threads | Stick rigidly to script |\n| Ask \"why\" and \"how\" | Accept surface answers |\n| Take verbatim notes | Par",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "ux-researcher"
    ]
  },
  "vcr-http-recording": {
    "name": "vcr-http-recording",
    "description": "VCR.py HTTP recording for Python tests. Use when testing Python code making HTTP requests, recording API responses for replay, or creating deterministic tests for external services.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "testing",
      "http",
      "mocking",
      "vcr",
      "recording"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "scripts": [
        "vcr-cassette.py"
      ],
      "checklists": [
        "vcr-checklist.md"
      ]
    },
    "content": "# VCR.py HTTP Recording\n\nRecord and replay HTTP interactions for Python tests.\n\n## Basic Setup\n\n```python\n# conftest.py\nimport pytest\n\n@pytest.fixture(scope=\"module\")\ndef vcr_config():\n    return {\n        \"cassette_library_dir\": \"tests/cassettes\",\n        \"record_mode\": \"once\",\n        \"match_on\": [\"uri\", \"method\"],\n        \"filter_headers\": [\"authorization\", \"x-api-key\"],\n        \"filter_query_parameters\": [\"api_key\", \"token\"],\n    }\n```\n\n## Basic Usage\n\n```python\nimport pytest\n\n@pytest.mark.vcr()\ndef test_fetch_user():\n    response = requests.get(\"https://api.example.com/users/1\")\n\n    assert response.status_code == 200\n    assert response.json()[\"name\"] == \"John Doe\"\n\n@pytest.mark.vcr(\"custom_cassette.yaml\")\ndef test_with_custom_cassette():\n    response = requests.get(\"https://api.example.com/data\")\n    assert response.status_code == 200\n```\n\n## Async Support\n\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.mark.asyncio\n@pytest.mark.vcr()\nasync def test_async_api_call():\n    async with AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/data\")\n\n    assert response.status_code == 200\n    assert \"items\" in response.json()\n```\n\n## Recording Modes\n\n```python\n@pytest.fixture(scope=\"module\")\ndef vcr_config():\n    import os\n\n    # CI: never record, only replay\n    if os.environ.get(\"CI\"):\n        record_mode = \"none\"\n    else:\n        record_mode = \"new_episodes\"\n\n    return {\"record_mode\": record_mode}\n```\n\n| Mode | Behavior |\n|------|----------|\n| `once` | Record if missing, then replay |\n| `new_episodes` | Record new, replay existing |\n| `none` | Never record (CI) |\n| `all` | Always record (refresh) |\n\n## Filtering Sensitive Data\n\n```python\ndef filter_request_body(request):\n    \"\"\"Redact sensitive data from request body.\"\"\"\n    import json\n    if request.body:\n        try:\n            body = json.loads(request.body)\n            if \"password\" in body:\n                body[\"password\"] = \"REDACTED\"\n            if \"api_key\" in body:\n                body[\"api_key\"] = \"REDACTED\"\n            request.body = json.dumps(body)\n        except json.JSONDecodeError:\n            pass\n    return request\n\n@pytest.fixture(scope=\"module\")\ndef vcr_config():\n    return {\n        \"filter_headers\": [\"authorization\", \"x-api-key\"],\n        \"before_record_request\": filter_request_body,\n    }\n```\n\n## LLM API Testing\n\n```python\ndef llm_request_matcher(r1, r2):\n    \"\"\"Match LLM requests ignoring dynamic fields.\"\"\"\n    import json\n\n    if r1.uri != r2.uri or r1.method != r2.method:\n        return False\n\n    body1 = json.loads(r1.body)\n    body2 = json.loads(r2.body)\n\n    # Ignore dynamic fields\n    for field in [\"request_id\", \"timestamp\"]:\n        body1.pop(field, None)\n        body2.pop(field, None)\n\n    return body1 == body2\n\n@pytest.fixture(scope=\"module\")\ndef vcr_config():\n    return {\n        \"custom_matchers\": [llm_request_matcher],\n    }\n```\n\n## Cassette File Example\n\n```yaml\n# tests/cassettes/test_fetch_user.yaml\nintera",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "test-generator"
    ]
  },
  "verify": {
    "name": "verify",
    "description": "Comprehensive verification with parallel test agents. Use when verifying implementations or validating changes.",
    "version": "3.1.0",
    "author": "OrchestKit",
    "tags": [
      "verification",
      "testing",
      "quality",
      "validation",
      "parallel-agents",
      "grading"
    ],
    "userInvocable": true,
    "context": "fork",
    "allowedTools": [
      "AskUserQuestion",
      "Bash",
      "Read",
      "Write",
      "Edit",
      "Grep",
      "Glob",
      "Task",
      "TaskCreate",
      "TaskUpdate",
      "TaskList",
      "mcp__memory__search_nodes"
    ],
    "skills": [
      "code-review-playbook",
      "security-scanning",
      "evidence-verification",
      "run-tests",
      "unit-testing",
      "integration-testing",
      "memory",
      "quality-gates"
    ],
    "agent": null,
    "structure": {
      "references": [
        "alternative-comparison.md",
        "grading-rubric.md",
        "policy-as-code.md",
        "report-template.md",
        "verification-checklist.md"
      ],
      "assets": [
        "quality-policy.yaml",
        "verification-report.md"
      ],
      "checklists": [
        "verification-checklist.md"
      ]
    },
    "content": "# Verify Feature\n\nComprehensive verification using parallel specialized agents with nuanced grading (0-10 scale) and improvement suggestions.\n\n## Quick Start\n\n```bash\n/verify authentication flow\n/verify user profile feature\n/verify --scope=backend database migrations\n```\n\n> **Opus 4.6**: Agents use native adaptive thinking (no MCP sequential-thinking needed). Extended 128K output supports comprehensive verification reports.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify verification scope:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What scope for this verification?\",\n    \"header\": \"Scope\",\n    \"options\": [\n      {\"label\": \"Full verification (Recommended)\", \"description\": \"All tests + security + code quality + grades\"},\n      {\"label\": \"Tests only\", \"description\": \"Run unit + integration + e2e tests\"},\n      {\"label\": \"Security audit\", \"description\": \"Focus on security vulnerabilities\"},\n      {\"label\": \"Code quality\", \"description\": \"Lint, types, complexity analysis\"},\n      {\"label\": \"Quick check\", \"description\": \"Just run tests, skip detailed analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full verification**: All 8 phases, all 5 parallel agents\n- **Tests only**: Skip phases 2 (security), 5 (UI/UX analysis)\n- **Security audit**: Focus on security-auditor agent\n- **Code quality**: Focus on code-quality-reviewer agent\n- **Quick check**: Run tests only, skip grading and suggestions\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — verifiers share findings) or **Task tool** (star — all report to lead):\n\n1. `ORCHESTKIT_PREFER_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Full verification with cross-domain concerns → recommend **Agent Teams**; Single-scope verification → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Finding correlation | Lead cross-references scores | Agents discuss overlapping concerns |\n| Security + test overlap | Independent scoring | security-auditor alerts test-generator about gaps |\n| Cost | ~200K tokens | ~500K tokens |\n| Best for | Focused verification | Full-stack verification with 5 agents |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining verification.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main verification task\nTaskCreate(\n  subject=\"Verify [feature-name] implementation\",\n  description=\"Comprehensive verification with nuanced grading\",\n  activeForm=\"Verifying [feature-name] implementation\"\n)\n\n# Create subtasks for 8-phase process\nphases = [\"Run code quality checks\", \"Execute security audit\",\n          \"Verify test coverage\", \"Validate API\", \"Check UI/UX\",\n          \"Calculate grades\", \"Generate suggestions\", \"Compile report\"]\nfor phase in phases:\n    TaskCreate(subject=phase, activeForm=f\"{phase}ing\")\n```\n\n---\n\n## Workflow Over",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": []
  },
  "video-pacing": {
    "name": "video-pacing",
    "description": "Video rhythm and timing for maximum engagement. Use when planning cut frequency, optimizing retention, or adapting pacing for different platforms",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "pacing",
      "rhythm",
      "editing",
      "attention",
      "engagement"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "attention-curves.md",
        "platform-pacing-rules.md",
        "rhythm-patterns.md"
      ]
    },
    "content": "# Video Pacing\n\nComprehensive guide to video rhythm, timing, and pacing for maximum viewer engagement across platforms.\n\n## Core Principle\n\n**Pacing = Information Density x Visual Change Rate**\n\nThe optimal pace balances cognitive load with visual stimulation. Too fast overwhelms; too slow loses attention.\n\n## Attention Curve Theory\n\n```\nEngagement\n    |\n100%|●━━━━━━━━━━●\n    |          ╲\n 80%|           ╲━━━━━━━━━━━━━━●\n    |                          ╲\n 60%|                           ╲━━━━━━●\n    |                                  ╲\n 40%|                                   ╲━━━━━━●\n    |                                          ╲\n 20%|                                           ╲━━━●\n    |\n  0%└────────────────────────────────────────────────▶\n    0s   3s   10s   30s   60s   90s   120s   180s\n              Time in Video\n\n■ Critical retention points:\n  • 0-3s: Hook (lose 33% without strong hook)\n  • 10s: First major drop-off\n  • 30s: Platform algorithm threshold\n  • 60s: Half-time engagement check\n```\n\n## Platform-Specific Pacing Rules\n\n| Platform | Optimal Cut Rate | Avg. Shot Duration | Hook Window | Sweet Spot Length |\n|----------|------------------|-------------------|-------------|-------------------|\n| TikTok   | 20-40 cuts/min   | 1.5-3 seconds     | 0.5 seconds | 15-30 seconds     |\n| Reels    | 15-30 cuts/min   | 2-4 seconds       | 1 second    | 30-60 seconds     |\n| YouTube Shorts | 15-25 cuts/min | 2-4 seconds    | 1.5 seconds | 30-60 seconds     |\n| YouTube Long | 8-15 cuts/min  | 4-8 seconds       | 5 seconds   | 8-15 minutes      |\n| LinkedIn | 5-10 cuts/min    | 6-12 seconds      | 3 seconds   | 60-90 seconds     |\n| Twitter/X | 15-25 cuts/min  | 2-4 seconds       | 1 second    | 15-45 seconds     |\n\n## Cut Frequency Patterns\n\n### High-Energy Pattern (TikTok, Reels)\n```\nTime:    |0s     |1.5s   |3s     |4.5s   |6s     |7.5s   |9s\nCuts:    ●━━━━━━━●━━━━━━━●━━━━━━━●━━━━━━━●━━━━━━━●━━━━━━━●\nEnergy:  [HIGH]  [HIGH]  [PEAK]  [HIGH]  [PEAK]  [HIGH]  [END]\n```\n\n### Building Tension Pattern\n```\nTime:    |0s       |4s       |7s      |9s     |10s   |10.5s |11s\nCuts:    ●━━━━━━━━━●━━━━━━━━━●━━━━━━━●━━━━━━●━━━━━●━━━━━●━━━▶\nSpeed:   [SLOW]    [MEDIUM]  [FAST]  [FASTER] [RAPID] [PEAK]\n```\n\n### Breathe Pattern (Documentary/Educational)\n```\nTime:    |0s       |8s       |16s       |20s     |28s      |36s\nCuts:    ●━━━━━━━━━●━━━━━━━━━●━━━━━━━━━━●━━━━━━━●━━━━━━━━━●\nRhythm:  [INTRO]   [DEVELOP]  [BREATHE]  [BUILD] [DEVELOP] [LAND]\n```\n\n## The 3-Second Rule\n\nEvery 3 seconds, provide ONE of:\n- New visual information (cut, motion, transition)\n- New audio information (voice change, sound effect, music shift)\n- New text information (caption, graphic, lower third)\n\n```\n0s        3s        6s        9s        12s\n|━━━━━━━━━|━━━━━━━━━|━━━━━━━━━|━━━━━━━━━|\n[CUT]     [TEXT]    [SFX]     [CUT]     [MUSIC]\n```\n\n## Rhythm Patterns\n\n### 1. Heartbeat Rhythm\nMimics natural pulse: strong-weak-strong-weak\n```\nBeat:     |●     |○     |●     |○     |●     |○\nTiming:   |0s",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "video-storyboarding": {
    "name": "video-storyboarding",
    "description": "Pre-production planning for tech demo videos. Use when planning scenes, structuring narrative flow, or applying AIDA framework to video content",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "video",
      "storyboard",
      "pre-production",
      "planning",
      "narrative",
      "remotion"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "demo-producer",
    "structure": {
      "references": [
        "aida-framework.md",
        "pre-production-checklist.md",
        "scene-templates.md"
      ]
    },
    "content": "# Video Storyboarding for Tech Demos\n\nPre-production planning system for creating compelling tech demo videos. Combines the AIDA marketing framework with structured scene planning.\n\n## Overview\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                    VIDEO PRODUCTION PIPELINE                     │\n├─────────────────────────────────────────────────────────────────┤\n│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐     │\n│  │ CONCEPT  │──▶│STORYBOARD│──▶│  ASSETS  │──▶│  RENDER  │     │\n│  │          │   │          │   │          │   │          │     │\n│  │ • AIDA   │   │ • Scenes │   │ • Code   │   │ • Export │     │\n│  │ • Hook   │   │ • Timing │   │ • B-roll │   │ • Review │     │\n│  │ • CTA    │   │ • Shots  │   │ • Audio  │   │ • Publish│     │\n│  └──────────┘   └──────────┘   └──────────┘   └──────────┘     │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n## AIDA Framework for Tech Demos\n\nThe AIDA framework structures your video to guide viewers from awareness to action.\n\n### Framework Timeline\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                         AIDA TIMELINE                            │\n├─────────────────────────────────────────────────────────────────┤\n│  0s              15s              45s              75s    90s   │\n│  │───────────────│────────────────│────────────────│──────│    │\n│  │   ATTENTION   │    INTEREST    │     DESIRE     │ACTION│    │\n│  │    (15%)      │     (35%)      │     (35%)      │(15%) │    │\n│                                                                  │\n│  Emotion: Curious   Engaged        Convinced        Motivated   │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Phase Summary\n\n| Phase | Duration | Goal | Content |\n|-------|----------|------|---------|\n| **A - Attention** | 10-15s | Stop the scroll | Bold claim, visual impact, pattern interrupt |\n| **I - Interest** | 30-40s | Demonstrate value | Problem setup, solution intro, feature highlights |\n| **D - Desire** | 30-40s | Build connection | Benefits, social proof, differentiation |\n| **A - Action** | 10-15s | Drive conversion | Clear CTA, next steps, closing |\n\n### Anti-Patterns to Avoid\n\n```\n❌ Logo animations (skip these)\n❌ Slow fade-ins\n❌ Generic stock footage\n❌ Reading from slides\n```\n\n## Scene Planning Template\n\n```yaml\n# scene-001-hook.yaml\nscene:\n  id: \"001\"\n  name: \"Hook\"\n  phase: \"attention\"\n\ntiming:\n  start: \"00:00\"\n  duration: \"00:08\"\n  end: \"00:08\"\n\ncontent:\n  narration: |\n    What if you could give Claude Code\n    the memory of a senior developer?\n\n  on_screen_text:\n    - text: \"199 Skills\"\n      animation: \"scale-in\"\n      timing: \"0:02-0:04\"\n\nvisuals:\n  background: \"dark gradient\"\n  main_element: \"animated skill icons\"\n\ntransitions:\n  in: \"cut\"\n  out: \"fade\"\n\nassets_required:\n  - \"skill-icons-spritesheet.png\"\n  - \"claude-logo.svg\"\n```\n\n## Timing Calculations\n\n### Video Length Guidelines\n\n| Pla",
    "contentTruncated": true,
    "plugins": [
      "ork-creative",
      "ork"
    ],
    "relatedAgents": []
  },
  "view-transitions": {
    "name": "view-transitions",
    "description": "View Transitions API for smooth page transitions, shared element animations, and SPA/MPA navigation in React applications. Use when adding view transitions or page animations.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "view-transitions",
      "page-transition",
      "shared-element",
      "navigation",
      "react-router",
      "animation",
      "spa",
      "mpa"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "react-router-integration.md"
      ],
      "scripts": [
        "view-transition-wrapper.tsx"
      ]
    },
    "content": "# View Transitions\n\nThe View Transitions API provides smooth, native transitions between different views in web applications. Supported in Chrome 126+ and Safari 18.2+.\n\n## Overview\n\n- Page navigation transitions in SPAs\n- Cross-document (MPA) transitions\n- Shared element animations (image galleries, cards)\n- Modal-to-page transitions\n- List item to detail view animations\n- Tab switching with smooth transitions\n\n## Core Patterns\n\n### 1. React Router 7.x Integration (Simplest)\n\n```tsx\nimport { Link, NavLink, Form } from 'react-router';\n\n// Enable view transitions on links\n<Link to=\"/about\" viewTransition>\n  About\n</Link>\n\n// NavLink with viewTransition\n<NavLink to=\"/dashboard\" viewTransition>\n  Dashboard\n</NavLink>\n\n// Form with viewTransition\n<Form method=\"post\" viewTransition>\n  <button type=\"submit\">Save</button>\n</Form>\n```\n\n### 2. useViewTransitionState Hook\n\n```tsx\nimport { useViewTransitionState, Link } from 'react-router';\n\nfunction ProductCard({ product }: { product: Product }) {\n  const isTransitioning = useViewTransitionState(`/products/${product.id}`);\n\n  return (\n    <Link to={`/products/${product.id}`} viewTransition>\n      <img\n        src={product.image}\n        alt={product.name}\n        style={{\n          viewTransitionName: isTransitioning ? 'product-image' : undefined,\n        }}\n      />\n    </Link>\n  );\n}\n\n// On detail page, match the transition name\nfunction ProductDetail({ product }: { product: Product }) {\n  return (\n    <img\n      src={product.image}\n      alt={product.name}\n      style={{ viewTransitionName: 'product-image' }}\n    />\n  );\n}\n```\n\n### 3. Manual startViewTransition (SPA)\n\n```tsx\nfunction navigateWithTransition(navigate: NavigateFunction, to: string) {\n  if (!document.startViewTransition) {\n    navigate(to);\n    return;\n  }\n\n  document.startViewTransition(() => {\n    navigate(to);\n  });\n}\n\n// With React state updates\nfunction handleTabChange(newTab: string) {\n  if (!document.startViewTransition) {\n    setActiveTab(newTab);\n    return;\n  }\n\n  document.startViewTransition(() => {\n    ReactDOM.flushSync(() => {\n      setActiveTab(newTab);\n    });\n  });\n}\n```\n\n### 4. Cross-Document Transitions (MPA)\n\n```css\n/* Enable in both source and target documents */\n@view-transition {\n  navigation: auto;\n}\n\n/* Customize the transition */\n::view-transition-old(root) {\n  animation: fade-out 0.3s ease-out;\n}\n\n::view-transition-new(root) {\n  animation: fade-in 0.3s ease-in;\n}\n\n@keyframes fade-out {\n  from { opacity: 1; }\n  to { opacity: 0; }\n}\n\n@keyframes fade-in {\n  from { opacity: 0; }\n  to { opacity: 1; }\n}\n```\n\n### 5. Shared Element Transitions\n\n```tsx\n// Source page (list)\nfunction ImageGallery({ images }: { images: Image[] }) {\n  return (\n    <div className=\"grid grid-cols-3 gap-4\">\n      {images.map((image) => (\n        <Link\n          key={image.id}\n          to={`/image/${image.id}`}\n          viewTransition\n        >\n          <img\n            src={image.thumbnail}\n            alt={image.alt}\n            style={{ vie",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  },
  "vision-language-models": {
    "name": "vision-language-models",
    "description": "GPT-5/4o, Claude 4.5, Gemini 2.5/3, Grok 4 vision patterns for image analysis, document understanding, and visual QA. Use when implementing image captioning, document/chart analysis, or multi-image comparison.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "vision",
      "multimodal",
      "image",
      "gpt-5",
      "claude-4",
      "gemini",
      "grok",
      "vlm"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "multimodal-specialist",
    "structure": {
      "references": [
        "cost-optimization.md",
        "document-vision.md",
        "image-captioning.md"
      ],
      "checklists": [
        "implementation.md"
      ]
    },
    "content": "# Vision Language Models ()\n\nIntegrate vision capabilities from leading multimodal models for image understanding, document analysis, and visual reasoning.\n\n## Overview\n\n- Image captioning and description generation\n- Visual question answering (VQA)\n- Document/chart/diagram analysis with OCR\n- Multi-image comparison and reasoning\n- Bounding box detection and region analysis\n- Video frame analysis\n\n## Model Comparison (January )\n\n| Model | Context | Strengths | Vision Input |\n|-------|---------|-----------|--------------|\n| **GPT-5.2** | 128K | Best general reasoning, multimodal | Up to 10 images |\n| **Claude Opus 4.6** | 1M | Best coding, sustained agent tasks, adaptive thinking | Up to 100 images |\n| **Gemini 2.5 Pro** | 1M+ | Longest context, video analysis | 3,600 images max |\n| **Gemini 3 Pro** | 1M | Deep Think, 100% AIME 2025 | Enhanced segmentation |\n| **Grok 4** | 2M | Real-time X integration, DeepSearch | Images + upcoming video |\n\n## Image Input Methods\n\n### Base64 Encoding (All Providers)\n\n```python\nimport base64\nimport mimetypes\n\ndef encode_image_base64(image_path: str) -> tuple[str, str]:\n    \"\"\"Encode local image to base64 with MIME type.\"\"\"\n    mime_type, _ = mimetypes.guess_type(image_path)\n    mime_type = mime_type or \"image/png\"\n\n    with open(image_path, \"rb\") as f:\n        base64_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n\n    return base64_data, mime_type\n```\n\n### OpenAI GPT-5/4o Vision\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ndef analyze_image_openai(image_path: str, prompt: str) -> str:\n    \"\"\"Analyze image using GPT-5 or GPT-4o.\"\"\"\n    base64_data, mime_type = encode_image_base64(image_path)\n\n    response = client.chat.completions.create(\n        model=\"gpt-5.2\",  # or \"gpt-4.1\" for cost optimization\n        messages=[{\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": prompt},\n                {\"type\": \"image_url\", \"image_url\": {\n                    \"url\": f\"data:{mime_type};base64,{base64_data}\",\n                    \"detail\": \"high\"  # low, high, or auto\n                }}\n            ]\n        }],\n        max_tokens=4096  # Required for vision\n    )\n    return response.choices[0].message.content\n```\n\n### Claude 4.5 Vision (Anthropic)\n\n```python\nimport anthropic\n\nclient = anthropic.Anthropic()\n\ndef analyze_image_claude(image_path: str, prompt: str) -> str:\n    \"\"\"Analyze image using Claude Opus 4.6 or Sonnet 4.5.\"\"\"\n    base64_data, media_type = encode_image_base64(image_path)\n\n    response = client.messages.create(\n        model=\"claude-opus-4-6\",  # or claude-sonnet-4-5\n        max_tokens=4096,\n        messages=[{\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": media_type,\n                        \"data\": base64_data\n                    }\n                },\n                {\"ty",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "multimodal-specialist"
    ]
  },
  "vite-advanced": {
    "name": "vite-advanced",
    "description": "Advanced Vite 7+ patterns including Environment API, plugin development, SSR configuration, library mode, and build optimization. Use when customizing build pipelines, creating plugins, or configuring multi-environment builds.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "vite",
      "build",
      "bundler",
      "plugins",
      "ssr",
      "library-mode",
      "environment-api",
      "optimization"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "chunk-optimization.md",
        "environment-api.md",
        "library-mode.md",
        "plugin-development.md",
        "ssr-configuration.md"
      ],
      "scripts": [
        "custom-plugin.ts",
        "library-config.ts",
        "multi-environment-config.ts"
      ],
      "checklists": [
        "production-build.md"
      ]
    },
    "content": "# Vite Advanced Patterns\n\nAdvanced configuration for Vite 7+ including Environment API.\n\n## Vite 7 Environment API (Key 2026 Feature)\n\nMulti-environment support is now first-class:\n\n```typescript\nimport { defineConfig } from 'vite'\n\nexport default defineConfig({\n  environments: {\n    // Browser client\n    client: {\n      build: {\n        outDir: 'dist/client',\n        manifest: true,\n      },\n    },\n    // Node.js SSR\n    ssr: {\n      build: {\n        outDir: 'dist/server',\n        target: 'node20',\n      },\n    },\n    // Edge runtime (Cloudflare, etc.)\n    edge: {\n      resolve: {\n        noExternal: true,\n        conditions: ['edge', 'worker'],\n      },\n      build: {\n        outDir: 'dist/edge',\n      },\n    },\n  },\n})\n```\n\n**Key Changes:**\n- Environments have their own module graph\n- Plugins access `this.environment` in hooks\n- `createBuilder` API for coordinated builds\n- Node.js 20.19+ or 22.12+ required\n\n## Plugin Development\n\nBasic plugin structure:\n\n```typescript\nexport function myPlugin(): Plugin {\n  return {\n    name: 'my-plugin',\n\n    // Called once when config is resolved\n    configResolved(config) {\n      // Access resolved config\n    },\n\n    // Transform individual modules\n    transform(code, id) {\n      // this.environment available in Vite 7+\n      if (id.endsWith('.special')) {\n        return { code: transformCode(code) }\n      }\n    },\n\n    // Virtual modules\n    resolveId(id) {\n      if (id === 'virtual:my-module') {\n        return '\\0virtual:my-module'\n      }\n    },\n    load(id) {\n      if (id === '\\0virtual:my-module') {\n        return 'export const value = \"generated\"'\n      }\n    },\n  }\n}\n```\n\n## SSR Configuration\n\nDevelopment (middleware mode):\n\n```typescript\nimport { createServer } from 'vite'\n\nconst vite = await createServer({\n  server: { middlewareMode: true },\n  appType: 'custom',\n})\n\napp.use('*', async (req, res) => {\n  const url = req.originalUrl\n  let template = fs.readFileSync('index.html', 'utf-8')\n  template = await vite.transformIndexHtml(url, template)\n\n  const { render } = await vite.ssrLoadModule('/src/entry-server.tsx')\n  const html = template.replace('<!--outlet-->', await render(url))\n\n  res.send(html)\n})\n```\n\nProduction build scripts:\n\n```json\n{\n  \"scripts\": {\n    \"build:client\": \"vite build --outDir dist/client\",\n    \"build:server\": \"vite build --outDir dist/server --ssr src/entry-server.tsx\"\n  }\n}\n```\n\n## Build Optimization\n\n```typescript\nexport default defineConfig({\n  build: {\n    target: 'baseline-widely-available', // Vite 7 default\n    sourcemap: false,\n    rollupOptions: {\n      output: {\n        manualChunks: {\n          vendor: ['react', 'react-dom'],\n          router: ['react-router-dom'],\n        },\n      },\n    },\n  },\n})\n```\n\n## Quick Reference\n\n| Feature | Vite 7 Status |\n|---------|---------------|\n| Environment API | Stable |\n| ESM-only distribution | Default |\n| Node.js requirement | 20.19+ or 22.12+ |\n| `buildApp` hook | New for plugins |\n| `createBuilder` | Multi-env builds |\n\n## Vite",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "ci-cd-engineer",
      "frontend-ui-developer",
      "performance-engineer"
    ]
  },
  "wcag-compliance": {
    "name": "wcag-compliance",
    "description": "WCAG 2.2 AA accessibility compliance patterns for web applications. Use when auditing accessibility or implementing WCAG requirements.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "accessibility",
      "wcag",
      "a11y",
      "aria",
      "screen-reader",
      "compliance"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob",
      "Bash"
    ],
    "skills": [],
    "agent": "accessibility-specialist",
    "structure": {
      "references": [
        "wcag-criteria.md"
      ],
      "scripts": [
        "accessible-form-template.tsx"
      ],
      "checklists": [
        "wcag-checklist.md"
      ]
    },
    "content": "# WCAG Compliance\n\nWeb Content Accessibility Guidelines 2.2 AA implementation for inclusive, legally compliant web applications.\n\n## Overview\n\n- Building accessible UI components from scratch\n- Auditing applications for ADA/Section 508 compliance\n- Implementing keyboard navigation and focus management\n- Supporting screen readers and assistive technologies\n- Fixing color contrast and visual accessibility issues\n\n## Quick Reference\n\n### Semantic HTML Structure\n```tsx\n<main>\n  <article>\n    <header><h1>Page Title</h1></header>\n    <section aria-labelledby=\"features-heading\">\n      <h2 id=\"features-heading\">Features</h2>\n      <ul><li>Feature 1</li></ul>\n    </section>\n    <aside aria-label=\"Related content\">...</aside>\n  </article>\n</main>\n```\n\n### ARIA Labels and States\n```tsx\n// Icon-only button\n<button aria-label=\"Save document\">\n  <svg aria-hidden=\"true\">...</svg>\n</button>\n\n// Form field with error\n<input\n  id=\"email\"\n  aria-required=\"true\"\n  aria-invalid={!!error}\n  aria-describedby={error ? \"email-error\" : \"email-hint\"}\n/>\n{error && <p id=\"email-error\" role=\"alert\">{error}</p>}\n```\n\n### Color Contrast (CSS)\n```css\n:root {\n  --text-primary: #1a1a1a;   /* 16.1:1 on white - normal text */\n  --text-secondary: #595959; /* 7.0:1 on white - secondary */\n  --focus-ring: #0052cc;     /* 7.3:1 - focus indicator */\n}\n:focus-visible {\n  outline: 3px solid var(--focus-ring);\n  outline-offset: 2px;\n}\n```\n\n## WCAG 2.2 AA Checklist\n\n| Criterion | Requirement | Test |\n|-----------|-------------|------|\n| 1.1.1 Non-text | Alt text for images | axe-core scan |\n| 1.3.1 Info | Semantic HTML, headings | Manual + automated |\n| 1.4.3 Contrast | 4.5:1 text, 3:1 large | WebAIM checker |\n| 1.4.11 Non-text Contrast | 3:1 UI components | Manual inspection |\n| 2.1.1 Keyboard | All functionality via keyboard | Tab through |\n| 2.4.3 Focus Order | Logical tab sequence | Manual test |\n| 2.4.7 Focus Visible | Clear focus indicator | Visual check |\n| 2.4.11 Focus Not Obscured | Focus not hidden by sticky elements | scroll-margin-top |\n| 2.5.7 Dragging | Single-pointer alternative | Button fallback |\n| 2.5.8 Target Size | Min 24x24px interactive | CSS audit |\n| 4.1.2 Name/Role/Value | Proper ARIA, labels | Screen reader test |\n\n## Key Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Conformance level | WCAG 2.2 AA | Legal standard (ADA, Section 508) |\n| Contrast ratio | 4.5:1 normal, 3:1 large | AA minimum requirement |\n| Target size | 24px min, 44px touch | 2.5.8 + mobile usability |\n| Focus indicator | 3px solid outline | High visibility, 3:1 contrast |\n| Live regions | polite default, assertive for errors | Avoids interruption |\n| Decorative images | alt=\"\" role=\"presentation\" | Hide from AT |\n| Skip link | First focusable element | Keyboard user efficiency |\n\n## Anti-Patterns (FORBIDDEN)\n\n- **Div soup**: Using `<div>` instead of semantic elements (`<nav>`, `<main>`, `<article>`)\n- **Color-only information**: Status indicated only by color with",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "accessibility-specialist",
      "frontend-ui-developer"
    ]
  },
  "web-research-workflow": {
    "name": "web-research-workflow",
    "description": "Unified decision tree for web research. Auto-selects WebFetch, Tavily, or agent-browser based on target site characteristics and available API keys. Use when researching web content, scraping, extracting raw markdown, or capturing documentation.",
    "version": "1.2.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "research",
      "browser",
      "webfetch",
      "tavily",
      "automation",
      "scraping",
      "content-extraction"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Bash",
      "Read",
      "Write",
      "WebFetch"
    ],
    "skills": [],
    "agent": "web-research-analyst",
    "structure": {},
    "content": "# Web Research Workflow\n\nUnified approach for web content research that automatically selects the right tool for each situation.\n\n## Quick Decision Tree\n\n```\nURL to research\n     │\n     ▼\n┌─────────────────┐\n│ 1. Try WebFetch │ ← Fast, free, no overhead\n│    (always try) │\n└─────────────────┘\n     │\nContent OK? ──Yes──► Parse and return\n     │\n     No (empty/partial/<500 chars)\n     │\n     ▼\n┌───────────────────────┐\n│ 2. TAVILY_API_KEY set?│\n└───────────────────────┘\n     │          │\n    Yes         No ──► Skip to step 3\n     │\n     ▼\n┌───────────────────────────┐\n│ Tavily search/extract/    │ ← Raw markdown, batch URLs\n│ crawl/research            │\n└───────────────────────────┘\n     │\nContent OK? ──Yes──► Parse and return\n     │\n     No (JS-rendered/auth-required)\n     │\n     ▼\n┌─────────────────────┐\n│ 3. Use agent-browser │ ← Full browser, last resort\n└─────────────────────┘\n     │\n├─ SPA (react/vue/angular) ──► wait --load networkidle\n├─ Login required ──► auth flow + state save\n├─ Dynamic content ──► wait --text \"Expected\"\n└─ Multi-page ──► crawl pattern\n```\n\n## Tavily Enhanced Research\n\nWhen `TAVILY_API_KEY` is set, Tavily provides a powerful middle tier between WebFetch and agent-browser. It returns raw markdown content, supports batch URL extraction, and offers semantic search with relevance scoring.\n\n**When to use Tavily over WebFetch:**\n- WebFetch returned <500 chars (likely incomplete)\n- You need raw markdown content (not Haiku-summarized)\n- Batch extracting content from multiple URLs\n- Semantic search with relevance scoring\n- Site discovery/crawling (map API)\n\n**When to skip Tavily and go to agent-browser:**\n- Content requires JavaScript rendering (SPAs)\n- Authentication/login is required\n- Interactive elements need clicking\n- Content is behind CAPTCHAs\n\n### Tavily Search (Semantic Web Search)\n\nReturns relevance-scored results with raw markdown content:\n\n```bash\ncurl -s -X POST 'https://api.tavily.com/search' \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: Bearer $TAVILY_API_KEY\" \\\n  -d '{\n    \"query\": \"your search query\",\n    \"search_depth\": \"advanced\",\n    \"max_results\": 5,\n    \"include_raw_content\": \"markdown\"\n  }' | python3 -m json.tool\n```\n\nOptions:\n- `search_depth`: `\"basic\"` (fast) or `\"advanced\"` (thorough, 2x cost)\n- `topic`: `\"general\"` (default) or `\"news\"` or `\"finance\"`\n- `include_domains`: `[\"example.com\"]` — restrict to specific sites\n- `exclude_domains`: `[\"reddit.com\"]` — filter out sites\n- `days`: `3` — limit to recent results (news/finance)\n- `include_raw_content`: `\"markdown\"` — get full page content\n\n### Tavily Extract (Batch URL Content)\n\nExtract raw content from up to 20 URLs at once:\n\n```bash\ncurl -s -X POST 'https://api.tavily.com/extract' \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: Bearer $TAVILY_API_KEY\" \\\n  -d '{\n    \"urls\": [\n      \"https://docs.example.com/guide\",\n      \"https://competitor.com/pricing\"\n    ]\n  }' | python3 -m json.tool\n```\n\nReturns markdown content for ",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "web-research-analyst"
    ]
  },
  "webapp-testing": {
    "name": "webapp-testing",
    "description": "Use when testing web applications with AI-assisted Playwright. Webapp testing covers autonomous test agents for planning, generating, and self-healing tests.",
    "version": "1.2.0",
    "author": "OrchestKit AI Agent Hub",
    "tags": [
      "playwright",
      "testing",
      "e2e",
      "automation",
      "agents"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [],
    "skills": [],
    "agent": "test-generator",
    "structure": {
      "references": [
        "generator-agent.md",
        "healer-agent.md",
        "planner-agent.md",
        "playwright-setup.md",
        "visual-regression.md"
      ],
      "assets": [
        "playwright-test-template.ts"
      ],
      "checklists": [
        "e2e-testing-checklist.md"
      ]
    },
    "content": "Autonomous end-to-end testing with Playwright's three specialized agents for planning, generating, and self-healing tests automatically.\n\n## The Three Agents\n\n1. **Planner** - Explores app and creates test plans\n2. **Generator** - Writes Playwright tests with best practices\n3. **Healer** - Fixes failing tests automatically\n\n## Quick Setup (CC 2.1.6)\n\n```bash\n# 1. Install Playwright\nnpm install --save-dev @playwright/test\nnpx playwright install\n```\n\n```json\n// 2. Create/update .mcp.json in project root\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@playwright/mcp@latest\"]\n    }\n  }\n}\n```\n\n```bash\n# 3. Initialize agents (after restarting Claude Code session)\nnpx playwright init-agents --loop=claude\n\n# 4. Create tests/seed.spec.ts (required for Planner)\n```\n\n**Requirements:** VS Code v1.105+ (Oct 9, 2025)\n\n## Agent Workflow\n\n```\n1. PLANNER   --> Explores app --> Creates specs/checkout.md\n                 (uses seed.spec.ts)\n                      |\n                      v\n2. GENERATOR --> Reads spec --> Tests live app --> Outputs tests/checkout.spec.ts\n                 (verifies selectors actually work)\n                      |\n                      v\n3. HEALER    --> Runs tests --> Fixes failures --> Updates selectors/waits\n                 (self-healing)\n```\n\n## Directory Structure\n\n```\nyour-project/\n├── specs/              <- Planner outputs (Markdown plans)\n├── tests/              <- Generator outputs (Playwright tests)\n│   └── seed.spec.ts    <- Required: Planner learns from this\n├── playwright.config.ts\n└── .mcp.json           <- MCP server config (CC 2.1.6)\n```\n\n## Key Concepts\n\n**seed.spec.ts is required** - Planner executes this to learn:\n- Environment setup (fixtures, hooks)\n- Authentication flow\n- Available UI elements\n\n**Generator validates live** - Doesn't just translate Markdown, actually tests app to verify selectors work.\n\n**Healer auto-fixes** - When UI changes break tests, Healer replays, finds new selectors, patches tests.\n\nSee `references/` for detailed agent patterns and commands.\n\n## Bundled Resources\n\n- `assets/playwright-test-template.ts` - Playwright test template with BasePage, ApiMocker, and CustomAssertions\n- `references/playwright-setup.md` - Playwright setup and configuration\n- `references/visual-regression.md` - Visual regression testing patterns\n\n## Related Skills\n\n- `e2e-testing` - Core end-to-end testing patterns with Playwright\n- `msw-mocking` - Mock Service Worker for API mocking in tests\n- `a11y-testing` - Accessibility testing integration with Playwright\n- `vcr-http-recording` - HTTP recording for deterministic test playback\n\n## Key Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Agent Architecture | Planner/Generator/Healer | Separation of concerns for autonomous testing |\n| Seed Requirement | seed.spec.ts mandatory | Planner needs context to learn app patterns |\n| Selector Strategy | Semantic locators | More resilient to UI changes than CSS",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "code-quality-reviewer",
      "frontend-ui-developer",
      "test-generator"
    ]
  },
  "worktree-coordination": {
    "name": "worktree-coordination",
    "description": "Coordinates multiple Claude instances across worktrees. Use when managing parallel development.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "coordination",
      "worktree",
      "multi-instance",
      "locking",
      "parallel-development"
    ],
    "userInvocable": true,
    "context": "none",
    "allowedTools": [
      "Read",
      "Write",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [
      "git-workflow",
      "commit",
      "stacked-prs"
    ],
    "agent": null,
    "structure": {},
    "content": "# Worktree Coordination Skill\n\n> **Agent Teams (CC 2.1.33+):** When `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` is set, native Agent Teams provides built-in teammate lifecycle management, peer-to-peer messaging, and shared task lists. This skill's custom file locking and coordination registry are superseded by Teams' native coordination. Use this skill only for **non-Teams worktree scenarios** (e.g., multiple independent Claude Code sessions without a shared team).\n\n## Commands\n\n### /worktree-status\nShow status of all active Claude Code instances.\n\n**Usage:** `/worktree-status [--json] [--clean]`\n\n**Actions:**\n1. Run `cc-worktree-status` to see all active instances\n2. Check for stale instances (no heartbeat > 5 min)\n3. View file locks across all instances\n\n**Output includes:**\n- Instance ID and branch\n- Current task (if set)\n- Health status (ACTIVE/STALE)\n- Files locked by each instance\n\n### /worktree-claim <file-path>\nExplicitly lock a file for this instance.\n\n**Usage:** `/worktree-claim src/auth/login.ts`\n\n**Actions:**\n1. Check if file is already locked\n2. If locked by another instance, show who holds it\n3. If available, acquire lock\n\n### /worktree-release <file-path>\nRelease lock on a file.\n\n**Usage:** `/worktree-release src/auth/login.ts`\n\n### /worktree-sync\nSync shared context and check for conflicts.\n\n**Usage:** `/worktree-sync [--check-conflicts] [--pull-decisions]`\n\n**Actions:**\n1. `--check-conflicts`: Run merge-tree against other active branches\n2. `--pull-decisions`: Show recent architectural decisions from other instances\n\n### /worktree-decision <decision>\nLog an architectural decision visible to all instances.\n\n**Usage:** `/worktree-decision \"Using Passport.js for OAuth\" --rationale \"Better middleware support\"`\n\n## Automatic Behaviors\n\n### File Lock Check (PreToolUse Hook)\nBefore any Write or Edit operation:\n1. Check if file is locked by another instance\n2. If locked → BLOCK with details about lock holder\n3. If unlocked → Acquire lock and proceed\n\n### Heartbeat (Lifecycle Hook)\nEvery 30 seconds:\n1. Update this instance's heartbeat timestamp\n2. Clean up stale instances (no heartbeat > 5 min)\n3. Release orphaned locks\n\n### Cleanup (Stop Hook)\nWhen Claude Code exits:\n1. Release all file locks held by this instance\n2. Unregister from coordination registry\n\n## File Lock States\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  FILE: src/auth/oauth.ts                                │\n├─────────────────────────────────────────────────────────┤\n│  Status: LOCKED                                         │\n│  Holder: cc-auth-a1b2c3                                 │\n│  Branch: feature/user-authentication                    │\n│  Task:   Implementing OAuth2 login flow                 │\n│  Since:  2 minutes ago                                  │\n├─────────────────────────────────────────────────────────┤\n│  Action: Wait for release or use /worktree-release     │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Regist",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "git-operations-engineer"
    ]
  },
  "zero-downtime-migration": {
    "name": "zero-downtime-migration",
    "description": "Safe database schema changes without downtime using expand-contract pattern and online schema changes. Use when deploying schema changes to production without service interruption.",
    "version": "2.0.0",
    "author": "OrchestKit",
    "tags": [
      "database",
      "migration",
      "zero-downtime",
      "expand-contract",
      "pgroll"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Bash",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "database-engineer",
    "structure": {
      "references": [
        "expand-contract-pattern.md",
        "pgroll-guide.md"
      ],
      "scripts": [
        "expand-contract-template.py"
      ],
      "checklists": [
        "zero-downtime-checklist.md"
      ]
    },
    "content": "# Zero-Downtime Migration ()\n\nDatabase migration patterns that ensure continuous service availability during schema changes.\n\n## Overview\n\n- Deploying schema changes to production systems with uptime requirements\n- Renaming or removing columns without breaking existing application code\n- Adding NOT NULL constraints to existing columns with data\n- Creating indexes on large tables without locking\n- Migrating data between columns or tables during live traffic\n- Using pgroll for automated expand-contract migrations\n\n## Quick Reference\n\n### Expand-Contract Overview\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                     EXPAND-CONTRACT PATTERN                              │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                          │\n│  Phase 1: EXPAND              Phase 2: MIGRATE           Phase 3: CONTRACT│\n│  ─────────────────           ──────────────────         ────────────────  │\n│  Add new column              Backfill data              Remove old column │\n│  (nullable)                  Update app to use new      (after app migrated)│\n│                              Both versions work                           │\n│                                                                          │\n│  ┌─────────┐                 ┌─────────┐                ┌─────────┐      │\n│  │old_col  │ ───────────────>│old_col  │ ─────────────> │new_col  │      │\n│  │         │                 │new_col  │                │         │      │\n│  └─────────┘                 └─────────┘                └─────────┘      │\n│                                                                          │\n│  Rollback: Drop new          Rollback: Use old          Rollback: N/A    │\n│                              (dual-write in app)        (commit)         │\n│                                                                          │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n### pgroll: Automated Expand-Contract\n\n```bash\n# Install pgroll ( recommended tool)\nbrew install xataio/pgroll/pgroll\n# or\ngo install github.com/xataio/pgroll@latest\n\n# Initialize pgroll in your database\npgroll init --postgres-url \"postgres://user:pass@localhost/db\"\n\n# Create a migration file (migrations/001_add_email_verified.json)\n```\n\n```json\n{\n  \"name\": \"001_add_email_verified\",\n  \"operations\": [\n    {\n      \"add_column\": {\n        \"table\": \"users\",\n        \"column\": {\n          \"name\": \"email_verified\",\n          \"type\": \"boolean\",\n          \"default\": \"false\",\n          \"nullable\": false\n        },\n        \"up\": \"false\"\n      }\n    }\n  ]\n}\n```\n\n```bash\n# Start migration (creates versioned schema)\npgroll start migrations/001_add_email_verified.json\n\n# App v1 uses: schema \"public_001_add_email_verified\"\n# App v2 uses: schema \"public\" (new version)\n\n# After verification, complete migration\npgroll complete\n\n# Rollback if issues\npgroll rollb",
    "contentTruncated": true,
    "plugins": [
      "ork",
      "orkl"
    ],
    "relatedAgents": [
      "database-engineer"
    ]
  },
  "zustand-patterns": {
    "name": "zustand-patterns",
    "description": "Zustand 5.x state management with slices, middleware, Immer, useShallow, and persistence patterns for React applications. Use when building state management with Zustand.",
    "version": "1.0.0",
    "author": "OrchestKit",
    "tags": [
      "zustand",
      "state-management",
      "react",
      "immer",
      "middleware",
      "persistence",
      "slices"
    ],
    "userInvocable": false,
    "context": "fork",
    "allowedTools": [
      "Read",
      "Write",
      "Grep",
      "Glob"
    ],
    "skills": [],
    "agent": "frontend-ui-developer",
    "structure": {
      "references": [
        "middleware-composition.md"
      ],
      "scripts": [
        "store-template.ts"
      ],
      "checklists": [
        "zustand-checklist.md"
      ]
    },
    "content": "# Zustand Patterns\n\nModern state management with Zustand 5.x - lightweight, TypeScript-first, no boilerplate.\n\n## Overview\n\n- Global state without Redux complexity\n- Shared state across components without prop drilling\n- Persisted state with localStorage/sessionStorage\n- Computed/derived state with selectors\n- State that needs middleware (logging, devtools, persistence)\n\n## Core Patterns\n\n### 1. Basic Store with TypeScript\n\n```typescript\nimport { create } from 'zustand';\n\ninterface BearState {\n  bears: number;\n  increase: (by: number) => void;\n  reset: () => void;\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n  reset: () => set({ bears: 0 }),\n}));\n```\n\n### 2. Slices Pattern (Modular Stores)\n\n```typescript\nimport { create, StateCreator } from 'zustand';\n\n// Auth slice\ninterface AuthSlice {\n  user: User | null;\n  login: (user: User) => void;\n  logout: () => void;\n}\n\nconst createAuthSlice: StateCreator<AuthSlice & CartSlice, [], [], AuthSlice> = (set) => ({\n  user: null,\n  login: (user) => set({ user }),\n  logout: () => set({ user: null }),\n});\n\n// Cart slice\ninterface CartSlice {\n  items: CartItem[];\n  addItem: (item: CartItem) => void;\n  clearCart: () => void;\n}\n\nconst createCartSlice: StateCreator<AuthSlice & CartSlice, [], [], CartSlice> = (set) => ({\n  items: [],\n  addItem: (item) => set((state) => ({ items: [...state.items, item] })),\n  clearCart: () => set({ items: [] }),\n});\n\n// Combined store\nconst useStore = create<AuthSlice & CartSlice>()((...a) => ({\n  ...createAuthSlice(...a),\n  ...createCartSlice(...a),\n}));\n```\n\n### 3. Immer Middleware (Immutable Updates)\n\n```typescript\nimport { create } from 'zustand';\nimport { immer } from 'zustand/middleware/immer';\n\ninterface TodoState {\n  todos: Todo[];\n  addTodo: (text: string) => void;\n  toggleTodo: (id: string) => void;\n  updateNested: (id: string, subtaskId: string, done: boolean) => void;\n}\n\nconst useTodoStore = create<TodoState>()(\n  immer((set) => ({\n    todos: [],\n    addTodo: (text) =>\n      set((state) => {\n        state.todos.push({ id: crypto.randomUUID(), text, done: false });\n      }),\n    toggleTodo: (id) =>\n      set((state) => {\n        const todo = state.todos.find((t) => t.id === id);\n        if (todo) todo.done = !todo.done;\n      }),\n    updateNested: (id, subtaskId, done) =>\n      set((state) => {\n        const todo = state.todos.find((t) => t.id === id);\n        const subtask = todo?.subtasks?.find((s) => s.id === subtaskId);\n        if (subtask) subtask.done = done;\n      }),\n  }))\n);\n```\n\n### 4. Persist Middleware\n\n```typescript\nimport { create } from 'zustand';\nimport { persist, createJSONStorage } from 'zustand/middleware';\n\ninterface SettingsState {\n  theme: 'light' | 'dark';\n  language: string;\n  setTheme: (theme: 'light' | 'dark') => void;\n}\n\nconst useSettingsStore = create<SettingsState>()(\n  persist(\n    (set) => ({\n      theme: 'light',\n      language: 'en',\n      setTheme: (t",
    "contentTruncated": true,
    "plugins": [
      "ork"
    ],
    "relatedAgents": [
      "frontend-ui-developer"
    ]
  }
};

export const SKILLS_SUMMARY = {
  "orkl": {
    "workflows": [
      "explore",
      "implement",
      "verify",
      "commit",
      "git-workflow",
      "stacked-prs",
      "issue-progress-tracking",
      "task-dependency-patterns"
    ],
    "memory": [
      "doctor",
      "remember",
      "memory",
      "memory-fabric",
      "best-practices",
      "mem0-memory"
    ],
    "product": [
      "product-strategy-frameworks",
      "business-case-analysis",
      "market-analysis-patterns",
      "okr-kpi-patterns",
      "prioritization-frameworks",
      "requirements-engineering"
    ],
    "git": [
      "review-pr",
      "create-pr",
      "commit",
      "fix-issue",
      "assess",
      "remember",
      "git-recovery",
      "feedback"
    ],
    "accessibility": [
      "aggregate-patterns",
      "a11y-testing",
      "wcag-compliance",
      "focus-management"
    ],
    "devops": [
      "devops-deployment",
      "observability-monitoring",
      "competitive-monitoring"
    ],
    "testing": [
      "verify",
      "review-pr",
      "unit-testing",
      "integration-testing",
      "e2e-testing",
      "test-data-management",
      "contract-testing",
      "test-standards-enforcer"
    ],
    "security": [
      "review-pr",
      "owasp-top-10",
      "auth-patterns",
      "defense-in-depth",
      "security-scanning",
      "browser-content-capture"
    ],
    "python": [
      "clean-architecture",
      "domain-driven-design",
      "aggregate-patterns"
    ],
    "llm": [
      "streaming-api-patterns"
    ],
    "rag": [
      "unit-testing",
      "test-standards-enforcer"
    ],
    "backend": [
      "explore",
      "api-design-framework",
      "clean-architecture",
      "domain-driven-design",
      "cqrs-patterns",
      "event-sourcing",
      "saga-patterns",
      "aggregate-patterns"
    ]
  },
  "ork-creative": {},
  "ork": {
    "includesAllOrkLite": true,
    "python": [
      "alembic-migrations",
      "api-versioning",
      "asyncio-advanced",
      "backend-architecture-enforcer",
      "background-jobs",
      "caching-strategies",
      "celery-advanced",
      "error-handling-rfc9457"
    ],
    "react": [
      "agent-loops",
      "biome-linting",
      "dashboard-patterns",
      "design-system-starter",
      "form-state-patterns",
      "i18n-date-patterns",
      "lazy-loading-patterns",
      "motion-animation-patterns"
    ],
    "llm": [
      "agent-loops",
      "alternative-agent-frameworks",
      "cache-cost-tracking",
      "context-engineering",
      "contextual-retrieval",
      "function-calling",
      "grpc-python",
      "high-performance-inference"
    ],
    "rag": [
      "agentic-rag-patterns",
      "contextual-retrieval",
      "embeddings",
      "hyde-retrieval",
      "llm-evaluation",
      "llm-testing",
      "multimodal-rag",
      "pgvector-search"
    ],
    "backend": [
      "api-versioning",
      "audit-full",
      "backend-architecture-enforcer",
      "caching-strategies",
      "error-handling-rfc9457",
      "fastapi-advanced",
      "grpc-python",
      "langgraph-functional"
    ]
  }
};
