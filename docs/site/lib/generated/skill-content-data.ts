// AUTO-GENERATED by scripts/generate-docs-data.js
// DO NOT EDIT MANUALLY — your changes will be overwritten.
// Only import this module when skill content is actually needed (on-demand).

export const SKILL_CONTENT: Record<string, { content: string; contentTruncated: boolean }> = {
  "accessibility": {
    "content": "# Accessibility\n\nComprehensive patterns for building accessible web applications: WCAG 2.2 AA compliance, keyboard focus management, and React Aria component patterns. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [WCAG Compliance](#wcag-compliance) | 3 | CRITICAL | Color contrast, semantic HTML, automated testing |\n| [Focus Management](#focus-management) | 3 | HIGH | Focus traps, focus restoration, keyboard navigation |\n| [React Aria](#react-aria) | 3 | HIGH | Accessible components, form hooks, overlay patterns |\n\n**Total: 9 rules across 3 categories**\n\n## Quick Start\n\n```tsx\n// Semantic HTML with ARIA\n<main>\n  <article>\n    <header><h1>Page Title</h1></header>\n    <section aria-labelledby=\"features-heading\">\n      <h2 id=\"features-heading\">Features</h2>\n    </section>\n  </article>\n</main>\n```\n\n```tsx\n// Focus trap with React Aria\nimport { FocusScope } from 'react-aria';\n\n<FocusScope contain restoreFocus autoFocus>\n  <div role=\"dialog\" aria-modal=\"true\">\n    {children}\n  </div>\n</FocusScope>\n```\n\n## WCAG Compliance\n\nWCAG 2.2 AA implementation for inclusive, legally compliant web applications.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Color Contrast | `rules/wcag-color-contrast.md` | 4.5:1 text, 3:1 UI components, focus indicators |\n| Semantic HTML | `rules/wcag-semantic-html.md` | Landmarks, headings, ARIA labels, form structure |\n| Testing | `rules/wcag-testing.md` | axe-core, Playwright a11y, screen reader testing |\n\n## Focus Management\n\nKeyboard focus management patterns for accessible interactive widgets.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Focus Trap | `rules/focus-trap.md` | Modal focus trapping, FocusScope, Escape key |\n| Focus Restoration | `rules/focus-restoration.md` | Return focus to trigger, focus first error |\n| Keyboard Navigation | `rules/focus-keyboard-nav.md` | Roving tabindex, skip links, arrow keys |\n\n## React Aria\n\nAdobe React Aria hooks for building WCAG-compliant interactive UI.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Components | `rules/aria-components.md` | useButton, useDialog, useMenu, FocusScope |\n| Forms | `rules/aria-forms.md` | useComboBox, useTextField, useListBox |\n| Overlays | `rules/aria-overlays.md` | useModalOverlay, useTooltip, usePopover |\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Conformance level | WCAG 2.2 AA (legal standard: ADA, Section 508) |\n| Contrast ratio | 4.5:1 normal text, 3:1 large text and UI components |\n| Target size | 24px min (WCAG 2.5.8), 44px for touch |\n| Focus indicator | 3px solid outline, 3:1 contrast |\n| Component library | React Aria hooks for control, react-aria-components for speed |\n| State management | react-stately hooks (designed for a11y) |\n| Focus management | FocusScope for modals, roving tabindex for widgets |\n| Testing | jest-axe ",
    "contentTruncated": true
  },
  "agent-orchestration": {
    "content": "# Agent Orchestration\n\nComprehensive patterns for building and coordinating AI agents -- from single-agent reasoning loops to multi-agent systems and framework selection. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Agent Loops](#agent-loops) | 2 | HIGH | ReAct reasoning, plan-and-execute, self-correction |\n| [Multi-Agent Coordination](#multi-agent-coordination) | 3 | CRITICAL | Supervisor routing, agent debate, result synthesis |\n| [Alternative Frameworks](#alternative-frameworks) | 3 | HIGH | CrewAI crews, AutoGen teams, framework comparison |\n| [Multi-Scenario](#multi-scenario) | 2 | MEDIUM | Parallel scenario orchestration, difficulty routing |\n\n**Total: 10 rules across 4 categories**\n\n## Quick Start\n\n```python\n# ReAct agent loop\nasync def react_loop(question: str, tools: dict, max_steps: int = 10) -> str:\n    history = REACT_PROMPT.format(tools=list(tools.keys()), question=question)\n    for step in range(max_steps):\n        response = await llm.chat([{\"role\": \"user\", \"content\": history}])\n        if \"Final Answer:\" in response.content:\n            return response.content.split(\"Final Answer:\")[-1].strip()\n        if \"Action:\" in response.content:\n            action = parse_action(response.content)\n            result = await tools[action.name](*action.args)\n            history += f\"\\nObservation: {result}\\n\"\n    return \"Max steps reached without answer\"\n```\n\n```python\n# Supervisor with fan-out/fan-in\nasync def multi_agent_analysis(content: str) -> dict:\n    agents = [(\"security\", security_agent), (\"perf\", perf_agent)]\n    tasks = [agent(content) for _, agent in agents]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    return await synthesize_findings(results)\n```\n\n## Agent Loops\n\nPatterns for autonomous LLM reasoning: ReAct (Reasoning + Acting), Plan-and-Execute with replanning, self-correction loops, and sliding-window memory management.\n\n**Key decisions:** Max steps 5-15, temperature 0.3-0.7, memory window 10-20 messages.\n\n## Multi-Agent Coordination\n\nFan-out/fan-in parallelism, supervisor routing with dependency ordering, conflict resolution (confidence-based or LLM arbitration), result synthesis, and CC Agent Teams (mesh topology for peer messaging in CC 2.1.33+).\n\n**Key decisions:** 3-8 specialists, parallelize independent agents, use Task tool (star) for simple work, Agent Teams (mesh) for cross-cutting concerns.\n\n## Alternative Frameworks\n\nCrewAI hierarchical crews with Flows (1.8+), OpenAI Agents SDK handoffs and guardrails (0.7.0), Microsoft Agent Framework (AutoGen + SK merger), GPT-5.2-Codex for long-horizon coding, and AG2 for open-source flexibility.\n\n**Key decisions:** Match framework to team expertise + use case. LangGraph for state machines, CrewAI for role-based teams, OpenAI SDK for handoff workflows, MS Agent for enterprise compliance.\n\n## Multi-Scenario\n\nOrchestrate a",
    "contentTruncated": true
  },
  "analytics": {
    "content": "# Cross-Project Analytics\n\nQuery local analytics data from `~/.claude/analytics/`. All data is local-only, privacy-safe (hashed project IDs, no PII).\n\n## Subcommands\n\nParse the user's argument to determine which report to show. If no argument provided, use AskUserQuestion to let them pick.\n\n| Subcommand | Description | Data Source | Reference |\n|------------|-------------|-------------|-----------|\n| `agents` | Top agents by frequency, duration, model breakdown | `agent-usage.jsonl` | `references/jq-queries.md` |\n| `models` | Model delegation breakdown (opus/sonnet/haiku) | `agent-usage.jsonl` | `references/jq-queries.md` |\n| `skills` | Top skills by invocation count | `skill-usage.jsonl` | `references/jq-queries.md` |\n| `hooks` | Slowest hooks and failure rates | `hook-timing.jsonl` | `references/jq-queries.md` |\n| `teams` | Team spawn counts, idle time, task completions | `team-activity.jsonl` | `references/jq-queries.md` |\n| `session` | Replay a session timeline with tools, tokens, timing | CC session JSONL | `references/session-replay.md` |\n| `cost` | Token cost estimation with cache savings | `stats-cache.json` | `references/cost-estimation.md` |\n| `trends` | Daily activity, model delegation, peak hours | `stats-cache.json` | `references/trends-analysis.md` |\n| `summary` | Unified view of all categories | All files | `references/jq-queries.md` |\n\n### Quick Start Example\n\n```bash\n# Top agents with model breakdown\njq -s 'group_by(.agent) | map({agent: .[0].agent, count: length}) | sort_by(-.count)' ~/.claude/analytics/agent-usage.jsonl\n\n# All-time token costs\njq '.modelUsage | to_entries | map({model: .key, input: .value.inputTokens, output: .value.outputTokens})' ~/.claude/stats-cache.json\n```\n\n### Quick Subcommand Guide\n\n**`agents`, `models`, `skills`, `hooks`, `teams`, `summary`** — Run the jq query from `references/jq-queries.md` for the matching subcommand. Present results as a markdown table.\n\n**`session`** — Follow the 4-step process in `references/session-replay.md`: locate session file, resolve reference (latest/partial/full ID), parse JSONL, present timeline.\n\n**`cost`** — Apply model-specific pricing from `references/cost-estimation.md` to CC's stats-cache.json. Show per-model breakdown, totals, and cache savings.\n\n**`trends`** — Follow the 4-step process in `references/trends-analysis.md`: daily activity, model delegation, peak hours, all-time stats.\n\n**`summary`** — Run all subcommands and present a unified view: total sessions, top 5 agents, top 5 skills, team activity, unique projects.\n\n## Data Files\n\nSee `references/data-locations.md` for complete data source documentation.\n\n| File | Contents |\n|------|----------|\n| `agent-usage.jsonl` | Agent spawn events with model, duration, success |\n| `skill-usage.jsonl` | Skill invocations |\n| `hook-timing.jsonl` | Hook execution timing and failure rates |\n| `session-summary.jsonl` | Session end summaries |\n| `task-usage.jsonl` | Task completions |\n| `team-activity.jsonl` | Team spawns an",
    "contentTruncated": true
  },
  "api-design": {
    "content": "# API Design\n\nComprehensive API design patterns covering REST/GraphQL framework design, versioning strategies, and RFC 9457 error handling. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [API Framework](#api-framework) | 3 | HIGH | REST conventions, resource modeling, OpenAPI specifications |\n| [Versioning](#versioning) | 3 | HIGH | URL path versioning, header versioning, deprecation/sunset policies |\n| [Error Handling](#error-handling) | 3 | HIGH | RFC 9457 Problem Details, validation errors, error type registries |\n| [GraphQL](#graphql) | 2 | HIGH | Strawberry code-first, DataLoader, permissions, subscriptions |\n| [gRPC](#grpc) | 2 | HIGH | Protobuf services, streaming, interceptors, retry |\n| [Streaming](#streaming) | 2 | HIGH | SSE endpoints, WebSocket bidirectional, async generators |\n\n| [Integrations](#integrations) | 2 | HIGH | Messaging platforms (WhatsApp, Telegram), Payload CMS patterns |\n\n**Total: 17 rules across 7 categories**\n\n## API Framework\n\nREST and GraphQL API design conventions for consistent, developer-friendly APIs.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| REST Conventions | `rules/framework-rest-conventions.md` | Plural nouns, HTTP methods, status codes, pagination |\n| Resource Modeling | `rules/framework-resource-modeling.md` | Hierarchical URLs, filtering, sorting, field selection |\n| OpenAPI | `rules/framework-openapi.md` | OpenAPI 3.1 specs, documentation, schema definitions |\n\n## Versioning\n\nStrategies for API evolution without breaking clients.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| URL Path | `rules/versioning-url-path.md` | `/api/v1/` prefix routing, version-specific schemas |\n| Header | `rules/versioning-header.md` | `X-API-Version` header, content negotiation |\n| Deprecation | `rules/versioning-deprecation.md` | Sunset headers, lifecycle management, breaking change policy |\n\n## Error Handling\n\nRFC 9457 Problem Details for machine-readable, standardized error responses.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Problem Details | `rules/errors-problem-details.md` | RFC 9457 schema, `application/problem+json`, exception classes |\n| Validation | `rules/errors-validation.md` | Field-level errors, Pydantic integration, 422 responses |\n| Error Catalog | `rules/errors-error-catalog.md` | Problem type registry, error type URIs, client handling |\n\n## GraphQL\n\nStrawberry GraphQL code-first schema with type-safe resolvers and FastAPI integration.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Schema Design | `rules/graphql-strawberry.md` | Type-safe schema, DataLoader, union errors, Private fields |\n| Patterns & Auth | `rules/graphql-schema.md` | Permission classes, FastAPI integration, subscriptions |\n\n## gRPC\n\nHigh-performance gRPC for internal microservice communication.\n\n| Rule | File | Key Pattern |\n|------|-",
    "contentTruncated": true
  },
  "architecture-decision-record": {
    "content": "# Architecture Decision Records\nArchitecture Decision Records (ADRs) are lightweight documents that capture important architectural decisions along with their context and consequences. This skill provides templates, examples, and best practices for creating and maintaining ADRs in your projects.\n\n## Overview\n- Making significant technology choices (databases, frameworks, cloud providers)\n- Designing system architecture or major components\n- Establishing patterns or conventions for the team\n- Evaluating trade-offs between multiple approaches\n- Documenting decisions that will impact future development\n\n## Why ADRs Matter\n\nADRs serve as architectural memory for your team:\n- **Context Preservation**: Capture why decisions were made, not just what was decided\n- **Onboarding**: Help new team members understand architectural rationale\n- **Prevent Revisiting**: Avoid endless debates about settled decisions\n- **Track Evolution**: See how architecture evolved over time\n- **Accountability**: Clear ownership and decision timeline\n\n## ADR Format (Nygard Template)\n\nEach ADR should follow this structure:\n\n### 1. Title\nFormat: `ADR-####: [Decision Title]`\nExample: `ADR-0001: Adopt Microservices Architecture`\n\n### 2. Status\nCurrent state of the decision:\n- **Proposed**: Under consideration\n- **Accepted**: Decision approved and being implemented\n- **Superseded**: Replaced by a later decision (reference ADR number)\n- **Deprecated**: No longer recommended but not yet replaced\n- **Rejected**: Considered but not adopted (document why)\n\n### 3. Context\n**What to include:**\n- Problem statement or opportunity\n- Business/technical constraints\n- Stakeholder requirements\n- Current state of the system\n- Forces at play (conflicting concerns)\n\n### 4. Decision\n**What to include:**\n- The choice being made\n- Key principles or patterns to follow\n- What will change as a result\n- Who is responsible for implementation\n\n**Be specific and actionable:**\n- ✅ \"We will adopt microservices architecture using Node.js with Express\"\n- ❌ \"We will consider using microservices\"\n\n### 5. Consequences\n**What to include:**\n- Positive outcomes (benefits)\n- Negative outcomes (costs, risks, trade-offs)\n- Neutral outcomes (things that change but aren't clearly better/worse)\n\n### 6. Alternatives Considered\n**Document at least 2 alternatives:**\n\n**For each alternative, explain:**\n- What it was\n- Why it was considered\n- Why it was not chosen\n\n### 7. References (Optional)\nLinks to relevant resources:\n- Meeting notes or discussion threads\n- Related ADRs\n- External research or articles\n- Proof of concept implementations\n\n## ADR Lifecycle\n\n```\nProposed → Accepted → [Implemented] → (Eventually) Superseded/Deprecated\n          ↓\n      Rejected\n```\n\n## Best Practices\n\n### 1. **Keep ADRs Immutable**\nOnce accepted, don't edit ADRs. Create new ADRs that supersede old ones.\n- ✅ Create ADR-0015 that supersedes ADR-0003\n- ❌ Update ADR-0003 with new decisions\n\n### 2. **Write in Present Tense**\nADRs are historical records ",
    "contentTruncated": true
  },
  "architecture-patterns": {
    "content": "# Architecture Patterns\n\nConsolidated architecture validation and enforcement patterns covering clean architecture, backend layer separation, project structure conventions, and test standards. Each category has individual rule files in `references/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Clean Architecture](#clean-architecture) | 3 | HIGH | SOLID principles, hexagonal architecture, ports & adapters, DDD |\n| [Project Structure](#project-structure) | 2 | HIGH | Folder conventions, nesting depth, import direction, barrel files |\n| [Backend Layers](#backend-layers) | 3 | HIGH | Router/service/repository separation, DI, file naming |\n| [Test Standards](#test-standards) | 3 | MEDIUM | AAA pattern, naming conventions, coverage thresholds |\n| [Right-Sizing](#right-sizing) | 2 | HIGH | Architecture tier selection, over-engineering prevention, context-aware enforcement |\n\n**Total: 13 rules across 5 categories**\n\n## Quick Start\n\n```python\n# Clean Architecture: Dependency Inversion via Protocol\nclass IUserRepository(Protocol):\n    async def get_by_id(self, id: str) -> User | None: ...\n\nclass UserService:\n    def __init__(self, repo: IUserRepository):\n        self._repo = repo  # Depends on abstraction, not concretion\n\n# FastAPI DI chain: DB -> Repository -> Service\ndef get_user_service(db: AsyncSession = Depends(get_db)) -> UserService:\n    return UserService(PostgresUserRepository(db))\n```\n\n```\n# Project Structure: Unidirectional Import Architecture\nshared/lib  ->  components  ->  features  ->  app\n(lowest)                                    (highest)\n\n# Backend Layers: Strict Separation\nRouters (HTTP) -> Services (Business Logic) -> Repositories (Data Access)\n```\n\n## Clean Architecture\n\nSOLID principles, hexagonal architecture, ports and adapters, and DDD tactical patterns for maintainable backends.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Hexagonal Architecture | `references/clean-hexagonal-ports-adapters.md` | Driving/driven ports, adapter implementations, layer structure |\n| SOLID & Dependency Rule | `references/clean-solid-dependency-rule.md` | Protocol-based interfaces, dependency inversion, FastAPI DI |\n| DDD Tactical Patterns | `references/clean-ddd-tactical-patterns.md` | Entities, value objects, aggregate roots, domain events |\n\n### Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Protocol vs ABC | Protocol (structural typing) |\n| Dataclass vs Pydantic | Dataclass for domain, Pydantic for API |\n| Repository granularity | One per aggregate root |\n| Transaction boundary | Service layer, not repository |\n| Event publishing | Collect in aggregate, publish after commit |\n\n## Project Structure\n\nFeature-based organization, max nesting depth, unidirectional imports, and barrel file prevention.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Folder Structure & Nesting | `references/structure-folder-conv",
    "contentTruncated": true
  },
  "ascii-visualizer": {
    "content": "# ASCII Visualizer\n\nConsistent, readable ASCII diagrams for architecture, workflows, file trees, and data visualizations. All output renders correctly in monospace terminals without external tools.\n\n**Core principle:** Encode information into structure, not decoration. Every diagram element should communicate something meaningful.\n\n\n## Box-Drawing Character Reference\n\n```\nStandard:  ┌─┐ │ └─┘  ├─┤ ┬ ┴ ┼\nHeavy:     ┏━┓ ┃ ┗━┛  ┣━┫ ┳ ┻ ╋\nDouble:    ╔═╗ ║ ╚═╝  ╠═╣ ╦ ╩ ╬\nRounded:   ╭─╮ │ ╰─╯\nArrows:    → ← ↑ ↓ ─> <─ ──> <──\nBlocks:    █ ▓ ░ ▏▎▍▌▋▊▉\nChecks:    ✓ ✗ ● ○ ◆ ◇ ★ ☆\n```\n\n### Weight Conventions\n\n| Weight | Characters | Use For |\n|--------|-----------|---------|\n| Standard `─│` | Normal boxes and connectors | Most diagrams |\n| Heavy `━┃` | Emphasis, borders, headers | Key components, outer frames |\n| Double `═║` | Separation, titles | Section dividers, title boxes |\n\n\n## Diagram Patterns\n\n### Architecture Diagrams\n\n```\n┌──────────────┐      ┌──────────────┐\n│   Frontend   │─────>│   Backend    │\n│   React 19   │      │   FastAPI    │\n└──────────────┘      └───────┬──────┘\n                              │\n                              v\n                      ┌──────────────┐\n                      │  PostgreSQL  │\n                      └──────────────┘\n```\n\n### File Trees with Annotations\n\n```\nsrc/\n├── api/\n│   ├── routes.py          [M] +45 -12    !! high-traffic path\n│   └── schemas.py         [M] +20 -5\n├── services/\n│   └── billing.py         [A] +180       ** new file\n└── tests/\n    └── test_billing.py    [A] +120       ** new file\n\nLegend: [A]dd [M]odify [D]elete  !! Risk  ** New\n```\n\n### Progress Bars\n\n```\n[████████░░] 80% Complete\n+ Design    (2 days)\n+ Backend   (5 days)\n~ Frontend  (3 days)\n- Testing   (pending)\n```\n\n### Swimlane / Timeline Diagrams\n\n```\nBackend  ===[Schema]======[API]===========================[Deploy]====>\n                |            |                                ^\n                |            +------blocks------+             |\n                |                               |             |\nFrontend ------[Wait]--------[Components]=======[Integration]=+\n\n=== Active work   --- Blocked/waiting   | Dependency\n```\n\n### Blast Radius (Concentric Rings)\n\n```\n            Ring 3: Tests (8 files)\n       +-------------------------------+\n       |    Ring 2: Transitive (5)      |\n       |   +------------------------+   |\n       |   |  Ring 1: Direct (3)     |   |\n       |   |   +--------------+      |   |\n       |   |   | CHANGED FILE |      |   |\n       |   |   +--------------+      |   |\n       |   +------------------------+   |\n       +-------------------------------+\n```\n\n### Comparison Tables\n\n```\nBEFORE                          AFTER\n┌────────────┐                  ┌────────────┐\n│  Monolith  │                  │  Service A │──┐\n│  (all-in-1)│                  └────────────┘  │  ┌──────────┐\n└────────────┘                  ┌────────────┐  ├─>│  Shared  │\n                                │  Service B │──┘  │  Queue   │\n   ",
    "contentTruncated": true
  },
  "assess": {
    "content": "# Assess\n\nComprehensive assessment skill for answering \"is this good?\" with structured evaluation, scoring, and actionable recommendations.\n\n## Quick Start\n\n```bash\n/ork:assess backend/app/services/auth.py\n/ork:assess our caching strategy\n/ork:assess the current database schema\n/ork:assess frontend/src/components/Dashboard\n```\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify assessment dimensions:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What dimensions to assess?\",\n    \"header\": \"Dimensions\",\n    \"options\": [\n      {\"label\": \"Full assessment (Recommended)\", \"description\": \"All dimensions: quality, maintainability, security, performance\"},\n      {\"label\": \"Code quality only\", \"description\": \"Readability, complexity, best practices\"},\n      {\"label\": \"Security focus\", \"description\": \"Vulnerabilities, attack surface, compliance\"},\n      {\"label\": \"Quick score\", \"description\": \"Just give me a 0-10 score with brief notes\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full assessment**: All 7 phases, parallel agents\n- **Code quality only**: Skip security and performance phases\n- **Security focus**: Prioritize security-auditor agent\n- **Quick score**: Single pass, brief output\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — assessors cross-validate scores) or **Task tool** (star — all report to lead):\n\n```python\nimport os\nteams_available = os.environ.get(\"CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS\") is not None\nforce_task_tool = os.environ.get(\"ORCHESTKIT_FORCE_TASK_TOOL\") == \"1\"\n\nif force_task_tool or not teams_available:\n    mode = \"task_tool\"\nelse:\n    # Teams available — use for full multi-dimensional assessment\n    mode = \"agent_teams\" if dimensions == \"full\" else \"task_tool\"\n```\n\n1. `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS` set → **Agent Teams mode** (for full assessment)\n2. Flag not set → **Task tool mode** (default)\n3. Quick score or single-dimension → **Task tool** (regardless of flag)\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Score calibration | Lead normalizes independently | Assessors discuss disagreements |\n| Cross-dimension findings | Lead correlates after completion | Security assessor alerts performance assessor of overlap |\n| Cost | ~200K tokens | ~500K tokens |\n| Best for | Quick scores, single dimension | Full multi-dimensional assessment |\n\n> **Context window:** For full codebase assessments (>20 files), use the 1M context window to avoid agent context exhaustion. On 200K context, the scope discovery in Phase 1.5 limits files to prevent overflow.\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining assessment.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main assessment task\nTaskCreate(\n  subject=\"Assess: {target}\",\n  description=\"Comprehensive evaluation with quality scores and recommendations\",\n  activeForm=\"Assessing {target}\"\n)",
    "contentTruncated": true
  },
  "async-jobs": {
    "content": "# Async Jobs\n\nPatterns for background task processing with Celery, ARQ, and Redis. Covers task queues, canvas workflows, scheduling, retry strategies, rate limiting, and production monitoring. Each category has individual rule files in `references/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Configuration](#configuration) | celery-config | HIGH | Celery app setup, broker, serialization, worker tuning |\n| [Task Routing](#task-routing) | task-routing | HIGH | Priority queues, multi-queue workers, dynamic routing |\n| [Canvas Workflows](#canvas-workflows) | canvas-workflows | HIGH | Chain, group, chord, nested workflows |\n| [Retry Strategies](#retry-strategies) | retry-strategies | HIGH | Exponential backoff, idempotency, dead letter queues |\n| [Scheduling](#scheduling) | scheduled-tasks | MEDIUM | Celery Beat, crontab, database-backed schedules |\n| [Monitoring](#monitoring) | monitoring-health | MEDIUM | Flower, custom events, health checks, metrics |\n| [Result Backends](#result-backends) | result-backends | MEDIUM | Redis results, custom states, progress tracking |\n| [ARQ Patterns](#arq-patterns) | arq-patterns | MEDIUM | Async Redis Queue for FastAPI, lightweight jobs |\n| [Temporal Workflows](#temporal-workflows) | temporal-workflows | HIGH | Durable workflow definitions, sagas, signals, queries |\n| [Temporal Activities](#temporal-activities) | temporal-activities | HIGH | Activity patterns, workers, heartbeats, testing |\n\n**Total: 10 rules across 9 categories**\n\n## Quick Start\n\n```python\n# Celery task with retry\nfrom celery import shared_task\n\n@shared_task(\n    bind=True,\n    max_retries=3,\n    autoretry_for=(ConnectionError, TimeoutError),\n    retry_backoff=True,\n)\ndef process_order(self, order_id: str) -> dict:\n    result = do_processing(order_id)\n    return {\"order_id\": order_id, \"status\": \"completed\"}\n```\n\n```python\n# ARQ task with FastAPI\nfrom arq import create_pool\nfrom arq.connections import RedisSettings\n\nasync def generate_report(ctx: dict, report_id: str) -> dict:\n    data = await ctx[\"db\"].fetch_report_data(report_id)\n    pdf = await render_pdf(data)\n    return {\"report_id\": report_id, \"size\": len(pdf)}\n\n@router.post(\"/api/v1/reports\")\nasync def create_report(data: ReportRequest, arq: ArqRedis = Depends(get_arq_pool)):\n    job = await arq.enqueue_job(\"generate_report\", data.report_id)\n    return {\"job_id\": job.job_id}\n```\n\n## Configuration\n\nProduction Celery app configuration with secure defaults and worker tuning.\n\n### Key Patterns\n\n- **JSON serialization** with `task_serializer=\"json\"` for safety\n- **Late acknowledgment** with `task_acks_late=True` to prevent task loss on crash\n- **Time limits** with both `task_time_limit` (hard) and `task_soft_time_limit` (soft)\n- **Fair distribution** with `worker_prefetch_multiplier=1`\n- **Reject on lost** with `task_reject_on_worker_lost=True`\n\n### Key Decisions\n\n| Decision | Recommendation |\n|----------|------",
    "contentTruncated": true
  },
  "audit-full": {
    "content": "# Full-Codebase Audit\n\nSingle-pass whole-project analysis leveraging Opus 4.6's extended context window. Loads entire codebases (~50K LOC) into context for cross-file vulnerability detection, architecture review, and dependency analysis.\n\n## Quick Start\n\n```bash\n/ork:audit-full                          # Full audit (all modes)\n/ork:audit-full security                 # Security-focused audit\n/ork:audit-full architecture             # Architecture review\n/ork:audit-full dependencies             # Dependency audit\n```\n\n> **Opus 4.6**: Uses `complexity: max` for extended thinking across entire codebases. 1M context (beta, Tier 4+) enables cross-file reasoning that chunked approaches miss.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify audit scope:\n\n```python\nAskUserQuestion(\n  questions=[\n    {\n      \"question\": \"What type of audit do you want to run?\",\n      \"header\": \"Audit mode\",\n      \"options\": [\n        {\"label\": \"Full audit (Recommended)\", \"description\": \"Security + architecture + dependencies in one pass\"},\n        {\"label\": \"Security audit\", \"description\": \"Cross-file vulnerability analysis, data flow tracing, OWASP mapping\"},\n        {\"label\": \"Architecture review\", \"description\": \"Pattern consistency, coupling analysis, dependency violations\"},\n        {\"label\": \"Dependency audit\", \"description\": \"License compliance, CVE checking, version currency\"}\n      ],\n      \"multiSelect\": false\n    },\n    {\n      \"question\": \"What should be audited?\",\n      \"header\": \"Scope\",\n      \"options\": [\n        {\"label\": \"Entire codebase\", \"description\": \"Load all source files into context\"},\n        {\"label\": \"Specific directory\", \"description\": \"Focus on a subdirectory (e.g., src/api/)\"},\n        {\"label\": \"Changed files only\", \"description\": \"Audit only files changed vs main branch\"}\n      ],\n      \"multiSelect\": false\n    }\n  ]\n)\n```\n\n**Based on answers, adjust workflow:**\n- **Full audit**: All 3 domains, maximum context usage\n- **Security only**: Focus token budget on source + config files\n- **Architecture only**: Focus on module boundaries, imports, interfaces\n- **Dependency only**: Focus on lock files, manifests, import maps\n- **Changed files only**: Use `git diff --name-only main...HEAD` to scope\n\n---\n\n## CRITICAL: Task Management is MANDATORY\n\n```python\nTaskCreate(\n  subject=\"Full-codebase audit\",\n  description=\"Single-pass audit using extended context\",\n  activeForm=\"Running full-codebase audit\"\n)\n\n# Phase subtasks\nTaskCreate(subject=\"Estimate token budget and plan loading\", activeForm=\"Estimating token budget\")\nTaskCreate(subject=\"Load codebase into context\", activeForm=\"Loading codebase\")\nTaskCreate(subject=\"Run audit analysis\", activeForm=\"Analyzing codebase\")\nTaskCreate(subject=\"Generate audit report\", activeForm=\"Generating report\")\n```\n\n---\n\n## STEP 1: Estimate Token Budget\n\nBefore loading files, estimate whether the codebase fits in context.\n\n### Run Token Estimation\n\n```bash\n# Use the estimatio",
    "contentTruncated": true
  },
  "audit-skills": {
    "content": "# audit-skills\n\nScans all `src/skills/*/SKILL.md` files and reports compliance with OrchestKit authoring standards. Each category has individual files in `rules/` and `references/` loaded on-demand.\n\n## Quick Reference\n\n| Category | File | Impact | When to Use |\n|----------|------|--------|-------------|\n| Audit Checks | `rules/audit-checks.md` | HIGH | What to validate per skill |\n| Status Rules | `rules/audit-status.md` | MEDIUM | PASS/WARN/FAIL classification |\n| Output Format | `references/output-format.md` | MEDIUM | Table layout and column definitions |\n| Edge Cases | `references/edge-cases.md` | LOW | Manifest \"all\", orchestration skills |\n\n**Total: 2 rules across 2 categories**\n\n## Workflow\n\n1. **Discover** — Glob `src/skills/*/SKILL.md` to get full skill list\n2. **Check each skill** — Run all checks from `rules/audit-checks.md` in parallel\n3. **Classify** — Apply status rules from `rules/audit-status.md`\n4. **Render** — Output table using format from `references/output-format.md`\n5. **Totals** — Show `X pass, Y warn, Z fail` at bottom\n\n## Quick Start\n\n```bash\nbash src/skills/audit-skills/scripts/run-audit.sh\n```\n\nOr invoke manually — Claude scans `src/skills/`, applies checks, and renders the summary table.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Manifest check | `\"skills\": \"all\"` in ork.json means ALL skills qualify — mark YES |\n| 0 rules + refs | WARN only — some orchestration skills are legitimately rules-free |\n| Broken refs | WARN (not FAIL) — file may exist under a different path |\n\n## Related Skills\n\n- `ork:skill-evolution` — Guidance on iterating and improving skills\n- `ork:quality-gates` — Broader codebase quality checks",
    "contentTruncated": false
  },
  "brainstorming": {
    "content": "# Brainstorming Ideas Into Designs\n\nTransform rough ideas into fully-formed designs through intelligent agent selection and structured exploration.\n\n**Core principle:** Analyze the topic, select relevant agents dynamically, explore alternatives in parallel, present design incrementally.\n\n---\n\n## STEP 0: Project Context Discovery\n\n**BEFORE creating tasks or selecting agents**, detect the project tier. This becomes the **complexity ceiling** for all downstream decisions.\n\n### Auto-Detection (scan codebase)\n\n```python\n# PARALLEL — quick signals (launch all in ONE message)\nGrep(pattern=\"take-home|assignment|interview|hackathon\", glob=\"README*\", output_mode=\"content\")\nGrep(pattern=\"take-home|assignment|interview|hackathon\", glob=\"*.md\", output_mode=\"content\")\nGlob(pattern=\".github/workflows/*\")\nGlob(pattern=\"**/Dockerfile\")\nGlob(pattern=\"**/terraform/**\")\nGlob(pattern=\"**/k8s/**\")\nGlob(pattern=\"CONTRIBUTING.md\")\n```\n\n### Tier Classification\n\n| Signal | Tier |\n|--------|------|\n| README says \"take-home\", \"assignment\", time limit | **1. Interview** |\n| < 10 files, no CI, no Docker | **2. Hackathon** |\n| `.github/workflows/`, 10-25 deps | **3. MVP** |\n| Module boundaries, Redis, background jobs | **4. Growth** |\n| K8s/Terraform, DDD structure, monorepo | **5. Enterprise** |\n| CONTRIBUTING.md, LICENSE, minimal deps | **6. Open Source** |\n\n**If confidence is low**, ask the user:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"What kind of project is this?\",\n  \"header\": \"Project tier\",\n  \"options\": [\n    {\"label\": \"Interview / take-home\", \"description\": \"8-15 files, 200-600 LOC, simple architecture\"},\n    {\"label\": \"Startup / MVP\", \"description\": \"MVC monolith, managed services, ship fast\"},\n    {\"label\": \"Growth / enterprise\", \"description\": \"Modular monolith or DDD, full observability\"},\n    {\"label\": \"Open source library\", \"description\": \"Minimal API surface, exhaustive tests\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Pass the detected tier as context to ALL downstream agents and phases.** The tier constrains which patterns are appropriate — see `scope-appropriate-architecture` skill for the full matrix.\n\n> **Override:** User can always override the detected tier. Warn them of trade-offs if they choose a higher tier than detected.\n\n---\n\n## STEP 0a: Verify User Intent with AskUserQuestion\n\n**Clarify brainstorming constraints:**\n\n```python\nAskUserQuestion(\n  questions=[\n    {\n      \"question\": \"What type of design exploration?\",\n      \"header\": \"Type\",\n      \"options\": [\n        {\"label\": \"Open exploration (Recommended)\", \"description\": \"Generate 10+ ideas, evaluate all, synthesize top 3\"},\n        {\"label\": \"Constrained design\", \"description\": \"I have specific requirements to work within\"},\n        {\"label\": \"Comparison\", \"description\": \"Compare 2-3 specific approaches I have in mind\"},\n        {\"label\": \"Quick ideation\", \"description\": \"Generate ideas fast, skip deep evaluation\"}\n      ],\n      \"multiSelect\": false\n    },\n    {\n      \"question\": \"An",
    "contentTruncated": true
  },
  "browser-tools": {
    "content": "# Browser Tools\n\nOrchestKit orchestration wrapper for browser automation. Delegates command documentation to the upstream `agent-browser` skill and adds security rules, rate limiting, and ethical scraping guardrails.\n\n## Decision Tree\n\n```bash\n# Fallback decision tree for web content\n# 1. Try WebFetch first (fast, no browser overhead)\n# 2. If empty/partial -> Try Tavily extract/crawl\n# 3. If SPA or interactive -> use agent-browser\n# 4. If login required -> authentication flow + state save\n# 5. If dynamic -> wait @element or wait --text\n```\n\n## Security Rules (4 rules)\n\nThis skill enforces 4 security and ethics rules in `rules/`:\n\n| Category | Rules | Priority |\n|----------|-------|----------|\n| Ethics & Security | `browser-scraping-ethics.md`, `browser-auth-security.md` | CRITICAL |\n| Reliability | `browser-rate-limiting.md`, `browser-snapshot-workflow.md` | HIGH |\n\nThese rules are enforced by the `agent-browser-safety` pre-tool hook.\n\n## Anti-Patterns (FORBIDDEN)\n\n```bash\n# Automation\nagent-browser fill @e2 \"hardcoded-password\"    # Never hardcode credentials\nagent-browser open \"$UNVALIDATED_URL\"          # Always validate URLs\n\n# Scraping\n# Crawling without checking robots.txt\n# No delay between requests (hammering servers)\n# Ignoring rate limit responses (429)\n\n# Content capture\nagent-browser get text body                    # Prefer targeted ref extraction\n# Trusting page content without validation\n# Not waiting for SPA hydration before extraction\n\n# Session management\n# Storing auth state in code repositories\n# Not cleaning up state files after use\n```\n\n## Related Skills\n\n- `agent-browser` (upstream) - Full command reference and usage patterns\n- `ork:web-research-workflow` - Unified decision tree for web research\n- `ork:testing-patterns` - Comprehensive testing patterns including E2E and webapp testing\n- `ork:api-design` - API design patterns for endpoints discovered during scraping",
    "contentTruncated": false
  },
  "checkpoint-resume": {
    "content": "# Checkpoint Resume\n\nRate-limit-resilient pipeline orchestrator. Saves progress to `.claude/pipeline-state.json` after every phase so long sessions survive interruptions.\n\n## Quick Reference\n\n| Category | Rule | Impact | Key Pattern |\n|----------|------|--------|-------------|\n| Phase Ordering | `rules/ordering-priority.md` | CRITICAL | GitHub issues/commits first, file-heavy phases last |\n| State Writes | `rules/state-write-timing.md` | CRITICAL | Write after every phase, never batch |\n| Mini-Commits | `rules/checkpoint-mini-commit.md` | HIGH | Every 3 phases, checkpoint commit format |\n\n**Total: 3 rules across 3 categories**\n\n## On Invocation\n\n**If `.claude/pipeline-state.json` exists:** run `scripts/show-status.sh` to display progress, then ask to resume, pick a different phase, or restart. See `references/resume-decision-tree.md` for the full decision tree.\n\n**If no state file exists:** ask the user to describe the task, build an execution plan, write initial state via `scripts/init-pipeline.sh <branch>`, begin Phase 1.\n\n## Execution Plan Structure\n\n```json\n{\n  \"phases\": [\n    { \"id\": \"create-issues\", \"name\": \"Create GitHub Issues\", \"dependencies\": [], \"status\": \"pending\" },\n    { \"id\": \"commit-scaffold\", \"name\": \"Commit Scaffold\", \"dependencies\": [], \"status\": \"pending\" },\n    { \"id\": \"write-source\", \"name\": \"Write Source Files\", \"dependencies\": [\"commit-scaffold\"], \"status\": \"pending\" }\n  ]\n}\n```\n\nPhases with empty `dependencies` may run in parallel via Task sub-agents (when they don't share file writes).\n\n## After Each Phase\n\n1. Update `.claude/pipeline-state.json` — see `rules/state-write-timing.md`\n2. Every 3 phases: create a mini-commit — see `rules/checkpoint-mini-commit.md`\n\n## References\n\n- [Pipeline State Schema](references/pipeline-state-schema.md) — full field-by-field schema with examples\n- [Pipeline State JSON Schema](references/pipeline-state.schema.json) — machine-readable JSON Schema for validation\n- [Resume Decision Tree](references/resume-decision-tree.md) — logic for resuming, picking phases, or restarting\n\n## Scripts\n\n- `scripts/init-pipeline.sh <branch>` — print skeleton state JSON to stdout\n- `scripts/show-status.sh [path]` — print human-readable pipeline status (requires `jq`)\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Phase granularity | One meaningful deliverable per phase (a commit, a set of issues, a feature) |\n| Parallelism | Task sub-agents only for phases with empty `dependencies` that don't share file writes |\n| Rate limit recovery | State is already saved — re-invoke `/checkpoint-resume` to continue |",
    "contentTruncated": false
  },
  "code-review-playbook": {
    "content": "# Code Review Playbook\nThis skill provides a comprehensive framework for effective code reviews that improve code quality, share knowledge, and foster collaboration. Whether you're a reviewer giving feedback or an author preparing code for review, this playbook ensures reviews are thorough, consistent, and constructive.\n\n## Overview\n- Reviewing pull requests or merge requests\n- Preparing code for review (self-review)\n- Establishing code review standards for teams\n- Training new developers on review best practices\n- Resolving disagreements about code quality\n- Improving review processes and efficiency\n\n## Code Review Philosophy\n\n### Purpose of Code Reviews\n\nCode reviews serve multiple purposes:\n\n1. **Quality Assurance**: Catch bugs, logic errors, and edge cases\n2. **Knowledge Sharing**: Spread domain knowledge across the team\n3. **Consistency**: Ensure codebase follows conventions and patterns\n4. **Mentorship**: Help developers improve their skills\n5. **Collective Ownership**: Build shared responsibility for code\n6. **Documentation**: Create discussion history for future reference\n\n### Principles\n\n**Be Kind and Respectful:**\n- Review the code, not the person\n- Assume positive intent\n- Praise good solutions\n- Frame feedback constructively\n\n**Be Specific and Actionable:**\n- Point to specific lines of code\n- Explain *why* something should change\n- Suggest concrete improvements\n- Provide examples when helpful\n\n**Balance Speed with Thoroughness:**\n- Aim for timely feedback (< 24 hours)\n- Don't rush critical reviews\n- Use automation for routine checks\n- Focus human review on logic and design\n\n**Distinguish Must-Fix from Nice-to-Have:**\n- Use conventional comments to indicate severity\n- Block merges only for critical issues\n- Allow authors to defer minor improvements\n- Capture deferred work in follow-up tickets\n\n---\n\n## Conventional Comments\n\nA standardized format for review comments that makes intent clear.\n\n### Format\n\n```\n<label> [decorations]: <subject>\n\n[discussion]\n```\n\n### Labels\n\n| Label | Meaning | Blocks Merge? |\n|-------|---------|---------------|\n| **praise** | Highlight something positive | No |\n| **nitpick** | Minor, optional suggestion | No |\n| **suggestion** | Propose an improvement | No |\n| **issue** | Problem that should be addressed | Usually |\n| **question** | Request clarification | No |\n| **thought** | Idea to consider | No |\n| **chore** | Routine task (formatting, deps) | No |\n| **note** | Informational comment | No |\n| **todo** | Follow-up work needed | Maybe |\n| **security** | Security concern | **Yes** |\n| **bug** | Potential bug | **Yes** |\n| **breaking** | Breaking change | **Yes** |\n\n### Decorations\n\nOptional modifiers in square brackets:\n\n| Decoration | Meaning |\n|------------|---------|\n| **[blocking]** | Must be addressed before merge |\n| **[non-blocking]** | Optional, can be deferred |\n| **[if-minor]** | Only if it's a quick fix |\n\n### Examples\n\n```typescript\n// ✅ Good: Clear, specific, actionable\n\npraise: Excellent use o",
    "contentTruncated": true
  },
  "commit": {
    "content": "# Smart Commit\n\nSimple, validated commit creation. Run checks locally, no agents needed for standard commits.\n\n## Quick Start\n\n```bash\n/ork:commit\n```\n\n## Workflow\n\n### Phase 1: Pre-Commit Safety Check\n\n```bash\n# CRITICAL: Verify we're not on dev/main\nBRANCH=$(git branch --show-current)\nif [[ \"$BRANCH\" == \"dev\" || \"$BRANCH\" == \"main\" || \"$BRANCH\" == \"master\" ]]; then\n  echo \"STOP! Cannot commit directly to $BRANCH\"\n  echo \"Create a feature branch: git checkout -b issue/<number>-<description>\"\n  exit 1\nfi\n```\n\n### Phase 2: Run Validation Locally\n\nRun every check that CI runs:\n\n```bash\n# Backend (Python)\npoetry run ruff format --check app/\npoetry run ruff check app/\npoetry run mypy app/\n\n# Frontend (Node.js)\nnpm run format:check\nnpm run lint\nnpm run typecheck\n```\n\nFix any failures before proceeding.\n\n### Phase 3: Review Changes\n\n```bash\ngit status\ngit diff --staged   # What will be committed\ngit diff            # Unstaged changes\n```\n\n### Phase 4: Stage and Commit\n\n```bash\n# Stage files\ngit add <files>\n# Or all: git add .\n\n# Commit with conventional format\ngit commit -m \"<type>(#<issue>): <brief description>\n\n- [Change 1]\n- [Change 2]\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n\n# Verify\ngit log -1 --stat\n```\n\n## Commit Types\n\n| Type | Use For |\n|------|---------|\n| `feat` | New feature |\n| `fix` | Bug fix |\n| `refactor` | Code improvement |\n| `docs` | Documentation |\n| `test` | Tests only |\n| `chore` | Build/deps/CI |\n\n## Rules\n\n1. **Run validation locally** - Don't spawn agents to run lint/test\n2. **NO file creation** - Don't create MD files or documentation\n3. **One logical change per commit** - Keep commits focused\n4. **Reference issues** - Use `#123` format in commit message\n5. **Subject line < 72 chars** - Keep it concise\n\n## Quick Commit\n\nFor trivial changes (typos, single-line fixes):\n\n```bash\ngit add . && git commit -m \"fix(#123): Fix typo in error message\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n```\n\n## Related Skills\n- `ork:create-pr`: Create pull requests from commits\n- `ork:review-pr`: Review changes before committing\n- `ork:fix-issue`: Fix issues and commit the fixes\n- `ork:issue-progress-tracking`: Auto-updates GitHub issues with commit progress\n\n## Rules\n\nEach category has individual rule files in `rules/` loaded on-demand:\n\n| Category | Rule | Impact | Key Pattern |\n|----------|------|--------|-------------|\n| Atomic Commits | `rules/atomic-commit.md` | CRITICAL | One logical change per commit, atomicity test |\n| Commit Splitting | `rules/commit-splitting.md` | HIGH | `git add -p`, interactive staging, separation strategies |\n| Conventional Format | `rules/conventional-format.md` | HIGH | type(scope): description, breaking changes |\n| Issue Reference | `rules/issue-reference-required.md` | HIGH | Reference issue `#N` in commits on issue branches |\n\n**Total: 4 rules across 4 categories**\n\n## References\n\n- [Conventional Commits](references/conventional-commits.md)\n- [Recovery](references/recovery.md)",
    "contentTruncated": false
  },
  "configure": {
    "content": "# OrchestKit Configuration\n\nInteractive setup for customizing your OrchestKit installation.\n\n## Quick Start\n\n```bash\n/ork:configure\n```\n\n## Step 1: Choose Preset\n\nUse AskUserQuestion:\n\n| Preset | Skills | Agents | Hooks | Description |\n|--------|--------|--------|-------|-------------|\n| **Complete** | 78 | 20 | 92 | Everything |\n| **Standard** | 78 | 0 | 92 | Skills, no agents |\n| **Lite** | 10 | 0 | 92 | Essential only |\n| **Hooks-only** | 0 | 0 | 92 | Just safety |\n| **Monorepo** | 78 | 20 | 92 | Complete + monorepo detection |\n\n## Step 2: Customize Skill Categories\n\nCategories available:\n- AI/ML (26 skills)\n- Backend (15 skills)\n- Frontend (8 skills)\n- Testing (13 skills)\n- Security (7 skills)\n- DevOps (4 skills)\n- Planning (6 skills)\n\n## Step 3: Customize Agents\n\n**Product Agents (6):**\n- market-intelligence\n- product-strategist\n- requirements-translator\n- ux-researcher\n- prioritization-analyst\n- business-case-builder\n\n**Technical Agents (14):**\n- backend-system-architect\n- frontend-ui-developer\n- database-engineer\n- llm-integrator\n- workflow-architect\n- data-pipeline-engineer\n- test-generator\n- code-quality-reviewer\n- security-auditor\n- security-layer-auditor\n- debug-investigator\n- metrics-architect\n- rapid-ui-designer\n- system-design-reviewer\n\n## Step 4: Configure Hooks\n\n**Safety Hooks (Always On):**\n- git-branch-protection\n- file-guard\n- redact-secrets\n\n**Toggleable Hooks:**\n- Productivity (auto-approve, logging)\n- Quality Gates (coverage, patterns)\n- Team Coordination (locks, conflicts)\n- Notifications (desktop, sound)\n\n> **CC 2.1.49 Managed Settings:** OrchestKit ships plugin `settings.json` with default hook permissions. These are *managed defaults* — users can override them in project or user settings. Enterprise admins can lock managed settings via managed profiles.\n\n## Step 5: Configure MCPs (Optional)\n\nAll 5 MCPs ship **enabled by default**. Tavily requires an API key; agentation requires a local package install.\n\n| MCP | Purpose | Default | Requires |\n|-----|---------|---------|----------|\n| context7 | Library documentation | enabled | Nothing |\n| memory | Cross-session persistence | enabled | Nothing |\n| sequential-thinking | Structured reasoning for subagents | enabled | Nothing |\n| tavily | Web search + extraction | enabled | API key (free tier: app.tavily.com) |\n| agentation | UI annotation tool | enabled | `npm install agentation-mcp` |\n\n> **Why all enabled?** OrchestKit ships 30+ Sonnet/Haiku subagents. While Opus 4.6 has native extended thinking, Sonnet and Haiku do not — they benefit from sequential-thinking. Tavily and agentation are used by specific agents (see `mcpServers` in agent frontmatter). CC's MCPSearch auto-defers schemas when overhead exceeds 10% of context, so token cost is managed automatically.\n\n> **Background agents:** MCP tools are NOT available in background subagents (hard CC platform limitation). Agents that need MCP tools must run in the foreground.\n\n**Already have these MCPs installed globally?** If T",
    "contentTruncated": true
  },
  "create-pr": {
    "content": "# Create Pull Request\n\nComprehensive PR creation with validation. All output goes directly to GitHub PR.\n\n## Quick Start\n\n```bash\n/ork:create-pr\n```\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify PR type:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of PR is this?\",\n    \"header\": \"Type\",\n    \"options\": [\n      {\"label\": \"Feature (Recommended)\", \"description\": \"New functionality with full validation\"},\n      {\"label\": \"Bug fix\", \"description\": \"Fix for existing issue\"},\n      {\"label\": \"Refactor\", \"description\": \"Code improvement, no behavior change\"},\n      {\"label\": \"Quick\", \"description\": \"Skip validation, just create PR\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Feature**: Full validation with all agents\n- **Bug fix**: Focus on test verification\n- **Refactor**: Skip new feature validation\n- **Quick**: Skip all validation, just create PR\n\n---\n\n## ⚠️ CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n**BEFORE doing ANYTHING else, create tasks to show progress:**\n\n```python\n# 1. Create main PR task IMMEDIATELY\nTaskCreate(\n  subject=\"Create PR for {branch}\",\n  description=\"PR creation with parallel validation agents\",\n  activeForm=\"Creating pull request\"\n)\n\n# 2. Create subtasks for phases\nTaskCreate(subject=\"Pre-flight checks\", activeForm=\"Running pre-flight checks\")\nTaskCreate(subject=\"Run parallel validation agents\", activeForm=\"Validating with agents\")\nTaskCreate(subject=\"Run local tests\", activeForm=\"Running local tests\")\nTaskCreate(subject=\"Create PR on GitHub\", activeForm=\"Creating GitHub PR\")\n\n# 3. Update status as you progress\nTaskUpdate(taskId=\"2\", status=\"in_progress\")  # When starting phase\nTaskUpdate(taskId=\"2\", status=\"completed\")    # When phase done\n```\n\n---\n\n## Workflow\n\n### Phase 1: Pre-Flight Checks\n\n```bash\n# Verify branch\nBRANCH=$(git branch --show-current)\nif [[ \"$BRANCH\" == \"dev\" || \"$BRANCH\" == \"main\" ]]; then\n  echo \"Cannot create PR from dev/main. Create a feature branch first.\"\n  exit 1\nfi\n\n# Check for uncommitted changes\nif [[ -n $(git status --porcelain) ]]; then\n  echo \"Uncommitted changes detected. Commit or stash first.\"\n  exit 1\nfi\n\n# Push branch if needed\ngit fetch origin\nif ! git rev-parse --verify origin/$BRANCH &>/dev/null; then\n  git push -u origin $BRANCH\nfi\n```\n\n### Phase 2: Parallel Pre-PR Validation (3 Agents)\n\nLaunch validation agents in ONE message BEFORE creating PR:\n\n```python\n# PARALLEL - All 3 in ONE message\nTask(\n  subagent_type=\"security-auditor\",\n  prompt=\"\"\"Security audit for PR changes:\n  1. Check for secrets/credentials in diff\n  2. Dependency vulnerabilities (npm audit/pip-audit)\n  3. OWASP Top 10 quick scan\n  Return: {status: PASS/BLOCK, issues: [...]}\n\n  Scope: ONLY read files directly relevant to the PR diff. Do NOT explore the entire codebase.\n\n  SUMMARY: End with: \"RESULT: [PASS|WARN|BLOCK] - [N] issues: [brief list or 'clean']\"\n  \"\"\",\n  run_in_background=True,\n  max_turns=2",
    "contentTruncated": true
  },
  "database-patterns": {
    "content": "# Database Patterns\n\nComprehensive patterns for database migrations, schema design, and version management. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Alembic Migrations](#alembic-migrations) | 3 | CRITICAL | Autogenerate, data migrations, branch management |\n| [Schema Design](#schema-design) | 3 | HIGH | Normalization, indexing strategies, NoSQL patterns |\n| [Versioning](#versioning) | 3 | HIGH | Changelogs, rollback plans, schema drift detection |\n| [Zero-Downtime Migration](#zero-downtime-migration) | 2 | CRITICAL | Expand-contract, pgroll, rollback monitoring |\n\n| [Database Selection](#database-selection) | 1 | HIGH | Choosing the right database, PostgreSQL vs MongoDB, cost analysis |\n\n**Total: 12 rules across 5 categories**\n\n## Quick Start\n\n```python\n# Alembic: Auto-generate migration from model changes\n# alembic revision --autogenerate -m \"add user preferences\"\n\ndef upgrade() -> None:\n    op.add_column('users', sa.Column('org_id', UUID(as_uuid=True), nullable=True))\n    op.execute(\"UPDATE users SET org_id = 'default-org-uuid' WHERE org_id IS NULL\")\n\ndef downgrade() -> None:\n    op.drop_column('users', 'org_id')\n```\n\n```sql\n-- Schema: Normalization to 3NF with proper indexing\nCREATE TABLE orders (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    customer_id UUID NOT NULL REFERENCES customers(id),\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\nCREATE INDEX idx_orders_customer_id ON orders(customer_id);\n```\n\n## Alembic Migrations\n\nMigration management with Alembic for SQLAlchemy 2.0 async applications.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Autogenerate | `rules/alembic-autogenerate.md` | Auto-generate from models, async env.py, review workflow |\n| Data Migration | `rules/alembic-data-migration.md` | Batch backfill, two-phase NOT NULL, zero-downtime |\n| Branching | `rules/alembic-branching.md` | Feature branches, merge migrations, conflict resolution |\n\n## Schema Design\n\nSQL and NoSQL schema design with normalization, indexing, and constraint patterns.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Normalization | `rules/schema-normalization.md` | 1NF-3NF, when to denormalize, JSON vs normalized |\n| Indexing | `rules/schema-indexing.md` | B-tree, GIN, HNSW, partial/covering indexes |\n| NoSQL Patterns | `rules/schema-nosql.md` | Embed vs reference, document design, sharding |\n\n## Versioning\n\nDatabase version control and change management across environments.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Changelog | `rules/versioning-changelog.md` | Schema version table, semantic versioning, audit trails |\n| Rollback | `rules/versioning-rollback.md` | Rollback testing, destructive rollback docs, CI verification |\n| Drift Detection | `rules/versioning-drift.md` | Environment sync, checksum verification, migration locks |\n\n## Database Selectio",
    "contentTruncated": true
  },
  "demo-producer": {
    "content": "# Demo Producer\n\nUniversal demo video creation for any content type.\n\n## Quick Start\n\n```bash\n/ork:demo-producer                    # Interactive mode - asks what to create\n/ork:demo-producer skill explore      # Create demo for a skill\n/ork:demo-producer plugin ork     # Create demo for a plugin\n/ork:demo-producer tutorial \"Building a REST API\"  # Custom tutorial\n```\n\n## Supported Content Types\n\n| Type | Source | Example |\n|------|--------|---------|\n| `skill` | skills/{name}/SKILL.md | `/ork:demo-producer skill commit` |\n| `agent` | agents/{name}.md | `/ork:demo-producer agent debug-investigator` |\n| `plugin` | plugins/{name}/plugin.json | `/ork:demo-producer plugin ork` |\n| `marketplace` | Marketplace install flow | `/ork:demo-producer marketplace ork` |\n| `tutorial` | Custom description | `/ork:demo-producer tutorial \"Git workflow\"` |\n| `cli` | Any CLI tool | `/ork:demo-producer cli \"npm create vite\"` |\n| `code` | Code walkthrough | `/ork:demo-producer code src/api/auth.ts` |\n\n## Interactive Flow\n\nWhen invoked without arguments, asks:\n\n### Question 1: Content Type\n```\nWhat type of demo do you want to create?\n\n○ Skill - OrchestKit skill showcase\n○ Agent - AI agent demonstration\n○ Plugin - Plugin installation/features\n○ Tutorial - Custom coding tutorial\n○ CLI Tool - Command-line tool demo\n○ Code Walkthrough - Explain existing code\n```\n\n### Question 2: Format\n```\nWhat format(s) do you need?\n\n☑ Horizontal (16:9) - YouTube, Twitter\n☑ Vertical (9:16) - TikTok, Reels, Shorts\n☐ Square (1:1) - Instagram, LinkedIn\n```\n\n### Question 3: Style\n```\nWhat style fits your content?\n\n○ Quick Demo (6-10s) - Fast showcase, single feature\n○ Standard Demo (15-25s) - Full workflow, multiple steps\n○ Tutorial (30-60s) - Detailed explanation, code examples\n○ Cinematic (60s+) - Story-driven, high polish\n○ Scrapbook (15-35s) - Warm paper, fast cuts, social proof collage (Anthropic style)\n```\n\n### Question 4: Audio\n```\nAudio preferences?\n\n○ Music Only - Subtle ambient background\n○ Music + SFX - Background + success sounds\n○ Silent - No audio\n```\n\n## Pipeline Architecture\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│                     Demo Producer Pipeline                        │\n├──────────────────────────────────────────────────────────────────┤\n│                                                                   │\n│  ┌─────────────┐    ┌──────────────┐    ┌─────────────────────┐  │\n│  │   Content   │───▶│   Content    │───▶│   Script Generator  │  │\n│  │   Detector  │    │   Analyzer   │    │   (per type)        │  │\n│  └─────────────┘    └──────────────┘    └──────────┬──────────┘  │\n│                                                     │             │\n│                                                     ▼             │\n│  ┌─────────────┐    ┌──────────────┐    ┌─────────────────────┐  │\n│  │  Remotion   │◀───│    VHS       │◀───│   Terminal Script   │  │\n│  │  Composer   │    │   Recorder   │    │   (.sh + .tape)     │  │\n│  └──────┬─",
    "contentTruncated": true
  },
  "devops-deployment": {
    "content": "# DevOps & Deployment Skill\n\nComprehensive frameworks for CI/CD pipelines, containerization, deployment strategies, and infrastructure automation.\n\n## Overview\n\n- Setting up CI/CD pipelines\n- Containerizing applications\n- Deploying to Kubernetes or cloud platforms\n- Implementing GitOps workflows\n- Managing infrastructure as code\n- Planning release strategies\n\n## Pipeline Architecture\n\n```\n┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐\n│    Code     │──>│    Build    │──>│    Test     │──>│   Deploy    │\n│   Commit    │   │   & Lint    │   │   & Scan    │   │  & Release  │\n└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘\n       │                 │                 │                 │\n       v                 v                 v                 v\n   Triggers         Artifacts          Reports          Monitoring\n```\n\n## Key Concepts\n\n### CI/CD Pipeline Stages\n\n1. **Lint & Type Check** - Code quality gates\n2. **Unit Tests** - Test coverage with reporting\n3. **Security Scan** - npm audit + Trivy vulnerability scanner\n4. **Build & Push** - Docker image to container registry\n5. **Deploy Staging** - Environment-gated deployment\n6. **Deploy Production** - Manual approval or automated\n\n### Container Best Practices\n\n**Multi-stage builds** minimize image size:\n- Stage 1: Install production dependencies only\n- Stage 2: Build application with dev dependencies\n- Stage 3: Production runtime with minimal footprint\n\n**Security hardening**:\n- Non-root user (uid 1001)\n- Read-only filesystem where possible\n- Health checks for orchestrator integration\n\n### Kubernetes Deployment\n\n**Essential manifests**:\n- Deployment with rolling update strategy\n- Service for internal routing\n- Ingress for external access with TLS\n- HorizontalPodAutoscaler for scaling\n\n**Security context**:\n- `runAsNonRoot: true`\n- `allowPrivilegeEscalation: false`\n- `readOnlyRootFilesystem: true`\n- Drop all capabilities\n\n### Deployment Strategies\n\n| Strategy | Use Case | Risk |\n|----------|----------|------|\n| **Rolling** | Default, gradual replacement | Low - automatic rollback |\n| **Blue-Green** | Instant switch, easy rollback | Medium - double resources |\n| **Canary** | Progressive traffic shift | Low - gradual exposure |\n\n**Rolling Update** (Kubernetes default):\n```yaml\nstrategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 25%\n    maxUnavailable: 0  # Zero downtime\n```\n\n### Secrets Management\n\nUse External Secrets Operator to sync from cloud providers:\n- AWS Secrets Manager\n- HashiCorp Vault\n- Azure Key Vault\n- GCP Secret Manager\n\n---\n\n## References\n\n### Docker Patterns\n**See: `references/docker-patterns.md`**\n\nKey topics covered:\n- Multi-stage build examples with 78% size reduction\n- Layer caching optimization\n- Security hardening (non-root, health checks)\n- Trivy vulnerability scanning\n- Docker Compose development setup\n\n### CI/CD Pipelines\n**See: `references/ci-cd-pipelines.md`**\n\nKey topics covered:\n- Branch strategy (Git Flow)\n- GitHub Acti",
    "contentTruncated": true
  },
  "distributed-systems": {
    "content": "# Distributed Systems Patterns\n\nComprehensive patterns for building reliable distributed systems. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Distributed Locks](#distributed-locks) | 3 | CRITICAL | Redis/Redlock locks, PostgreSQL advisory locks, fencing tokens |\n| [Resilience](#resilience) | 3 | CRITICAL | Circuit breakers, retry with backoff, bulkhead isolation |\n| [Idempotency](#idempotency) | 3 | HIGH | Idempotency keys, request dedup, database-backed idempotency |\n| [Rate Limiting](#rate-limiting) | 3 | HIGH | Token bucket, sliding window, distributed rate limits |\n| [Edge Computing](#edge-computing) | 2 | HIGH | Edge workers, V8 isolates, CDN caching, geo-routing |\n| [Event-Driven](#event-driven) | 2 | HIGH | Event sourcing, CQRS, transactional outbox, sagas |\n\n**Total: 16 rules across 6 categories**\n\n## Quick Start\n\n```python\n# Redis distributed lock with Lua scripts\nasync with RedisLock(redis_client, \"payment:order-123\"):\n    await process_payment(order_id)\n\n# Circuit breaker for external APIs\n@circuit_breaker(failure_threshold=5, recovery_timeout=30)\n@retry(max_attempts=3, base_delay=1.0)\nasync def call_external_api():\n    ...\n\n# Idempotent API endpoint\n@router.post(\"/payments\")\nasync def create_payment(\n    data: PaymentCreate,\n    idempotency_key: str = Header(..., alias=\"Idempotency-Key\"),\n):\n    return await idempotent_execute(db, idempotency_key, \"/payments\", process)\n\n# Token bucket rate limiting\nlimiter = TokenBucketLimiter(redis_client, capacity=100, refill_rate=10)\nif await limiter.is_allowed(f\"user:{user_id}\"):\n    await handle_request()\n```\n\n## Distributed Locks\n\nCoordinate exclusive access to resources across multiple service instances.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Redis & Redlock | `rules/locks-redis-redlock.md` | Lua scripts, SET NX, multi-node quorum |\n| PostgreSQL Advisory | `rules/locks-postgres-advisory.md` | Session/transaction locks, lock ID strategies |\n| Fencing Tokens | `rules/locks-fencing-tokens.md` | Owner validation, TTL, heartbeat extension |\n\n## Resilience\n\nProduction-grade fault tolerance for distributed systems.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Circuit Breaker | `rules/resilience-circuit-breaker.md` | CLOSED/OPEN/HALF_OPEN states, sliding window |\n| Retry & Backoff | `rules/resilience-retry-backoff.md` | Exponential backoff, jitter, error classification |\n| Bulkhead Isolation | `rules/resilience-bulkhead.md` | Semaphore tiers, rejection policies, queue depth |\n\n## Idempotency\n\nEnsure operations can be safely retried without unintended side effects.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Idempotency Keys | `rules/idempotency-keys.md` | Deterministic hashing, Stripe-style headers |\n| Request Dedup | `rules/idempotency-dedup.md` | Event consumer dedup, Redis + DB dual layer |\n| Database-Ba",
    "contentTruncated": true
  },
  "doctor": {
    "content": "# OrchestKit Health Diagnostics\n\n## Overview\n\nThe `/ork:doctor` command performs comprehensive health checks on your OrchestKit installation. It auto-detects installed plugins and validates 11 categories:\n\n1. **Installed Plugins** - Detects orkl or ork\n2. **Skills Validation** - Frontmatter, references, token budget (dynamic count)\n3. **Agents Validation** - Frontmatter, tool refs, skill refs (dynamic count)\n4. **Hook Health** - Registration, bundles, async patterns\n5. **Permission Rules** - Detects unreachable rules (CC 2.1.3 feature)\n6. **Schema Compliance** - Validates JSON files against schemas\n7. **Coordination System** - Checks lock health and registry integrity\n8. **Context Budget** - Monitors token usage against budget\n9. **Memory System** - Graph memory health\n10. **Claude Code Version** - Validates CC >= 2.1.47\n11. **External Dependencies** - Checks optional tool availability (agent-browser)\n12. **MCP Status** - Active vs disabled vs misconfigured, API key presence for paid MCPs\n\n## When to Use\n\n- After installing or updating OrchestKit\n- When hooks aren't firing as expected\n- Before deploying to a team environment\n- When debugging coordination issues\n- After running `npm run build`\n\n## Quick Start\n\n```bash\n/ork:doctor           # Standard health check\n/ork:doctor -v        # Verbose output\n/ork:doctor --json    # Machine-readable for CI\n```\n\n## CLI Options\n\n| Flag | Description |\n|------|-------------|\n| `-v`, `--verbose` | Detailed output per check |\n| `--json` | JSON output for CI integration |\n| `--category=X` | Run only specific category |\n\n## Health Check Categories\n\n### 0. Installed Plugins Detection\n\nAuto-detects which OrchestKit plugins are installed:\n\n```bash\n# Detection logic:\n# - Scans for .claude-plugin/plugin.json in plugin paths\n# - Identifies orkl or ork\n# - Counts skills/agents per installed plugin\n```\n\n**Output (orkl):**\n```\nInstalled Plugins: 1\n- orkl: 46 skills, 37 agents, 87 hook entries\n```\n\n**Output (ork full):**\n```\nInstalled Plugins: 1\n- ork: 67 skills, 37 agents, 87 hook entries\n```\n\n### 1. Skills Validation\n\nValidates skills in installed plugins (count varies by installation):\n\n```bash\n# Checks performed:\n# - SKILL.md frontmatter (name, description, user-invocable)\n# - context: fork field (required for CC 2.1.0+)\n# - Token budget compliance (300-5000 tokens)\n# - Internal link validation (references/ paths)\n# - Related Skills references exist\n```\n\n**Output (full ork):**\n```\nSkills: 67/67 valid\n- User-invocable: 24 commands\n- Reference skills: 38\n```\n\n**Output (orkl only):**\n```\nSkills: 46/46 valid\n- User-invocable: 24 commands\n- Reference skills: 21\n```\n\n### 2. Agents Validation\n\nValidates agents in installed plugins:\n\n```bash\n# Checks performed:\n# - Frontmatter fields (name, description, model, tools, skills)\n# - Model validation (opus, sonnet, haiku only)\n# - Skills references exist in src/skills/\n# - Tools are valid CC tools\n```\n\n**Output:**\n```\nAgents: 36/36 valid\n- Models: 12 sonnet, 15 haiku, 8 opus\n- All",
    "contentTruncated": true
  },
  "domain-driven-design": {
    "content": "# Domain-Driven Design Tactical Patterns\n\nModel complex business domains with entities, value objects, and bounded contexts.\n\n## Overview\n\n- Modeling complex business logic\n- Separating domain from infrastructure\n- Establishing clear boundaries between subdomains\n- Building rich domain models with behavior\n- Implementing ubiquitous language in code\n\n## Building Blocks Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    DDD Building Blocks                       │\n├─────────────────────────────────────────────────────────────┤\n│  ENTITIES           VALUE OBJECTS        AGGREGATES         │\n│  Order (has ID)     Money (no ID)        [Order]→Items      │\n│                                                              │\n│  DOMAIN SERVICES    REPOSITORIES         DOMAIN EVENTS      │\n│  PricingService     IOrderRepository     OrderSubmitted     │\n│                                                              │\n│  FACTORIES          SPECIFICATIONS       MODULES            │\n│  OrderFactory       OverdueOrderSpec     orders/, payments/ │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Quick Reference\n\n### Entity (Has Identity)\n\n```python\nfrom dataclasses import dataclass, field\nfrom uuid import UUID\nfrom uuid_utils import uuid7\n\n@dataclass\nclass Order:\n    \"\"\"Entity: Has identity, mutable state, lifecycle.\"\"\"\n    id: UUID = field(default_factory=uuid7)\n    customer_id: UUID = field(default=None)\n    status: str = \"draft\"\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, Order):\n            return NotImplemented\n        return self.id == other.id  # Identity equality\n\n    def __hash__(self) -> int:\n        return hash(self.id)\n```\n\nSee [entities-value-objects.md](references/entities-value-objects.md) for complete patterns.\n\n### Value Object (Immutable)\n\n```python\nfrom dataclasses import dataclass\nfrom decimal import Decimal\n\n@dataclass(frozen=True)  # MUST be frozen!\nclass Money:\n    \"\"\"Value Object: Defined by attributes, not identity.\"\"\"\n    amount: Decimal\n    currency: str\n\n    def __add__(self, other: \"Money\") -> \"Money\":\n        if self.currency != other.currency:\n            raise ValueError(\"Cannot add different currencies\")\n        return Money(self.amount + other.amount, self.currency)\n```\n\nSee [entities-value-objects.md](references/entities-value-objects.md) for Address, DateRange examples.\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Entity vs VO | Has unique ID + lifecycle? Entity. Otherwise VO |\n| Entity equality | By ID, not attributes |\n| Value object mutability | Always immutable (`frozen=True`) |\n| Repository scope | One per aggregate root |\n| Domain events | Collect in entity, publish after persist |\n| Context boundaries | By business capability, not technical |\n\n## Rules Quick Reference\n\n| Rule | Impact | What It Covers |\n|------|--------|----------------|\n| [aggregate-boundaries](rules/aggregate-bounda",
    "contentTruncated": true
  },
  "errors": {
    "content": "# Error Pattern Analysis\n\nAnalyze errors captured from Claude Code sessions to identify patterns and get actionable insights.\n\n## Quick Start\n\n```bash\n/errors              # Batch analysis of historical error patterns\n/debug               # CC 2.1.30 real-time debug for current session\n```\n\n### When to Use Which\n\n| Command | Purpose | Scope |\n|---------|---------|-------|\n| `/errors` | Batch analysis of error patterns (last 24h/7d) | Historical patterns |\n| `/debug` | Real-time debug of current session state | Current session |\n| `/ork:fix-issue` | Full RCA workflow for specific bug | Single issue |\n\n## Quick Analysis\n\n```bash\n# Run batch analysis on last 24h of errors\npython .claude/scripts/analyze_errors.py\n\n# Analyze last 7 days\npython .claude/scripts/analyze_errors.py --days 7\n\n# Generate markdown report\npython .claude/scripts/analyze_errors.py --report\n```\n\n## What Gets Captured\n\nThe error collector hook captures:\n- Tool name (Bash, mcp__memory__search_nodes, etc.)\n- Error message (first 500 chars)\n- Tool input (command/query that failed)\n- Timestamp and session ID\n\n**Location:** `.claude/logs/errors.jsonl`\n\n## Current Error Rules\n\nCheck learned patterns that trigger warnings:\n\n```bash\ncat .claude/rules/error_rules.json | jq '.rules[] | {id, signature, count: .occurrence_count}'\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `.claude/hooks/posttool/error-collector.sh` | Captures errors to JSONL |\n| `.claude/hooks/pretool/bash/error-pattern-warner.sh` | Warns before risky commands |\n| `.claude/scripts/analyze_errors.py` | Batch pattern analysis |\n| `.claude/rules/error_rules.json` | Learned error patterns |\n| `.claude/logs/errors.jsonl` | Raw error log |\n\n## Common Patterns\n\n### PostgreSQL Connection Errors\n\n```\npattern: role \"X\" does not exist\nfix: Use Docker connection: docker exec -it orchestkit-postgres-dev psql -U orchestkit_user -d orchestkit_dev\n\npattern: relation \"X\" does not exist\nfix: Check MCP postgres server connection string - may be connected to wrong database\n```\n\n## Related Skills\n- `ork:fix-issue`: Fix identified errors\n- `debug-investigator`: Debug error root causes\n## Adding New Rules\n\nRules are auto-generated by `analyze_errors.py` when patterns repeat 2+ times.\nFor manual rules, edit `.claude/rules/error_rules.json`:\n\n```json\n{\n  \"id\": \"custom-001\",\n  \"pattern\": \"your regex pattern\",\n  \"signature\": \"human readable signature\",\n  \"tool\": \"Bash\",\n  \"occurrence_count\": 1,\n  \"fix_suggestion\": \"How to fix this\"\n}\n```",
    "contentTruncated": false
  },
  "explore": {
    "content": "# Codebase Exploration\n\nMulti-angle codebase exploration using 3-5 parallel agents.\n\n## Quick Start\n\n```bash\n/ork:explore authentication\n```\n\n> **Opus 4.6**: Exploration agents use native adaptive thinking for deeper pattern recognition across large codebases.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify what the user wants to explore:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What aspect do you want to explore?\",\n    \"header\": \"Focus\",\n    \"options\": [\n      {\"label\": \"Full exploration (Recommended)\", \"description\": \"Code structure + data flow + architecture + health assessment\"},\n      {\"label\": \"Code structure only\", \"description\": \"Find files, classes, functions related to topic\"},\n      {\"label\": \"Data flow\", \"description\": \"Trace how data moves through the system\"},\n      {\"label\": \"Architecture patterns\", \"description\": \"Identify design patterns and integrations\"},\n      {\"label\": \"Quick search\", \"description\": \"Just find relevant files, skip deep analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full exploration**: All phases, all parallel agents\n- **Code structure only**: Skip phases 5-7 (health, dependencies, product)\n- **Data flow**: Focus phase 3 agents on data tracing\n- **Architecture patterns**: Focus on backend-system-architect agent\n- **Quick search**: Skip to phases 1-2 only, return file list\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh) or **Task tool** (star):\n\n1. `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Full exploration with 4+ agents → recommend **Agent Teams**; Quick/single-focus → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Discovery sharing | Lead synthesizes after all complete | Explorers share discoveries as they go |\n| Cross-referencing | Lead connects dots | Data flow explorer alerts architecture explorer |\n| Cost | ~150K tokens | ~400K tokens |\n| Best for | Quick/focused searches | Deep full-codebase exploration |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining exploration.\n\n---\n\n## Task Management (MANDATORY)\n\n**BEFORE doing ANYTHING else, create tasks to show progress:**\n\n```python\nTaskCreate(subject=\"Explore: {topic}\", description=\"Deep codebase exploration for {topic}\", activeForm=\"Exploring {topic}\")\nTaskCreate(subject=\"Initial file search\", activeForm=\"Searching files\")\nTaskCreate(subject=\"Check knowledge graph\", activeForm=\"Checking memory\")\nTaskCreate(subject=\"Launch exploration agents\", activeForm=\"Dispatching explorers\")\nTaskCreate(subject=\"Assess code health (0-10)\", activeForm=\"Assessing code health\")\nTaskCreate(subject=\"Map dependency hotspots\", activeForm=\"Mapping dependencies\")\nTaskCreate(subject=\"Add product perspective\", activeForm=\"Adding product context\")\nTaskCreate(subject=\"Generate explorat",
    "contentTruncated": true
  },
  "feedback": {
    "content": "# Feedback - Manage Learning System\n\nView and manage the OrchestKit feedback system that learns from your usage.\n\n## Overview\n\n- Checking feedback system status\n- Pausing/resuming learning\n- Resetting learned patterns\n- Exporting feedback data\n- Managing privacy settings\n- Enabling/disabling anonymous analytics sharing\n- Viewing privacy policy\n\n## Usage\n\n```\n/ork:feedback                    # Same as status\n/ork:feedback status             # Show current state\n/ork:feedback pause              # Pause learning\n/ork:feedback resume             # Resume learning\n/ork:feedback reset              # Clear learned patterns\n/ork:feedback export             # Export feedback data\n/ork:feedback settings           # Show/edit settings\n/ork:feedback opt-in             # Enable anonymous sharing\n/ork:feedback opt-out            # Disable anonymous sharing\n/ork:feedback privacy            # View privacy policy\n/ork:feedback export-analytics   # Export anonymous analytics for review\n```\n\n## Subcommands\n\n| Subcommand | Description |\n|------------|-------------|\n| `status` (default) | Show current feedback system state, learned patterns, agent performance |\n| `pause` | Temporarily pause learning without clearing data |\n| `resume` | Resume paused learning |\n| `reset` | Clear all learned patterns (requires \"RESET\" confirmation) |\n| `export` | Export all feedback data to `.claude/feedback/export-{date}.json` |\n| `settings` | Show/edit settings (usage: `/ork:feedback settings <key> <value>`) |\n| `opt-in` | Enable anonymous analytics sharing (GDPR-compliant consent) |\n| `opt-out` | Disable anonymous analytics sharing (revokes consent) |\n| `privacy` | Display the full privacy policy |\n| `export-analytics` | Export anonymous analytics to file for review before sharing |\n\n**Output:** Each subcommand displays formatted status, confirmation prompts, or exported file paths. See [Subcommand Reference](references/subcommand-reference.md) for detailed actions and expected output for each subcommand.\n\n## Consent and Security\n\nSee [Consent and Security Rules](rules/consent-and-security.md) for GDPR consent management, security restrictions, and analytics data sharing policies.\n\n## Related Skills\n\n- `ork:skill-evolution`: Evolve skills based on feedback\n\n## File Locations\n\nSee [File Locations](references/file-locations.md) for storage details.\n\nSee [Privacy Policy](references/privacy-policy.md) for full privacy documentation.",
    "contentTruncated": false
  },
  "fix-issue": {
    "content": "# Fix Issue\n\nSystematic issue resolution with hypothesis-based root cause analysis, similar issue detection, and prevention recommendations.\n\n## Quick Start\n\n```bash\n/ork:fix-issue 123\n/ork:fix-issue 456\n```\n\n> **Opus 4.6**: Root cause analysis uses native adaptive thinking. Dynamic token budgets scale with context window for thorough investigation.\n\n## Overview\n\nSystematic issue resolution with hypothesis-based root cause analysis. Uses parallel agents to investigate similar issues, form hypotheses, and validate fixes. Includes prevention recommendations and lessons learned capture to break recurring issue cycles.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify fix approach:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What approach for this fix?\",\n    \"header\": \"Approach\",\n    \"options\": [\n      {\"label\": \"Proper fix (Recommended)\", \"description\": \"Full RCA, tests, prevention recommendations\"},\n      {\"label\": \"Quick fix\", \"description\": \"Minimal fix to resolve the immediate issue\"},\n      {\"label\": \"Investigate first\", \"description\": \"Understand the issue before deciding on approach\"},\n      {\"label\": \"Hotfix\", \"description\": \"Emergency patch, minimal testing\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Proper fix**: All 11 phases, parallel agents for RCA\n- **Quick fix**: Skip phases 8-10 (prevention, runbook, lessons)\n- **Investigate first**: Only phases 1-4 (understand, search, hypotheses, analyze)\n- **Hotfix**: Minimal phases, skip similar issue search\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — RCA agents share hypotheses) or **Task tool** (star — all report to lead):\n\n1. `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Complex cross-cutting bugs (backend + frontend + tests involved) → recommend **Agent Teams**; Focused bugs (single domain) → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Hypothesis sharing | Lead relays between agents | Investigators share hypotheses in real-time |\n| Conflicting evidence | Lead resolves | Investigators debate directly |\n| Cost | ~250K tokens | ~600K tokens |\n| Best for | Single-domain bugs | Cross-cutting bugs with multiple hypotheses |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining investigation.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main fix task\nTaskCreate(\n  subject=\"Fix issue #{number}\",\n  description=\"Systematic issue resolution with hypothesis-based RCA\",\n  activeForm=\"Fixing issue #{number}\"\n)\n\n# Create subtasks for 11-phase process\nphases = [\"Understand issue\", \"Search similar issues\", \"Form hypotheses\",\n          \"Analyze root cause\", \"Design fix\", \"Implement fix\", \"Validate fix\",\n          \"Generate prevention\", \"Create runbook\", \"Capture lessons\", \"Commit and PR\"]\nfor phase",
    "contentTruncated": true
  },
  "git-workflow": {
    "content": "# Git Workflow\n\nComplete git workflow patterns: GitHub Flow branching, atomic commits, and recovery operations. Essential for maintaining clean, reviewable history.\n\n## Branch Naming Convention\n\n```bash\n# Feature branches (link to issue)\nissue/<number>-<brief-description>\nissue/123-add-user-auth\n\n# When no issue exists\nfeature/<description>\nfix/<description>\nhotfix/<description>\n```\n\n**Branch Rules:**\n1. `main` is always deployable\n2. Branch from `main`, PR back to `main`\n3. Branches live < 1-3 days\n4. Delete branch after merge\n\n---\n\n## Atomic Commit Checklist\n\n```\n[ ] Does ONE logical thing\n[ ] Leaves codebase working (tests pass)\n[ ] Message doesn't need \"and\" in title\n[ ] Can be reverted independently\n[ ] Title < 50 chars, body wraps at 72\n```\n\n### Interactive Staging\n\n```bash\n# Stage changes hunk-by-hunk\ngit add -p\n\n# Options:\n# y - stage this hunk\n# n - skip this hunk\n# s - split into smaller hunks\n# e - manually edit the hunk\n# q - quit\n\n# Review what's staged\ngit diff --staged    # What will be committed\ngit diff             # What won't be committed\n```\n\n### Commit Patterns\n\n```bash\n# Separate concerns\ngit add -p && git commit -m \"refactor: Extract database pool\"\ngit add -p && git commit -m \"feat(#456): Add query caching\"\n\n# Never combine unrelated changes\n# BAD:  \"feat: Add auth and fix formatting\"\n# GOOD: Two separate commits\n```\n\n---\n\n## Recovery Quick Reference\n\n### The Safety Net\n\n```bash\n# ALWAYS check reflog first - it has everything\ngit reflog\n\n# Shows ALL recent HEAD movements\n# Even \"deleted\" commits live here for 90 days\n```\n\n### Common Recovery Scenarios\n\n| Scenario | Not Pushed | Already Pushed |\n|----------|------------|----------------|\n| Undo commit | `git reset --soft HEAD~1` | `git revert HEAD` |\n| Wrong branch | cherry-pick + reset | cherry-pick + revert |\n| Lost commits | `git reset --hard HEAD@{N}` | N/A |\n| Bad rebase | `git rebase --abort` or reflog | reflog + force-with-lease |\n\n### Quick Recovery Commands\n\n```bash\n# Undo last commit, keep changes staged\ngit reset --soft HEAD~1\n\n# Find lost commits\ngit reflog | grep \"your message\"\n\n# Recover to previous state\ngit reset --hard HEAD@{1}\n\n# Safe force push (feature branches only)\ngit push --force-with-lease\n```\n\n---\n\n## Standard Workflow\n\n```bash\n# 1. Start fresh\ngit checkout main && git pull origin main\ngit checkout -b issue/123-my-feature\n\n# 2. Work with atomic commits\ngit add -p\ngit commit -m \"feat(#123): Add User model\"\n\n# 3. Stay updated\ngit fetch origin && git rebase origin/main\n\n# 4. Push and PR\ngit push -u origin issue/123-my-feature\ngh pr create --fill\n\n# 5. Cleanup after merge\ngit checkout main && git pull\ngit branch -d issue/123-my-feature\n```\n\n---\n\n## Anti-Patterns\n\n```\nAvoid:\n- Long-lived branches (> 1 week)\n- Merging main into feature (use rebase)\n- Direct commits to main\n- Force push to shared branches\n- Commits that need \"and\" in message\n- Committing broken code\n```\n\n---\n\n## Best Practices Summary\n\n1. **Branch from main** - Always start fresh\n2. **Stag",
    "contentTruncated": true
  },
  "github-operations": {
    "content": "# GitHub Operations\n\nComprehensive GitHub CLI (`gh`) operations for project management, from basic issue creation to advanced Projects v2 integration and milestone tracking via REST API.\n\n## Overview\n\n- Creating and managing GitHub issues and PRs\n- Working with GitHub Projects v2 custom fields\n- Managing milestones (sprints, releases) via REST API\n- Automating bulk operations with `gh`\n- Running GraphQL queries for complex operations\n\n---\n\n## Quick Reference\n\n### Issue Operations\n\n```bash\n# Create issue with labels and milestone\ngh issue create --title \"Bug: API returns 500\" --body \"...\" --label \"bug\" --milestone \"Sprint 5\"\n\n# List and filter issues\ngh issue list --state open --label \"backend\" --assignee @me\n\n# Edit issue metadata\ngh issue edit 123 --add-label \"high\" --milestone \"v2.0\"\n```\n\n### PR Operations\n\n```bash\n# Create PR with reviewers\ngh pr create --title \"feat: Add search\" --body \"...\" --base dev --reviewer @teammate\n\n# Watch CI status and auto-merge\ngh pr checks 456 --watch\ngh pr merge 456 --auto --squash --delete-branch\n\n# Resume a session linked to a PR (CC 2.1.27)\nclaude --from-pr 456           # Resume session with PR context (diff, comments, review status)\nclaude --from-pr https://github.com/org/repo/pull/456\n```\n\n> **Tip (CC 2.1.27):** Sessions created via `gh pr create` are automatically linked to the PR. Use `--from-pr` to resume with full PR context.\n\n### Milestone Operations (REST API)\n\n> **Footgun:** `gh issue edit --milestone` takes a **NAME** (string), not a number. The REST API uses a **NUMBER** (integer). Never pass a number to `--milestone`. See [CLI-vs-API Identifiers](references/cli-vs-api-identifiers.md).\n\n```bash\n# List milestones with progress\ngh api repos/:owner/:repo/milestones --jq '.[] | \"\\(.title): \\(.closed_issues)/\\(.open_issues + .closed_issues)\"'\n\n# Create milestone with due date\ngh api -X POST repos/:owner/:repo/milestones \\\n  -f title=\"Sprint 8\" -f due_on=\"2026-02-15T00:00:00Z\"\n\n# Close milestone (API uses number, not name)\nMILESTONE_NUM=$(gh api repos/:owner/:repo/milestones --jq '.[] | select(.title==\"Sprint 8\") | .number')\ngh api -X PATCH repos/:owner/:repo/milestones/$MILESTONE_NUM -f state=closed\n\n# Assign issues to milestone (CLI uses name, not number)\ngh issue edit 123 124 125 --milestone \"Sprint 8\"\n```\n\n### Projects v2 Operations\n\n```bash\n# Add issue to project\ngh project item-add 1 --owner @me --url https://github.com/org/repo/issues/123\n\n# Set custom field (requires GraphQL)\ngh api graphql -f query='mutation {...}' -f projectId=\"...\" -f itemId=\"...\"\n```\n\n---\n\n## JSON Output Patterns\n\n```bash\n# Get issue numbers matching criteria\ngh issue list --json number,labels --jq '[.[] | select(.labels[].name == \"bug\")] | .[].number'\n\n# PR summary with author\ngh pr list --json number,title,author --jq '.[] | \"\\(.number): \\(.title) by \\(.author.login)\"'\n\n# Find ready-to-merge PRs\ngh pr list --json number,reviewDecision,statusCheckRollupState \\\n  --jq '[.[] | select(.reviewDecision == \"APPROVED\" and .statusC",
    "contentTruncated": true
  },
  "golden-dataset": {
    "content": "# Golden Dataset\n\nComprehensive patterns for building, managing, and validating golden datasets for AI/ML evaluation. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n| -------- | ----- | ------ | ----------- |\n| [Curation](#curation) | 3 | HIGH | Content collection, annotation pipelines, diversity analysis |\n| [Management](#management) | 3 | HIGH | Versioning, backup/restore, CI/CD automation |\n| [Validation](#validation) | 3 | CRITICAL | Quality scoring, drift detection, regression testing |\n| [Add Workflow](#add-workflow) | 1 | HIGH | 9-phase curation, quality scoring, bias detection, silver-to-gold |\n\nTotal: 10 rules across 4 categories\n\n## Curation\n\nContent collection, multi-agent annotation, and diversity analysis for golden datasets.\n\n| Rule | File | Key Pattern |\n| ---- | ---- | ----------- |\n| Collection | `rules/curation-collection.md` | Content type classification, quality thresholds, duplicate prevention |\n| Annotation | `rules/curation-annotation.md` | Multi-agent pipeline, consensus aggregation, Langfuse tracing |\n| Diversity | `rules/curation-diversity.md` | Difficulty stratification, domain coverage, balance guidelines |\n\n## Management\n\nVersioning, storage, and CI/CD automation for golden datasets.\n\n| Rule | File | Key Pattern |\n| ---- | ---- | ----------- |\n| Versioning | `rules/management-versioning.md` | JSON backup format, embedding regeneration, disaster recovery |\n| Storage | `rules/management-storage.md` | Backup strategies, URL contract, data integrity checks |\n| CI Integration | `rules/management-ci.md` | GitHub Actions automation, pre-deployment validation, weekly backups |\n\n## Validation\n\nQuality scoring, drift detection, and regression testing for golden datasets.\n\n| Rule | File | Key Pattern |\n| ---- | ---- | ----------- |\n| Quality | `rules/validation-quality.md` | Schema validation, content quality, referential integrity |\n| Drift | `rules/validation-drift.md` | Duplicate detection, semantic similarity, coverage gap analysis |\n| Regression | `rules/validation-regression.md` | Difficulty distribution, pre-commit hooks, full dataset validation |\n\n## Add Workflow\n\nStructured workflow for adding new documents to the golden dataset.\n\n| Rule | File | Key Pattern |\n| ---- | ---- | ----------- |\n| Add Document | `rules/curation-add-workflow.md` | 9-phase curation, parallel quality analysis, bias detection |\n\n## Quick Start Example\n\n```python\nfrom app.shared.services.embeddings import embed_text\n\nasync def validate_before_add(document: dict, source_url_map: dict) -> dict:\n    \"\"\"Pre-addition validation for golden dataset entries.\"\"\"\n    errors = []\n\n    # 1. URL contract check\n    if \"placeholder\" in document.get(\"source_url\", \"\"):\n        errors.append(\"URL must be canonical, not a placeholder\")\n\n    # 2. Content quality\n    if len(document.get(\"title\", \"\")) < 10:\n        errors.append(\"Title too short (min 10 chars)\")\n\n    # 3. Tag requir",
    "contentTruncated": true
  },
  "help": {
    "content": "# OrchestKit Skill Directory\n\nInteractive guide to all user-invocable skills organized by category.\n\n## Quick Start\n\n```bash\n/ork:help           # Show all categories\n/ork:help build     # Show BUILD skills only\n/ork:help git       # Show GIT skills only\n```\n\n---\n\n## CRITICAL: Use AskUserQuestion for Category Selection\n\nWhen invoked without arguments, present categories interactively:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of task are you working on?\",\n    \"header\": \"Category\",\n    \"options\": [\n      {\"label\": \"BUILD\", \"description\": \"Implement features, brainstorm, verify\"},\n      {\"label\": \"GIT\", \"description\": \"Commits, PRs, issues, recovery\"},\n      {\"label\": \"MEMORY\", \"description\": \"Store decisions, search, sync context\"},\n      {\"label\": \"QUALITY\", \"description\": \"Assess code, health checks, golden datasets\"},\n      {\"label\": \"CONFIG\", \"description\": \"Configure OrchestKit, feedback, skill evolution\"},\n      {\"label\": \"EXPLORE\", \"description\": \"Explore codebase, coordinate worktrees\"},\n      {\"label\": \"MEDIA\", \"description\": \"Create demo videos\"},\n      {\"label\": \"Show all\", \"description\": \"List all 21 skills\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n---\n\n## Skill Categories\n\n### BUILD (3 skills)\n*Implement features and verify changes*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:implement` | Full-power feature implementation with parallel subagents | `/ork:implement user authentication` |\n| `/ork:brainstorming` | Design exploration with parallel agents | `/ork:brainstorming API design for payments` |\n| `/ork:verify` | Comprehensive verification with parallel test agents | `/ork:verify authentication flow` |\n\n---\n\n### GIT (5 skills)\n*Version control and GitHub operations*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:commit` | Creates commits with conventional format | `/ork:commit` |\n| `/ork:create-pr` | Create GitHub pull requests with validation | `/ork:create-pr` |\n| `/ork:review-pr` | PR review with parallel specialized agents | `/ork:review-pr 123` |\n| `/ork:fix-issue` | Fix GitHub issues with parallel analysis | `/ork:fix-issue 456` |\n| `/ork:git-recovery` | Recovery from git mistakes | `/ork:git-recovery` |\n\n---\n\n### MEMORY (2 skills)\n*Knowledge persistence and retrieval*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:remember` | Store decisions and patterns | `/ork:remember We use cursor pagination` |\n| `/ork:memory` | Search, load, sync, history, viz | `/ork:memory search pagination` |\n\n**Subcommands for `/ork:memory`:**\n- `search` - Search decisions and patterns\n- `load` - Load session context\n- `history` - View decision timeline\n- `viz` - Visualize knowledge graph\n\n---\n\n### QUALITY (4 skills)\n*Assessment and diagnostics*\n\n| Skill | Description | Example |\n|-------|-------------|---------|\n| `/ork:assess` | Rate quality 0-10 with pros/cons | `/ork:assess src/api/` |\n| `/ork:assess-complexity` | Assess ta",
    "contentTruncated": true
  },
  "i18n-date-patterns": {
    "content": "# i18n and Localization Patterns\n\n## Overview\n\nThis skill provides comprehensive guidance for implementing internationalization in React applications. It ensures ALL user-facing strings, date displays, currency, lists, and time calculations are locale-aware.\n\n**When to use this skill:**\n- Adding ANY user-facing text to components\n- Formatting dates, times, currency, lists, or ordinals\n- Implementing complex pluralization\n- Embedding React components in translated text\n- Supporting RTL languages (Hebrew, Arabic)\n\n**Bundled Resources:**\n- `references/formatting-utilities.md` - useFormatting hook API reference\n- `references/icu-messageformat.md` - ICU plural/select syntax\n- `references/trans-component.md` - Trans component for rich text\n- `checklists/i18n-checklist.md` - Implementation and review checklist\n- `examples/component-i18n-example.md` - Complete component example\n\n**Canonical Reference:** See `docs/i18n-standards.md` for the full i18n standards document.\n\n---\n\n## Core Patterns\n\n### 1. useTranslation Hook (All UI Strings)\n\nEvery visible string MUST use the translation function:\n\n```tsx\nimport { useTranslation } from 'react-i18next';\n\nfunction MyComponent() {\n  const { t } = useTranslation(['patients', 'common']);\n  \n  return (\n    <div>\n      <h1>{t('patients:title')}</h1>\n      <button>{t('common:actions.save')}</button>\n    </div>\n  );\n}\n```\n\n### 2. useFormatting Hook (Locale-Aware Data)\n\nAll locale-sensitive formatting MUST use the centralized hook:\n\n```tsx\nimport { useFormatting } from '@/hooks';\n\nfunction PriceDisplay({ amount, items }) {\n  const { formatILS, formatList, formatOrdinal } = useFormatting();\n  \n  return (\n    <div>\n      <p>Price: {formatILS(amount)}</p>        {/* ₪1,500.00 */}\n      <p>Items: {formatList(items)}</p>        {/* \"a, b, and c\" */}\n      <p>Position: {formatOrdinal(3)}</p>      {/* \"3rd\" */}\n    </div>\n  );\n}\n```\n\nSee `references/formatting-utilities.md` for the complete API.\n\n### 3. Date Formatting\n\nAll dates MUST use the centralized `@/lib/dates` library:\n\n```tsx\nimport { formatDate, formatDateShort, calculateWaitTime } from '@/lib/dates';\n\nconst date = formatDate(appointment.date);    // \"Jan 6, 2026\"\nconst waitTime = calculateWaitTime('09:30');  // \"15 min\"\n```\n\n### 4. ICU MessageFormat (Complex Plurals)\n\nUse ICU syntax in translation files for pluralization:\n\n```json\n{\n  \"patients\": \"{count, plural, =0 {No patients} one {# patient} other {# patients}}\"\n}\n```\n\n```tsx\nt('patients', { count: 5 })  // → \"5 patients\"\n```\n\nSee `references/icu-messageformat.md` for full syntax.\n\n### 5. Trans Component (Rich Text)\n\nFor embedded React components in translated text:\n\n```tsx\nimport { Trans } from 'react-i18next';\n\n<Trans\n  i18nKey=\"richText.welcome\"\n  values={{ name: userName }}\n  components={{ strong: <strong /> }}\n/>\n```\n\nSee `references/trans-component.md` for patterns.\n\n---\n\n## Translation File Structure\n\n```\nfrontend/src/i18n/locales/\n├── en/\n│   ├── common.json      # Shared: actions, status, time\n│   ├── p",
    "contentTruncated": true
  },
  "implement": {
    "content": "# Implement Feature\n\nParallel subagent execution for feature implementation with scope control and reflection.\n\n## Quick Start\n\n```bash\n/ork:implement user authentication\n/ork:implement real-time notifications\n/ork:implement dashboard analytics\n```\n\n---\n\n## Step 0: Project Context Discovery\n\n**BEFORE any work**, detect the project tier. This becomes the complexity ceiling for all patterns.\n\n### Auto-Detection\n\nScan codebase for signals: README keywords (take-home, interview), `.github/workflows/`, Dockerfile, terraform/, k8s/, CONTRIBUTING.md.\n\n### Tier Classification\n\n| Signal | Tier | Architecture Ceiling |\n|--------|------|---------------------|\n| README says \"take-home\", time limit | **1. Interview** ([details](references/interview-mode.md)) | Flat files, 8-15 files |\n| < 10 files, no CI | **2. Hackathon** | Single file if possible |\n| `.github/workflows/`, managed DB | **3. MVP** | MVC monolith |\n| Module boundaries, Redis, queues | **4. Growth** | Modular monolith, DI |\n| K8s/Terraform, monorepo | **5. Enterprise** | Hexagonal/DDD |\n| CONTRIBUTING.md, LICENSE | **6. Open Source** | Minimal API, exhaustive tests |\n\nIf confidence is low, use `AskUserQuestion` to ask the user. Pass detected tier to ALL downstream agents — see `scope-appropriate-architecture`.\n\n### Tier → Workflow Mapping\n\n| Tier | Phases | Max Agents |\n|------|--------|-----------|\n| 1. Interview | 1, 5 only | 2 |\n| 2. Hackathon | 5 only | 1 |\n| 3. MVP | 1-6, 9 | 3-4 |\n| 4-5. Growth/Enterprise | All 10 | 5-8 |\n| 6. Open Source | 1-7, 9-10 | 3-4 |\n\nUse `AskUserQuestion` to verify scope (full-stack / backend-only / frontend-only / prototype) and constraints.\n\n### Orchestration Mode\n\n- Agent Teams (mesh) when `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` and complexity >= 2.5\n- Task tool (star) otherwise; `ORCHESTKIT_FORCE_TASK_TOOL=1` to override\n- See [Orchestration Modes](references/orchestration-modes.md)\n\n### Worktree Isolation (CC 2.1.49)\n\nFor features touching 5+ files, offer worktree isolation to prevent conflicts with the main working tree:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"Isolate this feature in a git worktree?\",\n  \"header\": \"Isolation\",\n  \"options\": [\n    {\"label\": \"Yes — worktree (Recommended)\", \"description\": \"Creates isolated branch via EnterWorktree, merges back on completion\"},\n    {\"label\": \"No — work in-place\", \"description\": \"Edit files directly in current branch\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\nIf worktree selected:\n1. Call `EnterWorktree(name: \"feat-{slug}\")` to create isolated branch\n2. All agents work in the worktree directory\n3. On completion, merge back: `git checkout {original-branch} && git merge feat-{slug}`\n4. If merge conflicts arise, present diff to user via `AskUserQuestion`\n\nSee [Worktree Isolation Mode](references/worktree-isolation-mode.md) for detailed workflow.\n\n---\n\n## Task Management (MANDATORY)\n\nCreate tasks with `TaskCreate` BEFORE doing any work. Each phase gets a subtask. Update status with `TaskUpdate` as you prog",
    "contentTruncated": true
  },
  "issue-progress-tracking": {
    "content": "# Issue Progress Tracking\n\nCeremony guide for tracking GitHub issue progress via `gh` CLI. Ensures issues stay updated as work progresses from start to PR.\n\n## Quick Start\n\n```bash\n/ork:issue-progress-tracking 123\n```\n\n---\n\n## Phase 1: Start Work\n\nLabel the issue and create a feature branch:\n\n```bash\n# Move issue to in-progress\ngh issue edit $ARGUMENTS --add-label \"status:in-progress\" --remove-label \"status:todo\"\ngh issue comment $ARGUMENTS --body \"Starting work on this issue.\"\n\n# Create feature branch\ngit checkout -b issue/$ARGUMENTS-brief-description\n```\n\n**Rules:**\n- Always branch from the default branch (main/dev)\n- Branch name format: `issue/<number>-<brief-description>`\n- Never work directly on main/dev\n\n---\n\n## Phase 2: During Work — Small Commits\n\nCommit after each logical step, not at the end. Every commit references the issue:\n\n```bash\n# Each commit references the issue number\ngit commit -m \"feat(#$ARGUMENTS): add user model\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n```\n\n**Rules:**\n- One logical change per commit (atomic)\n- Reference issue in every commit: `type(#N): description`\n- Commit early and often — don't accumulate a massive diff\n\n---\n\n## Phase 3: Report Progress (Long Implementations)\n\nFor multi-step work, post progress updates:\n\n```bash\ngh issue comment $ARGUMENTS --body \"Progress update:\n- Completed: database schema, API endpoints\n- In progress: frontend components\n- Remaining: tests, documentation\"\n```\n\n**When to post updates:**\n- After completing a major milestone\n- When blocked or changing approach\n- Before stepping away from a long task\n\n---\n\n## Phase 4: Complete Work\n\nCreate the PR and update labels:\n\n```bash\n# Create PR that closes the issue\ngh pr create \\\n  --title \"feat(#$ARGUMENTS): brief description\" \\\n  --body \"Closes #$ARGUMENTS\n\n## Changes\n- Change 1\n- Change 2\n\n## Test Plan\n- [ ] Unit tests pass\n- [ ] Manual verification\"\n\n# Update issue status\ngh issue edit $ARGUMENTS --add-label \"status:in-review\" --remove-label \"status:in-progress\"\n```\n\n---\n\n## Rules Quick Reference\n\n| Rule | Impact | What It Covers |\n|------|--------|----------------|\n| [Start Work Ceremony](rules/start-work-ceremony.md) | HIGH | Branch creation, label updates, initial comment |\n| [Small Commits](rules/small-commits.md) | HIGH | Atomic commits referencing issues |\n\n**Total: 2 rules across 2 categories**\n\n---\n\n## Key Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Label prefix | `status:` | Consistent with GitHub conventions |\n| Branch format | `issue/<N>-desc` | Links branch to issue automatically |\n| Commit reference | `type(#N):` | Conventional commits + issue linking |\n| Progress comments | Manual | Keeps humans in the loop |\n\n---\n\n## Common Mistakes\n\n1. **Starting work without labeling** — team loses visibility into who is working on what\n2. **Giant commits at the end** — makes review harder and history useless for bisect\n3. **Forgetting to link PR to issue** — issue stays open after merge\n4. **Not",
    "contentTruncated": true
  },
  "langgraph": {
    "content": "# LangGraph Workflow Patterns\n\nComprehensive patterns for building production LangGraph workflows. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [State Management](#state-management) | 4 | CRITICAL | Designing workflow state schemas, accumulators, reducers |\n| [Routing & Branching](#routing--branching) | 3 | HIGH | Dynamic routing, retry loops, semantic routing |\n| [Parallel Execution](#parallel-execution) | 3 | HIGH | Fan-out/fan-in, map-reduce, concurrent agents |\n| [Supervisor Patterns](#supervisor-patterns) | 3 | HIGH | Central coordinators, round-robin, priority dispatch |\n| [Tool Calling](#tool-calling) | 4 | CRITICAL | Binding tools, ToolNode, dynamic selection, approvals |\n| [Checkpointing](#checkpointing) | 3 | HIGH | Persistence, recovery, cross-thread Store memory |\n| [Human-in-Loop](#human-in-loop) | 3 | MEDIUM | Approval gates, feedback loops, interrupt/resume |\n| [Streaming](#streaming) | 3 | MEDIUM | Real-time updates, token streaming, custom events |\n| [Subgraphs](#subgraphs) | 3 | MEDIUM | Modular composition, nested graphs, state mapping |\n| [Functional API](#functional-api) | 3 | MEDIUM | @entrypoint/@task decorators, migration from StateGraph |\n\n**Total: 32 rules across 10 categories**\n\n## State Management\n\nState schemas determine how data flows between nodes. Wrong schemas cause silent data loss.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| TypedDict State | `rules/state-typeddict.md` | `TypedDict` + `Annotated[list, add]` for accumulators |\n| Pydantic Validation | `rules/state-pydantic.md` | `BaseModel` at boundaries, TypedDict internally |\n| MessagesState | `rules/state-messages.md` | `MessagesState` or `add_messages` reducer |\n| Custom Reducers | `rules/state-reducers.md` | `Annotated[T, reducer_fn]` for merge/overwrite |\n\n## Routing & Branching\n\nControl flow between nodes. Always include END fallback to prevent hangs.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Conditional Edges | `rules/routing-conditional.md` | `add_conditional_edges` with explicit mapping |\n| Retry Loops | `rules/routing-retry-loops.md` | Loop-back edges with max retry counter |\n| Semantic Routing | `rules/routing-semantic.md` | Embedding similarity or `Command` API routing |\n\n## Parallel Execution\n\nRun independent nodes concurrently. Use `Annotated[list, add]` to accumulate results.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Fan-Out/Fan-In | `rules/parallel-fanout-fanin.md` | `Send` API for dynamic parallel branches |\n| Map-Reduce | `rules/parallel-map-reduce.md` | `asyncio.gather` + result aggregation |\n| Error Isolation | `rules/parallel-error-isolation.md` | `return_exceptions=True` + per-branch timeout |\n\n## Supervisor Patterns\n\nCentral coordinator routes to specialized workers. Workers return to supervisor.\n\n| Rule | File | Key Pattern |\n|------|------|-----",
    "contentTruncated": true
  },
  "llm-integration": {
    "content": "# LLM Integration\n\nPatterns for integrating LLMs into production applications: tool use, streaming, local inference, and fine-tuning. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Function Calling](#function-calling) | 3 | CRITICAL | Tool definitions, parallel execution, input validation |\n| [Streaming](#streaming) | 3 | HIGH | SSE endpoints, structured streaming, backpressure handling |\n| [Local Inference](#local-inference) | 3 | HIGH | Ollama setup, model selection, GPU optimization |\n| [Fine-Tuning](#fine-tuning) | 3 | HIGH | LoRA/QLoRA training, dataset preparation, evaluation |\n| [Context Optimization](#context-optimization) | 2 | HIGH | Window management, compression, caching, budget scaling |\n| [Evaluation](#evaluation) | 2 | HIGH | LLM-as-judge, RAGAS metrics, quality gates, benchmarks |\n| [Prompt Engineering](#prompt-engineering) | 2 | HIGH | CoT, few-shot, versioning, DSPy optimization |\n\n**Total: 18 rules across 7 categories**\n\n## Quick Start\n\n```python\n# Function calling: strict mode tool definition\ntools = [{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"search_documents\",\n        \"description\": \"Search knowledge base\",\n        \"strict\": True,\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n                \"limit\": {\"type\": \"integer\", \"description\": \"Max results\"}\n            },\n            \"required\": [\"query\", \"limit\"],\n            \"additionalProperties\": False\n        }\n    }\n}]\n```\n\n```python\n# Streaming: SSE endpoint with FastAPI\n@app.get(\"/chat/stream\")\nasync def stream_chat(prompt: str):\n    async def generate():\n        async for token in async_stream(prompt):\n            yield {\"event\": \"token\", \"data\": token}\n        yield {\"event\": \"done\", \"data\": \"\"}\n    return EventSourceResponse(generate())\n```\n\n```python\n# Local inference: Ollama with LangChain\nllm = ChatOllama(\n    model=\"deepseek-r1:70b\",\n    base_url=\"http://localhost:11434\",\n    temperature=0.0,\n    num_ctx=32768,\n)\n```\n\n```python\n# Fine-tuning: QLoRA with Unsloth\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/Meta-Llama-3.1-8B\",\n    max_seq_length=2048, load_in_4bit=True,\n)\nmodel = FastLanguageModel.get_peft_model(model, r=16, lora_alpha=32)\n```\n\n## Function Calling\n\nEnable LLMs to use external tools and return structured data. Use strict mode schemas (2026 best practice) for reliability. Limit to 5-15 tools per request, validate all inputs with Pydantic/Zod, and return errors as tool results.\n\n- `calling-tool-definition.md` -- Strict mode schemas, OpenAI/Anthropic formats, LangChain binding\n- `calling-parallel.md` -- Parallel tool execution, asyncio.gather, strict mode constraints\n- `calling-validation.md` -- Input validation, error handling, tool execution loops\n\n## Streaming\n\n",
    "contentTruncated": true
  },
  "mcp-patterns": {
    "content": "# MCP Patterns\n\nPatterns for building, composing, and securing Model Context Protocol servers. Based on the **2025-11-25 specification** — the latest stable release maintained by the [Agentic AI Foundation](https://agenticaifoundation.org/) (Linux Foundation), co-founded by Anthropic, Block, and OpenAI.\n\n> **Scaffolding a new server?** Use Anthropic's `mcp-builder` skill (`claude install anthropics/skills`) for project setup and evaluation creation. This skill focuses on **patterns, security, and advanced features** after initial setup.\n>\n> **Deploying to Cloudflare?** See the `building-mcp-server-on-cloudflare` skill for Workers-specific deployment patterns.\n\n## Decision Tree — Which Rule to Read\n\n```\nWhat are you building?\n│\n├── New MCP server\n│   ├── Setup & primitives ──────► rules/server-setup.md\n│   ├── Transport selection ─────► rules/server-transport.md\n│   └── Scaffolding ─────────────► mcp-builder skill (anthropics/skills)\n│\n├── Authentication & authorization\n│   └── OAuth 2.1 + OIDC ───────► rules/auth-oauth21.md\n│\n├── Advanced server features\n│   ├── Tool composition ────────► rules/advanced-composition.md\n│   ├── Resource caching ────────► rules/advanced-resources.md\n│   ├── Elicitation (user input) ► rules/elicitation.md\n│   ├── Sampling (agent loops) ──► rules/sampling-tools.md\n│   └── Interactive UI ──────────► rules/apps-ui.md\n│\n├── Client-side consumption\n│   └── Connecting to servers ───► rules/client-patterns.md\n│\n├── Security hardening\n│   ├── Prompt injection defense ► rules/security-injection.md\n│   └── Zero-trust & verification ► rules/security-hardening.md\n│\n├── Testing & debugging\n│   └── Inspector + unit tests ──► rules/testing-debugging.md\n│\n├── Discovery & ecosystem\n│   └── Registries & catalogs ──► rules/registry-discovery.md\n│\n└── Browser-native tools\n    └── WebMCP (W3C) ───────────► rules/webmcp-browser.md\n```\n\n## Quick Reference\n\n| Category | Rule | Impact | Key Pattern |\n|----------|------|--------|-------------|\n| **Server** | `server-setup.md` | HIGH | FastMCP lifespan, Tool/Resource/Prompt primitives |\n| **Server** | `server-transport.md` | HIGH | stdio for CLI, Streamable HTTP for production |\n| **Auth** | `auth-oauth21.md` | HIGH | PKCE, RFC 8707 resource indicators, token validation |\n| **Advanced** | `advanced-composition.md` | MEDIUM | Pipeline, parallel, and branching tool composition |\n| **Advanced** | `advanced-resources.md` | MEDIUM | Resource caching with TTL, LRU eviction, lifecycle |\n| **Advanced** | `elicitation.md` | MEDIUM | Server-initiated structured input from users |\n| **Advanced** | `sampling-tools.md` | MEDIUM | Server-side agent loops with tool calling |\n| **Advanced** | `apps-ui.md` | MEDIUM | Interactive UI via MCP Apps + @mcp-ui/* SDK |\n| **Client** | `client-patterns.md` | MEDIUM | TypeScript/Python MCP client connection patterns |\n| **Security** | `security-injection.md` | HIGH | Description sanitization, encoding normalization |\n| **Security** | `security-hardening.md` | HIGH | Zer",
    "contentTruncated": true
  },
  "memory": {
    "content": "# Memory - Read & Access Operations\n\nUnified read-side memory skill with subcommands for searching, loading, syncing, history, and visualization.\n\n## Usage\n\n```bash\n/ork:memory search <query>  # Search knowledge graph\n/ork:memory load             # Load context at session start\n/ork:memory history          # View decision timeline\n/ork:memory viz              # Visualize knowledge graph\n/ork:memory status           # Show memory system health\n```\n\n---\n\n## CRITICAL: Use AskUserQuestion When No Subcommand\n\nIf invoked without a subcommand, ask the user what they want:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What memory operation do you need?\",\n    \"header\": \"Operation\",\n    \"options\": [\n      {\"label\": \"search\", \"description\": \"Search decisions and patterns in knowledge graph\"},\n      {\"label\": \"load\", \"description\": \"Load relevant context for this session\"},\n      {\"label\": \"history\", \"description\": \"View decision timeline\"},\n      {\"label\": \"viz\", \"description\": \"Visualize knowledge graph as Mermaid\"},\n      {\"label\": \"status\", \"description\": \"Check memory system health\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n---\n\n## Subcommands\n\n### `search` - Search Knowledge Graph\n\nSearch past decisions, patterns, and entities from the knowledge graph.\n\n**Usage:**\n```bash\n/ork:memory search <query>                    # Search knowledge graph\n/ork:memory search --category <cat> <query>   # Filter by category\n/ork:memory search --limit <n> <query>        # Limit results (default: 10)\n/ork:memory search --agent <agent-id> <query> # Filter by agent scope\n/ork:memory search --global <query>           # Search cross-project best practices\n```\n\n**Flags:**\n\n| Flag | Behavior |\n|------|----------|\n| (default) | Search graph |\n| `--limit <n>` | Max results (default: 10) |\n| `--category <cat>` | Filter by category |\n| `--agent <agent-id>` | Filter results to a specific agent's memories |\n| `--global` | Search cross-project best practices |\n\n**Context-Aware Result Limits:**\n\nResult limits automatically adjust based on `context_window.used_percentage`:\n\n| Context Usage | Default Limit | Behavior |\n|---------------|---------------|----------|\n| 0-70% | 10 results | Full results with details |\n| 70-85% | 5 results | Reduced, summarized results |\n| >85% | 3 results | Minimal with \"more available\" hint |\n\n**Search Workflow:**\n\n1. Parse flags (--category, --limit, --agent, --global)\n2. Build filters from flags:\n   ```\n   Check for --category <cat> flag → metadata.category: \"<cat>\"\n   Check for --agent <agent-id> flag → agent_id: \"ork:{agent-id}\"\n   Check for --global flag → user_id: \"orchestkit-global-best-practices\"\n   ```\n3. Search knowledge graph via `mcp__memory__search_nodes`:\n   ```json\n   { \"query\": \"user's search query\" }\n   ```\n\n**Entity Types to Look For:**\n- `Technology`: Tools, frameworks, databases (pgvector, PostgreSQL, React)\n- `Agent`: OrchestKit agents (database-engineer, backend-system-architect)\n- `Pattern`: Named patterns (cursor-pag",
    "contentTruncated": true
  },
  "memory-fabric": {
    "content": "# Memory Fabric - Graph Orchestration\n\nKnowledge graph orchestration via mcp__memory__* for entity extraction, query parsing, deduplication, and cross-reference boosting.\n\n## Overview\n\n- Comprehensive memory retrieval from the knowledge graph\n- Cross-referencing entities within graph storage\n- Ensuring no relevant memories are missed\n- Building unified context from graph queries\n\n## Architecture Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Memory Fabric Layer                      │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│   ┌─────────────┐              ┌─────────────┐              │\n│   │   Query     │              │   Query     │              │\n│   │   Parser    │              │   Executor  │              │\n│   └──────┬──────┘              └──────┬──────┘              │\n│          │                            │                     │\n│          ▼                            ▼                     │\n│   ┌──────────────────────────────────────────────┐          │\n│   │            Graph Query Dispatch              │          │\n│   └──────────────────────┬───────────────────────┘          │\n│                          │                                  │\n│                ┌─────────▼──────────┐                       │\n│                │  mcp__memory__*    │                       │\n│                │  (Knowledge Graph) │                       │\n│                └─────────┬──────────┘                       │\n│                          │                                  │\n│                          ▼                                  │\n│        ┌─────────────────────────────────────────┐          │\n│        │        Result Normalizer                │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │     Deduplication Engine (>85% sim)     │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │  Cross-Reference Booster                │          │\n│        └─────────────────────┬───────────────────┘          │\n│                              │                              │\n│                              ▼                              │\n│        ┌─────────────────────────────────────────┐          │\n│        │  Final Ranking: recency × relevance     │          │\n│        │                 × source_authority      │          │\n│        └─────────────────────────────────────────┘          │\n│                                                             │\n└──────────────────────────",
    "contentTruncated": true
  },
  "monitoring-observability": {
    "content": "# Monitoring & Observability\n\nComprehensive patterns for infrastructure monitoring, LLM observability, and quality drift detection. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Infrastructure Monitoring](#infrastructure-monitoring) | 3 | CRITICAL | Prometheus metrics, Grafana dashboards, alerting rules |\n| [LLM Observability](#llm-observability) | 3 | HIGH | Langfuse tracing, cost tracking, evaluation scoring |\n| [Drift Detection](#drift-detection) | 3 | HIGH | Statistical drift, quality regression, drift alerting |\n| [Silent Failures](#silent-failures) | 3 | HIGH | Tool skipping, quality degradation, loop/token spike alerting |\n\n**Total: 12 rules across 4 categories**\n\n## Quick Start\n\n```python\n# Prometheus metrics with RED method\nfrom prometheus_client import Counter, Histogram\n\nhttp_requests = Counter('http_requests_total', 'Total requests', ['method', 'endpoint', 'status'])\nhttp_duration = Histogram('http_request_duration_seconds', 'Request latency',\n    buckets=[0.01, 0.05, 0.1, 0.5, 1, 2, 5])\n```\n\n```python\n# Langfuse LLM tracing\nfrom langfuse import observe, get_client\n\n@observe()\nasync def analyze_content(content: str):\n    get_client().update_current_trace(\n        user_id=\"user_123\", session_id=\"session_abc\",\n        tags=[\"production\", \"orchestkit\"],\n    )\n    return await llm.generate(content)\n```\n\n```python\n# PSI drift detection\nimport numpy as np\n\npsi_score = calculate_psi(baseline_scores, current_scores)\nif psi_score >= 0.25:\n    alert(\"Significant quality drift detected!\")\n```\n\n## Infrastructure Monitoring\n\nPrometheus metrics, Grafana dashboards, and alerting for application health.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Prometheus Metrics | `rules/monitoring-prometheus.md` | RED method, counters, histograms, cardinality |\n| Grafana Dashboards | `rules/monitoring-grafana.md` | Golden Signals, SLO/SLI, health checks |\n| Alerting Rules | `rules/monitoring-alerting.md` | Severity levels, grouping, escalation, fatigue prevention |\n\n## LLM Observability\n\nLangfuse-based tracing, cost tracking, and evaluation for LLM applications.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Langfuse Traces | `rules/llm-langfuse-traces.md` | @observe decorator, OTEL spans, agent graphs |\n| Cost Tracking | `rules/llm-cost-tracking.md` | Token usage, spend alerts, Metrics API |\n| Eval Scoring | `rules/llm-eval-scoring.md` | Custom scores, evaluator tracing, quality monitoring |\n\n## Drift Detection\n\nStatistical and quality drift detection for production LLM systems.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Statistical Drift | `rules/drift-statistical.md` | PSI, KS test, KL divergence, EWMA |\n| Quality Drift | `rules/drift-quality.md` | Score regression, baseline comparison, canary prompts |\n| Drift Alerting | `rules/drift-alerting.md` | Dynamic thresholds, cor",
    "contentTruncated": true
  },
  "multimodal-llm": {
    "content": "# Multimodal LLM Patterns\n\nIntegrate vision and audio capabilities from leading multimodal models. Covers image analysis, document understanding, real-time voice agents, speech-to-text, and text-to-speech.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Vision: Image Analysis](#vision-image-analysis) | 1 | HIGH | Image captioning, VQA, multi-image comparison, object detection |\n| [Vision: Document Understanding](#vision-document-understanding) | 1 | HIGH | OCR, chart/diagram analysis, PDF processing, table extraction |\n| [Vision: Model Selection](#vision-model-selection) | 1 | MEDIUM | Choosing provider, cost optimization, image size limits |\n| [Audio: Speech-to-Text](#audio-speech-to-text) | 1 | HIGH | Transcription, speaker diarization, long-form audio |\n| [Audio: Text-to-Speech](#audio-text-to-speech) | 1 | MEDIUM | Voice synthesis, expressive TTS, multi-speaker dialogue |\n| [Audio: Model Selection](#audio-model-selection) | 1 | MEDIUM | Real-time voice agents, provider comparison, pricing |\n\n**Total: 6 rules across 2 categories (Vision, Audio)**\n\n## Vision: Image Analysis\n\nSend images to multimodal LLMs for captioning, visual QA, and object detection. Always set `max_tokens` and resize images before encoding.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Image Analysis | `rules/vision-image-analysis.md` | Base64 encoding, multi-image, bounding boxes |\n\n## Vision: Document Understanding\n\nExtract structured data from documents, charts, and PDFs using vision models.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Document Vision | `rules/vision-document.md` | PDF page ranges, detail levels, OCR strategies |\n\n## Vision: Model Selection\n\nChoose the right vision provider based on accuracy, cost, and context window needs.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Vision Models | `rules/vision-models.md` | Provider comparison, token costs, image limits |\n\n## Audio: Speech-to-Text\n\nConvert audio to text with speaker diarization, timestamps, and sentiment analysis.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Speech-to-Text | `rules/audio-speech-to-text.md` | Gemini long-form, GPT-4o-Transcribe, AssemblyAI features |\n\n## Audio: Text-to-Speech\n\nGenerate natural speech from text with voice selection and expressive cues.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Text-to-Speech | `rules/audio-text-to-speech.md` | Gemini TTS, voice config, auditory cues |\n\n## Audio: Model Selection\n\nSelect the right audio/voice provider for real-time, transcription, or TTS use cases.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Audio Models | `rules/audio-models.md` | Real-time voice comparison, STT benchmarks, pricing |\n\n## Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| High accuracy vision | Claude Opus 4.6 or GPT-5 |\n| Long documents | Gemini 2.5 Pro (1M context) |\n| Cos",
    "contentTruncated": true
  },
  "performance": {
    "content": "# Performance\n\nComprehensive performance optimization patterns for frontend, backend, and LLM inference.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Core Web Vitals](#core-web-vitals) | 3 | CRITICAL | LCP, INP, CLS optimization with 2026 thresholds |\n| [Render Optimization](#render-optimization) | 3 | HIGH | React Compiler, memoization, virtualization |\n| [Lazy Loading](#lazy-loading) | 3 | HIGH | Code splitting, route splitting, preloading |\n| [Image Optimization](#image-optimization) | 3 | HIGH | Next.js Image, AVIF/WebP, responsive images |\n| [Profiling & Backend](#profiling--backend) | 3 | MEDIUM | React DevTools, py-spy, bundle analysis |\n| [LLM Inference](#llm-inference) | 3 | MEDIUM | vLLM, quantization, speculative decoding |\n| [Caching](#caching) | 2 | HIGH | Redis cache-aside, prompt caching, HTTP cache headers |\n| [Query & Data Fetching](#query--data-fetching) | 2 | HIGH | TanStack Query prefetching, optimistic updates, rollback |\n\n**Total: 22 rules across 8 categories**\n\n## Core Web Vitals\n\nGoogle's Core Web Vitals with 2026 stricter thresholds.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| LCP Optimization | `rules/cwv-lcp.md` | Preload hero, SSR, fetchpriority=\"high\" |\n| INP Optimization | `rules/cwv-inp.md` | scheduler.yield, useTransition, requestIdleCallback |\n| CLS Prevention | `rules/cwv-cls.md` | Explicit dimensions, aspect-ratio, font-display |\n\n### 2026 Thresholds\n\n| Metric | Current Good | 2026 Good |\n|--------|--------------|-----------|\n| LCP | <= 2.5s | <= 2.0s |\n| INP | <= 200ms | <= 150ms |\n| CLS | <= 0.1 | <= 0.08 |\n\n## Render Optimization\n\nReact render performance patterns for React 19+.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| React Compiler | `rules/render-compiler.md` | Auto-memoization, \"Memo\" badge verification |\n| Manual Memoization | `rules/render-memo.md` | useMemo/useCallback escape hatches, state colocation |\n| Virtualization | `rules/render-virtual.md` | TanStack Virtual for 100+ item lists |\n\n## Lazy Loading\n\nCode splitting and lazy loading with React.lazy and Suspense.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| React.lazy + Suspense | `rules/loading-lazy.md` | Component lazy loading, error boundaries |\n| Route Splitting | `rules/loading-splitting.md` | React Router 7.x, Vite manual chunks |\n| Preloading | `rules/loading-preload.md` | Prefetch on hover, modulepreload hints |\n\n## Image Optimization\n\nProduction image optimization for modern web applications.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Next.js Image | `rules/images-nextjs.md` | Image component, priority, blur placeholder |\n| Format Selection | `rules/images-formats.md` | AVIF/WebP, quality 75-85, picture element |\n| Responsive Images | `rules/images-responsive.md` | sizes prop, art direction, CDN loaders |\n\n## Profiling & Backend\n\nProfiling tools and backend optimization patterns.\n\n| Rule | File | ",
    "contentTruncated": true
  },
  "plan-viz": {
    "content": "# Plan Visualization\n\nRender planned changes as structured ASCII visualizations with risk analysis, execution order, and impact metrics. Every section answers a specific reviewer question.\n\n**Core principle:** Encode judgment into visualization, not decoration.\n\n```bash\n/ork:plan-viz                          # Auto-detect from current branch\n/ork:plan-viz billing module redesign  # Describe the plan\n/ork:plan-viz #234                     # Pull from GitHub issue\n```\n\n---\n\n## STEP 0: Detect or Clarify Plan Context\n\n**First**, attempt auto-detection by running `scripts/detect-plan-context.sh`:\n\n```bash\nbash \"$SKILL_DIR/scripts/detect-plan-context.sh\"\n```\n\nThis outputs branch name, issue number (if any), commit count, and file change summary.\n\n**If auto-detection finds a clear plan** (branch with commits diverging from main, or issue number in args), proceed to Step 1.\n\n**If ambiguous**, clarify with AskUserQuestion:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What should I visualize?\",\n    \"header\": \"Source\",\n    \"options\": [\n      {\"label\": \"Current branch changes (Recommended)\", \"description\": \"Auto-detect from git diff against main\"},\n      {\"label\": \"Describe the plan\", \"description\": \"I'll explain what I'm planning to change\"},\n      {\"label\": \"GitHub issue\", \"description\": \"Pull plan from a specific issue number\"},\n      {\"label\": \"Quick file diff only\", \"description\": \"Just show the change manifest, skip analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n---\n\n## STEP 1: Gather Data\n\nRun `scripts/analyze-impact.sh` for precise counts:\n\n```bash\nbash \"$SKILL_DIR/scripts/analyze-impact.sh\"\n```\n\nThis produces: files by action (add/modify/delete), line counts, test files affected, and dependency changes.\n\nFor architecture-level understanding, spawn an Explore agent on the affected directories:\n\n```python\nTask(\n  subagent_type=\"Explore\",\n  prompt=\"Explore the architecture of {affected_directories}. Return: component diagram, key data flows, health scores per module. Use the ascii-visualizer skill for diagrams.\",\n  model=\"haiku\"\n)\n```\n\n---\n\n## STEP 2: Render Tier 1 Header (Always)\n\nUse `assets/tier1-header.md` template. Fill in from gathered data. This is always shown first.\n\n```\nPLAN: {plan_name} ({issue_ref})  |  {phase_count} phases  |  {file_count} files  |  +{added} -{removed} lines\nRisk: {risk_level}  |  Confidence: {confidence}  |  Reversible until {last_safe_phase}\nBranch: {branch} -> {base_branch}\n\n[1] Changes  [2] Execution  [3] Risks  [4] Decisions  [5] Impact  [all]\n```\n\n**Risk level** = highest risk across all phases (LOW/MEDIUM/HIGH/CRITICAL).\n**Confidence** = LOW if >50% of changes are in untested code, MEDIUM if mixed, HIGH if well-tested paths.\n**Reversible until** = last phase before an irreversible operation (DROP, DELETE data, breaking API change).\n\n---\n\n## STEP 3: Ask Which Sections to Expand\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"Which sections to render?\",\n    \"header\": \"Sections\",\n    ",
    "contentTruncated": true
  },
  "product-frameworks": {
    "content": "# Product Frameworks\n\nComprehensive product management frameworks covering business analysis, market intelligence, strategy, prioritization, metrics, personas, requirements, and user research. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Business & Market](#business--market) | 4 | HIGH | ROI/NPV/IRR calculations, TCO analysis, TAM/SAM/SOM sizing, competitive landscape |\n| [Strategy & Prioritization](#strategy--prioritization) | 4 | HIGH | Value proposition canvas, go/no-go gates, RICE scoring, WSJF ranking |\n| [Metrics & OKRs](#metrics--okrs) | 4 | HIGH | OKR writing, KPI trees, leading/lagging indicators, instrumentation |\n| [Research & Requirements](#research--requirements) | 4 | HIGH | User personas, journey maps, interview guides, PRDs |\n\n**Total: 16 rules across 4 categories**\n\n## Quick Start\n\n```markdown\n## ROI Quick Calculation\nROI = (Net Benefits - Total Costs) / Total Costs x 100%\n\n## RICE Prioritization\nRICE Score = (Reach x Impact x Confidence) / Effort\n\n## OKR Structure\nObjective: Qualitative, inspiring goal\n  KR1: Quantitative measure (from X to Y)\n  KR2: Quantitative measure (from X to Y)\n\n## User Story Format\nAs a [persona], I want [goal], so that [benefit].\n```\n\n## Business & Market\n\nFinancial analysis and market intelligence frameworks for investment decisions.\n\n- **`business-roi`** -- ROI, NPV, IRR, payback period calculations with Python examples\n- **`business-cost-benefit`** -- TCO analysis, build vs buy comparison, sensitivity analysis\n- **`market-tam-sam-som`** -- TAM/SAM/SOM market sizing with top-down and bottom-up methods\n- **`market-competitive`** -- Porter's Five Forces, SWOT, competitive landscape mapping\n\n## Strategy & Prioritization\n\nStrategic decision frameworks and quantitative prioritization methods.\n\n- **`strategy-value-prop`** -- Value Proposition Canvas, JTBD framework, fit assessment\n- **`strategy-go-no-go`** -- Stage gate criteria, scoring template, decision thresholds\n- **`prioritize-rice`** -- RICE scoring with reach, impact, confidence, effort scales\n- **`prioritize-wsjf`** -- WSJF cost of delay, time criticality, MoSCoW method\n\n## Metrics & OKRs\n\nGoal-setting and measurement frameworks for metrics-driven teams.\n\n- **`metrics-okr`** -- OKR structure, writing objectives and key results, examples\n- **`metrics-kpi-trees`** -- Revenue and product health KPI trees, North Star metric\n- **`metrics-leading-lagging`** -- Leading vs lagging indicators, balanced dashboards\n- **`metrics-instrumentation`** -- Metric definition template, event naming, alerting\n\n## Research & Requirements\n\nUser research methods and requirements documentation patterns.\n\n- **`research-personas`** -- User persona template, empathy maps, persona examples\n- **`research-journey-mapping`** -- Customer journey maps, service blueprints, experience curves\n- **`research-user-interviews`** -- Interview guides, usab",
    "contentTruncated": true
  },
  "python-backend": {
    "content": "# Python Backend\n\nPatterns for building production Python backends with asyncio, FastAPI, SQLAlchemy 2.0, and connection pooling. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Asyncio](#asyncio) | 3 | HIGH | TaskGroup, structured concurrency, cancellation handling |\n| [FastAPI](#fastapi) | 3 | HIGH | Dependencies, middleware, background tasks |\n| [SQLAlchemy](#sqlalchemy) | 3 | HIGH | Async sessions, relationships, migrations |\n| [Pooling](#pooling) | 3 | MEDIUM | Database pools, HTTP sessions, tuning |\n\n**Total: 12 rules across 4 categories**\n\n## Quick Start\n\n```python\n# FastAPI + SQLAlchemy async session\nasync def get_db() -> AsyncGenerator[AsyncSession, None]:\n    async with async_session_factory() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n@router.get(\"/users/{user_id}\")\nasync def get_user(user_id: UUID, db: AsyncSession = Depends(get_db)):\n    result = await db.execute(select(User).where(User.id == user_id))\n    return result.scalar_one_or_none()\n```\n\n```python\n# Asyncio TaskGroup with timeout\nasync def fetch_all(urls: list[str]) -> list[dict]:\n    async with asyncio.timeout(30):\n        async with asyncio.TaskGroup() as tg:\n            tasks = [tg.create_task(fetch_url(url)) for url in urls]\n    return [t.result() for t in tasks]\n```\n\n## Asyncio\n\nModern Python asyncio patterns using structured concurrency, TaskGroup, and Python 3.11+ features.\n\n### Key Patterns\n\n- **TaskGroup** replaces `gather()` with structured concurrency and auto-cancellation\n- **`asyncio.timeout()`** context manager for composable timeouts\n- **Semaphore** for concurrency limiting (rate-limit HTTP requests)\n- **`except*`** with ExceptionGroup for handling multiple task failures\n- **`asyncio.to_thread()`** for bridging sync code to async\n\n### Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Task spawning | TaskGroup not gather() |\n| Timeouts | asyncio.timeout() context manager |\n| Concurrency limit | asyncio.Semaphore |\n| Sync bridge | asyncio.to_thread() |\n| Cancellation | Always re-raise CancelledError |\n\n## FastAPI\n\nProduction-ready FastAPI patterns for lifespan, dependencies, middleware, and settings.\n\n### Key Patterns\n\n- **Lifespan** with `asynccontextmanager` for startup/shutdown resource management\n- **Dependency injection** with class-based services and `Depends()`\n- **Middleware stack**: CORS -> RequestID -> Timing -> Logging\n- **Pydantic Settings** with `.env` and field validation\n- **Exception handlers** with RFC 7807 Problem Details\n\n### Key Decisions\n\n| Decision | Recommendation |\n|----------|----------------|\n| Lifespan | asynccontextmanager (not events) |\n| Dependencies | Class-based services with DI |\n| Settings | Pydantic Settings with .env |\n| Response | ORJSONResponse ",
    "contentTruncated": true
  },
  "quality-gates": {
    "content": "# Quality Gates\n\nThis skill teaches agents how to assess task complexity, enforce quality gates, and prevent wasted work on incomplete or poorly-defined tasks.\n\n**Key Principle:** Stop and clarify before proceeding with incomplete information. Better to ask questions than to waste cycles on the wrong solution.\n\n---\n\n## Overview\n\n### Auto-Activate Triggers\n- Receiving a new task assignment\n- Starting a complex feature implementation\n- Before allocating work in Squad mode\n- When requirements seem unclear or incomplete\n- After 3 failed attempts at the same task\n- When blocked by dependencies\n\n### Manual Activation\n- User asks for complexity assessment\n- Planning a multi-step project\n- Before committing to a timeline\n\n---\n\n## Core Concepts\n\n### Complexity Scoring (1-5 Scale)\n\n| Level | Files | Lines | Time | Characteristics |\n|-------|-------|-------|------|-----------------|\n| 1 - Trivial | 1 | < 50 | < 30 min | No deps, no unknowns |\n| 2 - Simple | 1-3 | 50-200 | 30 min - 2 hr | 0-1 deps, minimal unknowns |\n| 3 - Moderate | 3-10 | 200-500 | 2-8 hr | 2-3 deps, some unknowns |\n| 4 - Complex | 10-25 | 500-1500 | 8-24 hr | 4-6 deps, significant unknowns |\n| 5 - Very Complex | 25+ | 1500+ | 24+ hr | 7+ deps, many unknowns |\n\n**See:** `references/complexity-scoring.md` for detailed examples and assessment formulas.\n\n### Blocking Thresholds\n\n| Condition | Threshold | Action |\n|-----------|-----------|--------|\n| **YAGNI Gate** | **Justified ratio > 2.0** | **BLOCK with simpler alternatives** |\n| YAGNI Warning | Justified ratio 1.5-2.0 | WARN with simpler alternatives |\n| Critical Questions | > 3 unanswered | BLOCK |\n| Missing Dependencies | Any blocking | BLOCK |\n| Failed Attempts | >= 3 | BLOCK & ESCALATE |\n| Evidence Failure | 2 fix attempts | BLOCK |\n| Complexity Overflow | Level 4-5 no plan | BLOCK |\n\n**WARNING Conditions** (proceed with caution):\n- Level 3 complexity\n- 1-2 unanswered questions\n- 1-2 failed attempts\n\n**See:** `references/blocking-thresholds.md` for escalation protocols and decision logic.\n\n---\n\n## References\n\n### Complexity Scoring\n**See:** `references/complexity-scoring.md`\n\nKey topics covered:\n- Detailed Level 1-5 characteristics and examples\n- Quick assessment formula\n- Assessment checklist\n\n### Blocking Thresholds & Escalation\n**See:** `references/blocking-thresholds.md`\n\nKey topics covered:\n- BLOCKING vs WARNING conditions\n- Escalation protocol and message templates\n- Gate decision logic\n- Attempt tracking\n\n### Quality Gate Workflows\n**See:** `references/workflows.md`\n\nKey topics covered:\n- Pre-task gate validation workflow\n- Stuck detection and escalation workflow\n- Complexity breakdown workflow (Level 4-5)\n- Requirements completeness check\n\n### Gate Patterns\n**See:** `references/gate-patterns.md`\n\nKey topics covered:\n- Gate validation process templates\n- Integration with context system\n- Common pitfalls\n\n### LLM Quality Validation\n**See:** `references/llm-quality-validation.md`\n\nKey topics covered:\n- LLM-as-judge patterns\n- Qua",
    "contentTruncated": true
  },
  "rag-retrieval": {
    "content": "# RAG Retrieval\n\nComprehensive patterns for building production RAG systems. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Core RAG](#core-rag) | 4 | CRITICAL | Basic RAG, citations, hybrid search, context management |\n| [Embeddings](#embeddings) | 3 | HIGH | Model selection, chunking, batch/cache optimization |\n| [Contextual Retrieval](#contextual-retrieval) | 3 | HIGH | Context-prepending, hybrid BM25+vector, pipeline |\n| [HyDE](#hyde) | 3 | HIGH | Vocabulary mismatch, hypothetical document generation |\n| [Agentic RAG](#agentic-rag) | 4 | HIGH | Self-RAG, CRAG, knowledge graphs, adaptive routing |\n| [Multimodal RAG](#multimodal-rag) | 3 | MEDIUM | Image+text retrieval, PDF chunking, cross-modal search |\n| [Query Decomposition](#query-decomposition) | 3 | MEDIUM | Multi-concept queries, parallel retrieval, RRF fusion |\n| [Reranking](#reranking) | 3 | MEDIUM | Cross-encoder, LLM scoring, combined signals |\n| [PGVector](#pgvector) | 4 | HIGH | PostgreSQL hybrid search, HNSW indexes, schema design |\n\n**Total: 30 rules across 9 categories**\n\n## Core RAG\n\nFundamental patterns for retrieval, generation, and pipeline composition.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Basic RAG | `rules/core-basic-rag.md` | Retrieve + context + generate with citations |\n| Hybrid Search | `rules/core-hybrid-search.md` | RRF fusion (k=60) for semantic + keyword |\n| Context Management | `rules/core-context-management.md` | Token budgeting + sufficiency check |\n| Pipeline Composition | `rules/core-pipeline-composition.md` | Composable Decompose → HyDE → Retrieve → Rerank |\n\n## Embeddings\n\nEmbedding models, chunking strategies, and production optimization.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Models & API | `rules/embeddings-models.md` | Model selection, batch API, similarity |\n| Chunking | `rules/embeddings-chunking.md` | Semantic boundary splitting, 512 token sweet spot |\n| Advanced | `rules/embeddings-advanced.md` | Redis cache, Matryoshka dims, batch processing |\n\n## Contextual Retrieval\n\nAnthropic's context-prepending technique — 67% fewer retrieval failures.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Context Prepending | `rules/contextual-prepend.md` | LLM-generated context + prompt caching |\n| Hybrid Search | `rules/contextual-hybrid.md` | 40% BM25 / 60% vector weight split |\n| Complete Pipeline | `rules/contextual-pipeline.md` | End-to-end indexing + hybrid retrieval |\n\n## HyDE\n\nHypothetical Document Embeddings for bridging vocabulary gaps.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Generation | `rules/hyde-generation.md` | Embed hypothetical doc, not query |\n| Per-Concept | `rules/hyde-per-concept.md` | Parallel HyDE for multi-topic queries |\n| Fallback | `rules/hyde-fallback.md` | 2-3s timeout → direct embedding fallback |\n\n## Agentic RAG\n\nSe",
    "contentTruncated": true
  },
  "react-server-components-framework": {
    "content": "# React Server Components Framework\n\n## Overview\n\nReact Server Components (RSC) enable server-first rendering with client-side interactivity. This skill covers Next.js 16 App Router patterns, Server Components, Server Actions, and streaming.\n\n**When to use this skill:**\n- Building Next.js 16+ applications with the App Router\n- Designing component boundaries (Server vs Client Components)\n- Implementing data fetching with caching and revalidation\n- Creating mutations with Server Actions\n- Optimizing performance with streaming and Suspense\n\n---\n\n## Quick Reference\n\n### Server vs Client Components\n\n| Feature | Server Component | Client Component |\n|---------|-----------------|------------------|\n| Directive | None (default) | `'use client'` |\n| Async/await | Yes | No |\n| Hooks | No | Yes |\n| Browser APIs | No | Yes |\n| Database access | Yes | No |\n| Client JS bundle | Zero | Ships to client |\n\n**Key Rule**: Server Components can render Client Components, but Client Components cannot directly import Server Components (use `children` prop instead).\n\n### Data Fetching Quick Reference\n\n**Next.js 16 Cache Components (Recommended):**\n\n```tsx\nimport { cacheLife, cacheTag } from 'next/cache'\n\n// Cached component with duration\nasync function CachedProducts() {\n  'use cache'\n  cacheLife('hours')\n  cacheTag('products')\n  return await db.product.findMany()\n}\n\n// Invalidate cache\nimport { revalidateTag } from 'next/cache'\nrevalidateTag('products')\n```\n\n**Legacy Fetch Options (Next.js 15):**\n\n```tsx\n// Static (cached indefinitely)\nawait fetch(url, { cache: 'force-cache' })\n\n// Revalidate every 60 seconds\nawait fetch(url, { next: { revalidate: 60 } })\n\n// Always fresh\nawait fetch(url, { cache: 'no-store' })\n\n// Tag-based revalidation\nawait fetch(url, { next: { tags: ['posts'] } })\n```\n\n### Server Actions Quick Reference\n\n```tsx\n'use server'\n\nexport async function createPost(formData: FormData) {\n  const title = formData.get('title') as string\n  const post = await db.post.create({ data: { title } })\n  revalidatePath('/posts')\n  redirect(\"/posts/\" + post.id)\n}\n```\n\n### Async Params/SearchParams (Next.js 16)\n\nRoute parameters and search parameters are now Promises that must be awaited:\n\n```tsx\n// app/posts/[slug]/page.tsx\nexport default async function PostPage({\n  params,\n  searchParams,\n}: {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ page?: string }>\n}) {\n  const { slug } = await params\n  const { page } = await searchParams\n  return <Post slug={slug} page={page} />\n}\n```\n\n**Note:** Also applies to `layout.tsx`, `generateMetadata()`, and route handlers. See `references/nextjs-16-upgrade.md` for complete migration guide.\n\n---\n\n## References\n\n### Server Components\n**See: `references/server-components.md`**\n\nKey topics covered:\n- Async server components and direct database access\n- Data fetching patterns (parallel, sequential, cached)\n- Route segment config (dynamic, revalidate, PPR)\n- generateStaticParams for SSG\n- Error handling and composition patte",
    "contentTruncated": true
  },
  "release-checklist": {
    "content": "# Release Checklist\n\nSequential release gate for OrchestKit. Each step reports `[PASS]` or `[FAIL]`. Stop on first failure, suggest a fix, then continue after user confirmation.\n\nSee [references/release-flow.md](references/release-flow.md) for why the order matters and hotfix guidance.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Pre-Release Gates](#pre-release-gates) | 2 | CRITICAL | Before every release commit |\n| [Release Commit](#release-commit) | 2 | HIGH | Staging, committing, tagging, pushing |\n\n**Total: 4 rules across 2 categories**\n\n## Quick Start\n\n```bash\n# Run all pre-release gates in order (stop on first failure)\nnpm run build && npm test && npm run test:security && npm run typecheck\nbash src/skills/validate-counts/scripts/validate-counts.sh\ngit diff  # review before staging\n```\n\n## Pre-Release Gates\n\nMust all pass before writing any release commit. See `rules/gate-build-and-test.md` and `rules/gate-counts-and-diff.md`.\n\n| Step | Command | Rule File |\n|------|---------|-----------|\n| 1. Build | `npm run build` | `rules/gate-build-and-test.md` |\n| 2. Tests | `npm test` | `rules/gate-build-and-test.md` |\n| 3. Security | `npm run test:security` | `rules/gate-build-and-test.md` |\n| 4. TypeScript | `npm run typecheck` | `rules/gate-build-and-test.md` |\n| 5. Validate counts | `/validate-counts` | `rules/gate-counts-and-diff.md` |\n| 6. Diff review | `git diff` | `rules/gate-counts-and-diff.md` |\n\n## Release Commit\n\nSteps after all gates pass. See `rules/commit-staging.md` and `rules/commit-tag-push.md`.\n\n| Step | Action | Rule File |\n|------|--------|-----------|\n| 7. Changelog | Entry exists in `CHANGELOG.md` | `rules/commit-staging.md` |\n| 8. Version bump | `package.json` + `CLAUDE.md` both updated | `rules/commit-staging.md` |\n| 9. Stage files | `git add <specific files>` — never `-A` | `rules/commit-staging.md` |\n| 10. Commit | `release: vX.Y.Z` conventional format | `rules/commit-tag-push.md` |\n| 11. Tag | `git tag vX.Y.Z` | `rules/commit-tag-push.md` |\n| 12. Push | Run `scripts/pre-push-confirm.sh` — confirm first | `rules/commit-tag-push.md` |\n\n## Related Skills\n\n- `validate-counts` — Count consistency check (step 5 of this checklist)\n- `audit-skills` — Broader skill quality audit (run before major releases)\n- `checkpoint-resume` — Rate-limit-resilient pipelines for long release sessions\n\n## Common Mistakes\n\n1. Running `npm test` before `npm run build` — tests run against stale dist\n2. Using `git add -A` — accidentally stages secrets or unrelated in-progress work\n3. Forgetting to bump `CLAUDE.md` version alongside `package.json`\n4. Pushing without explicit user confirmation — irreversible on shared remotes\n5. Skipping security tests — non-negotiable, even for patch releases",
    "contentTruncated": false
  },
  "release-management": {
    "content": "# Release Management\n\nAutomate releases with `gh release`, semantic versioning, and changelog generation.\n\n## Quick Reference\n\n### Create Release\n\n```bash\n# Auto-generate notes from PRs\ngh release create v1.2.0 --generate-notes\n\n# With custom title\ngh release create v1.2.0 --title \"Version 1.2.0: Performance Update\" --generate-notes\n\n# Draft release (review before publishing)\ngh release create v1.2.0 --draft --generate-notes\n\n# Pre-release (beta, rc)\ngh release create v1.2.0-beta.1 --prerelease --generate-notes\n\n# With custom notes\ngh release create v1.2.0 --notes \"## Highlights\n- New auth system\n- 50% faster search\"\n\n# From notes file\ngh release create v1.2.0 --notes-file RELEASE_NOTES.md\n```\n\n### List & View Releases\n\n```bash\n# List all releases\ngh release list\n\n# View specific release\ngh release view v1.2.0\n\n# View in browser\ngh release view v1.2.0 --web\n\n# JSON output\ngh release list --json tagName,publishedAt,isPrerelease\n```\n\n### Verify Releases (gh CLI 2.86.0+)\n\n```bash\n# Verify release attestation (sigstore)\ngh release verify v1.2.0\n\n# Verify specific asset\ngh release verify-asset v1.2.0 ./dist/app.zip\n\n# Verify with custom trust policy\ngh release verify v1.2.0 --owner myorg\n```\n\n### Manage Releases\n\n```bash\n# Edit release\ngh release edit v1.2.0 --title \"New Title\" --notes \"Updated notes\"\n\n# Delete release\ngh release delete v1.2.0\n\n# Upload assets\ngh release upload v1.2.0 ./dist/app.zip ./dist/app.tar.gz\n```\n\n---\n\n## Semantic Versioning\n\n```text\nMAJOR.MINOR.PATCH\n  │     │     │\n  │     │     └── Bug fixes (backwards compatible)\n  │     └──────── New features (backwards compatible)\n  └────────────── Breaking changes\n\nExamples:\n  1.0.0 → 1.0.1  (patch: bug fix)\n  1.0.1 → 1.1.0  (minor: new feature)\n  1.1.0 → 2.0.0  (major: breaking change)\n\nPre-release:\n  2.0.0-alpha.1  (early testing)\n  2.0.0-beta.1   (feature complete)\n  2.0.0-rc.1     (release candidate)\n```\n\n---\n\n## Release Workflow\n\n### Standard Release\n\n```bash\n# 1. Ensure main is up to date\ngit checkout main\ngit pull origin main\n\n# 2. Determine version bump\n# Check commits since last release\ngh release view --json tagName -q .tagName  # Current: v1.2.3\ngit log v1.2.3..HEAD --oneline\n\n# 3. Create and push tag\ngit tag -a v1.3.0 -m \"Release v1.3.0\"\ngit push origin v1.3.0\n\n# 4. Create GitHub release\ngh release create v1.3.0 \\\n  --title \"v1.3.0: Feature Name\" \\\n  --generate-notes\n\n# 5. Close milestone if used\ngh api -X PATCH repos/:owner/:repo/milestones/5 -f state=closed\n```\n\n### Hotfix Release\n\n```bash\n# 1. Branch from release tag\ngit checkout -b hotfix/v1.2.4 v1.2.3\n\n# 2. Fix and commit\ngit commit -m \"fix: Critical security patch\"\n\n# 3. Tag and release\ngit tag -a v1.2.4 -m \"Hotfix: Security patch\"\ngit push origin v1.2.4\ngh release create v1.2.4 --title \"v1.2.4: Security Hotfix\" \\\n  --notes \"Critical security fix for authentication bypass\"\n\n# 4. Merge fix to main\ngit checkout main\ngit cherry-pick <commit-sha>\ngit push origin main\n```\n\n---\n\n## Changelog Generation\n\n### Auto-Generated (f",
    "contentTruncated": true
  },
  "remember": {
    "content": "# Remember - Store Decisions and Patterns\n\nStore important decisions, patterns, or context in the knowledge graph for future sessions. Supports tracking success/failure outcomes for building a Best Practice Library.\n\n## Architecture\n\nThe remember skill uses **knowledge graph** as storage:\n\n1. **Knowledge Graph**: Entity and relationship storage via `mcp__memory__create_entities` and `mcp__memory__create_relations` - FREE, zero-config, always works\n\n**Benefits:**\n- Zero configuration required - works out of the box\n- Explicit relationship queries (e.g., \"what does X use?\")\n- Cross-referencing between entities\n- No cloud dependency\n\n**Automatic Entity Extraction:**\n- Extracts capitalized terms as potential entities (PostgreSQL, React, pgvector)\n- Detects agent names (database-engineer, backend-system-architect)\n- Identifies pattern names (cursor-pagination, connection-pooling)\n- Recognizes \"X uses Y\", \"X recommends Y\", \"X requires Y\" relationship patterns\n\n## Usage\n\n### Store Decisions (Default)\n```\n/ork:remember <text>\n/ork:remember --category <category> <text>\n/ork:remember --success <text>     # Mark as successful pattern\n/ork:remember --failed <text>      # Mark as anti-pattern\n/ork:remember --success --category <category> <text>\n\n# Agent-scoped memory\n/ork:remember --agent <agent-id> <text>         # Store in agent-specific scope\n/ork:remember --global <text>                   # Store as cross-project best practice\n```\n\n## Flags\n\n| Flag | Behavior |\n|------|----------|\n| (default) | Write to graph |\n| `--success` | Mark as successful pattern |\n| `--failed` | Mark as anti-pattern |\n| `--category <cat>` | Set category |\n| `--agent <agent-id>` | Scope memory to a specific agent |\n| `--global` | Store as cross-project best practice |\n\n## Categories\n\n- `decision` - Why we chose X over Y (default)\n- `architecture` - System design and patterns\n- `pattern` - Code conventions and standards\n- `blocker` - Known issues and workarounds\n- `constraint` - Limitations and requirements\n- `preference` - User/team preferences\n- `pagination` - Pagination strategies\n- `database` - Database patterns\n- `authentication` - Auth approaches\n- `api` - API design patterns\n- `frontend` - Frontend patterns\n- `performance` - Performance optimizations\n\n## Outcome Flags\n\n- `--success` - Pattern that worked well (positive outcome)\n- `--failed` - Pattern that caused problems (anti-pattern)\n\nIf neither flag is provided, the memory is stored as neutral (informational).\n\n## Workflow\n\n### 1. Parse Input\n\n```\nCheck for --success flag → outcome: success\nCheck for --failed flag → outcome: failed\nCheck for --category <category> flag\nCheck for --agent <agent-id> flag → agent_id: \"ork:{agent-id}\"\nCheck for --global flag → use global user_id\nExtract the text to remember\nIf no category specified, auto-detect from content\n```\n\n### 2. Auto-Detect Category\n\n| Keywords | Category |\n|----------|----------|\n| chose, decided, selected | decision |\n| architecture, design, system | architecture |\n| p",
    "contentTruncated": true
  },
  "responsive-patterns": {
    "content": "# Responsive Patterns\n\nModern responsive design patterns using Container Queries, fluid typography, and mobile-first strategies for React applications (2026 best practices).\n\n## Overview\n\n- Building reusable components that adapt to their container\n- Implementing fluid typography that scales smoothly\n- Creating responsive layouts without media query overload\n- Building design system components for multiple contexts\n- Optimizing for variable container sizes (sidebars, modals, grids)\n\n## Core Concepts\n\n### Container Queries vs Media Queries\n\n| Feature | Media Queries | Container Queries |\n|---------|---------------|-------------------|\n| Responds to | Viewport size | Container size |\n| Component reuse | Context-dependent | Truly portable |\n| Browser support | Universal | Baseline 2023+ |\n| Use case | Page layouts | Component layouts |\n\n## CSS Patterns\n\n> See [rules/css-patterns.md](rules/css-patterns.md) for complete CSS examples: container queries, cqi/cqb units, fluid typography with clamp(), mobile-first breakpoints, CSS Grid patterns, and scroll-queries.\n\n**Key patterns covered:** Container Query basics, Container Query Units (cqi/cqb), Fluid Typography with clamp(), Container-Based Fluid Typography, Mobile-First Breakpoints, CSS Grid Responsive Patterns, Container Scroll-Queries (Chrome 126+).\n\n## React Patterns\n\n> See [rules/react-patterns.md](rules/react-patterns.md) for complete React examples: ResponsiveCard component, Tailwind container queries, useContainerQuery hook, and responsive images.\n\n**Key patterns covered:** Responsive Component with Container Queries, Tailwind CSS Container Queries, useContainerQuery Hook, Responsive Images Pattern.\n\n## Accessibility Considerations\n\n```css\n/* IMPORTANT: Always include rem in fluid typography */\n/* This ensures user font preferences are respected */\n\n/* ❌ WRONG: Viewport-only ignores user preferences */\nfont-size: 5vw;\n\n/* ✅ CORRECT: Include rem to respect user settings */\nfont-size: clamp(1rem, 0.5rem + 2vw, 2rem);\n\n/* User zooming must still work */\n@media (min-width: 768px) {\n  /* Use em/rem, not px, for breakpoints in ideal world */\n  /* (browsers still use px, but consider user zoom) */\n}\n```\n\n## Anti-Patterns (FORBIDDEN)\n\n```css\n/* ❌ NEVER: Use only viewport units for text */\n.title {\n  font-size: 5vw; /* Ignores user font preferences! */\n}\n\n/* ❌ NEVER: Use cqw/cqh (use cqi/cqb instead) */\n.card {\n  padding: 5cqw; /* cqw = container width, not logical */\n}\n/* ✅ CORRECT: Use logical units */\n.card {\n  padding: 5cqi; /* Container inline = logical direction */\n}\n\n/* ❌ NEVER: Container queries without container-type */\n@container (min-width: 400px) {\n  /* Won't work without container-type on parent! */\n}\n\n/* ❌ NEVER: Desktop-first media queries */\n.element {\n  display: grid;\n  grid-template-columns: repeat(4, 1fr);\n}\n@media (max-width: 768px) {\n  .element {\n    grid-template-columns: 1fr; /* Overriding = more CSS */\n  }\n}\n\n/* ❌ NEVER: Fixed pixel breakpoints for text */\n@media (min-width: 768p",
    "contentTruncated": true
  },
  "review-pr": {
    "content": "# Review PR\n\nDeep code review using 6-7 parallel specialized agents.\n\n## Quick Start\n\n```bash\n/ork:review-pr 123\n/ork:review-pr feature-branch\n```\n\n> **Opus 4.6**: Parallel agents use native adaptive thinking for deeper analysis. Complexity-aware routing matches agent model to review difficulty.\n\n---\n\n## Argument Resolution\n\nThe PR number or branch is passed as the skill argument. Resolve it immediately:\n\n```python\nPR_NUMBER = \"$ARGUMENTS\"  # e.g., \"123\" or \"feature-branch\"\n\n# If no argument provided, check environment\nif not PR_NUMBER:\n    PR_NUMBER = os.environ.get(\"ORCHESTKIT_PR_URL\", \"\").split(\"/\")[-1]\n\n# If still empty, detect from current branch\nif not PR_NUMBER:\n    PR_NUMBER = \"$(gh pr view --json number -q .number 2>/dev/null)\"\n```\n\nUse `PR_NUMBER` consistently in all subsequent commands and agent prompts.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify review focus:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What type of review do you need?\",\n    \"header\": \"Focus\",\n    \"options\": [\n      {\"label\": \"Full review (Recommended)\", \"description\": \"Security + code quality + tests + architecture\"},\n      {\"label\": \"Security focus\", \"description\": \"Prioritize security vulnerabilities\"},\n      {\"label\": \"Performance focus\", \"description\": \"Focus on performance implications\"},\n      {\"label\": \"Quick review\", \"description\": \"High-level review, skip deep analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full review**: All 6-7 parallel agents\n- **Security focus**: Prioritize security-auditor, reduce other agents\n- **Performance focus**: Add frontend-performance-engineer agent\n- **Quick review**: Single code-quality-reviewer agent only\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nSee [Orchestration Mode Selection](references/orchestration-mode-selection.md)\n\n---\n\n## CRITICAL: Task Management is MANDATORY (CC 2.1.16)\n\n**BEFORE doing ANYTHING else, create tasks to track progress:**\n\n```python\n# 1. Create main review task IMMEDIATELY\nTaskCreate(\n  subject=\"Review PR #{number}\",\n  description=\"Comprehensive code review with parallel agents\",\n  activeForm=\"Reviewing PR #{number}\"\n)\n\n# 2. Create subtasks for each phase\nTaskCreate(subject=\"Gather PR information\", activeForm=\"Gathering PR information\")\nTaskCreate(subject=\"Launch review agents\", activeForm=\"Dispatching review agents\")\nTaskCreate(subject=\"Run validation checks\", activeForm=\"Running validation checks\")\nTaskCreate(subject=\"Synthesize review\", activeForm=\"Synthesizing review\")\nTaskCreate(subject=\"Submit review\", activeForm=\"Submitting review\")\n\n# 3. Update status as you progress\nTaskUpdate(taskId=\"2\", status=\"in_progress\")  # When starting\nTaskUpdate(taskId=\"2\", status=\"completed\")    # When done\n```\n\n---\n\n## Phase 1: Gather PR Information\n\n```bash\n# Get PR details\ngh pr view $PR_NUMBER --json title,body,files,additions,deletions,commits,author\n\n# View the diff\ngh pr diff $PR_NUMBER\n\n# Chec",
    "contentTruncated": true
  },
  "scope-appropriate-architecture": {
    "content": "# Scope-Appropriate Architecture\n\nRight-size every architectural decision to the project's actual needs. Not every project needs hexagonal architecture, CQRS, or microservices.\n\n**Core principle:** Detect the project tier first, then constrain all downstream pattern choices to that tier's complexity ceiling.\n\n---\n\n## The 6 Project Tiers\n\n| Tier | LOC Ratio | Architecture | DB | Auth | Tests |\n|------|-----------|-------------|-----|------|-------|\n| **1. Interview/Take-home** | 1.0-1.3x | Flat files, no layers | SQLite / JSON | None or basic | 8-15 focused |\n| **2. Hackathon/Prototype** | 0.8-1.0x | Single file if possible | SQLite / in-memory | None | Zero |\n| **3. Startup/MVP** | 1.0-1.5x | MVC monolith | Managed Postgres | Clerk/Supabase Auth | Happy path + critical |\n| **4. Growth-stage** | 1.5-2.0x | Modular monolith | Postgres + Redis | Auth service | Unit + integration |\n| **5. Enterprise** | 2.0-3.0x | Hexagonal/DDD | Postgres + queues | OAuth2/SAML | Full pyramid |\n| **6. Open Source** | 1.2-1.8x | Minimal API surface | Configurable | Optional | Exhaustive public API |\n\n**LOC Ratio** = total lines / core business logic lines. Higher ratio = more infrastructure code relative to business value.\n\n---\n\n## Auto-Detection Signals\n\n| Signal | Tier Indicator |\n|--------|---------------|\n| README contains \"take-home\", \"assignment\", \"interview\" | Tier 1 |\n| Time limit mentioned (e.g., \"4 hours\", \"weekend\") | Tier 1-2 |\n| < 10 files, no CI, no Docker | Tier 1-2 |\n| `.github/workflows/` present | Tier 3+ |\n| `package.json` with 20+ dependencies | Tier 3+ |\n| Kubernetes/Terraform files present | Tier 4-5 |\n| `CONTRIBUTING.md`, `CODE_OF_CONDUCT.md` | Tier 6 |\n| Monorepo with `packages/` or `apps/` | Tier 4-5 |\n\n**When confidence is low:** Ask the user with `AskUserQuestion`.\n\n---\n\n## Pattern Appropriateness Matrix\n\n| Pattern | Interview | Hackathon | MVP | Growth | Enterprise |\n|---------|-----------|-----------|-----|--------|------------|\n| Repository pattern | OVERKILL | OVERKILL | BORDERLINE | APPROPRIATE | REQUIRED |\n| Event-driven arch | OVERKILL | OVERKILL | OVERKILL | SELECTIVE | APPROPRIATE |\n| DI containers | OVERKILL | OVERKILL | LIGHT ONLY | APPROPRIATE | REQUIRED |\n| Separate DTO layers | OVERKILL | OVERKILL | 1 EXTRA | 2 LAYERS | ALL LAYERS |\n| Microservices | NEVER | NEVER | NEVER | EXTRACT ONLY | APPROPRIATE |\n| CQRS | OVERKILL | OVERKILL | OVERKILL | OVERKILL | WHEN JUSTIFIED |\n| Hexagonal architecture | OVERKILL | OVERKILL | OVERKILL | BORDERLINE | APPROPRIATE |\n| DDD (bounded contexts) | OVERKILL | OVERKILL | OVERKILL | SELECTIVE | APPROPRIATE |\n| Message queues | OVERKILL | OVERKILL | BORDERLINE | APPROPRIATE | REQUIRED |\n| API versioning | SKIP | SKIP | URL prefix | Header-based | Full strategy |\n| Error handling | try/catch | console.log | Error boundary | Error service | RFC 9457 |\n| Logging | console.log | none | Structured JSON | Centralized | OpenTelemetry |\n\n**Rule of thumb:** If a pattern shows OVERKILL for the detected tie",
    "contentTruncated": true
  },
  "security-patterns": {
    "content": "# Security Patterns\n\nComprehensive security patterns for building hardened applications. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Authentication](#authentication) | 3 | CRITICAL | JWT tokens, OAuth 2.1/PKCE, RBAC/permissions |\n| [Defense-in-Depth](#defense-in-depth) | 2 | CRITICAL | Multi-layer security, zero-trust architecture |\n| [Input Validation](#input-validation) | 3 | HIGH | Schema validation (Zod/Pydantic), output encoding, file uploads |\n| [OWASP Top 10](#owasp-top-10) | 2 | CRITICAL | Injection prevention, broken authentication fixes |\n| [LLM Safety](#llm-safety) | 3 | HIGH | Prompt injection defense, output guardrails, content filtering |\n| [PII Masking](#pii-masking) | 2 | HIGH | PII detection/redaction with Presidio, Langfuse, LLM Guard |\n| [Scanning](#scanning) | 3 | HIGH | Dependency audit, SAST (Semgrep/Bandit), secret detection |\n| [Advanced Guardrails](#advanced-guardrails) | 2 | CRITICAL | NeMo/Guardrails AI validators, red-teaming, OWASP LLM |\n\n**Total: 20 rules across 8 categories**\n\n## Quick Start\n\n```python\n# Argon2id password hashing\nfrom argon2 import PasswordHasher\nph = PasswordHasher()\npassword_hash = ph.hash(password)\nph.verify(password_hash, password)\n```\n\n```python\n# JWT access token (15-min expiry)\nimport jwt\nfrom datetime import datetime, timedelta, timezone\npayload = {\n    'sub': user_id, 'type': 'access',\n    'exp': datetime.now(timezone.utc) + timedelta(minutes=15),\n}\ntoken = jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n```\n\n```typescript\n// Zod v4 schema validation\nimport { z } from 'zod';\nconst UserSchema = z.object({\n  email: z.string().email(),\n  name: z.string().min(2).max(100),\n  role: z.enum(['user', 'admin']).default('user'),\n});\nconst result = UserSchema.safeParse(req.body);\n```\n\n```python\n# PII masking with Langfuse\nimport re\nfrom langfuse import Langfuse\n\ndef mask_pii(data, **kwargs):\n    if isinstance(data, str):\n        data = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', '[REDACTED_EMAIL]', data)\n        data = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[REDACTED_SSN]', data)\n    return data\n\nlangfuse = Langfuse(mask=mask_pii)\n```\n\n## Authentication\n\nSecure authentication with OAuth 2.1, Passkeys/WebAuthn, JWT tokens, and role-based access control.\n\n| Rule | Description |\n|------|-------------|\n| `auth-jwt.md` | JWT creation, verification, expiry, refresh token rotation |\n| `auth-oauth.md` | OAuth 2.1 with PKCE, DPoP, Passkeys/WebAuthn |\n| `auth-rbac.md` | Role-based access control, permission decorators, MFA |\n\n**Key Decisions:** Argon2id > bcrypt | Access tokens 15 min | PKCE required | Passkeys > TOTP > SMS\n\n## Defense-in-Depth\n\nMulti-layer security architecture with no single point of failure.\n\n| Rule | Description |\n|------|-------------|\n| `defense-layers.md` | 8-layer security architecture (edge to observability) |\n| `defense-zero-trust.md` | Immutable request conte",
    "contentTruncated": true
  },
  "skill-evolution": {
    "content": "# Skill Evolution Manager\n\nEnables skills to automatically improve based on usage patterns, user edits, and success rates. Provides version control with safe rollback capability.\n\n## Overview\n\n- Reviewing how skills are performing across sessions\n- Identifying patterns in user edits to skill outputs\n- Applying learned improvements to skill templates\n- Rolling back problematic skill changes\n- Tracking skill version history and success rates\n\n## Quick Reference\n\n| Command | Description |\n|---------|-------------|\n| `/ork:skill-evolution` | Show evolution report for all skills |\n| `/ork:skill-evolution analyze <skill-id>` | Analyze specific skill patterns |\n| `/ork:skill-evolution evolve <skill-id>` | Review and apply suggestions |\n| `/ork:skill-evolution history <skill-id>` | Show version history |\n| `/ork:skill-evolution rollback <skill-id> <version>` | Restore previous version |\n\n---\n\n## How It Works\n\nThe skill evolution system operates in three phases:\n\n```\nCOLLECT                    ANALYZE                    ACT\n───────                    ───────                    ───\n┌─────────────┐           ┌─────────────┐           ┌─────────────┐\n│ PostTool    │──────────▶│ Evolution   │──────────▶│ /ork:skill  │\n│ Edit        │  patterns │ Analyzer    │ suggest   │ evolve      │\n│ Tracker     │           │ Engine      │           │ command     │\n└─────────────┘           └─────────────┘           └─────────────┘\n     │                          │                          │\n     ▼                          ▼                          ▼\n┌─────────────┐           ┌─────────────┐           ┌─────────────┐\n│ edit-       │           │ evolution-  │           │ versions/   │\n│ patterns.   │           │ registry.   │           │ snapshots   │\n│ jsonl       │           │ json        │           │             │\n└─────────────┘           └─────────────┘           └─────────────┘\n```\n\n### Edit Pattern Categories\n\nThe system tracks these common edit patterns:\n\n| Pattern | Description | Detection |\n|---------|-------------|-----------|\n| `add_pagination` | User adds pagination to API responses | `limit.*offset`, `cursor.*pagination` |\n| `add_rate_limiting` | User adds rate limiting | `rate.?limit`, `throttl` |\n| `add_error_handling` | User adds try/catch blocks | `try.*catch`, `except` |\n| `add_types` | User adds TypeScript/Python types | `interface\\s`, `Optional` |\n| `add_validation` | User adds input validation | `validate`, `Pydantic`, `Zod` |\n| `add_logging` | User adds logging/observability | `logger\\.`, `console.log` |\n| `remove_comments` | User removes generated comments | Pattern removal detection |\n| `add_auth_check` | User adds authentication checks | `@auth`, `@require_auth` |\n\n### Suggestion Thresholds\n\n| Threshold | Default | Description |\n|-----------|---------|-------------|\n| Minimum Samples | 5 | Uses before generating suggestions |\n| Add Threshold | 70% | Frequency to suggest adding pattern |\n| Auto-Apply Confidence | 85% | Confidence for auto-applicat",
    "contentTruncated": true
  },
  "task-dependency-patterns": {
    "content": "# Task Dependency Patterns\n\n## Overview\n\nClaude Code 2.1.16 introduces a native Task Management System with four tools:\n- **TaskCreate**: Create new tasks with subject, description, and activeForm\n- **TaskUpdate**: Update status (pending → in_progress → completed), set dependencies\n- **TaskGet**: Retrieve full task details including blockers\n- **TaskList**: View all tasks with status and dependency summary\n\nTasks enable structured work tracking, parallel coordination, and clear progress visibility.\n\n## When to Use\n\n- Breaking down complex multi-step implementations\n- Coordinating parallel work across multiple files\n- Tracking progress on large features\n- Managing dependencies between related changes\n- Providing visibility into work status\n\n## Key Patterns\n\n### 1. Task Decomposition\n\nBreak complex work into atomic, trackable units:\n\n```\nFeature: Add user authentication\n\nTasks:\n#1. [pending] Create User model\n#2. [pending] Add auth endpoints (blockedBy: #1)\n#3. [pending] Implement JWT tokens (blockedBy: #2)\n#4. [pending] Add auth middleware (blockedBy: #3)\n#5. [pending] Write integration tests (blockedBy: #4)\n```\n\n### 2. Dependency Chains\n\nUse `addBlockedBy` to create execution order:\n\n```json\n// Task #3 cannot start until #1 and #2 complete\n{\"taskId\": \"3\", \"addBlockedBy\": [\"1\", \"2\"]}\n```\n\n### 3. Status Workflow\n\n```\npending → in_progress → completed\n   ↓           ↓\n(unblocked)  (active)\n\npending/in_progress → deleted (CC 2.1.20)\n```\n\n- **pending**: Task created but not started\n- **in_progress**: Actively being worked on\n- **completed**: Work finished and verified\n- **deleted**: Task removed (CC 2.1.20) - permanently removes the task\n\n### Task Deletion (CC 2.1.20)\n\nCC 2.1.20 adds `status: \"deleted\"` to permanently remove tasks:\n\n```json\n// Delete a task\n{\"taskId\": \"3\", \"status\": \"deleted\"}\n```\n\n**When to delete:**\n- Orphaned tasks whose blockers have all failed\n- Tasks superseded by a different approach\n- Duplicate tasks created in error\n- Tasks from a cancelled pipeline\n\n**When NOT to delete:**\n- Tasks that might be retried later (keep as pending)\n- Tasks with useful history (mark completed instead)\n- Tasks blocked by in_progress work (wait for resolution)\n\n### 4. activeForm Pattern\n\nProvide present-continuous form for spinner display:\n\n| subject (imperative) | activeForm (continuous) |\n|---------------------|------------------------|\n| Run tests | Running tests |\n| Update schema | Updating schema |\n| Fix authentication | Fixing authentication |\n\n## Agent Teams (CC 2.1.33+)\n\nCC 2.1.33 introduces Agent Teams for multi-agent coordination with shared task lists and peer-to-peer messaging.\n\n### Team Workflow\n\n```\n1. TeamCreate(\"my-feature\")           → Creates team + shared task list\n2. TaskCreate(subject, description)    → Add tasks to shared list\n3. Task(prompt, team_name, name)       → Spawn teammates\n4. TaskUpdate(owner: \"teammate-name\")  → Assign tasks\n5. SendMessage(type: \"message\")        → Direct teammate communication\n6. SendMessage(type: \"s",
    "contentTruncated": true
  },
  "testing-patterns": {
    "content": "# Testing Patterns\n\nComprehensive patterns for building production test suites. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [Unit Testing](#unit-testing) | 3 | CRITICAL | AAA pattern, parametrized tests, fixture scoping |\n| [Integration Testing](#integration-testing) | 3 | HIGH | API endpoints, database tests, component integration |\n| [E2E Testing](#e2e-testing) | 3 | HIGH | Playwright, AI agents, page objects |\n| [Pytest Advanced](#pytest-advanced) | 3 | HIGH | Custom markers, xdist parallel, plugins |\n| [API Mocking](#api-mocking) | 3 | HIGH | MSW 2.x, VCR.py, LLM API mocking |\n| [Test Data](#test-data) | 3 | MEDIUM | Factories, fixtures, seeding/cleanup |\n| [Verification](#verification) | 3 | MEDIUM | Property-based, stateful, contract testing |\n| [Performance](#performance) | 3 | MEDIUM | k6 load tests, Locust, test types |\n| [LLM Testing](#llm-testing) | 3 | HIGH | Mock responses, DeepEval, structured output |\n| [Accessibility](#accessibility) | 3 | MEDIUM | jest-axe, Playwright axe, CI gates |\n| [Execution](#execution) | 2 | HIGH | Parallel runs (xdist/matrix), coverage thresholds/reporting |\n| [Validation](#validation) | 2 | HIGH | Zod schema testing, tRPC/Prisma end-to-end type safety |\n| [Evidence](#evidence) | 1 | MEDIUM | Task completion verification, exit codes, evidence protocol |\n\n**Total: 35 rules across 13 categories**\n\n## Quick Start\n\n```python\n# pytest: AAA pattern with fixtures\n@pytest.fixture\ndef user(db_session):\n    return UserFactory.create(role=\"admin\")\n\ndef test_user_can_publish(user, article):\n    result = article.publish(by=user)\n    assert result.status == \"published\"\n```\n\n```typescript\n// Vitest + MSW: API integration test\nconst server = setupServer(\n  http.get('/api/users', () => HttpResponse.json([{ id: 1 }]))\n);\ntest('renders user list', async () => {\n  render(<UserList />);\n  expect(await screen.findByText('User 1')).toBeInTheDocument();\n});\n```\n\n## Unit Testing\n\nIsolated business logic tests with fast, deterministic execution.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| AAA Pattern | `rules/unit-aaa-pattern.md` | Arrange-Act-Assert with Vitest/pytest |\n| Parametrized Tests | `rules/unit-parametrized.md` | `test.each`, `@pytest.mark.parametrize`, indirect |\n| Fixture Scoping | `rules/unit-fixture-scoping.md` | function/module/session scope selection |\n\n## Integration Testing\n\nComponent interactions, API endpoints, and database integration.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| API Testing | `rules/integration-api.md` | Supertest, httpx AsyncClient, FastAPI TestClient |\n| Database Testing | `rules/integration-database.md` | In-memory SQLite, transaction rollback, test containers |\n| Component Integration | `rules/integration-component.md` | React Testing Library, QueryClientProvider |\n\n## E2E Testing\n\nEnd-to-end validation with Playwrig",
    "contentTruncated": true
  },
  "ui-components": {
    "content": "# UI Components\n\nComprehensive patterns for building accessible UI component libraries with shadcn/ui and Radix Primitives. Covers CVA variants, OKLCH theming, cn() utility, component extension, asChild composition, dialog/menu patterns, and data-attribute styling. Each category has individual rule files in `rules/` loaded on-demand.\n\n## Quick Reference\n\n| Category | Rules | Impact | When to Use |\n|----------|-------|--------|-------------|\n| [shadcn/ui](#shadcnui) | 3 | HIGH | CVA variants, component customization, form patterns, data tables |\n| [Radix Primitives](#radix-primitives) | 3 | HIGH | Dialogs, polymorphic composition, data-attribute styling |\n| [Design System Tokens](#design-system-tokens) | 1 | HIGH | W3C tokens, OKLCH theming, Tailwind @theme, spacing scales |\n| [Design System Components](#design-system-components) | 1 | HIGH | Atomic design, CVA variants, accessibility, Storybook |\n| [Forms](#forms) | 2 | HIGH | React Hook Form v7, Zod validation, Server Actions |\n\n**Total: 10 rules across 4 categories**\n\n## Quick Start\n\n```tsx\n// CVA variant system with cn() utility\nimport { cva, type VariantProps } from 'class-variance-authority'\nimport { cn } from '@/lib/utils'\n\nconst buttonVariants = cva(\n  'inline-flex items-center justify-center rounded-md font-medium transition-colors',\n  {\n    variants: {\n      variant: {\n        default: 'bg-primary text-primary-foreground hover:bg-primary/90',\n        destructive: 'bg-destructive text-destructive-foreground',\n        outline: 'border border-input bg-background hover:bg-accent',\n        ghost: 'hover:bg-accent hover:text-accent-foreground',\n      },\n      size: {\n        default: 'h-10 px-4 py-2',\n        sm: 'h-9 px-3',\n        lg: 'h-11 px-8',\n      },\n    },\n    defaultVariants: { variant: 'default', size: 'default' },\n  }\n)\n```\n\n```tsx\n// Radix Dialog with asChild composition\nimport { Dialog } from 'radix-ui'\n\n<Dialog.Root>\n  <Dialog.Trigger asChild>\n    <Button>Open</Button>\n  </Dialog.Trigger>\n  <Dialog.Portal>\n    <Dialog.Overlay className=\"fixed inset-0 bg-black/50\" />\n    <Dialog.Content className=\"data-[state=open]:animate-in\">\n      <Dialog.Title>Title</Dialog.Title>\n      <Dialog.Description>Description</Dialog.Description>\n      <Dialog.Close>Close</Dialog.Close>\n    </Dialog.Content>\n  </Dialog.Portal>\n</Dialog.Root>\n```\n\n## shadcn/ui\n\nBeautifully designed, accessible components built on CVA variants, cn() utility, and OKLCH theming.\n\n| Rule | File | Key Pattern |\n|------|------|-------------|\n| Customization | `rules/shadcn-customization.md` | CVA variants, cn() utility, OKLCH theming, component extension |\n| Forms | `rules/shadcn-forms.md` | Form field wrappers, react-hook-form integration, validation |\n| Data Table | `rules/shadcn-data-table.md` | TanStack Table integration, column definitions, sorting/filtering |\n\n## Radix Primitives\n\nUnstyled, accessible React primitives for building high-quality design systems.\n\n| Rule | File | Key Pattern |\n|------|------|-------------",
    "contentTruncated": true
  },
  "upgrade-assessment": {
    "content": "# Upgrade Assessment\n\nEvaluate platform upgrade readiness for Claude model transitions, Claude Code version bumps, and OrchestKit plugin updates. Produces a structured JSON assessment report with a 0-10 readiness score across 6 dimensions.\n\n## When to Use\n\n- Before upgrading the Claude model (e.g., Sonnet 4 to Opus 4.6)\n- Before upgrading Claude Code to a new major/minor version\n- Before upgrading OrchestKit to a new major version\n- When evaluating whether a team environment is ready for a platform change\n- As part of release planning for model or platform migrations\n\n## Quick Start\n\n```bash\n/ork:upgrade-assessment           # Interactive assessment\n/ork:upgrade-assessment --json    # Machine-readable output\n```\n\n---\n\n## 6-Phase Workflow\n\n### Phase 0: Scope Definition\n\n**Tool:** `AskUserQuestion`\n\nDetermine the assessment scope before scanning. Ask the user:\n\n> What type of upgrade are you assessing?\n> 1. **Full platform** - Model + CC version + OrchestKit (comprehensive)\n> 2. **Model only** - Switching Claude model (e.g., Sonnet 4.5 to Opus 4.6)\n> 3. **CC version only** - Claude Code version bump (e.g., 2.1.32 to 2.1.33)\n> 4. **OrchestKit only** - Plugin version upgrade (e.g., 5.x to 6.x)\n\nRecord the scope and target versions. If the user does not specify target versions, research the latest available in Phase 2.\n\n---\n\n### Phase 1: Detection\n\n**Tools:** `Bash`, `Read`, `Grep`, `Glob`\n\nRun precondition checks and environment detection. See [Detection Checks](rules/detection-checks.md) for verification scripts and expected output format.\n\n---\n\n### Phase 2: Research\n\n**Tools:** `WebSearch`, `WebFetch`\n\nResearch the target versions for new capabilities and breaking changes:\n\n1. **Model changes:** Search for target model capabilities, breaking changes, new tool support\n2. **CC version changes:** Search for changelog, new hook types, skill format changes, deprecated fields\n3. **OrchestKit changes:** Read CHANGELOG.md, identify new/removed/renamed skills, hook migration needs\n\n**Research queries:**\n```\n\"Claude {target_model} capabilities release notes\"\n\"Claude Code {target_version} changelog breaking changes\"\n\"Claude {target_model} vs {current_model} differences\"\n```\n\n---\n\n### Phase 3: Codebase Scan\n\n**Tools:** `Grep`, `Glob`, `Read`\n\nScan the codebase for patterns affected by the upgrade. See [Codebase Scan Patterns](rules/codebase-scan-patterns.md) for grep patterns and severity classification.\n\n---\n\n### Phase 4: Scoring\n\nRate readiness 0-10 across 6 dimensions using the scoring rubric from `platform-upgrade-knowledge`. See [Scoring Rubric](references/scoring-rubric.md) for per-dimension thresholds, weights, and score interpretation.\n\n---\n\n### Phase 5: Recommendations\n\nGenerate prioritized action items based on Phase 3 findings and Phase 4 scores. See [Recommendation Format](references/recommendation-format.md) for priority assignment algorithm, effort estimation, and recommendation structure.\n\n---\n\n## Output Format\n\nThe assessment produces a structu",
    "contentTruncated": true
  },
  "validate-counts": {
    "content": "# Validate Counts\n\nChecks that hook, skill, and agent counts are consistent across all authoritative sources in OrchestKit. Outputs a comparison table and flags drift with precise file references.\n\n## Quick Start\n\n```bash\n# Full validation: counts src/ vs CLAUDE.md and manifests (run from repo root)\nbash src/skills/validate-counts/scripts/validate-counts.sh\n\n# Just get raw counts from src/\nbash src/skills/validate-counts/scripts/count-all.sh\n```\n\n## Rules\n\n| Category | Rule | Impact | Key Pattern |\n|----------|------|--------|-------------|\n| Count Sources | `rules/sources-authoritative.md` | HIGH | Filesystem is authoritative; derived sources must match |\n| Drift Detection | `rules/drift-reporting.md` | HIGH | Comparison table + flag with file:field references |\n\n**Total: 2 rules across 2 categories**\n\n## Workflow\n\n1. Run `scripts/validate-counts.sh` for full validation (counts + drift comparison), or `scripts/count-all.sh` for raw counts only\n2. Read `CLAUDE.md` — extract counts from Project Overview and Version section\n3. Read `manifests/ork.json` and `manifests/orkl.json` — check skill/agent/hook array lengths\n4. Build the comparison table (see `rules/drift-reporting.md` for format)\n5. Flag any mismatches with file + field references; otherwise output \"All counts consistent.\"\n\n## References\n\n- [Count Locations](references/count-locations.md) — Where every count lives and why drift happens\n\n## Related Skills\n\n- `release-checklist` — Uses validate-counts as step 5 of the release gate\n- `doctor` — Broader health check that includes count validation\n- `audit-skills` — Quality audit for skill structure and completeness\n\n## Common Mistakes\n\n1. Counting from `plugins/` instead of `src/` — plugins/ may be empty after an interrupted build\n2. Flagging `orkl` vs `ork` skill differences as drift — `orkl` intentionally excludes some skills\n3. Forgetting the hook breakdown: global + agent-scoped + skill-scoped must sum to total",
    "contentTruncated": false
  },
  "verify": {
    "content": "# Verify Feature\n\nComprehensive verification using parallel specialized agents with nuanced grading (0-10 scale) and improvement suggestions.\n\n## Quick Start\n\n```bash\n/ork:verify authentication flow\n/ork:verify user profile feature\n/ork:verify --scope=backend database migrations\n```\n\n> **Opus 4.6**: Agents use native adaptive thinking (no MCP sequential-thinking needed). Extended 128K output supports comprehensive verification reports.\n\n---\n\n## STEP 0: Verify User Intent with AskUserQuestion\n\n**BEFORE creating tasks**, clarify verification scope:\n\n```python\nAskUserQuestion(\n  questions=[{\n    \"question\": \"What scope for this verification?\",\n    \"header\": \"Scope\",\n    \"options\": [\n      {\"label\": \"Full verification (Recommended)\", \"description\": \"All tests + security + code quality + grades\"},\n      {\"label\": \"Tests only\", \"description\": \"Run unit + integration + e2e tests\"},\n      {\"label\": \"Security audit\", \"description\": \"Focus on security vulnerabilities\"},\n      {\"label\": \"Code quality\", \"description\": \"Lint, types, complexity analysis\"},\n      {\"label\": \"Quick check\", \"description\": \"Just run tests, skip detailed analysis\"}\n    ],\n    \"multiSelect\": false\n  }]\n)\n```\n\n**Based on answer, adjust workflow:**\n- **Full verification**: All 8 phases, all 5 parallel agents\n- **Tests only**: Skip phases 2 (security), 5 (UI/UX analysis)\n- **Security audit**: Focus on security-auditor agent\n- **Code quality**: Focus on code-quality-reviewer agent\n- **Quick check**: Run tests only, skip grading and suggestions\n\n---\n\n## STEP 0b: Select Orchestration Mode\n\nChoose **Agent Teams** (mesh — verifiers share findings) or **Task tool** (star — all report to lead):\n\n1. `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` → **Agent Teams mode**\n2. Agent Teams unavailable → **Task tool mode** (default)\n3. Otherwise: Full verification with cross-domain concerns → recommend **Agent Teams**; Single-scope verification → **Task tool**\n\n| Aspect | Task Tool | Agent Teams |\n|--------|-----------|-------------|\n| Finding correlation | Lead cross-references scores | Agents discuss overlapping concerns |\n| Security + test overlap | Independent scoring | security-auditor alerts test-generator about gaps |\n| Cost | ~200K tokens | ~500K tokens |\n| Best for | Focused verification | Full-stack verification with 5 agents |\n\n> **Fallback:** If Agent Teams encounters issues, fall back to Task tool for remaining verification.\n\n---\n\n## Task Management (CC 2.1.16)\n\n```python\n# Create main verification task\nTaskCreate(\n  subject=\"Verify [feature-name] implementation\",\n  description=\"Comprehensive verification with nuanced grading\",\n  activeForm=\"Verifying [feature-name] implementation\"\n)\n\n# Create subtasks for 8-phase process\nphases = [\"Run code quality checks\", \"Execute security audit\",\n          \"Verify test coverage\", \"Validate API\", \"Check UI/UX\",\n          \"Calculate grades\", \"Generate suggestions\", \"Compile report\"]\nfor phase in phases:\n    TaskCreate(subject=phase, activeForm=f\"{phase}ing\")\n`",
    "contentTruncated": true
  },
  "vite-advanced": {
    "content": "# Vite Advanced Patterns\n\nAdvanced configuration for Vite 7+ including Environment API.\n\n## Vite 7 Environment API (Key 2026 Feature)\n\nMulti-environment support is now first-class:\n\n```typescript\nimport { defineConfig } from 'vite'\n\nexport default defineConfig({\n  environments: {\n    // Browser client\n    client: {\n      build: {\n        outDir: 'dist/client',\n        manifest: true,\n      },\n    },\n    // Node.js SSR\n    ssr: {\n      build: {\n        outDir: 'dist/server',\n        target: 'node20',\n      },\n    },\n    // Edge runtime (Cloudflare, etc.)\n    edge: {\n      resolve: {\n        noExternal: true,\n        conditions: ['edge', 'worker'],\n      },\n      build: {\n        outDir: 'dist/edge',\n      },\n    },\n  },\n})\n```\n\n**Key Changes:**\n- Environments have their own module graph\n- Plugins access `this.environment` in hooks\n- `createBuilder` API for coordinated builds\n- Node.js 20.19+ or 22.12+ required\n\n## Plugin Development\n\nBasic plugin structure:\n\n```typescript\nexport function myPlugin(): Plugin {\n  return {\n    name: 'my-plugin',\n\n    // Called once when config is resolved\n    configResolved(config) {\n      // Access resolved config\n    },\n\n    // Transform individual modules\n    transform(code, id) {\n      // this.environment available in Vite 7+\n      if (id.endsWith('.special')) {\n        return { code: transformCode(code) }\n      }\n    },\n\n    // Virtual modules\n    resolveId(id) {\n      if (id === 'virtual:my-module') {\n        return '\\0virtual:my-module'\n      }\n    },\n    load(id) {\n      if (id === '\\0virtual:my-module') {\n        return 'export const value = \"generated\"'\n      }\n    },\n  }\n}\n```\n\n## SSR Configuration\n\nDevelopment (middleware mode):\n\n```typescript\nimport { createServer } from 'vite'\n\nconst vite = await createServer({\n  server: { middlewareMode: true },\n  appType: 'custom',\n})\n\napp.use('*', async (req, res) => {\n  const url = req.originalUrl\n  let template = fs.readFileSync('index.html', 'utf-8')\n  template = await vite.transformIndexHtml(url, template)\n\n  const { render } = await vite.ssrLoadModule('/src/entry-server.tsx')\n  const html = template.replace('<!--outlet-->', await render(url))\n\n  res.send(html)\n})\n```\n\nProduction build scripts:\n\n```json\n{\n  \"scripts\": {\n    \"build:client\": \"vite build --outDir dist/client\",\n    \"build:server\": \"vite build --outDir dist/server --ssr src/entry-server.tsx\"\n  }\n}\n```\n\n## Build Optimization\n\n```typescript\nexport default defineConfig({\n  build: {\n    target: 'baseline-widely-available', // Vite 7 default\n    sourcemap: false,\n    rollupOptions: {\n      output: {\n        manualChunks: {\n          vendor: ['react', 'react-dom'],\n          router: ['react-router-dom'],\n        },\n      },\n    },\n  },\n})\n```\n\n## Quick Reference\n\n| Feature | Vite 7 Status |\n|---------|---------------|\n| Environment API | Stable |\n| ESM-only distribution | Default |\n| Node.js requirement | 20.19+ or 22.12+ |\n| `buildApp` hook | New for plugins |\n| `createBuilder` | Multi-env builds |\n\n## Vite",
    "contentTruncated": true
  },
  "web-research-workflow": {
    "content": "# Web Research Workflow\n\nUnified approach for web content research that automatically selects the right tool for each situation.\n\n## Quick Decision Tree\n\n```\nURL to research\n     │\n     ▼\n┌─────────────────┐\n│ 1. Try WebFetch │ ← Fast, free, no overhead\n│    (always try) │\n└─────────────────┘\n     │\nContent OK? ──Yes──► Parse and return\n     │\n     No (empty/partial/<500 chars)\n     │\n     ▼\n┌───────────────────────┐\n│ 2. TAVILY_API_KEY set?│\n└───────────────────────┘\n     │          │\n    Yes         No ──► Skip to step 3\n     │\n     ▼\n┌───────────────────────────┐\n│ Tavily search/extract/    │ ← Raw markdown, batch URLs\n│ crawl/research            │\n└───────────────────────────┘\n     │\nContent OK? ──Yes──► Parse and return\n     │\n     No (JS-rendered/auth-required)\n     │\n     ▼\n┌─────────────────────┐\n│ 3. Use agent-browser │ ← Full browser, last resort\n└─────────────────────┘\n     │\n├─ SPA (react/vue/angular) ──► wait --load networkidle\n├─ Login required ──► auth flow + state save\n├─ Dynamic content ──► wait --text \"Expected\"\n└─ Multi-page ──► crawl pattern\n```\n\n## Tavily Enhanced Research\n\nWhen `TAVILY_API_KEY` is set, Tavily provides a powerful middle tier between WebFetch and agent-browser. It returns raw markdown content, supports batch URL extraction, and offers semantic search with relevance scoring. If `TAVILY_API_KEY` is not set, the 3-tier tree collapses to 2-tier (WebFetch → agent-browser) automatically.\n\nSee [Tool Selection](rules/tool-selection.md) for when-to-use-what tables, escalation heuristics, SPA detection patterns, and cost awareness.\n\nSee [Tavily API Reference](references/tavily-api.md) for Search, Extract, Map, Crawl, and Research endpoint examples and options.\n\n## Browser Patterns\n\nFor content requiring JavaScript rendering, authentication, or multi-page crawling, fall back to agent-browser.\n\nSee [Browser Patterns](rules/browser-patterns.md) for auto-fallback, authentication flow, multi-page research patterns, best practices, and troubleshooting.\n\n## Competitive Monitoring\n\nTrack competitor websites for changes in pricing, features, positioning, and content.\n\nSee [Competitor Page Monitoring](rules/monitoring-competitor.md) for snapshot capture, structured data extraction, and change classification.\n\nSee [Change Detection & Discovery](rules/monitoring-change-detection.md) for diff detection, structured comparison, Tavily site discovery, and CI automation.\n\n### Change Classification\n\n| Severity | Examples | Action |\n|----------|----------|--------|\n| Critical | Price increase/decrease, major feature change | Immediate alert |\n| High | New feature added, feature removed | Review required |\n| Medium | Copy changes, positioning shift | Note for analysis |\n| Low | Typos, minor styling | Log only |\n\n## Integration with Agents\n\nThis skill is used by:\n- `web-research-analyst` - Primary user\n- `market-intelligence` - Competitor research\n- `product-strategist` - Deep competitive analysis\n- `ux-researcher` - Design system capture\n-",
    "contentTruncated": true
  },
  "worktree-coordination": {
    "content": "# Worktree Coordination Skill\n\n> **CC 2.1.47 Worktree Fixes:** Claude Code 2.1.47 resolved three critical worktree issues: skills/agents not discovered in worktrees, background tasks failing in worktrees, and Windows worktree session matching. Worktrees are now first-class citizens — no workarounds needed.\n\n> **Agent Teams (CC 2.1.33+):** When `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` is set, native Agent Teams provides built-in teammate lifecycle management, peer-to-peer messaging, and shared task lists. This skill's custom file locking and coordination registry are superseded by Teams' native coordination. Use this skill only for **non-Teams worktree scenarios** (e.g., multiple independent Claude Code sessions without a shared team).\n\n## Native Worktree Support (CC 2.1.49)\n\nCC 2.1.49 added native worktree creation via the `EnterWorktree` tool and `--worktree (-w)` CLI flag:\n\n```bash\n# CLI flag — creates worktree and switches session into it\nclaude --worktree          # auto-named worktree\nclaude -w my-feature       # named worktree\n\n# Tool — available to agents and skills\nEnterWorktree(name=\"my-feature\")  # creates .claude/worktrees/my-feature/\n```\n\n**Key behaviors:**\n- Worktrees are created inside `.claude/worktrees/` with a new branch based on HEAD\n- On session exit, user is prompted to keep or remove the worktree\n- Skills, agents, and hooks are fully discovered in worktrees (fixed in CC 2.1.47)\n\n> **When to use native vs this skill:** Use `EnterWorktree` for single-session isolation (quick feature branches). Use this skill's coordination registry for **multi-session** scenarios where multiple Claude instances need file locking and decision sharing.\n\n## Commands\n\n### /worktree-status\nShow status of all active Claude Code instances.\n\n**Usage:** `/worktree-status [--json] [--clean]`\n\n**Actions:**\n1. Run `cc-worktree-status` to see all active instances\n2. Check for stale instances (no heartbeat > 5 min)\n3. View file locks across all instances\n\n**Output includes:**\n- Instance ID and branch\n- Current task (if set)\n- Health status (ACTIVE/STALE)\n- Files locked by each instance\n\n### /worktree-claim <file-path>\nExplicitly lock a file for this instance.\n\n**Usage:** `/worktree-claim src/auth/login.ts`\n\n**Actions:**\n1. Check if file is already locked\n2. If locked by another instance, show who holds it\n3. If available, acquire lock\n\n### /worktree-release <file-path>\nRelease lock on a file.\n\n**Usage:** `/worktree-release src/auth/login.ts`\n\n### /worktree-sync\nSync shared context and check for conflicts.\n\n**Usage:** `/worktree-sync [--check-conflicts] [--pull-decisions]`\n\n**Actions:**\n1. `--check-conflicts`: Run merge-tree against other active branches\n2. `--pull-decisions`: Show recent architectural decisions from other instances\n\n### /worktree-decision <decision>\nLog an architectural decision visible to all instances.\n\n**Usage:** `/worktree-decision \"Using Passport.js for OAuth\" --rationale \"Better middleware support\"`\n\n## Automatic Behaviors\n\n### File Lo",
    "contentTruncated": true
  },
  "zustand-patterns": {
    "content": "# Zustand Patterns\n\nModern state management with Zustand 5.x - lightweight, TypeScript-first, no boilerplate.\n\n## Overview\n\n- Global state without Redux complexity\n- Shared state across components without prop drilling\n- Persisted state with localStorage/sessionStorage\n- Computed/derived state with selectors\n- State that needs middleware (logging, devtools, persistence)\n\n## Core Patterns\n\n### 1. Basic Store with TypeScript\n\n```typescript\nimport { create } from 'zustand';\n\ninterface BearState {\n  bears: number;\n  increase: (by: number) => void;\n  reset: () => void;\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by })),\n  reset: () => set({ bears: 0 }),\n}));\n```\n\n### 2. Slices Pattern (Modular Stores)\n\n```typescript\nimport { create, StateCreator } from 'zustand';\n\n// Auth slice\ninterface AuthSlice {\n  user: User | null;\n  login: (user: User) => void;\n  logout: () => void;\n}\n\nconst createAuthSlice: StateCreator<AuthSlice & CartSlice, [], [], AuthSlice> = (set) => ({\n  user: null,\n  login: (user) => set({ user }),\n  logout: () => set({ user: null }),\n});\n\n// Cart slice\ninterface CartSlice {\n  items: CartItem[];\n  addItem: (item: CartItem) => void;\n  clearCart: () => void;\n}\n\nconst createCartSlice: StateCreator<AuthSlice & CartSlice, [], [], CartSlice> = (set) => ({\n  items: [],\n  addItem: (item) => set((state) => ({ items: [...state.items, item] })),\n  clearCart: () => set({ items: [] }),\n});\n\n// Combined store\nconst useStore = create<AuthSlice & CartSlice>()((...a) => ({\n  ...createAuthSlice(...a),\n  ...createCartSlice(...a),\n}));\n```\n\n### 3. Immer Middleware (Immutable Updates)\n\n```typescript\nimport { create } from 'zustand';\nimport { immer } from 'zustand/middleware/immer';\n\ninterface TodoState {\n  todos: Todo[];\n  addTodo: (text: string) => void;\n  toggleTodo: (id: string) => void;\n  updateNested: (id: string, subtaskId: string, done: boolean) => void;\n}\n\nconst useTodoStore = create<TodoState>()(\n  immer((set) => ({\n    todos: [],\n    addTodo: (text) =>\n      set((state) => {\n        state.todos.push({ id: crypto.randomUUID(), text, done: false });\n      }),\n    toggleTodo: (id) =>\n      set((state) => {\n        const todo = state.todos.find((t) => t.id === id);\n        if (todo) todo.done = !todo.done;\n      }),\n    updateNested: (id, subtaskId, done) =>\n      set((state) => {\n        const todo = state.todos.find((t) => t.id === id);\n        const subtask = todo?.subtasks?.find((s) => s.id === subtaskId);\n        if (subtask) subtask.done = done;\n      }),\n  }))\n);\n```\n\n### 4. Persist Middleware\n\n```typescript\nimport { create } from 'zustand';\nimport { persist, createJSONStorage } from 'zustand/middleware';\n\ninterface SettingsState {\n  theme: 'light' | 'dark';\n  language: string;\n  setTheme: (theme: 'light' | 'dark') => void;\n}\n\nconst useSettingsStore = create<SettingsState>()(\n  persist(\n    (set) => ({\n      theme: 'light',\n      language: 'en',\n      setTheme: (t",
    "contentTruncated": true
  }
};
